"""
Tushare æ¶¨è·Œåœä¸é¾™å¤´å› å­æ¨¡å—

è¯¥æ¨¡å—æä¾›æ¶¨è·Œåœåˆ†æå’Œé¾™å¤´å› å­è®¡ç®—åŠŸèƒ½ï¼Œä½œä¸º Mixin ç±»æ··å…¥ä¸»ç±»ã€‚

Features
--------
- æ¶¨è·Œåœåˆ—è¡¨è·å–
- å¯äº¤æ˜“æ€§æ£€æŸ¥
- è¿æ¿å¤©æ•°è®¡ç®—
- é¾™å¤´ä¿¡ä»°å› å­
- é€€å¸‚è‚¡ç¥¨ä¿¡æ¯
"""

from typing import Optional, List
from datetime import datetime, timedelta
import logging

import pandas as pd
import numpy as np

logger = logging.getLogger(__name__)


class TushareLimitFactorMixin:
    """
    Tushare æ¶¨è·Œåœ/é¾™å¤´å› å­ Mixin
    
    æä¾›æ¶¨è·Œåœåˆ†æå’Œé¾™å¤´å› å­è®¡ç®—åŠŸèƒ½ï¼Œéœ€è¦ä¸ TushareDataLoaderBase ç»„åˆä½¿ç”¨ã€‚
    """
    
    def fetch_limit_list(
        self,
        trade_date: str,
        limit_type: str = "U"
    ) -> Optional[pd.DataFrame]:
        """
        è·å–æ¯æ—¥æ¶¨è·Œåœè‚¡ç¥¨åˆ—è¡¨
        
        Parameters
        ----------
        trade_date : str
            äº¤æ˜“æ—¥æœŸï¼Œæ ¼å¼ YYYYMMDD æˆ– YYYY-MM-DD
        limit_type : str
            æ¶¨è·Œåœç±»å‹ï¼š"U"(æ¶¨åœ) æˆ– "D"(è·Œåœ)
        
        Returns
        -------
        Optional[pd.DataFrame]
            æ¶¨è·Œåœæ˜ç»†æ•°æ®
        """
        trade_date = trade_date.replace("-", "")
        
        logger.debug(f"è·å–æ¶¨è·Œåœåˆ—è¡¨: {trade_date}, ç±»å‹={limit_type}")
        
        cache_file = self.cache_dir / f"limit_list_{trade_date}_{limit_type}.parquet"
        if cache_file.exists():
            try:
                df = pd.read_parquet(cache_file)
                if not df.empty:
                    logger.debug(f"ä»ç¼“å­˜åŠ è½½æ¶¨è·Œåœåˆ—è¡¨: {trade_date}, {len(df)} æ¡")
                    return df
            except Exception:
                pass
        
        df = self._fetch_with_retry(
            self.pro.limit_list,
            trade_date=trade_date,
            limit_type=limit_type
        )
        
        if df is None or df.empty:
            logger.debug(f"è·å–æ¶¨è·Œåœåˆ—è¡¨å¤±è´¥: {trade_date}")
            return None
        
        df["stock_code"] = df["ts_code"].str[:6]
        
        rename_map = {"open_times": "open_num"}
        df = df.rename(columns=rename_map)
        
        if "open_num" not in df.columns:
            df["open_num"] = 0
        if "fc_ratio" not in df.columns and "fd_amount" in df.columns and "amount" in df.columns:
            df["fc_ratio"] = df["fd_amount"] / df["amount"].replace(0, np.nan) * 100
        
        try:
            df.to_parquet(cache_file, index=False)
        except Exception:
            pass
        
        logger.debug(f"è·å–æ¶¨è·Œåœåˆ—è¡¨æˆåŠŸ: {trade_date}, {len(df)} æ¡")
        return df
    
    def fetch_limit_list_batch(
        self,
        start_date: str,
        end_date: str,
        limit_type: str = "U",
        show_progress: bool = True
    ) -> pd.DataFrame:
        """
        æ‰¹é‡è·å–å¤šæ—¥æ¶¨è·Œåœåˆ—è¡¨
        
        Parameters
        ----------
        start_date : str
            å¼€å§‹æ—¥æœŸ
        end_date : str
            ç»“æŸæ—¥æœŸ
        limit_type : str
            æ¶¨è·Œåœç±»å‹
        show_progress : bool
            æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
        
        Returns
        -------
        pd.DataFrame
            åˆå¹¶åçš„æ¶¨è·Œåœæ•°æ®
        """
        start_date = start_date.replace("-", "")
        end_date = end_date.replace("-", "")
        
        calendar = self.fetch_trade_calendar(start_date, end_date)
        
        all_data = []
        total = len(calendar)
        
        if show_progress:
            try:
                from tqdm import tqdm
                iterator = tqdm(
                    calendar,
                    desc="ğŸ”¥ è·å–æ¶¨åœæ•°æ®",
                    unit="å¤©",
                    ncols=80
                )
            except ImportError:
                iterator = calendar
                logger.info(f"å¼€å§‹è·å–æ¶¨åœæ•°æ®: {total} ä¸ªäº¤æ˜“æ—¥...")
        else:
            iterator = calendar
        
        for date in iterator:
            date_str = date.strftime("%Y%m%d")
            df = self.fetch_limit_list(date_str, limit_type)
            if df is not None and not df.empty:
                all_data.append(df)
        
        if not all_data:
            return pd.DataFrame()
        
        result = pd.concat(all_data, ignore_index=True)
        logger.info(f"æ‰¹é‡è·å–æ¶¨åœæ•°æ®å®Œæˆ: {len(calendar)} å¤©, {len(result)} æ¡è®°å½•")
        return result
    
    def check_tradability(
        self,
        stock_list: List[str],
        trade_date: str,
        check_limit_up: bool = True,
        check_suspend: bool = True
    ) -> pd.DataFrame:
        """
        æ£€æŸ¥è‚¡ç¥¨çš„å¯äº¤æ˜“æ€§
        
        Parameters
        ----------
        stock_list : List[str]
            è‚¡ç¥¨ä»£ç åˆ—è¡¨
        trade_date : str
            äº¤æ˜“æ—¥æœŸ
        check_limit_up : bool
            æ˜¯å¦æ£€æŸ¥æ¶¨åœ
        check_suspend : bool
            æ˜¯å¦æ£€æŸ¥åœç‰Œ
        
        Returns
        -------
        pd.DataFrame
            å¯äº¤æ˜“æ€§ç»“æœ
        """
        trade_date = trade_date.replace("-", "")
        
        result = pd.DataFrame({
            'stock_code': stock_list,
            'is_tradable': True,
            'is_limit_up': False,
            'is_one_word_limit': False,
            'is_limit_down': False,
            'is_suspended': False,
            'limit_strength': 0.0,
            'reason': ''
        })
        
        if not stock_list:
            return result
        
        if check_limit_up:
            limit_up_df = self.fetch_limit_list(trade_date, "U")
            if limit_up_df is not None and not limit_up_df.empty:
                limit_up_codes = set(limit_up_df['stock_code'].tolist())
                
                for idx, row in result.iterrows():
                    code = row['stock_code']
                    if code in limit_up_codes:
                        result.at[idx, 'is_limit_up'] = True
                        
                        stock_limit = limit_up_df[limit_up_df['stock_code'] == code].iloc[0]
                        
                        open_times = stock_limit.get('open_times', 0) or 0
                        fc_ratio = stock_limit.get('fc_ratio', 0) or 0
                        strength = stock_limit.get('strth', 0) or 0
                        
                        result.at[idx, 'limit_strength'] = strength
                        
                        if open_times == 0 or fc_ratio > 50:
                            result.at[idx, 'is_one_word_limit'] = True
                            result.at[idx, 'is_tradable'] = False
                            result.at[idx, 'reason'] = f'ä¸€å­—æ¶¨åœ(å¼€æ¿{open_times}æ¬¡,å°æ¯”{fc_ratio:.0f}%)'
                        elif fc_ratio > 30:
                            result.at[idx, 'reason'] = f'æ¶¨åœ(å°æ¯”{fc_ratio:.0f}%,å¯èƒ½éš¾ä¹°)'
        
        limit_down_df = self.fetch_limit_list(trade_date, "D")
        if limit_down_df is not None and not limit_down_df.empty:
            limit_down_codes = set(limit_down_df['stock_code'].tolist())
            
            for idx, row in result.iterrows():
                if row['stock_code'] in limit_down_codes:
                    result.at[idx, 'is_limit_down'] = True
                    if not result.at[idx, 'reason']:
                        result.at[idx, 'reason'] = 'è·Œåœ(å–å‡ºå¯èƒ½å—é™)'
        
        if check_suspend:
            try:
                suspend_df = self._fetch_with_retry(
                    self.pro.suspend_d,
                    trade_date=trade_date,
                    suspend_type='S'
                )
                
                if suspend_df is not None and not suspend_df.empty:
                    suspend_codes = set(suspend_df['ts_code'].str[:6].tolist())
                    
                    for idx, row in result.iterrows():
                        if row['stock_code'] in suspend_codes:
                            result.at[idx, 'is_suspended'] = True
                            result.at[idx, 'is_tradable'] = False
                            result.at[idx, 'reason'] = 'åœç‰Œ'
            except Exception as e:
                logger.debug(f"è·å–åœç‰Œä¿¡æ¯å¤±è´¥: {e}")
        
        tradable_count = result['is_tradable'].sum()
        logger.info(
            f"å¯äº¤æ˜“æ€§æ£€æŸ¥ {trade_date}: "
            f"æ€»è®¡ {len(stock_list)} åª, å¯äº¤æ˜“ {tradable_count} åª, "
            f"æ¶¨åœ {result['is_limit_up'].sum()} åª, "
            f"ä¸€å­—æ¿ {result['is_one_word_limit'].sum()} åª"
        )
        
        return result
    
    def calculate_consecutive_limits(
        self,
        stock_code: str,
        end_date: str,
        days_back: int = 30
    ) -> int:
        """
        è®¡ç®—è‚¡ç¥¨çš„è¿æ¿å¤©æ•°
        
        Parameters
        ----------
        stock_code : str
            è‚¡ç¥¨ä»£ç 
        end_date : str
            æˆªæ­¢æ—¥æœŸ
        days_back : int
            å›æº¯å¤©æ•°
        
        Returns
        -------
        int
            è¿ç»­æ¶¨åœå¤©æ•°
        """
        end_date = end_date.replace("-", "")
        start_date = (
            datetime.strptime(end_date, "%Y%m%d") - timedelta(days=days_back)
        ).strftime("%Y%m%d")
        
        calendar = self.fetch_trade_calendar(start_date, end_date)
        if len(calendar) == 0:
            return 0
        
        consecutive_count = 0
        
        for date in reversed(calendar):
            date_str = date.strftime("%Y%m%d")
            limit_df = self.fetch_limit_list(date_str, limit_type="U")
            
            if limit_df is None or limit_df.empty:
                if consecutive_count == 0:
                    continue
                else:
                    break
            
            if stock_code in limit_df["stock_code"].values:
                consecutive_count += 1
            else:
                if consecutive_count > 0:
                    break
                if consecutive_count == 0:
                    date_diff = (datetime.strptime(end_date, "%Y%m%d") - date).days
                    if date_diff > 5:
                        return 0
        
        return consecutive_count
    
    def fetch_delisted_stocks(
        self,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None
    ) -> pd.DataFrame:
        """
        è·å–é€€å¸‚è‚¡ç¥¨ä¿¡æ¯
        
        Parameters
        ----------
        start_date : Optional[str]
            é€€å¸‚æ—¥æœŸèµ·å§‹
        end_date : Optional[str]
            é€€å¸‚æ—¥æœŸç»“æŸ
        
        Returns
        -------
        pd.DataFrame
            é€€å¸‚è‚¡ç¥¨ä¿¡æ¯
        """
        logger.info("è·å–é€€å¸‚è‚¡ç¥¨ä¿¡æ¯...")
        
        cache_file = self.cache_dir / "delisted_stocks.parquet"
        
        if cache_file.exists():
            try:
                cache_mtime = datetime.fromtimestamp(cache_file.stat().st_mtime)
                if (datetime.now() - cache_mtime).days < 7:
                    df = pd.read_parquet(cache_file)
                    logger.debug(f"ä»ç¼“å­˜åŠ è½½é€€å¸‚è‚¡ç¥¨: {len(df)} åª")
                    return df
            except Exception:
                pass
        
        try:
            df = self._fetch_with_retry(
                self.pro.stock_basic,
                exchange='',
                list_status='D',
                fields='ts_code,name,list_date,delist_date'
            )
            
            if df is None or df.empty:
                logger.warning("æœªè·å–åˆ°é€€å¸‚è‚¡ç¥¨ä¿¡æ¯")
                return pd.DataFrame()
            
            df['stock_code'] = df['ts_code'].str[:6]
            df['is_delisted'] = True
            
            if start_date or end_date:
                if 'delist_date' in df.columns:
                    df['delist_date'] = pd.to_datetime(df['delist_date'])
                    if start_date:
                        start = pd.to_datetime(start_date)
                        df = df[df['delist_date'] >= start]
                    if end_date:
                        end = pd.to_datetime(end_date)
                        df = df[df['delist_date'] <= end]
            
            try:
                df.to_parquet(cache_file)
            except Exception as e:
                logger.debug(f"ç¼“å­˜é€€å¸‚è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {e}")
            
            logger.info(f"è·å–é€€å¸‚è‚¡ç¥¨å®Œæˆ: {len(df)} åª")
            return df
            
        except Exception as e:
            logger.warning(f"è·å–é€€å¸‚è‚¡ç¥¨å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def fetch_name_change_history(
        self,
        stock_code: Optional[str] = None,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None
    ) -> pd.DataFrame:
        """
        è·å–è‚¡ç¥¨æ›´åå†å²
        
        Parameters
        ----------
        stock_code : Optional[str]
            è‚¡ç¥¨ä»£ç 
        start_date : Optional[str]
            æ›´åæ—¥æœŸèµ·å§‹
        end_date : Optional[str]
            æ›´åæ—¥æœŸç»“æŸ
        
        Returns
        -------
        pd.DataFrame
            æ›´åå†å²
        """
        logger.debug(f"è·å–è‚¡ç¥¨æ›´åå†å²: {stock_code or 'å…¨éƒ¨'}")
        
        try:
            kwargs = {}
            if stock_code:
                if not ('.' in stock_code):
                    suffix = '.SH' if stock_code.startswith(('6', '9')) else '.SZ'
                    kwargs['ts_code'] = stock_code + suffix
                else:
                    kwargs['ts_code'] = stock_code
            
            if start_date:
                kwargs['start_date'] = start_date.replace('-', '')
            if end_date:
                kwargs['end_date'] = end_date.replace('-', '')
            
            df = self._fetch_with_retry(
                self.pro.namechange,
                **kwargs
            )
            
            if df is None or df.empty:
                return pd.DataFrame()
            
            df['stock_code'] = df['ts_code'].str[:6]
            
            logger.debug(f"è·å–æ›´åå†å²å®Œæˆ: {len(df)} æ¡")
            return df
            
        except Exception as e:
            logger.warning(f"è·å–æ›´åå†å²å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def calculate_limit_strength(
        self,
        trade_date: str,
        min_fl_ratio: float = 1.0
    ) -> pd.DataFrame:
        """
        è®¡ç®—æ¶¨åœå°æ¿å¼ºåº¦å› å­ï¼ˆé¾™å¤´ä¿¡ä»°å› å­ï¼‰
        
        Parameters
        ----------
        trade_date : str
            äº¤æ˜“æ—¥æœŸ
        min_fl_ratio : float
            æœ€ä½å°æµæ¯”é˜ˆå€¼ï¼ˆ%ï¼‰
        
        Returns
        -------
        pd.DataFrame
            æ¶¨åœå¼ºåº¦å› å­æ•°æ®
        """
        trade_date = trade_date.replace("-", "")
        
        logger.info(f"ğŸ‰ è®¡ç®—é¾™å¤´ä¿¡ä»°å› å­: {trade_date}")
        
        limit_df = self.fetch_limit_list(trade_date, limit_type="U")
        
        if limit_df is None or limit_df.empty:
            logger.warning(f"æ— æ¶¨åœæ•°æ®: {trade_date}")
            return pd.DataFrame()
        
        result = limit_df.copy()
        
        if "fd_amount" in result.columns and "amount" in result.columns:
            result["bid_strength"] = (
                result["fd_amount"] / result["amount"].replace(0, np.nan)
            )
        elif "fc_ratio" in result.columns:
            result["bid_strength"] = result["fc_ratio"] / 100
        else:
            result["bid_strength"] = 0.5
        
        if "fl_ratio" not in result.columns:
            result["fl_ratio"] = 0
        if "open_num" not in result.columns:
            result["open_num"] = 0
        
        result["is_strong_limit"] = (
            (result["fl_ratio"] >= min_fl_ratio) & 
            (result["open_num"] == 0)
        )
        
        result["dragon_score"] = result["bid_strength"].rank(pct=True)
        result.loc[~result["is_strong_limit"], "dragon_score"] *= 0.5
        result["dragon_score"] = result["dragon_score"].clip(0, 1)
        result["dragon_score"] = result["dragon_score"].fillna(0)
        
        output_cols = [
            "stock_code", "ts_code", "name", "close", "pct_chg",
            "fd_amount", "amount", "bid_strength", "fl_ratio", 
            "open_num", "is_strong_limit", "dragon_score"
        ]
        output_cols = [c for c in output_cols if c in result.columns]
        
        result = result[output_cols].copy()
        result = result.sort_values("dragon_score", ascending=False)
        
        strong_count = result["is_strong_limit"].sum()
        logger.info(
            f"âœ… é¾™å¤´å› å­è®¡ç®—å®Œæˆ: {len(result)} åªæ¶¨åœ, "
            f"{strong_count} åªå¼ºåŠ¿æ¿, "
            f"top5å¾—åˆ†={result['dragon_score'].head(5).mean():.3f}"
        )
        
        return result
    
    def calculate_dragon_head_factor(
        self,
        trade_date: str,
        days_back: int = 5,
        consecutive_weight: float = 0.3,
        strength_weight: float = 0.7
    ) -> pd.DataFrame:
        """
        è®¡ç®—å®Œæ•´é¾™å¤´ä¿¡ä»°å› å­ï¼ˆå«è¿æ¿æº¢ä»·ï¼‰
        
        Parameters
        ----------
        trade_date : str
            äº¤æ˜“æ—¥æœŸ
        days_back : int
            å›æº¯å¤©æ•°
        consecutive_weight : float
            è¿æ¿æº¢ä»·æƒé‡
        strength_weight : float
            å°æ¿å¼ºåº¦æƒé‡
        
        Returns
        -------
        pd.DataFrame
            é¾™å¤´ä¿¡ä»°å› å­æ•°æ®
        """
        trade_date = trade_date.replace("-", "")
        
        logger.info(f"ğŸ² è®¡ç®—å®Œæ•´é¾™å¤´ä¿¡ä»°å› å­: {trade_date}")
        
        strength_df = self.calculate_limit_strength(trade_date)
        
        if strength_df.empty:
            return pd.DataFrame()
        
        result = strength_df.copy()
        
        logger.info(f"è®¡ç®—è¿æ¿å¤©æ•°: {len(result)} åªè‚¡ç¥¨...")
        
        consecutive_days_list = []
        for stock in result["stock_code"]:
            cons_days = self.calculate_consecutive_limits(
                stock, trade_date, days_back=days_back
            )
            consecutive_days_list.append(cons_days)
        
        result["consecutive_days"] = consecutive_days_list
        
        def calc_consecutive_score(days: int) -> float:
            if days <= 0:
                return 0.0
            elif days == 1:
                return 1.0
            elif days == 2:
                return 1.5
            elif days == 3:
                return 2.0
            else:
                return 2.5 + 0.2 * (days - 4)
        
        result["consecutive_premium"] = result["consecutive_days"].apply(calc_consecutive_score)
        
        max_premium = result["consecutive_premium"].max()
        if max_premium > 0:
            result["consecutive_score"] = result["consecutive_premium"] / max_premium
        else:
            result["consecutive_score"] = 0
        
        result["dragon_head_factor"] = (
            strength_weight * result["dragon_score"] +
            consecutive_weight * result["consecutive_score"]
        )
        
        result["dragon_head_factor"] = result["dragon_head_factor"].clip(0, 1)
        result = result.sort_values("dragon_head_factor", ascending=False)
        
        multi_limit = (result["consecutive_days"] >= 2).sum()
        logger.info(
            f"âœ… é¾™å¤´å› å­è®¡ç®—å®Œæˆ: "
            f"{len(result)} åªæ¶¨åœ, {multi_limit} åªè¿æ¿, "
            f"æœ€é«˜è¿æ¿={result['consecutive_days'].max()}å¤©"
        )
        
        return result
    
    def get_dragon_candidates(
        self,
        trade_date: str,
        min_consecutive: int = 1,
        min_factor: float = 0.6,
        top_n: int = 20
    ) -> pd.DataFrame:
        """
        è·å–é¾™å¤´å€™é€‰è‚¡
        
        Parameters
        ----------
        trade_date : str
            äº¤æ˜“æ—¥æœŸ
        min_consecutive : int
            æœ€ä½è¿æ¿å¤©æ•°
        min_factor : float
            æœ€ä½é¾™å¤´å› å­å¾—åˆ†
        top_n : int
            è¿”å›è‚¡ç¥¨æ•°é‡ä¸Šé™
        
        Returns
        -------
        pd.DataFrame
            ç­›é€‰åçš„é¾™å¤´å€™é€‰è‚¡åˆ—è¡¨
        """
        dragon_df = self.calculate_dragon_head_factor(trade_date)
        
        if dragon_df.empty:
            return pd.DataFrame()
        
        mask = (
            (dragon_df["consecutive_days"] >= min_consecutive) &
            (dragon_df["dragon_head_factor"] >= min_factor) &
            (dragon_df["is_strong_limit"] == True)
        )
        
        candidates = dragon_df[mask].head(top_n).copy()
        
        logger.info(
            f"ğŸ¯ é¾™å¤´å€™é€‰è‚¡ç­›é€‰å®Œæˆ: "
            f"{len(candidates)} åª (æ¡ä»¶: è¿æ¿>={min_consecutive}, å› å­>={min_factor})"
        )
        
        return candidates

