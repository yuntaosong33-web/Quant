"""
æ¯æ—¥æ›´æ–°è¿è¡Œå™¨æ¨¡å—

æœ¬æ¨¡å—æä¾›æ¯æ—¥æ•°æ®æ›´æ–°ã€å› å­è®¡ç®—ã€è°ƒä»“ä¿¡å·ç”Ÿæˆå’ŒæŠ¥å‘Šè¾“å‡ºçš„æ ¸å¿ƒé€»è¾‘ã€‚
"""
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Any, Optional, List
import logging
import json
import os

import pandas as pd
import numpy as np

from .strategy import MultiFactorStrategy
from .report_generator import ReportGenerator
from .features import calculate_factor_ic, calculate_forward_returns
from .utils.messaging import send_pushplus_msg

# å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…å¾ªç¯ä¾èµ–
TushareDataLoader = None
AShareDataCleaner = None
DataLoader = None

logger = logging.getLogger(__name__)

# é»˜è®¤è·¯å¾„
DATA_RAW_PATH = Path("data/raw")
DATA_PROCESSED_PATH = Path("data/processed")
REPORTS_PATH = Path("reports")


def _lazy_import():
    """å»¶è¿Ÿå¯¼å…¥é‡å‹æ¨¡å—"""
    global TushareDataLoader, AShareDataCleaner, DataLoader
    
    if TushareDataLoader is None:
        try:
            from .tushare import TushareDataLoader
        except ImportError:
            TushareDataLoader = None
    
    if AShareDataCleaner is None:
        try:
            from .data_loader import AShareDataCleaner
        except ImportError:
            AShareDataCleaner = None


class DailyUpdateRunner:
    """
    æ¯æ—¥æ›´æ–°è¿è¡Œå™¨
    
    è´Ÿè´£æ‰§è¡Œæ¯æ—¥æ•°æ®æ›´æ–°ã€å› å­è®¡ç®—ã€è°ƒä»“ä¿¡å·ç”Ÿæˆå’ŒæŠ¥å‘Šè¾“å‡ºã€‚
    
    Parameters
    ----------
    config : Optional[Dict[str, Any]]
        é…ç½®å‚æ•°
    
    Attributes
    ----------
    config : Dict[str, Any]
        é…ç½®å‚æ•°
    tushare_loader : TushareDataLoader
        Tushare æ•°æ®åŠ è½½å™¨
    strategy : MultiFactorStrategy
        å¤šå› å­ç­–ç•¥
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None) -> None:
        """åˆå§‹åŒ–æ¯æ—¥æ›´æ–°è¿è¡Œå™¨"""
        _lazy_import()
        
        self.logger = logging.getLogger(__name__)
        self.config = config or self._get_default_config()
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        DATA_RAW_PATH.mkdir(parents=True, exist_ok=True)
        DATA_PROCESSED_PATH.mkdir(parents=True, exist_ok=True)
        REPORTS_PATH.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self._init_components()
        
        # çŠ¶æ€å˜é‡
        self.today = pd.Timestamp.now().normalize()
        self.ohlcv_data: Optional[pd.DataFrame] = None
        self.financial_data: Optional[pd.DataFrame] = None
        self.industry_data: Optional[pd.DataFrame] = None
        self.factor_data: Optional[pd.DataFrame] = None
        self.benchmark_data: Optional[pd.DataFrame] = None
        self.current_positions: Dict[str, float] = {}
        self.target_positions: Dict[str, float] = {}
        
        # æŠ¥å‘Šç”Ÿæˆå™¨
        self.report_generator = ReportGenerator(self.config, REPORTS_PATH)
        
        # åŠ è½½å½“å‰æŒä»“
        self.load_current_holdings()
        
        self.logger.info("DailyUpdateRunner åˆå§‹åŒ–å®Œæˆ")
    
    def _get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "data": {
                "stock_pool": "hs300",
                "start_date": "2020-01-01",
                "update_days": 5,
            },
            "strategy": {
                "name": "Multi-Factor Strategy",
                "value_weight": 0.0,
                "quality_weight": 0.3,
                "momentum_weight": 0.7,
                "top_n": 5,
                "min_listing_days": 126,
            },
            "portfolio": {
                "total_capital": 300000,
                "max_weight": 0.25,
                "risk_free_rate": 0.02,
            },
            "report": {
                "format": "markdown",
                "output_dir": "reports",
            },
        }
    
    def _init_components(self) -> None:
        """åˆå§‹åŒ–å„ç»„ä»¶"""
        # Tushare æ•°æ®åŠ è½½å™¨
        tushare_config = self.config.get("tushare", {})
        api_token = tushare_config.get("api_token") or os.environ.get("TUSHARE_TOKEN", "")
        
        if not api_token:
            self.logger.warning("Tushare API Token æœªé…ç½®ï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")
        
        self.tushare_loader = TushareDataLoader(
            api_token=api_token,
            cache_dir=tushare_config.get("cache_dir", "data/tushare_cache")
        )
        
        self.data_cleaner = AShareDataCleaner()
        
        # ç­–ç•¥
        strategy_config = self.config.get("strategy", {})
        llm_config = self.config.get("llm", {})
        
        self.strategy = MultiFactorStrategy(
            name=strategy_config.get("name", "Multi-Factor Strategy"),
            config={
                "value_weight": strategy_config.get("value_weight", 0.0),
                "quality_weight": strategy_config.get("quality_weight", 0.3),
                "momentum_weight": strategy_config.get("momentum_weight", 0.7),
                "size_weight": strategy_config.get("size_weight", 0.0),
                "sentiment_weight": strategy_config.get("sentiment_weight", 0.0),
                "top_n": strategy_config.get("top_n", 5),
                "min_listing_days": strategy_config.get("min_listing_days", 126),
                "exclude_chinext": strategy_config.get("exclude_chinext", False),
                "exclude_star": strategy_config.get("exclude_star", False),
                "value_col": strategy_config.get("value_col", "value_zscore"),
                "quality_col": strategy_config.get("quality_col", "turnover_5d_zscore"),
                "momentum_col": strategy_config.get("momentum_col", "sharpe_20_zscore"),
                "size_col": strategy_config.get("size_col", "small_cap_zscore"),
                "rebalance_frequency": strategy_config.get("rebalance_frequency", "monthly"),
                "rebalance_buffer": strategy_config.get("rebalance_buffer", 0.05),
                "holding_bonus": strategy_config.get("holding_bonus", 0.0),
                "turnover_threshold": strategy_config.get("turnover_threshold", 50.0),
                "volatility_threshold": strategy_config.get("volatility_threshold", 5.0),
                "min_daily_amount": strategy_config.get("min_daily_amount", 50_000_000),
                "min_circ_mv": strategy_config.get("min_circ_mv", None),
                "max_price": strategy_config.get("max_price", 100.0),
                "max_rsi": strategy_config.get("max_rsi", 80.0),
                "min_efficiency": strategy_config.get("min_efficiency", 0.3),
                "overheat_check_col": strategy_config.get("overheat_check_col", strategy_config.get("quality_col", "turnover_5d_zscore")),
                "market_risk": self.config.get("risk", {}).get("market_risk", {}),
                "market_regime": strategy_config.get("market_regime", {}),
                "score_normalization": strategy_config.get("score_normalization", {}),
                "llm": llm_config,
            }
        )

    def _compute_ic_results(self) -> pd.DataFrame:
        """
        è®¡ç®—å› å­ IC ç›‘æ§ç»“æœï¼ˆç”¨äºæŠ¥å‘Šä¸åœ¨çº¿è‡ªé€‚åº”ï¼‰ã€‚

        Returns
        -------
        pd.DataFrame
            å› å­ IC ç»Ÿè®¡è¡¨ï¼›è‹¥æœªå¯ç”¨æˆ–æ•°æ®ä¸è¶³åˆ™è¿”å›ç©ºè¡¨ã€‚
        """
        ic_cfg = self.config.get("ic_monitor", {})
        if not ic_cfg.get("enabled", False):
            return pd.DataFrame()

        if self.factor_data is None or self.factor_data.empty:
            return pd.DataFrame()

        try:
            sample_days = int(ic_cfg.get("sample_days", 30))
            lookback_days = int(ic_cfg.get("lookback_days", 5))
            monitored_factors: List[str] = list(ic_cfg.get("monitored_factors", []))
            if not monitored_factors:
                return pd.DataFrame()

            df = self.factor_data.copy()
            if 'trade_date' in df.columns:
                df['trade_date'] = pd.to_datetime(df['trade_date'])
                unique_dates = pd.DatetimeIndex(sorted(df['trade_date'].unique()))
                if len(unique_dates) > sample_days:
                    start_dt = unique_dates[-sample_days]
                    df = df[df['trade_date'] >= start_dt]

            # è®¡ç®—å‰ç»æ”¶ç›Š
            df = calculate_forward_returns(
                data=df,
                periods=[lookback_days],
                stock_col='stock_code' if 'stock_code' in df.columns else 'symbol',
                price_col='close'
            )
            ret_col = f'forward_return_{lookback_days}d'
            # å…³é”®ï¼šå‰”é™¤â€œæœªæ¥æ”¶ç›Šä¸å¯å¾—â€çš„æ ·æœ¬ï¼ˆæœ€è¿‘ lookback_days å¤©å¿…ç„¶æ˜¯ NaNï¼‰
            if ret_col in df.columns:
                df = df[df[ret_col].notna()].copy()

            # ç›‘æ§å› å­é¢„ç­›é€‰ï¼šå‰”é™¤â€œå‡ ä¹å…¨ç¼ºå¤±/å…¨å¸¸æ•°â€çš„å› å­ï¼Œé¿å…åˆ·å±ä¸è¯¯å¯¼
            date_col = 'trade_date' if 'trade_date' in df.columns else ('date' if 'date' in df.columns else None)
            if date_col is None:
                return pd.DataFrame()

            valid_factors: List[str] = []
            skipped: List[str] = []
            min_valid_days = int(ic_cfg.get("min_valid_days", 8))
            min_non_null = int(ic_cfg.get("min_non_null_rows", 5000))

            for fac in monitored_factors:
                if fac not in df.columns:
                    skipped.append(f"{fac}(missing)")
                    continue
                s = df[fac]
                if int(s.notna().sum()) < min_non_null:
                    skipped.append(f"{fac}(few_non_null)")
                    continue
                if int(s.dropna().nunique()) <= 1:
                    skipped.append(f"{fac}(constant)")
                    continue

                # è‡³å°‘æœ‰è‹¥å¹²äº¤æ˜“æ—¥æ¨ªæˆªé¢éâ€œå¸¸æ•°â€ï¼Œå¦åˆ™ Spearman ä¼šå¤§é‡ NaN
                try:
                    nunique_by_day = df.groupby(date_col)[fac].nunique(dropna=True)
                    if int((nunique_by_day > 1).sum()) < min_valid_days:
                        skipped.append(f"{fac}(few_valid_days)")
                        continue
                except Exception:
                    skipped.append(f"{fac}(group_fail)")
                    continue

                valid_factors.append(fac)

            if skipped:
                self.logger.info(f"ICç›‘æ§é¢„ç­›é€‰å‰”é™¤å› å­: {', '.join(skipped[:10])}" + (" ..." if len(skipped) > 10 else ""))
            if not valid_factors:
                return pd.DataFrame()

            # IC
            ic_df = calculate_factor_ic(
                data=df,
                factor_cols=valid_factors,
                return_col=ret_col,
                date_col=date_col,
                stock_col='stock_code' if 'stock_code' in df.columns else 'symbol',
                log_results=False
            )
            return ic_df
        except Exception as e:
            self.logger.warning(f"IC ç›‘æ§è®¡ç®—å¤±è´¥ï¼ˆå¿½ç•¥å¹¶é™çº§ï¼‰: {e}")
            return pd.DataFrame()
    
    def _validate_and_fix_data_units(self, df: pd.DataFrame, data_type: str) -> pd.DataFrame:
        """
        å¯¹æ•°æ®è¿›è¡Œå•ä½ä¸€è‡´æ€§æ£€æŸ¥ï¼Œå¹¶è‡ªåŠ¨çº æ­£ã€‚
        
        Tushare æ•°æ®çš„æ ‡å‡†å•ä½:
        - volume: è‚¡ (æ‰‹éœ€è¦ * 100)
        - amount: åƒå…ƒ (éœ€è¦è½¬æ¢ä¸ºå…ƒ: * 1000)
        - total_mv/circ_mv: ä¸‡å…ƒ (éœ€è¦è½¬æ¢ä¸ºå…ƒ: * 10000)
        
        ç»Ÿä¸€è¾“å‡ºå•ä½:
        - volume: è‚¡
        - amount: å…ƒ
        - total_mv/circ_mv: å…ƒ
        
        Parameters
        ----------
        df : pd.DataFrame
            å¾…æ£€æŸ¥çš„æ•°æ®
        data_type : str
            æ•°æ®ç±»å‹: "ohlcv" æˆ– "financial"
        
        Returns
        -------
        pd.DataFrame
            å•ä½å·²ç»Ÿä¸€çš„æ•°æ®
        """
        if df.empty:
            return df
        
        df = df.copy()
        corrections = []
        
        if data_type == "ohlcv":
            # æ£€æŸ¥å¹¶ä¿®æ­£æˆäº¤é‡å•ä½ (é¢„æœŸä¸ºè‚¡ï¼Œæ­£å¸¸è‚¡ç¥¨å•æ—¥æˆäº¤é‡åº” > 10ä¸‡è‚¡)
            if 'volume' in df.columns:
                median_vol = df['volume'].median()
                if median_vol < 10000:
                    # å¯èƒ½æ˜¯æ‰‹ï¼Œè½¬æ¢ä¸ºè‚¡
                    df['volume'] = df['volume'] * 100
                    corrections.append(f"volume: æ‰‹â†’è‚¡ (*100)")
            
            # æ£€æŸ¥å¹¶ä¿®æ­£æˆäº¤é¢å•ä½ (Tushare åŸå§‹ä¸ºåƒå…ƒï¼Œç»Ÿä¸€è½¬æ¢ä¸ºå…ƒ)
            if 'amount' in df.columns:
                median_amt = df['amount'].median()
                if median_amt < 1e8:
                    # å¯èƒ½æ˜¯åƒå…ƒï¼Œè½¬æ¢ä¸ºå…ƒ
                    df['amount'] = df['amount'] * 1000
                    corrections.append(f"amount: åƒå…ƒâ†’å…ƒ (*1000)")
                    
        elif data_type == "financial":
            # æ£€æŸ¥å¹¶ä¿®æ­£å¸‚å€¼å•ä½ (Tushare åŸå§‹ä¸ºä¸‡å…ƒï¼Œç»Ÿä¸€è½¬æ¢ä¸ºå…ƒ)
            for col in ['total_mv', 'circ_mv']:
                if col in df.columns:
                    max_val = df[col].max()
                    # ä¸‡å…ƒå•ä½ä¸‹ï¼Œåƒäº¿å¸‚å€¼ = 1e7 ä¸‡å…ƒ
                    if max_val < 1e10:
                        # å¯èƒ½æ˜¯ä¸‡å…ƒï¼Œè½¬æ¢ä¸ºå…ƒ
                        df[col] = df[col] * 10000
                        corrections.append(f"{col}: ä¸‡å…ƒâ†’å…ƒ (*10000)")
        
        if corrections:
            self.logger.info(f"ğŸ“ æ•°æ®å•ä½è‡ªåŠ¨ä¿®æ­£ ({data_type}): {', '.join(corrections)}")
        
        return df
    
    def _validate_data_units(self, df: pd.DataFrame, data_type: str) -> None:
        """
        å¯¹æ•°æ®è¿›è¡Œå•ä½ä¸€è‡´æ€§æ£€æŸ¥ï¼ˆä»…æ£€æŸ¥ä¸ä¿®æ”¹ï¼Œç”¨äºæ—¥å¿—è®°å½•ï¼‰ã€‚
        
        å®é™…ä¿®æ­£è¯·ä½¿ç”¨ _validate_and_fix_data_units æ–¹æ³•ã€‚
        """
        if df.empty:
            return
        
        if data_type == "ohlcv":
            if 'volume' in df.columns:
                median_vol = df['volume'].median()
                if median_vol < 1000:
                    self.logger.warning(
                        f"âš ï¸ OHLCV 'volume' å•ä½å¯èƒ½é”™è¯¯ (ä¸­ä½æ•° {median_vol:.0f})ï¼Œ"
                        f"é¢„æœŸä¸ºè‚¡ï¼Œå½“å‰å¯èƒ½ä¸ºæ‰‹"
                    )
            
            if 'amount' in df.columns:
                median_amt = df['amount'].median()
                if median_amt > 1e12:
                    self.logger.warning(
                        f"âš ï¸ OHLCV 'amount' å•ä½å¼‚å¸¸ (ä¸­ä½æ•° {median_amt:.0f})ï¼Œ"
                        f"è¯·ç¡®è®¤å•ä½ä¸€è‡´æ€§"
                    )
                    
        elif data_type == "financial":
            for col in ['total_mv', 'circ_mv']:
                if col in df.columns:
                    max_val = df[col].max()
                    if max_val > 1e15:
                        self.logger.warning(
                            f"âš ï¸ è´¢åŠ¡æ•°æ® '{col}' å•ä½å¼‚å¸¸ "
                            f"(æœ€å¤§å€¼ {max_val:.2e})ï¼Œè¯·ç¡®è®¤å•ä½ä¸€è‡´æ€§"
                        )
    
    def load_current_holdings(self) -> None:
        """åŠ è½½å½“å‰æŒä»“"""
        holdings_path = DATA_PROCESSED_PATH / "real_holdings.json"
        
        if holdings_path.exists():
            try:
                with open(holdings_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                self.current_positions = data.get("positions", {})
                self.current_positions = {str(k): float(v) for k, v in self.current_positions.items()}
                
                self.logger.info(
                    f"å·²åŠ è½½æŒä»“æ•°æ®: {len(self.current_positions)} åªè‚¡ç¥¨, "
                    f"æ€»å¸‚å€¼ Â¥{sum(self.current_positions.values()):,.0f}"
                )
            except Exception as e:
                self.logger.warning(f"åŠ è½½æŒä»“æ–‡ä»¶å¤±è´¥: {e}")
                self.current_positions = {}
        else:
            self.logger.info("æŒä»“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆå§‹åŒ–ä¸ºç©ºæŒä»“")
            self.current_positions = {}
    
    def save_current_holdings(
        self,
        buy_orders: Dict[str, float],
        sell_orders: Dict[str, float]
    ) -> None:
        """ä¿å­˜å½“å‰æŒä»“"""
        new_positions = self.current_positions.copy()
        
        for stock, amount in buy_orders.items():
            new_positions[stock] = new_positions.get(stock, 0) + amount
        
        for stock, amount in sell_orders.items():
            if stock in new_positions:
                new_positions[stock] -= amount
                if new_positions[stock] <= 0:
                    del new_positions[stock]
        
        holdings_data = {
            "update_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "update_date": self.today.strftime("%Y-%m-%d"),
            "positions": new_positions,
            "total_value": sum(new_positions.values()),
            "num_stocks": len(new_positions),
        }
        
        holdings_path = DATA_PROCESSED_PATH / "real_holdings.json"
        
        try:
            with open(holdings_path, 'w', encoding='utf-8') as f:
                json.dump(holdings_data, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"æŒä»“å·²æ›´æ–°: {len(new_positions)} åªè‚¡ç¥¨")
            self.current_positions = new_positions
        except Exception as e:
            self.logger.error(f"ä¿å­˜æŒä»“æ–‡ä»¶å¤±è´¥: {e}")
    
    def import_broker_holdings(
        self,
        csv_path: Optional[str] = None,
        positions: Optional[Dict[str, float]] = None,
        cash: float = 0.0
    ) -> bool:
        """
        ä»åˆ¸å•†å¯¼å…¥å®é™…æŒä»“ï¼ˆæ—¥ç»ˆå¯¹è´¦ï¼‰
        
        æ”¯æŒä¸¤ç§æ–¹å¼ï¼š
        1. ä» CSV æ–‡ä»¶å¯¼å…¥ï¼ˆåˆ¸å•†å¯¼å‡ºï¼‰
        2. ç›´æ¥ä¼ å…¥æŒä»“å­—å…¸
        
        Parameters
        ----------
        csv_path : Optional[str]
            åˆ¸å•†å¯¼å‡ºçš„æŒä»“ CSV æ–‡ä»¶è·¯å¾„
            é¢„æœŸåˆ—ï¼šè‚¡ç¥¨ä»£ç , æŒä»“å¸‚å€¼ (æˆ– è¯åˆ¸ä»£ç , å¸‚å€¼)
        positions : Optional[Dict[str, float]]
            ç›´æ¥ä¼ å…¥çš„æŒä»“å­—å…¸ {è‚¡ç¥¨ä»£ç : å¸‚å€¼}
        cash : float
            å¯ç”¨ç°é‡‘
        
        Returns
        -------
        bool
            å¯¼å…¥æ˜¯å¦æˆåŠŸ
        """
        self.logger.info("=" * 50)
        self.logger.info("å¼€å§‹æ—¥ç»ˆå¯¹è´¦ï¼šå¯¼å…¥åˆ¸å•†å®é™…æŒä»“")
        self.logger.info("=" * 50)
        
        imported_positions: Dict[str, float] = {}
        
        if csv_path:
            try:
                import_df = pd.read_csv(csv_path, encoding='utf-8')
                
                # å°è¯•è¯†åˆ«åˆ—å
                stock_col = None
                amount_col = None
                
                # å¸¸è§çš„è‚¡ç¥¨ä»£ç åˆ—å
                for col in ['è‚¡ç¥¨ä»£ç ', 'è¯åˆ¸ä»£ç ', 'stock_code', 'symbol', 'ä»£ç ']:
                    if col in import_df.columns:
                        stock_col = col
                        break
                
                # å¸¸è§çš„å¸‚å€¼åˆ—å
                for col in ['æŒä»“å¸‚å€¼', 'å¸‚å€¼', 'å‚è€ƒå¸‚å€¼', 'amount', 'value', 'å¸‚å€¼ï¼ˆå…ƒï¼‰']:
                    if col in import_df.columns:
                        amount_col = col
                        break
                
                if stock_col is None or amount_col is None:
                    self.logger.error(
                        f"æ— æ³•è¯†åˆ« CSV åˆ—åï¼Œè¯·ç¡®ä¿åŒ…å«è‚¡ç¥¨ä»£ç å’Œå¸‚å€¼åˆ—ã€‚"
                        f"å½“å‰åˆ—: {list(import_df.columns)}"
                    )
                    return False
                
                for _, row in import_df.iterrows():
                    stock = str(row[stock_col]).strip()
                    # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç ï¼ˆæå–6ä½æ•°å­—ï¼‰
                    import re
                    match = re.search(r'\d{6}', stock)
                    if match:
                        stock = match.group()
                    
                    amount = float(row[amount_col])
                    if amount > 0:
                        imported_positions[stock] = amount
                
                self.logger.info(f"ä» CSV å¯¼å…¥ {len(imported_positions)} åªè‚¡ç¥¨æŒä»“")
                
            except Exception as e:
                self.logger.error(f"CSV å¯¼å…¥å¤±è´¥: {e}")
                return False
        
        elif positions:
            imported_positions = positions.copy()
            self.logger.info(f"ç›´æ¥å¯¼å…¥ {len(imported_positions)} åªè‚¡ç¥¨æŒä»“")
        
        else:
            self.logger.error("è¯·æä¾› csv_path æˆ– positions å‚æ•°")
            return False
        
        # è®¡ç®—ä¸ç³»ç»ŸæŒä»“çš„åå·®
        self._log_holdings_diff(imported_positions, cash)
        
        # ä¿å­˜æ–°æŒä»“
        holdings_data = {
            "update_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "update_date": self.today.strftime("%Y-%m-%d"),
            "positions": imported_positions,
            "cash": cash,
            "total_value": sum(imported_positions.values()) + cash,
            "num_stocks": len(imported_positions),
            "source": "broker_import",
            "note": "ä»åˆ¸å•†å®é™…æŒä»“å¯¼å…¥ï¼ˆæ—¥ç»ˆå¯¹è´¦ï¼‰"
        }
        
        holdings_path = DATA_PROCESSED_PATH / "real_holdings.json"
        
        try:
            with open(holdings_path, 'w', encoding='utf-8') as f:
                json.dump(holdings_data, f, ensure_ascii=False, indent=2)
            
            self.current_positions = imported_positions
            self.logger.info(f"âœ… æ—¥ç»ˆå¯¹è´¦å®Œæˆ: {len(imported_positions)} åªè‚¡ç¥¨, ç°é‡‘ Â¥{cash:,.0f}")
            return True
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜æŒä»“å¤±è´¥: {e}")
            return False
    
    def _log_holdings_diff(self, new_positions: Dict[str, float], new_cash: float) -> None:
        """è®°å½•æŒä»“åå·®ï¼ˆç³»ç»ŸæŒä»“ vs åˆ¸å•†å®é™…ï¼‰"""
        old_positions = self.current_positions
        
        all_stocks = set(old_positions.keys()) | set(new_positions.keys())
        
        diff_lines = []
        total_old = sum(old_positions.values())
        total_new = sum(new_positions.values())
        
        for stock in sorted(all_stocks):
            old_amt = old_positions.get(stock, 0)
            new_amt = new_positions.get(stock, 0)
            diff = new_amt - old_amt
            
            if abs(diff) > 100:  # å¿½ç•¥å°åå·®
                if old_amt == 0:
                    diff_lines.append(f"  + {stock}: Â¥{new_amt:,.0f} (æ–°å¢)")
                elif new_amt == 0:
                    diff_lines.append(f"  - {stock}: Â¥{old_amt:,.0f} (æ¸…ä»“)")
                else:
                    sign = '+' if diff > 0 else ''
                    diff_lines.append(f"  Î” {stock}: Â¥{old_amt:,.0f} â†’ Â¥{new_amt:,.0f} ({sign}{diff:,.0f})")
        
        if diff_lines:
            self.logger.warning("æŒä»“åå·®æ£€æµ‹ï¼ˆç³»ç»Ÿ vs åˆ¸å•†ï¼‰:")
            for line in diff_lines:
                self.logger.warning(line)
            
            total_diff = total_new - total_old
            self.logger.warning(f"  æ€»å¸‚å€¼åå·®: Â¥{total_diff:+,.0f} ({total_diff/total_old*100:+.1f}%)" if total_old > 0 else f"  æ€»å¸‚å€¼: Â¥{total_new:,.0f}")
        else:
            self.logger.info("æŒä»“æ— åå·®")
    
    def update_market_data(self) -> bool:
        """æ›´æ–°å¸‚åœºæ•°æ®"""
        self.logger.info("å¼€å§‹æ›´æ–°å¸‚åœºæ•°æ®...")
        
        try:
            # æ£€æŸ¥ä»Šæ—¥ç¼“å­˜
            ohlcv_path = DATA_RAW_PATH / f"ohlcv_{self.today.strftime('%Y%m%d')}.parquet"
            if ohlcv_path.exists():
                try:
                    self.ohlcv_data = pd.read_parquet(ohlcv_path)
                    if not self.ohlcv_data.empty:
                        self.logger.info(f"ä½¿ç”¨ç¼“å­˜æ•°æ®: {ohlcv_path.name}")
                        return True
                except Exception as e:
                    self.logger.warning(f"è¯»å–ç¼“å­˜å¤±è´¥: {e}")
            
            data_config = self.config.get("data", {})
            stock_pool = data_config.get("stock_pool", "hs300")
            
            end_date = self.today.strftime("%Y%m%d")
            update_days = data_config.get("update_days", 5)
            start_date = (self.today - timedelta(days=update_days * 2)).strftime("%Y%m%d")
            
            # è·å–è‚¡ç¥¨åˆ—è¡¨
            if stock_pool == "all":
                stock_list = self.tushare_loader.fetch_all_stocks()
            else:
                stock_list = self.tushare_loader.fetch_index_constituents(stock_pool)
            
            if not stock_list:
                self.logger.error(f"æ— æ³•è·å– {stock_pool} è‚¡ç¥¨åˆ—è¡¨")
                return False
            
            self.logger.info(f"è‚¡ç¥¨æ± : {stock_pool}, è‚¡ç¥¨æ•°é‡: {len(stock_list)}")
            
            # ===== ä¼˜åŒ–ï¼šä½¿ç”¨æŒ‰æ—¥æœŸæ¨¡å¼è·å–æ—¥çº¿æ•°æ®ï¼ˆå¤§å¹…å‡å°‘APIè°ƒç”¨ï¼‰=====
            # æ—¥æ›´åœºæ™¯ä¸‹ï¼ŒæŒ‰æ—¥æœŸè·å–æ›´é«˜æ•ˆï¼šæ¯ä¸ªäº¤æ˜“æ—¥1æ¬¡APIè°ƒç”¨
            # è€ŒæŒ‰è‚¡ç¥¨è·å–ï¼šæ¯åªè‚¡ç¥¨2æ¬¡APIè°ƒç”¨ï¼ˆdaily + adj_factorï¼‰
            fetch_mode = data_config.get("fetch_mode", "by_date")  # by_date / by_stock
            
            if fetch_mode == "by_date":
                self.logger.info(f"ğŸ“Š ä½¿ç”¨ã€æŒ‰æ—¥æœŸã€‘é«˜æ•ˆæ¨¡å¼è·å–æ—¥çº¿æ•°æ®")
                self.ohlcv_data = self.tushare_loader.fetch_daily_range_optimized(
                    start_date, end_date, stock_list, show_progress=True
                )
            else:
                # å…¼å®¹æ—§æ¨¡å¼
                self.logger.info(f"ğŸ“Š ä½¿ç”¨ã€æŒ‰è‚¡ç¥¨ã€‘ä¼ ç»Ÿæ¨¡å¼è·å–æ—¥çº¿æ•°æ®")
                self.ohlcv_data = self.tushare_loader.fetch_daily_data_batch(
                    stock_list, start_date, end_date
                )
            
            if self.ohlcv_data is None or self.ohlcv_data.empty:
                self.logger.error("æœªè·å–åˆ°ä»»ä½• OHLCV æ•°æ®")
                return False
            
            self.logger.info(f"OHLCV æ•°æ®æ›´æ–°å®Œæˆï¼Œå…± {len(self.ohlcv_data)} æ¡è®°å½•")
            
            # ä¿å­˜æ•°æ®
            self.ohlcv_data.to_parquet(ohlcv_path)
            self._current_stock_list = stock_list
            
            return True
            
        except Exception as e:
            self.logger.error(f"æ›´æ–°å¸‚åœºæ•°æ®å¤±è´¥: {e}")
            return False
    
    def update_financial_data(self) -> bool:
        """æ›´æ–°è´¢åŠ¡æ•°æ®"""
        self.logger.info("å¼€å§‹æ›´æ–°è´¢åŠ¡æ•°æ®...")
        
        financial_path = DATA_RAW_PATH / f"financial_{self.today.strftime('%Y%m%d')}.parquet"
        if financial_path.exists():
            try:
                self.financial_data = pd.read_parquet(financial_path)
                if not self.financial_data.empty:
                    self.logger.info(f"ä½¿ç”¨ç¼“å­˜æ•°æ®: {financial_path.name}")
                    return True
            except Exception as e:
                self.logger.warning(f"è¯»å–ç¼“å­˜å¤±è´¥: {e}")
        
        try:
            if self.ohlcv_data is None:
                return False
            
            # è·å–å”¯ä¸€è‚¡ç¥¨åˆ—è¡¨
            stocks = list(set(self.ohlcv_data['stock_code'].unique().tolist()))
            
            # ===== ä¼˜åŒ–ï¼šæ¯æ—¥åŸºç¡€æŒ‡æ ‡å·²ç»æ˜¯é«˜æ•ˆæ¨¡å¼ï¼ˆ1æ¬¡APIè°ƒç”¨è·å–å…¨å¸‚åœºï¼‰=====
            # fetch_daily_basic æ˜¯æŒ‰æ—¥æœŸè·å–ï¼Œéå¸¸é«˜æ•ˆ
            basic_df = self.tushare_loader.fetch_daily_basic(stock_list=stocks)
            
            # ç«‹å³é‡ç½®ç´¢å¼•ï¼Œé¿å…åç»­æ“ä½œçš„ç´¢å¼•é—®é¢˜
            if basic_df is not None and not basic_df.empty:
                basic_df = basic_df.copy().reset_index(drop=True)
            
            # ===== è´¢åŠ¡æŒ‡æ ‡è·å–ç­–ç•¥ =====
            # fina_indicator éœ€è¦é€åªè‚¡ç¥¨è·å–ï¼Œä½†æœ‰7å¤©ç¼“å­˜
            # å¦‚æœç¼“å­˜å‘½ä¸­ç‡é«˜ï¼Œå®é™…APIè°ƒç”¨ä¼šå¾ˆå°‘
            data_config = self.config.get("data", {})
            skip_fina_indicator = data_config.get("skip_fina_indicator", False)
            
            if skip_fina_indicator:
                # è·³è¿‡è´¢åŠ¡æŒ‡æ ‡è·å–ï¼ˆä»…ä½¿ç”¨ daily_basic çš„ä¼°å€¼æ•°æ®ï¼‰
                self.logger.info("è·³è¿‡è´¢åŠ¡æŒ‡æ ‡è·å–ï¼ˆä½¿ç”¨ daily_basic ä¼°å€¼æ•°æ®ï¼‰")
                fina_df = pd.DataFrame()
            else:
                # è·å–è´¢åŠ¡æŒ‡æ ‡ï¼ˆæœ‰ç¼“å­˜ä¿æŠ¤ï¼Œä½¿ç”¨é…ç½®çš„æ‰¹æ¬¡å‚æ•°ï¼‰
                fina_batch_size = data_config.get("fina_batch_size", 300)
                fina_batch_sleep = data_config.get("fina_batch_sleep", 0.0)  # é»˜è®¤ä¸ä¼‘æ¯
                self.logger.info(f"ğŸ“ˆ è´¢åŠ¡æŒ‡æ ‡è·å–å‚æ•°: batch_size={fina_batch_size}, batch_sleep={fina_batch_sleep}s")
                fina_df = self.tushare_loader.fetch_financial_batch(
                    stocks, 
                    show_progress=True,
                    batch_size=fina_batch_size,
                    batch_sleep=fina_batch_sleep
                )
                
                # ç«‹å³é‡ç½®ç´¢å¼•
                if fina_df is not None and not fina_df.empty:
                    fina_df = fina_df.copy().reset_index(drop=True)
            
            # é˜²å¾¡æ€§å¤„ç†ï¼šç¡®ä¿ DataFrame æœ‰æ­£ç¡®çš„ç»“æ„
            if basic_df is None:
                basic_df = pd.DataFrame()
            if fina_df is None:
                fina_df = pd.DataFrame()
            
            # é‡ç½®ç´¢å¼•ï¼Œé¿å…ç´¢å¼•å†²çª - ä½¿ç”¨ RangeIndex å¼ºåˆ¶å”¯ä¸€ç´¢å¼•
            if not basic_df.empty:
                basic_df = basic_df.copy()
                basic_df.index = pd.RangeIndex(len(basic_df))
            if not fina_df.empty:
                fina_df = fina_df.copy()
                fina_df.index = pd.RangeIndex(len(fina_df))
            
            if not basic_df.empty and not fina_df.empty:
                # ç¡®ä¿ä¸¤è¾¹éƒ½å»é‡
                basic_df_dedup = basic_df.drop_duplicates(subset=['stock_code'], keep='last')
                basic_df_dedup.index = pd.RangeIndex(len(basic_df_dedup))
                
                # æ£€æŸ¥ fina_df æ˜¯å¦åŒ…å«éœ€è¦çš„åˆ—
                fina_cols = ['stock_code']
                if 'roe' in fina_df.columns:
                    fina_cols.append('roe')
                
                # å…ˆå¤åˆ¶å†é€‰æ‹©åˆ—ï¼Œé¿å…ç´¢å¼•é—®é¢˜
                fina_subset = fina_df[fina_cols].copy()
                fina_subset.index = pd.RangeIndex(len(fina_subset))
                fina_df_dedup = fina_subset.drop_duplicates(subset=['stock_code'], keep='last')
                fina_df_dedup.index = pd.RangeIndex(len(fina_df_dedup))
                
                merged_df = basic_df_dedup.merge(
                    fina_df_dedup,
                    on='stock_code',
                    how='left'
                )
                # åˆ é™¤é‡å¤çš„åˆ—å
                merged_df = merged_df.loc[:, ~merged_df.columns.duplicated(keep='first')]
                self.logger.info(f"åˆå¹¶è´¢åŠ¡æ•°æ®: basic={len(basic_df_dedup)}, fina={len(fina_df_dedup)}, merged={len(merged_df)}")
            elif not basic_df.empty:
                merged_df = basic_df.drop_duplicates(subset=['stock_code'], keep='last')
                merged_df.index = pd.RangeIndex(len(merged_df))
            elif not fina_df.empty:
                merged_df = fina_df.drop_duplicates(subset=['stock_code'], keep='last')
                merged_df.index = pd.RangeIndex(len(merged_df))
            else:
                return False
            
            self.financial_data = merged_df
            self.financial_data.to_parquet(financial_path)
            
            self.logger.info(f"è´¢åŠ¡æ•°æ®æ›´æ–°å®Œæˆ: {len(self.financial_data)} æ¡è®°å½•")
            return True
            
        except Exception as e:
            self.logger.error(f"è´¢åŠ¡æ•°æ®è·å–å¤±è´¥: {e}")
            return False
    
    def update_benchmark_data(self) -> bool:
        """æ›´æ–°åŸºå‡†æŒ‡æ•°æ•°æ®ï¼ˆç”¨äºå¤§ç›˜é£æ§ï¼‰"""
        self.logger.info("å¼€å§‹æ›´æ–°åŸºå‡†æŒ‡æ•°æ•°æ®...")
        
        try:
            risk_config = self.config.get("risk", {}).get("market_risk", {})
            benchmark_code = risk_config.get("benchmark", "000300")
            
            end_date = self.today.strftime("%Y%m%d")
            start_date = (self.today - timedelta(days=120)).strftime("%Y%m%d")
            
            self.benchmark_data = self.tushare_loader.fetch_index_daily(
                benchmark_code, start_date, end_date
            )
            
            if self.benchmark_data is not None and not self.benchmark_data.empty:
                self.logger.info(f"åŸºå‡†æŒ‡æ•°æ•°æ®æ›´æ–°å®Œæˆ: {len(self.benchmark_data)} æ¡")
                return True
            else:
                self.logger.warning("æœªè·å–åˆ°åŸºå‡†æŒ‡æ•°æ•°æ®ï¼Œå¤§ç›˜é£æ§å¯èƒ½ä¸ç”Ÿæ•ˆ")
                return False
                
        except Exception as e:
            self.logger.warning(f"åŸºå‡†æŒ‡æ•°æ•°æ®è·å–å¤±è´¥: {e}")
            return False
    
    def calculate_factors(self) -> bool:
        """è®¡ç®—å› å­æ•°æ®"""
        self.logger.info("å¼€å§‹è®¡ç®—å› å­æ•°æ®...")
        
        try:
            if self.ohlcv_data is None or self.ohlcv_data.empty:
                self.logger.error("OHLCV æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è®¡ç®—å› å­")
                return False
            
            # ========================================
            # æ•°æ®å•ä½ä¸€è‡´æ€§æ£€æŸ¥ä¸è‡ªåŠ¨ä¿®æ­£
            # ========================================
            self.ohlcv_data = self._validate_and_fix_data_units(self.ohlcv_data, "ohlcv")
            
            # åˆå¹¶ OHLCV å’Œè´¢åŠ¡æ•°æ®
            df = self.ohlcv_data.copy()
            
            if self.financial_data is not None and not self.financial_data.empty:
                self.financial_data = self._validate_and_fix_data_units(self.financial_data, "financial")
                
                # ========================================
                # è´¢åŠ¡æ•°æ®æ—¥æœŸå¯¹é½ï¼ˆä¿®å¤å‰è§†åå·®ï¼‰
                # ========================================
                # è´¢åŠ¡æ•°æ®é€šå¸¸æ˜¯æˆªé¢æ•°æ®ï¼ˆæŸä¸€å¤©çš„å¿«ç…§ï¼‰ï¼Œéœ€è¦æŒ‰æ—¥æœŸå¯¹é½
                # ç­–ç•¥ï¼šä½¿ç”¨ OHLCV æ•°æ®ä¸­æ¯ä¸ª trade_date å¯¹åº”çš„è´¢åŠ¡æ•°æ®
                # å¦‚æœè´¢åŠ¡æ•°æ®æœ‰ trade_dateï¼Œåˆ™æŒ‰ (stock_code, trade_date) åˆå¹¶
                # å¦åˆ™ï¼Œåªå–æœ€æ–°è´¢åŠ¡æ•°æ®å¹¿æ’­åˆ°æœ€æ–°äº¤æ˜“æ—¥
                
                fin_df = self.financial_data.copy()
                
                if 'trade_date' in fin_df.columns:
                    # è´¢åŠ¡æ•°æ®æœ‰æ—¥æœŸï¼ŒæŒ‰ (stock_code, trade_date) ç²¾ç¡®åˆå¹¶
                    df = df.merge(
                        fin_df,
                        on=['stock_code', 'trade_date'],
                        how='left',
                        suffixes=('', '_fin')
                    )
                    self.logger.info("è´¢åŠ¡æ•°æ®å·²æŒ‰ (stock_code, trade_date) ç²¾ç¡®åˆå¹¶")
                else:
                    # è´¢åŠ¡æ•°æ®æ— æ—¥æœŸï¼Œä½¿ç”¨æœ€æ–°å¿«ç…§
                    # åªå¯¹ OHLCV ä¸­æœ€æ–°äº¤æ˜“æ—¥çš„æ•°æ®åˆå¹¶è´¢åŠ¡
                    latest_trade_date = df['trade_date'].max()
                    
                    # ä¸ºè´¢åŠ¡æ•°æ®æ·»åŠ æ ‡è®°ï¼Œè¡¨ç¤ºä»…é€‚ç”¨äºæœ€æ–°æ—¥æœŸ
                    fin_df_dedup = fin_df.drop_duplicates(subset=['stock_code'], keep='last')
                    
                    # åªå¯¹æœ€æ–°æ—¥æœŸçš„æ•°æ®åˆå¹¶è´¢åŠ¡å­—æ®µ
                    df_latest = df[df['trade_date'] == latest_trade_date].copy()
                    df_historical = df[df['trade_date'] != latest_trade_date].copy()
                    
                    df_latest = df_latest.merge(
                        fin_df_dedup,
                        on='stock_code',
                        how='left',
                        suffixes=('', '_fin')
                    )
                    
                    # å†å²æ•°æ®ä¸åˆå¹¶è´¢åŠ¡ï¼ˆé¿å…å‰è§†åå·®ï¼‰
                    # ä½†éœ€è¦ç¡®ä¿åˆ—ä¸€è‡´
                    for col in fin_df_dedup.columns:
                        if col != 'stock_code' and col not in df_historical.columns:
                            df_historical[col] = np.nan
                    
                    df = pd.concat([df_historical, df_latest], ignore_index=True)
                    self.logger.warning(
                        f"è´¢åŠ¡æ•°æ®æ—  trade_date åˆ—ï¼Œä»…åˆå¹¶åˆ°æœ€æ–°äº¤æ˜“æ—¥ {latest_trade_date}ï¼Œ"
                        f"å†å²æ—¥æœŸè´¢åŠ¡å­—æ®µä¸º NaNï¼ˆé¿å…å‰è§†åå·®ï¼‰"
                    )
            
            # è®¡ç®—æŠ€æœ¯å› å­ï¼ˆæŒ‰è‚¡ç¥¨åˆ†ç»„ï¼‰
            factor_dfs = []
            
            for stock_code, group in df.groupby('stock_code'):
                group = group.sort_values('trade_date')
                
                # RSI
                if 'close' in group.columns:
                    delta = group['close'].diff()
                    gain = delta.where(delta > 0, 0)
                    loss = (-delta).where(delta < 0, 0)
                    
                    avg_gain = gain.ewm(alpha=1/20, min_periods=20).mean()
                    avg_loss = loss.ewm(alpha=1/20, min_periods=20).mean()
                    rs = avg_gain / avg_loss.replace(0, np.nan)
                    group['rsi_20'] = 100 - (100 / (1 + rs))
                
                # æ¢æ‰‹ç‡5æ—¥å‡å€¼ï¼ˆå…¼å®¹ turnover_rate å’Œ turn åˆ—åï¼‰
                turn_col = 'turn' if 'turn' in group.columns else ('turnover_rate' if 'turnover_rate' in group.columns else None)
                if turn_col:
                    group['turnover_5d'] = group[turn_col].rolling(5).mean()
                
                # 20æ—¥æ”¶ç›Šç‡ï¼ˆåŠ¨é‡ï¼‰
                if 'close' in group.columns:
                    group['return_20'] = group['close'].pct_change(20)
                    
                    # è·¯å¾„æ•ˆç‡
                    abs_changes = group['close'].diff().abs().rolling(20).sum()
                    net_change = group['close'].diff(20).abs()
                    group['efficiency_20'] = net_change / abs_changes.replace(0, np.nan)
                    
                    # å¤æ™®æ¯”ç‡ï¼ˆç®€åŒ–ç‰ˆï¼‰
                    returns = group['close'].pct_change()
                    group['sharpe_20'] = (
                        returns.rolling(20).mean() / returns.rolling(20).std().replace(0, np.nan)
                    ) * np.sqrt(252)
                    
                    # æ³¢åŠ¨ç‡ï¼ˆå¹´åŒ–ï¼Œ20æ—¥ï¼‰
                    group['volatility_20'] = returns.rolling(20).std().replace(0, np.nan) * np.sqrt(252)
                
                # ===== Alpha åŸå­å› å­ï¼ˆç”¨äº momentum_composite_zscoreï¼‰=====
                # alpha_002: ä»·æ ¼æŒ¯å¹…å› å­
                if {'high', 'low', 'close'}.issubset(group.columns):
                    group['alpha_002'] = (group['high'] - group['low']) / group['close'].replace(0, np.nan)
                    
                    # alpha_005: å°¾ç›˜å¼ºåº¦å› å­
                    range_hl = (group['high'] - group['low']).replace(0, np.nan)
                    group['alpha_005'] = (group['close'] - group['low']) / range_hl
                
                # alpha_003: é‡ä»·èƒŒç¦»å› å­ï¼ˆ5æ—¥ï¼‰
                if {'close', 'volume'}.issubset(group.columns):
                    price_change = group['close'].pct_change(5)
                    volume_change = group['volume'].pct_change(5)
                    group['alpha_003'] = price_change - volume_change
                
                factor_dfs.append(group)
            
            self.factor_data = pd.concat(factor_dfs, ignore_index=True)
            
            # ========================================
            # Z-Score æ ‡å‡†åŒ– - æŒ‰äº¤æ˜“æ—¥æ¨ªæˆªé¢ï¼ˆä¿®å¤å‰è§†åå·®ï¼‰
            # ========================================
            zscore_cols = {
                'rsi_20': 'rsi_20_zscore',
                'turnover_5d': 'turnover_5d_zscore',
                'return_20': 'momentum_zscore',
                'sharpe_20': 'sharpe_20_zscore',
                'efficiency_20': 'efficiency_20_zscore',
                'volatility_20': 'volatility_20_zscore',
                'alpha_002': 'alpha_002_zscore',
                'alpha_003': 'alpha_003_zscore',
                'alpha_005': 'alpha_005_zscore',
                'pe_ttm': 'pe_ttm_zscore',
                'pb': 'pb_zscore',
            }
            
            def cross_sectional_zscore(group: pd.DataFrame, col: str) -> pd.Series:
                """æŒ‰äº¤æ˜“æ—¥æ¨ªæˆªé¢è®¡ç®—Z-Scoreï¼ˆæ¶ˆé™¤å‰è§†åå·®ï¼‰"""
                values = group[col]
                mean = values.mean()
                std = values.std()
                if std > 0 and not pd.isna(std):
                    return (values - mean) / std
                return pd.Series(0.0, index=group.index)
            
            for src_col, dst_col in zscore_cols.items():
                if src_col in self.factor_data.columns:
                    # ä¼°å€¼ç±»å­—æ®µï¼šè¿‡æ»¤éæ­£å€¼ï¼Œé¿å… log / æ¯”ç‡å¼‚å¸¸æ±¡æŸ“æ¨ªæˆªé¢
                    if src_col in ('pe_ttm', 'pb'):
                        self.factor_data[src_col] = pd.to_numeric(self.factor_data[src_col], errors='coerce')
                        self.factor_data.loc[self.factor_data[src_col] <= 0, src_col] = np.nan
                    # æŒ‰ trade_date åˆ†ç»„ï¼Œæ¯ä¸ªäº¤æ˜“æ—¥å†…éƒ¨æ¨ªæˆªé¢æ ‡å‡†åŒ–
                    self.factor_data[dst_col] = self.factor_data.groupby('trade_date', group_keys=False).apply(
                        lambda g: cross_sectional_zscore(g, src_col), include_groups=False
                    )
                    self.logger.debug(f"æ¨ªæˆªé¢æ ‡å‡†åŒ–å®Œæˆ: {src_col} -> {dst_col}")
            
            # å°å¸‚å€¼å› å­ï¼ˆåŒæ ·æŒ‰äº¤æ˜“æ—¥æ¨ªæˆªé¢ï¼‰
            if 'circ_mv' in self.factor_data.columns:
                def small_cap_zscore(group: pd.DataFrame) -> pd.Series:
                    """å°å¸‚å€¼å› å­ï¼šå¯¹æ•°å¸‚å€¼çš„è´ŸZ-Score"""
                    log_mv = np.log(group['circ_mv'].replace(0, np.nan))
                    mean = log_mv.mean()
                    std = log_mv.std()
                    if std > 0 and not pd.isna(std):
                        return -(log_mv - mean) / std
                    return pd.Series(0.0, index=group.index)
                
                self.factor_data['small_cap_zscore'] = self.factor_data.groupby('trade_date', group_keys=False).apply(
                    small_cap_zscore, include_groups=False
                )
                self.logger.debug("æ¨ªæˆªé¢æ ‡å‡†åŒ–å®Œæˆ: circ_mv -> small_cap_zscore")
            
            # ========================================
            # å¤åˆå› å­ï¼ˆä¸ strategy_config.yaml å¯¹é½ï¼‰
            # ========================================
            # quality_composite_zscore = 50% turnover + 30% low_vol + 20% efficiency
            if {'turnover_5d_zscore', 'volatility_20_zscore', 'efficiency_20_zscore'}.issubset(self.factor_data.columns):
                low_vol_z = -self.factor_data['volatility_20_zscore'].fillna(0.0)
                quality_raw = (
                    0.5 * self.factor_data['turnover_5d_zscore'].fillna(0.0)
                    + 0.3 * low_vol_z
                    + 0.2 * self.factor_data['efficiency_20_zscore'].fillna(0.0)
                )
                self.factor_data['quality_composite_raw'] = quality_raw
                self.factor_data['quality_composite_zscore'] = self.factor_data.groupby('trade_date', group_keys=False).apply(
                    lambda g: cross_sectional_zscore(g, 'quality_composite_raw'), include_groups=False
                )
                self.logger.info("å¤åˆå› å­å·²ç”Ÿæˆ: quality_composite_zscore")
            else:
                self.logger.warning("ç¼ºå°‘å¤åˆè´¨é‡å› å­æ‰€éœ€åˆ—ï¼Œæœªç”Ÿæˆ quality_composite_zscore")
            
            # momentum_composite_zscore = alpha_002/003/005 + efficiencyï¼ˆç­‰æƒï¼‰
            if {'alpha_002_zscore', 'alpha_003_zscore', 'alpha_005_zscore', 'efficiency_20_zscore'}.issubset(self.factor_data.columns):
                mom_raw = (
                    0.25 * self.factor_data['alpha_002_zscore'].fillna(0.0)
                    + 0.25 * self.factor_data['alpha_003_zscore'].fillna(0.0)
                    + 0.25 * self.factor_data['alpha_005_zscore'].fillna(0.0)
                    + 0.25 * self.factor_data['efficiency_20_zscore'].fillna(0.0)
                )
                self.factor_data['momentum_composite_raw'] = mom_raw
                self.factor_data['momentum_composite_zscore'] = self.factor_data.groupby('trade_date', group_keys=False).apply(
                    lambda g: cross_sectional_zscore(g, 'momentum_composite_raw'), include_groups=False
                )
                self.logger.info("å¤åˆå› å­å·²ç”Ÿæˆ: momentum_composite_zscore")
            else:
                self.logger.warning("ç¼ºå°‘å¤åˆåŠ¨é‡å› å­æ‰€éœ€åˆ—ï¼Œæœªç”Ÿæˆ momentum_composite_zscore")
            
            # value_composite_zscore = ä¼°å€¼ï¼ˆä½PEã€ä½PBæ›´å¥½ï¼‰
            if {'pe_ttm_zscore', 'pb_zscore'}.issubset(self.factor_data.columns):
                # zscoreè¶Šä½ä»£è¡¨ä¼°å€¼è¶Šä½ï¼Œå› æ­¤å–è´Ÿå·å˜æˆâ€œé«˜åˆ†=æ›´ä¾¿å®œâ€
                value_raw = -(0.5 * self.factor_data['pe_ttm_zscore'].fillna(0.0) + 0.5 * self.factor_data['pb_zscore'].fillna(0.0))
                self.factor_data['value_composite_raw'] = value_raw
                self.factor_data['value_composite_zscore'] = self.factor_data.groupby('trade_date', group_keys=False).apply(
                    lambda g: cross_sectional_zscore(g, 'value_composite_raw'), include_groups=False
                )
                self.logger.info("å¤åˆå› å­å·²ç”Ÿæˆ: value_composite_zscore")
            else:
                self.logger.warning("ç¼ºå°‘ä¼°å€¼å­—æ®µ(pe_ttm/pb)ï¼Œæœªç”Ÿæˆ value_composite_zscore")
            
            # é…ç½®ä¸€è‡´æ€§æ£€æŸ¥ï¼ˆé¿å…â€œç­–ç•¥å¼•ç”¨åˆ—ä¸å­˜åœ¨â€å¯¼è‡´åä¹‰é€‚é…ä½†å®é™…æ— æ•ˆï¼‰
            required_cols = {
                'value_col': self.strategy.value_col,
                'quality_col': self.strategy.quality_col,
                'momentum_col': self.strategy.momentum_col,
                'size_col': self.strategy.size_col,
            }
            missing = [k for k, v in required_cols.items() if v not in self.factor_data.columns]
            if missing:
                self.logger.warning(f"âš ï¸ ç­–ç•¥é…ç½®çš„å› å­åˆ—åœ¨factor_dataä¸­ç¼ºå¤±: {missing} -> {[(k, required_cols[k]) for k in missing]}")
            
            # ä¿å­˜å› å­æ•°æ®
            factor_path = DATA_PROCESSED_PATH / f"factors_{self.today.strftime('%Y%m%d')}.parquet"
            self.factor_data.to_parquet(factor_path)
            
            self.logger.info(f"å› å­è®¡ç®—å®Œæˆ: {len(self.factor_data)} æ¡è®°å½•")
            return True
            
        except Exception as e:
            self.logger.error(f"å› å­è®¡ç®—å¤±è´¥: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return False
    
    def is_rebalance_day(self) -> bool:
        """åˆ¤æ–­ä»Šå¤©æ˜¯å¦æ˜¯è°ƒä»“æ—¥"""
        frequency = self.strategy.rebalance_frequency
        
        if frequency == "weekly":
            return self.today.dayofweek == 4  # å‘¨äº”
        else:  # monthly
            next_day = self.today + timedelta(days=1)
            return self.today.month != next_day.month
    
    def generate_target_positions(self) -> bool:
        """ç”Ÿæˆç›®æ ‡æŒä»“"""
        self.logger.info("ç”Ÿæˆç›®æ ‡æŒä»“...")
        
        try:
            if self.factor_data is None or self.factor_data.empty:
                self.logger.error("å› å­æ•°æ®ä¸ºç©º")
                return False
            
            # è¿‡æ»¤å½“æ—¥æ•°æ®
            latest_date = pd.to_datetime(self.factor_data['trade_date']).max()
            day_data = self.factor_data[
                pd.to_datetime(self.factor_data['trade_date']) == latest_date
            ]
            
            if day_data.empty:
                self.logger.error("å½“æ—¥æ•°æ®ä¸ºç©º")
                return False

            # æ ‡è®°æ˜¯å¦ä¸ºå½“å‰æŒä»“ï¼ˆç”¨äºæŒè‚¡æƒ¯æ€§åŠ åˆ†/è§£é‡Šï¼‰
            if 'stock_code' in day_data.columns:
                holding_set = set(self.current_positions.keys())
                day_data = day_data.copy()
                day_data['is_holding'] = day_data['stock_code'].astype(str).isin(holding_set)

            # è®¡ç®— IC ç›‘æ§ï¼ˆç”¨äºæŠ¥å‘Š + å› å­åœ¨çº¿è‡ªé€‚åº”ï¼‰
            ic_results = self._compute_ic_results()
            if hasattr(self.report_generator, "set_ic_results") and ic_results is not None and not ic_results.empty:
                self.report_generator.set_ic_results(ic_results)
            
            # åº”ç”¨å¸‚åœºçŠ¶æ€è‡ªé€‚åº”æƒé‡ï¼ˆè‹¥å¯ç”¨ï¼‰
            try:
                if hasattr(self.strategy, 'apply_adaptive_weights') and self.benchmark_data is not None:
                    self.strategy.apply_adaptive_weights(index_data=self.benchmark_data, date=latest_date)
            except Exception as e:
                self.logger.warning(f"è‡ªé€‚åº”æƒé‡åº”ç”¨å¤±è´¥ï¼ˆå¿½ç•¥å¹¶é™çº§ï¼‰: {e}")

            # IC ç†”æ–­ï¼šå¼±é¢„æµ‹åŠ›å› å­è‡ªåŠ¨é™æƒï¼ˆé¿å…â€œå¤±æ•ˆå› å­æ‹–ç´¯â€ï¼‰
            try:
                ic_cfg = self.config.get("ic_monitor", {})
                if ic_cfg.get("enabled", False) and ic_cfg.get("circuit_breaker_enabled", False):
                    if hasattr(self.strategy, "apply_factor_circuit_breaker") and ic_results is not None and not ic_results.empty:
                        self.strategy.apply_factor_circuit_breaker(
                            ic_results=ic_results,
                            ic_threshold=float(ic_cfg.get("circuit_breaker_ic_threshold", 0.005)),
                            ir_threshold=float(ic_cfg.get("circuit_breaker_ir_threshold", 0.2))
                        )
            except Exception as e:
                self.logger.warning(f"å› å­ç†”æ–­åº”ç”¨å¤±è´¥ï¼ˆå¿½ç•¥å¹¶é™çº§ï¼‰: {e}")

            # IC æ–¹å‘æ ¡å‡†ï¼šIC ä¸ºè´Ÿæ—¶è‡ªåŠ¨åå‘ä½¿ç”¨ï¼ˆæŠŠâ€œåå‘é¢„æµ‹åŠ›â€è½¬æˆ alphaï¼‰
            try:
                dir_cfg = self.config.get("ic_monitor", {}).get("directional_adjustment", {})
                if dir_cfg.get("enabled", True):
                    if hasattr(self.strategy, "apply_factor_direction_from_ic") and ic_results is not None and not ic_results.empty:
                        self.strategy.apply_factor_direction_from_ic(
                            ic_results=ic_results,
                            abs_ic_threshold=float(dir_cfg.get("abs_ic_threshold", 0.02)),
                            ir_threshold=float(dir_cfg.get("ir_threshold", 0.3)),
                            positive_ratio_threshold=float(dir_cfg.get("positive_ratio_threshold", 0.55))
                        )
            except Exception as e:
                self.logger.warning(f"å› å­æ–¹å‘æ ¡å‡†å¤±è´¥ï¼ˆå¿½ç•¥å¹¶é™çº§ï¼‰: {e}")
            
            # å®ç›˜å¯äº¤æ˜“æ€§è¿‡æ»¤ï¼ˆæ¶¨è·Œåœ/ä¸€å­—æ¿/æµåŠ¨æ€§/STç­‰ï¼‰
            try:
                if hasattr(self.strategy, 'filter_stocks'):
                    filtered_day_data = self.strategy.filter_stocks(day_data, date=latest_date)
                else:
                    filtered_day_data = day_data
            except Exception as e:
                self.logger.warning(f"è¿‡æ»¤å™¨æ‰§è¡Œå¤±è´¥ï¼ˆå¿½ç•¥å¹¶é™çº§ï¼‰: {e}")
                filtered_day_data = day_data

            # è¡Œä¸šæ˜ å°„ï¼ˆç”¨äºè¡Œä¸šåˆ†æ•£/é»‘åå•ï¼›è‹¥å¤±è´¥è‡ªåŠ¨é™çº§ï¼‰
            try:
                industry_cfg = self.config.get("strategy", {}).get("industry_constraints", {})
                if industry_cfg.get("enabled", False) and 'stock_code' in filtered_day_data.columns:
                    source = str(industry_cfg.get("source", "tushare_industry"))
                    if source.lower().startswith("sw"):
                        level = int(industry_cfg.get("sw_level", 1))
                        industry_map = self.tushare_loader.fetch_sw_industry_mapping(level=level)
                    else:
                        industry_map = self.tushare_loader.fetch_industry_mapping(use_cache=True)

                    if industry_map:
                        filtered_day_data = filtered_day_data.copy()
                        filtered_day_data['industry'] = filtered_day_data['stock_code'].astype(str).map(industry_map)
            except Exception as e:
                self.logger.warning(f"è¡Œä¸šæ˜ å°„å¤±è´¥ï¼ˆå¿½ç•¥å¹¶é™çº§ï¼‰: {e}")
            
            # é€‰è‚¡
            selected_stocks = self.strategy.select_top_stocks(
                filtered_day_data,
                n=self.strategy.top_n,
                date=latest_date
            )
            
            if not selected_stocks:
                self.logger.warning("æœªé€‰å‡ºä»»ä½•è‚¡ç¥¨")
                self.target_positions = {}
                return True

            # é€‰è‚¡è§£é‡Šæ•°æ®ï¼ˆç”¨äºæŠ¥å‘Šå±•ç¤ºï¼šåˆ†æ•°åˆ†è§£ã€å…³é”®å› å­å€¼ï¼‰
            self._selection_details = self._build_selection_details(
                day_data=filtered_day_data,
                selected_stocks=selected_stocks
            )
            
            # ç”Ÿæˆç­‰æƒé‡æŒä»“
            portfolio_config = self.config.get("portfolio", {})
            total_capital = portfolio_config.get("total_capital", 300000)

            # åŠ¨æ€ä»“ä½ï¼šå¼±å¸‚/é«˜æ³¢åŠ¨ç•™ç°é‡‘ï¼ˆposition_scale ç”±ç­–ç•¥è‡ªé€‚åº”æ¨¡å—æä¾›ï¼‰
            try:
                pos_scale = self.strategy.get_position_scale() if hasattr(self.strategy, "get_position_scale") else 1.0
            except Exception:
                pos_scale = 1.0

            invested_capital = float(total_capital) * float(np.clip(pos_scale, 0.0, 1.0))
            weight = invested_capital / len(selected_stocks)
            
            self.target_positions = {
                stock: weight
                for stock in selected_stocks
            }
            
            self.logger.info(
                f"ç›®æ ‡æŒä»“ç”Ÿæˆå®Œæˆ: {len(self.target_positions)} åªè‚¡ç¥¨, "
                f"ä»“ä½ç³»æ•° {pos_scale:.0%}, æ¯åªçº¦ Â¥{weight:,.0f}"
            )
            
            return True
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆç›®æ ‡æŒä»“å¤±è´¥: {e}")
            return False

    def _build_selection_details(
        self,
        day_data: pd.DataFrame,
        selected_stocks: List[str]
    ) -> pd.DataFrame:
        """
        æ„å»ºé€‰è‚¡æ‰“åˆ†æ˜ç»†ï¼ˆç”¨äºæŠ¥å‘Šè§£é‡Šï¼‰
        
        Parameters
        ----------
        day_data : pd.DataFrame
            å½“æ—¥æ•°æ®ï¼ˆå·²è¿‡æ»¤åçš„æ¨ªæˆªé¢ï¼‰
        selected_stocks : List[str]
            å…¥é€‰è‚¡ç¥¨åˆ—è¡¨
        
        Returns
        -------
        pd.DataFrame
            é€‰è‚¡æ˜ç»†è¡¨
        """
        if day_data is None or day_data.empty:
            return pd.DataFrame()
        
        stock_col = 'stock_code' if 'stock_code' in day_data.columns else None
        if stock_col is None:
            return pd.DataFrame()
        
        # å…ˆåšæ—¥çº§å»é‡ï¼Œé¿å…åŒä¸€è‚¡ç¥¨å¤šè¡Œå½±å“å½’ä¸€åŒ–
        full_df = day_data.copy()
        if 'trade_date' in full_df.columns:
            full_df = full_df.sort_values('trade_date', ascending=False)
        full_df = full_df.drop_duplicates(subset=[stock_col], keep='first')
        
        # ===== ä»ç¼“å­˜è¯»å–æƒ…ç»ªï¼ˆä¸é¢å¤–è°ƒç”¨LLMï¼‰=====
        date_str = None
        if 'trade_date' in full_df.columns:
            try:
                date_str = pd.to_datetime(full_df['trade_date']).max().strftime('%Y-%m-%d')
            except Exception:
                date_str = None
        if date_str is None:
            date_str = pd.Timestamp.now().strftime('%Y-%m-%d')
        
        sentiment_df = self._load_sentiment_cache_for_date(date_str)
        sentiment_scores: Optional[pd.Series] = None
        if not sentiment_df.empty:
            sentiment_scores = pd.Series(
                sentiment_df['score'].values,
                index=sentiment_df['stock_code'].astype(str).values
            )
        
        # åˆ†é¡¹è´¡çŒ®ï¼šç”¨â€œåŒä¸€æ‰¹å€™é€‰æ¨ªæˆªé¢â€åšå½’ä¸€åŒ–ï¼Œé¿å…åªåœ¨å…¥é€‰é›†åˆä¸Šç¼©æ”¾
        try:
            score_ret = self.strategy.calculate_total_score(
                full_df,
                sentiment_scores=sentiment_scores,
                return_components=True
            )
            total_score, components = score_ret  # type: ignore[misc]
        except Exception as e:
            self.logger.warning(f"é€‰è‚¡åˆ†æ•°åˆ†è§£å¤±è´¥: {e}")
            total_score = pd.Series(0.0, index=full_df.index)
            components = {}
        
        full_df['base_score'] = total_score
        for name, series in components.items():
            full_df[f'contrib_{name}'] = series
        
        # ç»‘å®šç¼“å­˜ä¸­çš„æƒ…ç»ªåˆ†ä¸ç½®ä¿¡åº¦ï¼ˆåŸå§‹å€¼ï¼Œä¾¿äºè§£é‡Šï¼‰
        if not sentiment_df.empty:
            tmp = sentiment_df.copy()
            tmp['stock_code'] = tmp['stock_code'].astype(str)
            full_df[stock_col] = full_df[stock_col].astype(str)
            full_df = full_df.merge(
                tmp[['stock_code', 'score', 'confidence', 'category', 'summary']],
                left_on=stock_col,
                right_on='stock_code',
                how='left',
                suffixes=('', '_sent')
            )
            full_df = full_df.rename(columns={
                'score': 'sentiment_score',
                'confidence': 'sentiment_confidence',
                'category': 'sentiment_category',
                'summary': 'sentiment_summary',
            })
        
        sel_df = full_df[full_df[stock_col].astype(str).isin([str(s) for s in selected_stocks])].copy()
        if sel_df.empty:
            return pd.DataFrame()
        
        # å…³é”®åˆ—ï¼ˆè‹¥å­˜åœ¨åˆ™ä¿ç•™ï¼‰
        keep_cols = [
            'trade_date', 'stock_code', 'name', 'close', 'amount', 'pct_change',
            'industry',
            self.strategy.value_col, self.strategy.quality_col, self.strategy.momentum_col, self.strategy.size_col,
            'quality_composite_zscore', 'momentum_composite_zscore', 'value_composite_zscore',
            'turnover_5d_zscore', 'volatility_20_zscore', 'efficiency_20_zscore',
            'sentiment_score', 'sentiment_confidence', 'sentiment_category',
            'is_holding', 'base_score',
            'contrib_value', 'contrib_quality', 'contrib_momentum', 'contrib_size',
            'contrib_sentiment',
        ]
        existing_cols = [c for c in keep_cols if c in sel_df.columns]
        sel_df = sel_df[existing_cols]
        
        # ç»Ÿä¸€ä¸ºå­—ç¬¦ä¸²ä»£ç å¹¶æ’åº
        sel_df['stock_code'] = sel_df['stock_code'].astype(str)
        sel_df = sel_df.sort_values('base_score', ascending=False, kind='mergesort')
        sel_df = sel_df.drop_duplicates(subset=['stock_code'], keep='first')
        
        return sel_df.reset_index(drop=True)

    def _load_sentiment_cache_for_date(self, date_str: str) -> pd.DataFrame:
        """
        ä» sentiment_cache.json è¯»å–æŒ‡å®šæ—¥æœŸçš„æƒ…ç»ªç»“æœï¼ˆä¸è§¦å‘LLMè¯·æ±‚ï¼‰
        
        ç¼“å­˜é”®æ ¼å¼: "{stock_code}_{YYYY-MM-DD}"
        
        Parameters
        ----------
        date_str : str
            æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)
        
        Returns
        -------
        pd.DataFrame
            åˆ—: stock_code, score, confidence, category, summary
        """
        llm_cfg = self.config.get("llm", {})
        cache_path = llm_cfg.get("cache_path", "data/processed/sentiment_cache.json")
        path = Path(cache_path)
        if not path.exists():
            return pd.DataFrame()
        
        try:
            with open(path, "r", encoding="utf-8") as f:
                raw = json.load(f)
        except Exception as e:
            self.logger.warning(f"è¯»å–æƒ…ç»ªç¼“å­˜å¤±è´¥: {e}")
            return pd.DataFrame()
        
        records: List[Dict[str, Any]] = []
        suffix = f"_{date_str}"
        for k, v in raw.items():
            if not isinstance(k, str) or not k.endswith(suffix):
                continue
            stock_code = k[: -len(suffix)]
            if not stock_code:
                continue
            if not isinstance(v, dict):
                continue
            records.append({
                "stock_code": str(stock_code),
                "score": float(v.get("score", 0.0)),
                "confidence": float(v.get("confidence", 0.0)),
                "category": str(v.get("category", "")),
                "summary": str(v.get("summary", "")),
            })
        
        if not records:
            return pd.DataFrame()
        
        df = pd.DataFrame(records)
        df = df.drop_duplicates(subset=["stock_code"], keep="last")
        return df
    
    def calculate_trade_orders(self) -> tuple:
        """
        è®¡ç®—äº¤æ˜“è®¢å•ï¼ˆå¢å¼ºç‰ˆï¼‰
        
        åŠŸèƒ½ï¼š
        1. åº”ç”¨æ¢ä»“ç¼“å†²å¸¦ï¼ˆå‡å°‘ä¸å¿…è¦äº¤æ˜“ï¼‰
        2. å¯æ‰§è¡Œæ€§æ£€æŸ¥ï¼ˆåœç‰Œ/æ¶¨è·Œåœ/æµåŠ¨æ€§ï¼‰
        3. äº¤æ˜“æˆæœ¬ä¼°ç®—
        4. æ‰§è¡Œä¼˜å…ˆçº§æ’åºï¼ˆå…ˆå–åä¹°ï¼‰
        
        Returns
        -------
        tuple
            (buy_orders, sell_orders, order_details)
        """
        buy_orders: Dict[str, float] = {}
        sell_orders: Dict[str, float] = {}
        
        # è·å–é…ç½®å‚æ•°
        strategy_config = self.config.get("strategy", {})
        trading_config = self.config.get("trading", {})
        portfolio_config = self.config.get("portfolio", {})
        
        rebalance_buffer = strategy_config.get("rebalance_buffer", 0.05)
        min_trade_amount = trading_config.get("min_trade_amount", 5000)  # æœ€å°äº¤æ˜“é‡‘é¢
        commission_rate = trading_config.get("commission_rate", 0.0003)
        stamp_duty = trading_config.get("stamp_duty", 0.001)
        min_commission = 5.0  # Aè‚¡æœ€ä½ä½£é‡‘
        total_capital = portfolio_config.get("total_capital", 300000)
        
        # è·å–å½“æ—¥è¡Œæƒ…æ•°æ®ç”¨äºå¯æ‰§è¡Œæ€§æ£€æŸ¥
        latest_data = self._get_latest_market_data()
        
        # åˆå§‹åŒ–è®¢å•è¯¦æƒ…
        self._order_details: Dict[str, Dict[str, Any]] = {}
        
        # ========================================
        # Step 1: è®¡ç®—åŸå§‹å·®é¢
        # ========================================
        raw_buy_orders: Dict[str, float] = {}
        raw_sell_orders: Dict[str, float] = {}
        
        # å–å‡ºï¼šå½“å‰æŒæœ‰ä½†ç›®æ ‡ä¸æŒæœ‰æˆ–éœ€è¦å‡ä»“çš„è‚¡ç¥¨
        for stock, current_amount in self.current_positions.items():
            target_amount = self.target_positions.get(stock, 0)
            if target_amount < current_amount:
                raw_sell_orders[stock] = current_amount - target_amount
        
        # ä¹°å…¥ï¼šç›®æ ‡æŒæœ‰ä½†å½“å‰ä¸æŒæœ‰æˆ–éœ€è¦åŠ ä»“çš„è‚¡ç¥¨
        for stock, target_amount in self.target_positions.items():
            current_amount = self.current_positions.get(stock, 0)
            if target_amount > current_amount:
                raw_buy_orders[stock] = target_amount - current_amount
        
        # ========================================
        # Step 2: åº”ç”¨æ¢ä»“ç¼“å†²å¸¦
        # ========================================
        for stock, amount in raw_sell_orders.items():
            current_amount = self.current_positions.get(stock, 0)
            if current_amount > 0:
                drift_ratio = amount / current_amount
                if drift_ratio > rebalance_buffer:
                    sell_orders[stock] = amount
                    self.logger.debug(f"å–å‡º {stock}: åç§» {drift_ratio:.1%} > ç¼“å†² {rebalance_buffer:.1%}")
                else:
                    self.logger.debug(f"è·³è¿‡å–å‡º {stock}: åç§» {drift_ratio:.1%} <= ç¼“å†² {rebalance_buffer:.1%}")
            else:
                sell_orders[stock] = amount
        
        for stock, amount in raw_buy_orders.items():
            target_amount = self.target_positions.get(stock, 0)
            if target_amount > 0:
                drift_ratio = amount / target_amount
                # ä¹°å…¥ä½¿ç”¨æ›´å®½æ¾çš„ç¼“å†²ï¼ˆæ–°å»ºä»“ä½é™¤å¤–ï¼‰
                current_amount = self.current_positions.get(stock, 0)
                if current_amount == 0 or drift_ratio > rebalance_buffer:
                    buy_orders[stock] = amount
                else:
                    self.logger.debug(f"è·³è¿‡ä¹°å…¥ {stock}: åç§» {drift_ratio:.1%} <= ç¼“å†² {rebalance_buffer:.1%}")
            else:
                buy_orders[stock] = amount
        
        # ========================================
        # Step 3: è¿‡æ»¤æœ€å°äº¤æ˜“é‡‘é¢
        # ========================================
        buy_orders = {k: v for k, v in buy_orders.items() if v >= min_trade_amount}
        sell_orders = {k: v for k, v in sell_orders.items() if v >= min_trade_amount}
        
        # ========================================
        # Step 4: å¯æ‰§è¡Œæ€§æ£€æŸ¥ä¸äº¤æ˜“æˆæœ¬ä¼°ç®—
        # ========================================
        for stock, amount in {**sell_orders, **buy_orders}.items():
            is_buy = stock in buy_orders
            detail = self._check_executability(stock, amount, is_buy, latest_data)
            detail['amount'] = amount
            detail['side'] = 'BUY' if is_buy else 'SELL'
            
            # ä¼°ç®—äº¤æ˜“æˆæœ¬
            cost = self._estimate_trade_cost(amount, is_buy, commission_rate, stamp_duty, min_commission)
            detail.update(cost)
            
            self._order_details[stock] = detail
        
        # ========================================
        # Step 5: æ‰§è¡Œä¼˜å…ˆçº§æ’åºï¼ˆå…ˆå–åä¹°ï¼ŒæŒ‰æµåŠ¨æ€§æ’åºï¼‰
        # ========================================
        # å–å‡ºæŒ‰æµåŠ¨æ€§ä»é«˜åˆ°ä½ï¼ˆä¼˜å…ˆå–å‡ºæµåŠ¨æ€§å¥½çš„ï¼‰
        sell_orders = dict(sorted(
            sell_orders.items(),
            key=lambda x: self._order_details.get(x[0], {}).get('daily_amount', 0),
            reverse=True
        ))
        
        # ä¹°å…¥æŒ‰æµåŠ¨æ€§ä»é«˜åˆ°ä½
        buy_orders = dict(sorted(
            buy_orders.items(),
            key=lambda x: self._order_details.get(x[0], {}).get('daily_amount', 0),
            reverse=True
        ))
        
        # ç»Ÿè®¡
        executable_count = sum(1 for d in self._order_details.values() if d.get('is_executable', True))
        total_count = len(self._order_details)
        self.logger.info(
            f"äº¤æ˜“è®¢å•è®¡ç®—å®Œæˆ: ä¹°å…¥ {len(buy_orders)} åª, å–å‡º {len(sell_orders)} åª, "
            f"å¯æ‰§è¡Œ {executable_count}/{total_count}"
        )
        
        return buy_orders, sell_orders
    
    def _get_latest_market_data(self) -> Dict[str, Dict[str, Any]]:
        """è·å–æœ€æ–°å¸‚åœºæ•°æ®ç”¨äºå¯æ‰§è¡Œæ€§æ£€æŸ¥"""
        result = {}
        
        if self.factor_data is None or self.factor_data.empty:
            return result
        
        latest_date = pd.to_datetime(self.factor_data['trade_date']).max()
        latest_df = self.factor_data[
            pd.to_datetime(self.factor_data['trade_date']) == latest_date
        ]
        
        for _, row in latest_df.iterrows():
            stock = str(row.get('stock_code', ''))
            if not stock:
                continue
            
            result[stock] = {
                'close': row.get('close', 0),
                'high': row.get('high', 0),
                'low': row.get('low', 0),
                'open': row.get('open', 0),
                'volume': row.get('volume', 0),
                'amount': row.get('amount', 0),
                'pct_change': row.get('pct_change', row.get('pctChg', 0)),
                'turnover_rate': row.get('turnover_rate', 0),
                'name': row.get('name', row.get('stock_name', '')),
                'is_suspended': row.get('is_suspended', False),
            }
        
        return result
    
    def _check_executability(
        self,
        stock: str,
        amount: float,
        is_buy: bool,
        market_data: Dict[str, Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        æ£€æŸ¥è®¢å•å¯æ‰§è¡Œæ€§
        
        Returns
        -------
        Dict[str, Any]
            åŒ…å«å¯æ‰§è¡Œæ€§çŠ¶æ€å’ŒåŸå› 
        """
        result = {
            'is_executable': True,
            'executability_issues': [],
            'daily_amount': 0,
            'impact_ratio': 0,
        }
        
        data = market_data.get(stock, {})
        
        if not data:
            result['is_executable'] = True  # æ— æ•°æ®æ—¶é»˜è®¤å¯æ‰§è¡Œï¼Œäººå·¥ç¡®è®¤
            result['executability_issues'].append('âš ï¸ æ— æœ€æ–°è¡Œæƒ…æ•°æ®')
            return result
        
        daily_amount = data.get('amount', 0)
        result['daily_amount'] = daily_amount
        
        # 1. åœç‰Œæ£€æŸ¥
        if data.get('is_suspended', False) or data.get('volume', 0) == 0:
            result['is_executable'] = False
            result['executability_issues'].append('ğŸš« åœç‰Œ')
        
        # 2. æ¶¨è·Œåœæ£€æŸ¥
        pct_change = data.get('pct_change', 0)
        high = data.get('high', 0)
        low = data.get('low', 0)
        close = data.get('close', 0)
        
        # åˆ¤æ–­æ˜¯å¦æ¶¨åœï¼ˆæ¶¨å¹…>=9.5% ä¸” æœ€é«˜=æœ€ä½=æ”¶ç›˜ï¼Œæˆ–è€…æ¶¨å¹…>=9.5%ä¸”æ˜¯ä¹°å…¥ï¼‰
        if pct_change >= 9.5:
            if high == low == close:
                result['is_executable'] = False
                result['executability_issues'].append('ğŸ”´ ä¸€å­—æ¶¨åœ(æ— æ³•ä¹°å…¥)')
            elif is_buy:
                result['executability_issues'].append('âš ï¸ æ¶¨åœ(å¯èƒ½æ— æ³•ä¹°å…¥)')
        
        # åˆ¤æ–­æ˜¯å¦è·Œåœ
        if pct_change <= -9.5:
            if high == low == close:
                result['is_executable'] = False
                result['executability_issues'].append('ğŸŸ¢ ä¸€å­—è·Œåœ(æ— æ³•å–å‡º)')
            elif not is_buy:
                result['executability_issues'].append('âš ï¸ è·Œåœ(å¯èƒ½æ— æ³•å–å‡º)')
        
        # 3. æµåŠ¨æ€§æ£€æŸ¥
        if daily_amount > 0:
            impact_ratio = amount / daily_amount
            result['impact_ratio'] = impact_ratio

            trading_cfg = self.config.get("trading", {})
            max_impact_ratio = float(trading_cfg.get("max_impact_ratio", 0.10))
            warn_impact_ratio = min(0.05, max_impact_ratio)

            if impact_ratio > warn_impact_ratio:
                result['executability_issues'].append(f'âš ï¸ å†²å‡»æˆæœ¬é«˜({impact_ratio:.1%})')
            if impact_ratio > max_impact_ratio:
                result['is_executable'] = False
                result['executability_issues'].append(f'ğŸš« æµåŠ¨æ€§ä¸è¶³({impact_ratio:.1%})')
        else:
            result['executability_issues'].append('âš ï¸ æ— æˆäº¤é¢æ•°æ®')
        
        # 4. ST/é€€å¸‚æ£€æŸ¥
        name = data.get('name', '')
        st_keywords = ('ST', '*ST', 'é€€', 'S', 'PT')
        if any(kw in str(name) for kw in st_keywords):
            result['executability_issues'].append('âš ï¸ ST/é€€å¸‚é£é™©')
        
        return result
    
    def _estimate_trade_cost(
        self,
        amount: float,
        is_buy: bool,
        commission_rate: float = 0.0003,
        stamp_duty: float = 0.001,
        min_commission: float = 5.0
    ) -> Dict[str, float]:
        """
        ä¼°ç®—äº¤æ˜“æˆæœ¬
        
        Returns
        -------
        Dict[str, float]
            äº¤æ˜“æˆæœ¬æ˜ç»†
        """
        # ä½£é‡‘ï¼ˆæœ€ä½5å…ƒï¼‰
        commission = max(amount * commission_rate, min_commission)
        
        # å°èŠ±ç¨ï¼ˆä»…å–å‡ºï¼‰
        stamp = amount * stamp_duty if not is_buy else 0
        
        # æ»‘ç‚¹ï¼ˆå‡è®¾0.1%ï¼‰
        slippage_rate = self.config.get("trading", {}).get("slippage", 0.001)
        slippage = amount * slippage_rate
        
        total_cost = commission + stamp + slippage
        
        return {
            'commission': commission,
            'stamp_duty': stamp,
            'slippage': slippage,
            'total_cost': total_cost,
            'cost_rate': total_cost / amount if amount > 0 else 0,
        }
    
    def generate_report(
        self,
        buy_orders: Dict[str, float],
        sell_orders: Dict[str, float],
        format: str = "markdown"
    ) -> str:
        """ç”Ÿæˆå¢å¼ºç‰ˆæŠ¥å‘Šï¼ˆå«äº¤æ˜“æˆæœ¬ã€å¯æ‰§è¡Œæ€§ã€é£æ§ä¿¡æ¯ï¼‰"""
        strategy_info = {
            'name': self.strategy.name,
            'value_weight': self.strategy.value_weight,
            'quality_weight': self.strategy.quality_weight,
            'momentum_weight': self.strategy.momentum_weight,
            'size_weight': getattr(self.strategy, 'size_weight', 0),
            'top_n': self.strategy.top_n,
        }
        
        # è·å–è®¢å•è¯¦æƒ…
        order_details = getattr(self, '_order_details', {})
        selection_details = getattr(self, '_selection_details', pd.DataFrame())
        
        # è·å–é£æ§çŠ¶æ€
        risk_status = self._get_risk_status()
        
        # ç”Ÿæˆå¢å¼ºç‰ˆæŠ¥å‘Š
        return self._generate_enhanced_report(
            buy_orders=buy_orders,
            sell_orders=sell_orders,
            target_positions=self.target_positions,
            strategy_info=strategy_info,
            order_details=order_details,
            selection_details=selection_details,
            risk_status=risk_status,
            report_date=self.today.strftime('%Y-%m-%d'),
            format=format
        )
    
    def _get_risk_status(self) -> Dict[str, Any]:
        """è·å–é£æ§çŠ¶æ€"""
        risk_status = {
            'market_risk_triggered': False,
            'market_risk_reason': '',
            'factor_breaker_triggered': [],
            'position_drift': 0.0,
        }
        
        # æ£€æŸ¥å¤§ç›˜é£æ§
        risk_config = self.config.get("risk", {}).get("market_risk", {})
        if risk_config.get("enabled", True) and self.benchmark_data is not None:
            try:
                benchmark_df = self.benchmark_data.copy()
                if not isinstance(benchmark_df.index, pd.DatetimeIndex):
                    if 'trade_date' in benchmark_df.columns:
                        benchmark_df['trade_date'] = pd.to_datetime(benchmark_df['trade_date'])
                        benchmark_df = benchmark_df.set_index('trade_date')
                
                benchmark_df = benchmark_df.sort_index()
                
                ma_period = risk_config.get("ma_period", 60)
                drop_threshold = risk_config.get("drop_threshold", 0.10)
                drop_lookback = risk_config.get("drop_lookback", 20)
                
                if len(benchmark_df) >= ma_period:
                    latest_close = benchmark_df['close'].iloc[-1]
                    ma_value = benchmark_df['close'].rolling(ma_period).mean().iloc[-1]
                    
                    # æ£€æŸ¥æ˜¯å¦è·Œç ´å‡çº¿
                    below_ma = latest_close < ma_value
                    
                    # æ£€æŸ¥å›æ’¤
                    if len(benchmark_df) >= drop_lookback:
                        lookback_high = benchmark_df['close'].iloc[-drop_lookback:].max()
                        drawdown = (latest_close - lookback_high) / lookback_high
                        
                        if below_ma and drawdown < -drop_threshold:
                            risk_status['market_risk_triggered'] = True
                            risk_status['market_risk_reason'] = (
                                f"æŒ‡æ•°è·Œç ´{ma_period}æ—¥å‡çº¿ ä¸” "
                                f"{drop_lookback}æ—¥å›æ’¤ {drawdown:.1%} < -{drop_threshold:.0%}"
                            )
                        else:
                            risk_status['market_risk_reason'] = (
                                f"æŒ‡æ•°{'ä½äº' if below_ma else 'é«˜äº'}{ma_period}æ—¥å‡çº¿, "
                                f"å›æ’¤ {drawdown:.1%}"
                            )
            except Exception as e:
                self.logger.warning(f"é£æ§çŠ¶æ€æ£€æŸ¥å¤±è´¥: {e}")
        
        return risk_status
    
    def _generate_enhanced_report(
        self,
        buy_orders: Dict[str, float],
        sell_orders: Dict[str, float],
        target_positions: Dict[str, float],
        strategy_info: Dict[str, Any],
        order_details: Dict[str, Dict[str, Any]],
        selection_details: pd.DataFrame,
        risk_status: Dict[str, Any],
        report_date: str,
        format: str = "markdown"
    ) -> str:
        """ç”Ÿæˆå¢å¼ºç‰ˆæŠ¥å‘Š"""
        portfolio_config = self.config.get("portfolio", {})
        total_capital = portfolio_config.get("total_capital", 300000)
        
        # è®¡ç®—æ±‡æ€»ç»Ÿè®¡
        total_buy = sum(buy_orders.values())
        total_sell = sum(sell_orders.values())
        total_cost = sum(d.get('total_cost', 0) for d in order_details.values())
        executable_count = sum(1 for d in order_details.values() if d.get('is_executable', True))
        
        if format == "html":
            return self._generate_enhanced_html_report(
                buy_orders, sell_orders, target_positions, strategy_info,
                order_details, selection_details, risk_status, report_date, total_capital,
                total_buy, total_sell, total_cost, executable_count
            )
        else:
            return self._generate_enhanced_markdown_report(
                buy_orders, sell_orders, target_positions, strategy_info,
                order_details, selection_details, risk_status, report_date, total_capital,
                total_buy, total_sell, total_cost, executable_count
            )
    
    def _generate_enhanced_markdown_report(
        self,
        buy_orders: Dict[str, float],
        sell_orders: Dict[str, float],
        target_positions: Dict[str, float],
        strategy_info: Dict[str, Any],
        order_details: Dict[str, Dict[str, Any]],
        selection_details: pd.DataFrame,
        risk_status: Dict[str, Any],
        report_date: str,
        total_capital: float,
        total_buy: float,
        total_sell: float,
        total_cost: float,
        executable_count: int
    ) -> str:
        """ç”Ÿæˆå¢å¼ºç‰ˆ Markdown æŠ¥å‘Š"""
        lines = [
            f"# ğŸ“Š æ¯æ—¥è°ƒä»“æŠ¥å‘Š",
            f"",
            f"**æŠ¥å‘Šæ—¥æœŸ**: {report_date}",
            f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"",
        ]
        
        # ========== é£æ§çŠ¶æ€ ==========
        lines.extend([
            f"## ğŸ›¡ï¸ é£æ§çŠ¶æ€",
            f"",
        ])
        
        if risk_status.get('market_risk_triggered'):
            lines.extend([
                f"âš ï¸ **å¤§ç›˜é£æ§è§¦å‘**: {risk_status.get('market_risk_reason', '')}",
                f"",
                f"> å»ºè®®ï¼šé™ä½ä»“ä½æˆ–æš‚åœæ–°å¼€ä»“",
                f"",
            ])
        else:
            lines.extend([
                f"âœ… å¤§ç›˜é£æ§æœªè§¦å‘: {risk_status.get('market_risk_reason', 'æ­£å¸¸')}",
                f"",
            ])
        
        # ========== ç­–ç•¥æ¦‚è§ˆ ==========
        lines.extend([
            f"## ğŸ“ˆ ç­–ç•¥æ¦‚è§ˆ",
            f"",
            f"| æŒ‡æ ‡ | æ•°å€¼ |",
            f"|------|------|",
            f"| ç­–ç•¥åç§° | {strategy_info.get('name', 'N/A')} |",
            f"| æ€»èµ„é‡‘ | Â¥{total_capital:,.0f} |",
            f"| ç›®æ ‡æŒä»“æ•° | {len(target_positions)} |",
            f"| å¯æ‰§è¡Œè®¢å• | {executable_count}/{len(order_details)} |",
            f"| é¢„ä¼°æ€»æˆæœ¬ | Â¥{total_cost:,.0f} ({total_cost/total_capital*100:.2f}%) |",
            f"",
        ])
        
        # ========== å–å‡ºæ¸…å•ï¼ˆå…ˆå–åä¹°ï¼‰==========
        lines.extend([
            f"## ğŸ“‰ æ˜æ—¥éœ€å–å‡ºï¼ˆæŒ‰æµåŠ¨æ€§æ’åºï¼Œä¼˜å…ˆæ‰§è¡Œï¼‰",
            f"",
        ])
        
        if sell_orders:
            lines.extend([
                f"| è‚¡ç¥¨ä»£ç  | å–å‡ºé‡‘é¢ | ä½£é‡‘ | å°èŠ±ç¨ | æ€»æˆæœ¬ | å¯æ‰§è¡Œæ€§ |",
                f"|----------|----------|------|--------|--------|----------|",
            ])
            for stock, amount in sell_orders.items():
                detail = order_details.get(stock, {})
                commission = detail.get('commission', 0)
                stamp = detail.get('stamp_duty', 0)
                cost = detail.get('total_cost', 0)
                issues = detail.get('executability_issues', [])
                exec_status = 'âœ…' if detail.get('is_executable', True) else 'ğŸš«'
                if issues:
                    exec_status += ' ' + ' '.join(issues[:2])
                lines.append(f"| {stock} | Â¥{amount:,.0f} | Â¥{commission:.0f} | Â¥{stamp:.0f} | Â¥{cost:.0f} | {exec_status} |")
            lines.extend([
                f"",
                f"**å–å‡ºæ€»é‡‘é¢**: Â¥{total_sell:,.0f}",
                f"",
            ])
        else:
            lines.extend([f"*æ— éœ€å–å‡º*", f""])
        
        # ========== ä¹°å…¥æ¸…å• ==========
        lines.extend([
            f"## ğŸ“ˆ æ˜æ—¥éœ€ä¹°å…¥ï¼ˆæŒ‰æµåŠ¨æ€§æ’åºï¼‰",
            f"",
        ])
        
        if buy_orders:
            lines.extend([
                f"| è‚¡ç¥¨ä»£ç  | ä¹°å…¥é‡‘é¢ | ä½£é‡‘ | æ»‘ç‚¹ | æ€»æˆæœ¬ | å†²å‡»æ¯” | å¯æ‰§è¡Œæ€§ |",
                f"|----------|----------|------|------|--------|--------|----------|",
            ])
            for stock, amount in buy_orders.items():
                detail = order_details.get(stock, {})
                commission = detail.get('commission', 0)
                slippage = detail.get('slippage', 0)
                cost = detail.get('total_cost', 0)
                impact = detail.get('impact_ratio', 0)
                issues = detail.get('executability_issues', [])
                exec_status = 'âœ…' if detail.get('is_executable', True) else 'ğŸš«'
                if issues:
                    exec_status += ' ' + ' '.join(issues[:2])
                lines.append(f"| {stock} | Â¥{amount:,.0f} | Â¥{commission:.0f} | Â¥{slippage:.0f} | Â¥{cost:.0f} | {impact:.1%} | {exec_status} |")
            lines.extend([
                f"",
                f"**ä¹°å…¥æ€»é‡‘é¢**: Â¥{total_buy:,.0f}",
                f"",
            ])
        else:
            lines.extend([f"*æ— éœ€ä¹°å…¥*", f""])
        
        # ========== ç›®æ ‡æŒä»“ ==========
        lines.extend([
            f"## ğŸ“‹ ç›®æ ‡æŒä»“æ˜ç»†",
            f"",
            f"| è‚¡ç¥¨ä»£ç  | ç›®æ ‡é‡‘é¢ | æƒé‡ |",
            f"|----------|----------|------|",
        ])
        
        total_target = sum(target_positions.values()) if target_positions else 1
        for stock, amount in sorted(target_positions.items(), key=lambda x: -x[1]):
            weight = amount / total_target
            lines.append(f"| {stock} | Â¥{amount:,.0f} | {weight:.1%} |")

        # ========== é€‰è‚¡æ‰“åˆ†æ˜ç»† ==========
        if selection_details is not None and not selection_details.empty:
            lines.extend([
                "",
                "## ğŸ§® é€‰è‚¡æ‰“åˆ†æ˜ç»†ï¼ˆä¸å«LLMæƒ…ç»ªåŠ åˆ†ï¼‰",
                "",
                "| è‚¡ç¥¨ä»£ç  | æŒä»“? | base_score | è´¨é‡å¤åˆ | åŠ¨é‡å¤åˆ | ä»·å€¼å¤åˆ | æƒ…ç»ªåˆ† | ç½®ä¿¡åº¦ | è´¡çŒ®:è´¨é‡ | è´¡çŒ®:åŠ¨é‡ | è´¡çŒ®:å¸‚å€¼ | è´¡çŒ®:æƒ…ç»ª |",
                "|----------|-------|-----------|----------|----------|----------|--------|--------|----------|----------|----------|----------|",
            ])
            for _, row in selection_details.iterrows():
                stock = str(row.get('stock_code', ''))
                is_hold = "âœ…" if bool(row.get('is_holding', False)) else ""
                base_score = float(row.get('base_score', 0.0)) if not isinstance(row.get('base_score', 0.0), pd.Series) else 0.0
                
                # å®‰å…¨è·å–å› å­å€¼ï¼ˆé¿å… Series è½¬ float é”™è¯¯ï¼‰
                def safe_float(val, default=0.0):
                    if val is None or (isinstance(val, pd.Series) and val.empty):
                        return default
                    if isinstance(val, pd.Series):
                        return float(val.iloc[0]) if len(val) > 0 else default
                    try:
                        return float(val)
                    except (ValueError, TypeError):
                        return default
                
                q = safe_float(row.get('quality_composite_zscore', row.get(self.strategy.quality_col, 0.0)))
                m = safe_float(row.get('momentum_composite_zscore', row.get(self.strategy.momentum_col, 0.0)))
                v = safe_float(row.get('value_composite_zscore', row.get(self.strategy.value_col, 0.0)))
                s = safe_float(row.get('sentiment_score', 0.0))
                conf = safe_float(row.get('sentiment_confidence', 0.0))
                cq = safe_float(row.get('contrib_quality', 0.0))
                cm = safe_float(row.get('contrib_momentum', 0.0))
                cs = safe_float(row.get('contrib_size', 0.0))
                cse = safe_float(row.get('contrib_sentiment', 0.0))
                lines.append(
                    f"| {stock} | {is_hold} | {base_score:.3f} | {q:.2f} | {m:.2f} | {v:.2f} | "
                    f"{s:.2f} | {conf:.2f} | {cq:.3f} | {cm:.3f} | {cs:.3f} | {cse:.3f} |"
                )
        
        # ========== æ‰§è¡ŒSOPæé†’ ==========
        lines.extend([
            f"",
            f"## ğŸ“ æ‰§è¡ŒSOPæé†’",
            f"",
            f"1. **ç›˜å‰ç¡®è®¤**: æ£€æŸ¥æ ‡çš„æ˜¯å¦åœç‰Œ/æ¶¨è·Œåœ/ä¸€å­—æ¿",
            f"2. **æ‰§è¡Œé¡ºåº**: å…ˆå–åä¹°ï¼Œä¼˜å…ˆå¤„ç†æµåŠ¨æ€§å¥½çš„æ ‡çš„",
            f"3. **éƒ¨åˆ†æˆäº¤**: å¦‚æ— æ³•å®Œå…¨æˆäº¤ï¼Œè®°å½•å®é™…æˆäº¤é‡‘é¢",
            f"4. **æ”¶ç›˜å¯¹è´¦**: ä»åˆ¸å•†å¯¼å‡ºå®é™…æŒä»“ï¼Œæ›´æ–° `real_holdings.json`",
            f"",
            f"---",
            f"",
            f"*æœ¬æŠ¥å‘Šç”± Aè‚¡é‡åŒ–äº¤æ˜“ç³»ç»Ÿ è‡ªåŠ¨ç”Ÿæˆ*",
        ])
        
        return "\n".join(lines)
    
    def _generate_enhanced_html_report(
        self,
        buy_orders: Dict[str, float],
        sell_orders: Dict[str, float],
        target_positions: Dict[str, float],
        strategy_info: Dict[str, Any],
        order_details: Dict[str, Dict[str, Any]],
        selection_details: pd.DataFrame,
        risk_status: Dict[str, Any],
        report_date: str,
        total_capital: float,
        total_buy: float,
        total_sell: float,
        total_cost: float,
        executable_count: int
    ) -> str:
        """ç”Ÿæˆå¢å¼ºç‰ˆ HTML æŠ¥å‘Š"""
        # ç”Ÿæˆå–å‡ºè¡¨æ ¼è¡Œ
        sell_rows = ""
        for stock, amount in sell_orders.items():
            detail = order_details.get(stock, {})
            commission = detail.get('commission', 0)
            stamp = detail.get('stamp_duty', 0)
            cost = detail.get('total_cost', 0)
            is_exec = detail.get('is_executable', True)
            issues = ' '.join(detail.get('executability_issues', [])[:2])
            row_class = '' if is_exec else 'not-executable'
            sell_rows += f'''
            <tr class="{row_class}">
                <td>{stock}</td>
                <td>Â¥{amount:,.0f}</td>
                <td>Â¥{commission:.0f}</td>
                <td>Â¥{stamp:.0f}</td>
                <td>Â¥{cost:.0f}</td>
                <td>{'âœ…' if is_exec else 'ğŸš«'} {issues}</td>
            </tr>'''
        
        # ç”Ÿæˆä¹°å…¥è¡¨æ ¼è¡Œ
        buy_rows = ""
        for stock, amount in buy_orders.items():
            detail = order_details.get(stock, {})
            commission = detail.get('commission', 0)
            slippage = detail.get('slippage', 0)
            cost = detail.get('total_cost', 0)
            impact = detail.get('impact_ratio', 0)
            is_exec = detail.get('is_executable', True)
            issues = ' '.join(detail.get('executability_issues', [])[:2])
            row_class = '' if is_exec else 'not-executable'
            buy_rows += f'''
            <tr class="{row_class}">
                <td>{stock}</td>
                <td>Â¥{amount:,.0f}</td>
                <td>Â¥{commission:.0f}</td>
                <td>Â¥{slippage:.0f}</td>
                <td>Â¥{cost:.0f}</td>
                <td>{impact:.1%}</td>
                <td>{'âœ…' if is_exec else 'ğŸš«'} {issues}</td>
            </tr>'''
        
        # ç”ŸæˆæŒä»“è¡¨æ ¼è¡Œ
        position_rows = ""
        total_target = sum(target_positions.values()) if target_positions else 1
        for stock, amount in sorted(target_positions.items(), key=lambda x: -x[1]):
            weight = amount / total_target
            position_rows += f"<tr><td>{stock}</td><td>Â¥{amount:,.0f}</td><td>{weight:.1%}</td></tr>"

        # é€‰è‚¡æ‰“åˆ†æ˜ç»†è¡¨æ ¼
        selection_rows = ""
        if selection_details is not None and not selection_details.empty:
            for _, row in selection_details.iterrows():
                stock = str(row.get('stock_code', ''))
                is_hold = "âœ…" if bool(row.get('is_holding', False)) else ""
                
                # å®‰å…¨è·å–å› å­å€¼ï¼ˆé¿å… Series è½¬ float é”™è¯¯ï¼‰
                def safe_float(val, default=0.0):
                    if val is None or (isinstance(val, pd.Series) and val.empty):
                        return default
                    if isinstance(val, pd.Series):
                        return float(val.iloc[0]) if len(val) > 0 else default
                    try:
                        return float(val)
                    except (ValueError, TypeError):
                        return default
                
                base_score = safe_float(row.get('base_score', 0.0))
                q = safe_float(row.get('quality_composite_zscore', row.get(self.strategy.quality_col, 0.0)))
                m = safe_float(row.get('momentum_composite_zscore', row.get(self.strategy.momentum_col, 0.0)))
                v = safe_float(row.get('value_composite_zscore', row.get(self.strategy.value_col, 0.0)))
                s = safe_float(row.get('sentiment_score', 0.0))
                conf = safe_float(row.get('sentiment_confidence', 0.0))
                cq = safe_float(row.get('contrib_quality', 0.0))
                cm = safe_float(row.get('contrib_momentum', 0.0))
                cs = safe_float(row.get('contrib_size', 0.0))
                cse = safe_float(row.get('contrib_sentiment', 0.0))
                selection_rows += (
                    f"<tr><td>{stock}</td><td>{is_hold}</td><td>{base_score:.3f}</td>"
                    f"<td>{q:.2f}</td><td>{m:.2f}</td><td>{v:.2f}</td>"
                    f"<td>{s:.2f}</td><td>{conf:.2f}</td>"
                    f"<td>{cq:.3f}</td><td>{cm:.3f}</td><td>{cs:.3f}</td><td>{cse:.3f}</td></tr>"
                )
        
        # é£æ§çŠ¶æ€æ˜¾ç¤º
        risk_class = "risk-alert" if risk_status.get('market_risk_triggered') else "risk-ok"
        risk_icon = "âš ï¸" if risk_status.get('market_risk_triggered') else "âœ…"
        risk_text = risk_status.get('market_risk_reason', 'æ­£å¸¸')
        
        selection_section = ""
        if selection_rows:
            selection_section = f"""
        <div class="card">
            <h2>ğŸ§® é€‰è‚¡æ‰“åˆ†æ˜ç»†ï¼ˆä¸å«LLMæƒ…ç»ªåŠ åˆ†ï¼‰</h2>
            <table>
                <thead>
                    <tr>
                        <th>è‚¡ç¥¨ä»£ç </th><th>æŒä»“?</th><th>base_score</th>
                        <th>è´¨é‡å¤åˆ</th><th>åŠ¨é‡å¤åˆ</th><th>ä»·å€¼å¤åˆ</th>
                        <th>æƒ…ç»ªåˆ†</th><th>ç½®ä¿¡åº¦</th>
                        <th>è´¡çŒ®:è´¨é‡</th><th>è´¡çŒ®:åŠ¨é‡</th><th>è´¡çŒ®:å¸‚å€¼</th>
                        <th>è´¡çŒ®:æƒ…ç»ª</th>
                    </tr>
                </thead>
                <tbody>{selection_rows}</tbody>
            </table>
        </div>
            """
        
        html = f'''
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>æ¯æ—¥è°ƒä»“æŠ¥å‘Š - {report_date}</title>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Arial, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            color: #eee;
            min-height: 100vh;
            padding: 2rem;
        }}
        .container {{ max-width: 1200px; margin: 0 auto; }}
        h1 {{
            font-size: 2.5rem;
            margin-bottom: 0.5rem;
            background: linear-gradient(90deg, #00d9ff, #00ff88);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }}
        .meta {{ color: #888; margin-bottom: 2rem; }}
        .card {{
            background: rgba(255, 255, 255, 0.05);
            border-radius: 12px;
            padding: 1.5rem;
            margin-bottom: 1.5rem;
            border: 1px solid rgba(255, 255, 255, 0.1);
        }}
        .card h2 {{ font-size: 1.3rem; margin-bottom: 1rem; color: #00d9ff; }}
        .card.sell h2 {{ color: #ff6b6b; }}
        .card.buy h2 {{ color: #00ff88; }}
        .card.risk-alert {{ border-color: #ff6b6b; background: rgba(255, 107, 107, 0.1); }}
        .card.risk-ok {{ border-color: #00ff88; }}
        .stats {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); gap: 1rem; }}
        .stat {{ text-align: center; padding: 1rem; background: rgba(0, 217, 255, 0.1); border-radius: 8px; }}
        .stat-value {{ font-size: 1.5rem; font-weight: bold; color: #00d9ff; }}
        .stat-label {{ font-size: 0.85rem; color: #888; margin-top: 0.25rem; }}
        table {{ width: 100%; border-collapse: collapse; font-size: 0.9rem; }}
        th, td {{ padding: 0.6rem; text-align: left; border-bottom: 1px solid rgba(255, 255, 255, 0.1); }}
        th {{ color: #888; font-weight: 500; }}
        tr:hover {{ background: rgba(255, 255, 255, 0.03); }}
        tr.not-executable {{ opacity: 0.6; background: rgba(255, 107, 107, 0.1); }}
        .total {{ margin-top: 1rem; padding-top: 1rem; border-top: 2px solid rgba(255, 255, 255, 0.1); font-weight: bold; }}
        .buy-total {{ color: #00ff88; }}
        .sell-total {{ color: #ff6b6b; }}
        .footer {{ text-align: center; color: #666; margin-top: 2rem; font-size: 0.85rem; }}
        .empty {{ text-align: center; color: #666; padding: 2rem; }}
        .sop {{ background: rgba(0, 217, 255, 0.05); padding: 1rem; border-radius: 8px; }}
        .sop li {{ margin: 0.5rem 0; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ“Š æ¯æ—¥è°ƒä»“æŠ¥å‘Š</h1>
        <p class="meta">æŠ¥å‘Šæ—¥æœŸ: {report_date} | ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        
        <div class="card {risk_class}">
            <h2>ğŸ›¡ï¸ é£æ§çŠ¶æ€</h2>
            <p>{risk_icon} {risk_text}</p>
        </div>
        
        <div class="card">
            <h2>ğŸ“ˆ ç­–ç•¥æ¦‚è§ˆ</h2>
            <div class="stats">
                <div class="stat">
                    <div class="stat-value">Â¥{total_capital:,.0f}</div>
                    <div class="stat-label">æ€»èµ„é‡‘</div>
                </div>
                <div class="stat">
                    <div class="stat-value">{len(target_positions)}</div>
                    <div class="stat-label">ç›®æ ‡æŒä»“æ•°</div>
                </div>
                <div class="stat">
                    <div class="stat-value">{executable_count}/{len(order_details)}</div>
                    <div class="stat-label">å¯æ‰§è¡Œè®¢å•</div>
                </div>
                <div class="stat">
                    <div class="stat-value">Â¥{total_cost:,.0f}</div>
                    <div class="stat-label">é¢„ä¼°æ€»æˆæœ¬</div>
                </div>
            </div>
        </div>
        
        <div class="card sell">
            <h2>ğŸ“‰ æ˜æ—¥éœ€å–å‡ºï¼ˆæŒ‰æµåŠ¨æ€§æ’åºï¼Œä¼˜å…ˆæ‰§è¡Œï¼‰</h2>
            {f"""
            <table>
                <thead><tr><th>è‚¡ç¥¨ä»£ç </th><th>å–å‡ºé‡‘é¢</th><th>ä½£é‡‘</th><th>å°èŠ±ç¨</th><th>æ€»æˆæœ¬</th><th>å¯æ‰§è¡Œæ€§</th></tr></thead>
                <tbody>{sell_rows}</tbody>
            </table>
            <p class="total sell-total">å–å‡ºæ€»é‡‘é¢: Â¥{total_sell:,.0f}</p>
            """ if sell_orders else '<p class="empty">æ— éœ€å–å‡º</p>'}
        </div>
        
        <div class="card buy">
            <h2>ğŸ“ˆ æ˜æ—¥éœ€ä¹°å…¥ï¼ˆæŒ‰æµåŠ¨æ€§æ’åºï¼‰</h2>
            {f"""
            <table>
                <thead><tr><th>è‚¡ç¥¨ä»£ç </th><th>ä¹°å…¥é‡‘é¢</th><th>ä½£é‡‘</th><th>æ»‘ç‚¹</th><th>æ€»æˆæœ¬</th><th>å†²å‡»æ¯”</th><th>å¯æ‰§è¡Œæ€§</th></tr></thead>
                <tbody>{buy_rows}</tbody>
            </table>
            <p class="total buy-total">ä¹°å…¥æ€»é‡‘é¢: Â¥{total_buy:,.0f}</p>
            """ if buy_orders else '<p class="empty">æ— éœ€ä¹°å…¥</p>'}
        </div>
        
        <div class="card">
            <h2>ğŸ“‹ ç›®æ ‡æŒä»“æ˜ç»†</h2>
            <table>
                <thead><tr><th>è‚¡ç¥¨ä»£ç </th><th>ç›®æ ‡é‡‘é¢</th><th>æƒé‡</th></tr></thead>
                <tbody>{position_rows}</tbody>
            </table>
        </div>

        {selection_section}
        
        <div class="card">
            <h2>ğŸ“ æ‰§è¡ŒSOPæé†’</h2>
            <ul class="sop">
                <li><strong>ç›˜å‰ç¡®è®¤</strong>: æ£€æŸ¥æ ‡çš„æ˜¯å¦åœç‰Œ/æ¶¨è·Œåœ/ä¸€å­—æ¿</li>
                <li><strong>æ‰§è¡Œé¡ºåº</strong>: å…ˆå–åä¹°ï¼Œä¼˜å…ˆå¤„ç†æµåŠ¨æ€§å¥½çš„æ ‡çš„</li>
                <li><strong>éƒ¨åˆ†æˆäº¤</strong>: å¦‚æ— æ³•å®Œå…¨æˆäº¤ï¼Œè®°å½•å®é™…æˆäº¤é‡‘é¢</li>
                <li><strong>æ”¶ç›˜å¯¹è´¦</strong>: ä»åˆ¸å•†å¯¼å‡ºå®é™…æŒä»“ï¼Œæ›´æ–° real_holdings.json</li>
            </ul>
        </div>
        
        <p class="footer">æœ¬æŠ¥å‘Šç”± Aè‚¡é‡åŒ–äº¤æ˜“ç³»ç»Ÿ è‡ªåŠ¨ç”Ÿæˆ</p>
    </div>
</body>
</html>
        '''
        return html
    
    def save_report(self, report_content: str, format: str = "markdown") -> Path:
        """ä¿å­˜æŠ¥å‘Š"""
        return self.report_generator.save_report(
            report_content,
            self.today.strftime('%Y%m%d'),
            format
        )
    
    def run(self, force_rebalance: bool = False) -> bool:
        """
        æ‰§è¡Œå®Œæ•´çš„æ¯æ—¥æ›´æ–°æµç¨‹
        
        Parameters
        ----------
        force_rebalance : bool
            æ˜¯å¦å¼ºåˆ¶è°ƒä»“
        
        Returns
        -------
        bool
            æ‰§è¡Œæ˜¯å¦æˆåŠŸ
        """
        self.logger.info("=" * 50)
        self.logger.info(f"å¼€å§‹æ¯æ—¥æ›´æ–°ä»»åŠ¡: {self.today.strftime('%Y-%m-%d')}")
        self.logger.info("=" * 50)
        
        # Step 1: æ›´æ–°å¸‚åœºæ•°æ®
        self.logger.info("Step 1/6: æ›´æ–°å¸‚åœºæ•°æ®")
        if not self.update_market_data():
            self.logger.error("å¸‚åœºæ•°æ®æ›´æ–°å¤±è´¥")
            return False
        
        # Step 2: æ›´æ–°è´¢åŠ¡æ•°æ®
        self.logger.info("Step 2/6: æ›´æ–°è´¢åŠ¡æ•°æ®")
        if not self.update_financial_data():
            self.logger.error("è´¢åŠ¡æ•°æ®æ›´æ–°å¤±è´¥")
            return False
        
        # Step 3: æ›´æ–°åŸºå‡†æŒ‡æ•°
        self.logger.info("Step 3/6: æ›´æ–°åŸºå‡†æŒ‡æ•°")
        self.update_benchmark_data()
        
        # Step 4: è®¡ç®—å› å­
        self.logger.info("Step 4/6: è®¡ç®—å› å­æ•°æ®")
        if not self.calculate_factors():
            self.logger.error("å› å­è®¡ç®—å¤±è´¥")
            return False
        
        # Step 5: åˆ¤æ–­æ˜¯å¦è°ƒä»“æ—¥
        is_rebalance = force_rebalance or self.is_rebalance_day()
        
        if is_rebalance:
            self.logger.info("Step 5/6: ç”Ÿæˆç›®æ ‡æŒä»“ï¼ˆè°ƒä»“æ—¥ï¼‰")
            if not self.generate_target_positions():
                self.logger.error("ç›®æ ‡æŒä»“ç”Ÿæˆå¤±è´¥")
                return False
        else:
            self.logger.info("Step 5/6: éè°ƒä»“æ—¥ï¼Œè·³è¿‡æŒä»“ç”Ÿæˆ")
            self.target_positions = self.current_positions.copy()
        
        # Step 6: ç”ŸæˆæŠ¥å‘Š
        self.logger.info("Step 6/6: ç”Ÿæˆäº¤æ˜“æŠ¥å‘Š")
        buy_orders, sell_orders = self.calculate_trade_orders()
        
        report_paths = {}
        for fmt in ["markdown", "html"]:
            report_content = self.generate_report(buy_orders, sell_orders, format=fmt)
            report_paths[fmt] = self.save_report(report_content, format=fmt)
        
        # æ›´æ–°æŒä»“
        self.save_current_holdings(buy_orders, sell_orders)

        # PushPlus æ¨é€ï¼ˆå¯é€‰ï¼‰
        try:
            notif_cfg = self.config.get("notification", {})
            if notif_cfg.get("enabled", False):
                token = str(notif_cfg.get("pushplus_token", "")).strip()
                if token:
                    buy_cnt = len(buy_orders)
                    sell_cnt = len(sell_orders)
                    selected = list(self.target_positions.keys())[:10]
                    title = f"Quant æ—¥æŠ¥ {self.today.strftime('%Y-%m-%d')}"
                    report_path = report_paths.get('html') or report_paths.get('markdown')
                    content_lines = [
                        "### äº¤æ˜“ä¿¡å·",
                        f"- ä¹°å…¥: {buy_cnt} åª",
                        f"- å–å‡º: {sell_cnt} åª",
                        f"- ç›®æ ‡æŒä»“: {len(self.target_positions)} åª",
                        "",
                        "### æ ‡çš„ï¼ˆå‰6åªï¼‰",
                    ]
                    content_lines.extend([f"- {s}" for s in selected[:6]])
                    content_lines.extend(["", f"æŠ¥å‘Šå·²ç”Ÿæˆï¼š{report_path}"])
                    content = "\n".join(content_lines)

                    send_pushplus_msg(
                        token=token,
                        title=title,
                        content=content,
                        template="markdown",
                        topic=notif_cfg.get("topic"),
                        channel=notif_cfg.get("channel"),
                        timeout=float(notif_cfg.get("timeout", 30)),
                        max_retries=int(notif_cfg.get("max_retries", 3)),
                    )
                else:
                    self.logger.warning("PushPlus token ä¸ºç©ºï¼Œå·²è·³è¿‡æ¨é€")
        except Exception as e:
            self.logger.warning(f"PushPlus æ¨é€å¤±è´¥ï¼ˆå¿½ç•¥å¹¶ç»§ç»­ï¼‰: {e}")
        
        self.logger.info("=" * 50)
        self.logger.info("æ¯æ—¥æ›´æ–°ä»»åŠ¡å®Œæˆ")
        self.logger.info("=" * 50)
        
        return True


def run_daily_update(
    force_rebalance: bool = False,
    config: Optional[Dict[str, Any]] = None
) -> bool:
    """
    è¿è¡Œæ¯æ—¥æ›´æ–°
    
    Parameters
    ----------
    force_rebalance : bool
        æ˜¯å¦å¼ºåˆ¶è°ƒä»“
    config : Optional[Dict[str, Any]]
        é…ç½®å‚æ•°
    
    Returns
    -------
    bool
        æ‰§è¡Œæ˜¯å¦æˆåŠŸ
    """
    runner = DailyUpdateRunner(config)
    return runner.run(force_rebalance)

