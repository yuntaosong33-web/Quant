"""
ç­–ç•¥é€»è¾‘å®ç°æ¨¡å—

è¯¥æ¨¡å—å®šä¹‰äº¤æ˜“ç­–ç•¥çš„æŠ½è±¡æ¥å£å’Œå…·ä½“å®ç°ï¼Œæ”¯æŒå¤šç§ç­–ç•¥ç±»å‹ã€‚
ä½¿ç”¨æŠ½è±¡åŸºç±»ç¡®ä¿ç­–ç•¥çš„ä¸€è‡´æ€§å’Œå¯æ‰©å±•æ€§ã€‚
"""

from abc import ABC, abstractmethod
from typing import Optional, List, Dict, Any, Tuple
from dataclasses import dataclass
from enum import Enum
import logging

import pandas as pd
import numpy as np
try:
    import akshare as ak
except ImportError:
    ak = None

# å¯¼å…¥ LLM ç†”æ–­å™¨å¼‚å¸¸ï¼ˆç”¨äºé£æ§ï¼‰
try:
    from src.llm_client import LLMCircuitBreakerError
except ImportError:
    try:
        from llm_client import LLMCircuitBreakerError
    except ImportError:
        # å®šä¹‰å›é€€ç±»ä»¥é¿å…å¯¼å…¥é”™è¯¯
        class LLMCircuitBreakerError(RuntimeError):
            """LLM ç†”æ–­å™¨è§¦å‘å¼‚å¸¸ï¼ˆå›é€€å®šä¹‰ï¼‰"""
            pass

logger = logging.getLogger(__name__)


class SignalType(Enum):
    """äº¤æ˜“ä¿¡å·ç±»å‹æšä¸¾"""
    BUY = 1
    SELL = -1
    HOLD = 0


@dataclass
class TradeSignal:
    """
    äº¤æ˜“ä¿¡å·æ•°æ®ç±»
    
    Attributes
    ----------
    timestamp : pd.Timestamp
        ä¿¡å·æ—¶é—´
    symbol : str
        è‚¡ç¥¨ä»£ç 
    signal_type : SignalType
        ä¿¡å·ç±»å‹
    price : float
        ä¿¡å·ä»·æ ¼
    strength : float
        ä¿¡å·å¼ºåº¦ (0-1)
    reason : str
        ä¿¡å·åŸå› è¯´æ˜
    """
    timestamp: pd.Timestamp
    symbol: str
    signal_type: SignalType
    price: float
    strength: float = 1.0
    reason: str = ""


class BaseStrategy(ABC):
    """
    ç­–ç•¥æŠ½è±¡åŸºç±»
    
    æ‰€æœ‰äº¤æ˜“ç­–ç•¥å¿…é¡»ç»§æ‰¿æ­¤ç±»å¹¶å®ç°æŠ½è±¡æ–¹æ³•ã€‚
    å®šä¹‰ç­–ç•¥çš„åŸºæœ¬æ¥å£å’Œé€šç”¨åŠŸèƒ½ã€‚
    
    Attributes
    ----------
    name : str
        ç­–ç•¥åç§°
    config : Dict[str, Any]
        ç­–ç•¥é…ç½®å‚æ•°
    
    Methods
    -------
    generate_signals(data)
        ç”Ÿæˆäº¤æ˜“ä¿¡å·
    calculate_position_size(signal, portfolio_value)
        è®¡ç®—ä»“ä½å¤§å°
    on_data(data)
        æ•°æ®æ›´æ–°æ—¶çš„å›è°ƒ
    """
    
    def __init__(
        self,
        name: str,
        config: Optional[Dict[str, Any]] = None
    ) -> None:
        """
        åˆå§‹åŒ–ç­–ç•¥
        
        Parameters
        ----------
        name : str
            ç­–ç•¥åç§°
        config : Optional[Dict[str, Any]]
            ç­–ç•¥é…ç½®å‚æ•°
        """
        self.name = name
        self.config = config or {}
        self._signals: List[TradeSignal] = []
        self._positions: Dict[str, float] = {}
        
        # ä»é…ç½®åŠ è½½å‚æ•°
        self._max_positions = self.config.get("max_positions", 10)
        self._position_size = self.config.get("position_size", 0.1)
        self._stop_loss = self.config.get("stop_loss", 0.08)
        self._take_profit = self.config.get("take_profit", 0.20)
        
        # ATR åŠ¨æ€æ­¢æŸå‚æ•°
        self._use_atr_stop_loss = self.config.get("use_atr_stop_loss", True)
        self._atr_period = self.config.get("atr_period", 14)
        self._atr_multiplier = self.config.get("atr_multiplier", 2.5)
        
        logger.info(f"ç­–ç•¥ '{name}' åˆå§‹åŒ–å®Œæˆ")
    
    @abstractmethod
    def generate_signals(self, data: pd.DataFrame) -> pd.Series:
        """
        ç”Ÿæˆäº¤æ˜“ä¿¡å·
        
        Parameters
        ----------
        data : pd.DataFrame
            åŒ…å«OHLCVå’Œå› å­çš„æ•°æ®æ¡†
        
        Returns
        -------
        pd.Series
            ä¿¡å·åºåˆ—ï¼Œ1è¡¨ç¤ºä¹°å…¥ï¼Œ-1è¡¨ç¤ºå–å‡ºï¼Œ0è¡¨ç¤ºæŒæœ‰
        """
        pass
    
    @abstractmethod
    def calculate_position_size(
        self,
        signal: TradeSignal,
        portfolio_value: float
    ) -> float:
        """
        è®¡ç®—ä»“ä½å¤§å°
        
        Parameters
        ----------
        signal : TradeSignal
            äº¤æ˜“ä¿¡å·
        portfolio_value : float
            å½“å‰ç»„åˆä»·å€¼
        
        Returns
        -------
        float
            å»ºè®®ä»“ä½é‡‘é¢
        """
        pass
    
    def on_data(self, data: pd.DataFrame) -> Optional[TradeSignal]:
        """
        æ•°æ®æ›´æ–°æ—¶çš„å›è°ƒæ–¹æ³•
        
        Parameters
        ----------
        data : pd.DataFrame
            æœ€æ–°æ•°æ®
        
        Returns
        -------
        Optional[TradeSignal]
            äº¤æ˜“ä¿¡å·ï¼Œå¦‚æœæ²¡æœ‰ä¿¡å·åˆ™è¿”å›None
        """
        signals = self.generate_signals(data)
        
        if signals.iloc[-1] != 0:
            signal = TradeSignal(
                timestamp=data.index[-1],
                symbol=data.get("symbol", "UNKNOWN"),
                signal_type=SignalType.BUY if signals.iloc[-1] > 0 else SignalType.SELL,
                price=data["close"].iloc[-1],
                strength=abs(signals.iloc[-1]),
            )
            self._signals.append(signal)
            return signal
        
        return None
    
    def get_signals_df(self) -> pd.DataFrame:
        """
        è·å–ä¿¡å·å†å²DataFrame
        
        Returns
        -------
        pd.DataFrame
            ä¿¡å·å†å²è®°å½•
        """
        if not self._signals:
            return pd.DataFrame()
        
        return pd.DataFrame([
            {
                "timestamp": s.timestamp,
                "symbol": s.symbol,
                "signal": s.signal_type.value,
                "price": s.price,
                "strength": s.strength,
                "reason": s.reason,
            }
            for s in self._signals
        ])
    
    def reset(self) -> None:
        """é‡ç½®ç­–ç•¥çŠ¶æ€"""
        self._signals.clear()
        self._positions.clear()
        logger.info(f"ç­–ç•¥ '{self.name}' çŠ¶æ€å·²é‡ç½®")
    
    def calculate_atr(
        self,
        high: pd.Series,
        low: pd.Series,
        close: pd.Series,
        period: int = 14
    ) -> pd.Series:
        """
        è®¡ç®— ATRï¼ˆå¹³å‡çœŸå®æ³¢å¹…ï¼‰
        
        ATR = è¿‡å» N æ—¥ True Range çš„ç§»åŠ¨å¹³å‡
        True Range = max(high - low, |high - prev_close|, |low - prev_close|)
        
        Parameters
        ----------
        high : pd.Series
            æœ€é«˜ä»·åºåˆ—
        low : pd.Series
            æœ€ä½ä»·åºåˆ—
        close : pd.Series
            æ”¶ç›˜ä»·åºåˆ—
        period : int, optional
            è®¡ç®—å‘¨æœŸï¼Œé»˜è®¤ 14
        
        Returns
        -------
        pd.Series
            ATR å€¼åºåˆ—
        """
        prev_close = close.shift(1)
        
        # è®¡ç®— True Range
        tr1 = high - low
        tr2 = (high - prev_close).abs()
        tr3 = (low - prev_close).abs()
        
        true_range = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
        
        # è®¡ç®— ATRï¼ˆä½¿ç”¨ EWM æˆ– SMAï¼‰
        atr = true_range.rolling(window=period, min_periods=1).mean()
        
        return atr
    
    def calculate_dynamic_stop_loss(
        self,
        data: pd.DataFrame,
        entry_prices: Optional[pd.Series] = None
    ) -> pd.Series:
        """
        è®¡ç®—åŸºäº ATR çš„åŠ¨æ€æ­¢æŸä»·æ ¼
        
        æ­¢æŸä»· = å…¥åœºä»· - ATR_Multiplier * ATR(14)
        
        å¯¹äº30ä¸‡å°èµ„é‡‘è´¦æˆ·ï¼Œä½¿ç”¨ ATR æ­¢æŸæ¯”å›ºå®šç™¾åˆ†æ¯”æ›´é€‚åˆï¼š
        - æ³¢åŠ¨å¤§çš„è‚¡ç¥¨æ­¢æŸæ›´å®½ï¼Œé¿å…è¢«æ´—å‡º
        - æ³¢åŠ¨å°çš„è‚¡ç¥¨æ­¢æŸæ›´ç´§ï¼Œä¿æŠ¤åˆ©æ¶¦
        
        Parameters
        ----------
        data : pd.DataFrame
            ä»·æ ¼æ•°æ®ï¼Œå¿…é¡»åŒ…å« high, low, close åˆ—
        entry_prices : Optional[pd.Series]
            å…¥åœºä»·æ ¼åºåˆ—ã€‚å¦‚æœä¸º Noneï¼Œä½¿ç”¨æ”¶ç›˜ä»·ä½œä¸ºå‚è€ƒ
        
        Returns
        -------
        pd.Series
            åŠ¨æ€æ­¢æŸä»·æ ¼åºåˆ—
        
        Examples
        --------
        >>> stop_prices = strategy.calculate_dynamic_stop_loss(ohlcv_data)
        >>> # æ£€æŸ¥æ˜¯å¦è§¦å‘æ­¢æŸ
        >>> triggered = data['close'] < stop_prices
        
        Notes
        -----
        é»˜è®¤é…ç½®ï¼š
        - ATR å‘¨æœŸ: 14 æ—¥
        - ATR ä¹˜æ•°: 2.5
        - æ­¢æŸä»· = å…¥åœºä»· - 2.5 * ATR(14)
        """
        if not self._use_atr_stop_loss:
            # å›é€€åˆ°å›ºå®šç™¾åˆ†æ¯”æ­¢æŸ
            entry = entry_prices if entry_prices is not None else data['close']
            return entry * (1 - self._stop_loss)
        
        # è®¡ç®— ATR
        atr = self.calculate_atr(
            data['high'],
            data['low'],
            data['close'],
            period=self._atr_period
        )
        
        # è®¡ç®—æ­¢æŸè·ç¦»
        stop_distance = self._atr_multiplier * atr
        
        # è®¡ç®—æ­¢æŸä»·æ ¼
        entry = entry_prices if entry_prices is not None else data['close']
        stop_loss_price = entry - stop_distance
        
        # ç¡®ä¿æ­¢æŸä»·æ ¼ä¸ä¸ºè´Ÿ
        stop_loss_price = stop_loss_price.clip(lower=0)
        
        return stop_loss_price
    
    def check_stop_loss_triggered(
        self,
        data: pd.DataFrame,
        entry_prices: pd.Series,
        current_prices: pd.Series
    ) -> pd.Series:
        """
        æ£€æŸ¥æ˜¯å¦è§¦å‘åŠ¨æ€æ­¢æŸ
        
        Parameters
        ----------
        data : pd.DataFrame
            ä»·æ ¼æ•°æ®ï¼ˆç”¨äºè®¡ç®— ATRï¼‰
        entry_prices : pd.Series
            å…¥åœºä»·æ ¼
        current_prices : pd.Series
            å½“å‰ä»·æ ¼
        
        Returns
        -------
        pd.Series
            å¸ƒå°”åºåˆ—ï¼ŒTrue è¡¨ç¤ºè§¦å‘æ­¢æŸ
        """
        stop_prices = self.calculate_dynamic_stop_loss(data, entry_prices)
        return current_prices < stop_prices


class MACrossStrategy(BaseStrategy):
    """
    åŒå‡çº¿äº¤å‰ç­–ç•¥
    
    å½“çŸ­æœŸå‡çº¿ä¸Šç©¿é•¿æœŸå‡çº¿æ—¶ä¹°å…¥ï¼Œä¸‹ç©¿æ—¶å–å‡ºã€‚
    
    Parameters
    ----------
    short_window : int
        çŸ­æœŸå‡çº¿å‘¨æœŸ
    long_window : int
        é•¿æœŸå‡çº¿å‘¨æœŸ
    
    Examples
    --------
    >>> config = {"short_window": 5, "long_window": 20}
    >>> strategy = MACrossStrategy("MA Cross", config)
    >>> signals = strategy.generate_signals(price_data)
    """
    
    def __init__(
        self,
        name: str = "MA Cross Strategy",
        config: Optional[Dict[str, Any]] = None
    ) -> None:
        """
        åˆå§‹åŒ–å‡çº¿äº¤å‰ç­–ç•¥
        
        Parameters
        ----------
        name : str
            ç­–ç•¥åç§°
        config : Optional[Dict[str, Any]]
            é…ç½®å‚æ•°ï¼ŒåŒ…å« short_window å’Œ long_window
        """
        super().__init__(name, config)
        self.short_window = self.config.get("short_window", 5)
        self.long_window = self.config.get("long_window", 20)
        
        logger.info(
            f"å‡çº¿äº¤å‰ç­–ç•¥å‚æ•°: çŸ­æœŸ={self.short_window}, é•¿æœŸ={self.long_window}"
        )
    
    def generate_signals(self, data: pd.DataFrame) -> pd.Series:
        """
        ç”Ÿæˆå‡çº¿äº¤å‰ä¿¡å·
        
        Parameters
        ----------
        data : pd.DataFrame
            ä»·æ ¼æ•°æ®ï¼Œå¿…é¡»åŒ…å« 'close' åˆ—
        
        Returns
        -------
        pd.Series
            äº¤æ˜“ä¿¡å·åºåˆ—
        """
        close = data["close"]
        
        # è®¡ç®—å‡çº¿
        short_ma = close.rolling(window=self.short_window, min_periods=1).mean()
        long_ma = close.rolling(window=self.long_window, min_periods=1).mean()
        
        # ç”Ÿæˆä¿¡å·
        signals = pd.Series(0, index=data.index)
        
        # é‡‘å‰ä¹°å…¥ä¿¡å·
        golden_cross = (short_ma > long_ma) & (short_ma.shift(1) <= long_ma.shift(1))
        signals[golden_cross] = 1
        
        # æ­»å‰å–å‡ºä¿¡å·
        death_cross = (short_ma < long_ma) & (short_ma.shift(1) >= long_ma.shift(1))
        signals[death_cross] = -1
        
        return signals
    
    def calculate_position_size(
        self,
        signal: TradeSignal,
        portfolio_value: float
    ) -> float:
        """
        è®¡ç®—ä»“ä½å¤§å°
        
        ä½¿ç”¨å›ºå®šæ¯”ä¾‹ä»“ä½ç®¡ç†ã€‚
        
        Parameters
        ----------
        signal : TradeSignal
            äº¤æ˜“ä¿¡å·
        portfolio_value : float
            ç»„åˆä»·å€¼
        
        Returns
        -------
        float
            å»ºè®®ä»“ä½é‡‘é¢
        """
        base_size = portfolio_value * self._position_size
        adjusted_size = base_size * signal.strength
        
        return adjusted_size


class RSIStrategy(BaseStrategy):
    """
    RSIè¶…ä¹°è¶…å–ç­–ç•¥
    
    å½“RSIä½äºè¶…å–çº¿æ—¶ä¹°å…¥ï¼Œé«˜äºè¶…ä¹°çº¿æ—¶å–å‡ºã€‚
    
    Parameters
    ----------
    rsi_period : int
        RSIè®¡ç®—å‘¨æœŸ
    oversold : float
        è¶…å–é˜ˆå€¼
    overbought : float
        è¶…ä¹°é˜ˆå€¼
    """
    
    def __init__(
        self,
        name: str = "RSI Strategy",
        config: Optional[Dict[str, Any]] = None
    ) -> None:
        """
        åˆå§‹åŒ–RSIç­–ç•¥
        
        Parameters
        ----------
        name : str
            ç­–ç•¥åç§°
        config : Optional[Dict[str, Any]]
            é…ç½®å‚æ•°
        """
        super().__init__(name, config)
        self.rsi_period = self.config.get("rsi_period", 14)
        self.oversold = self.config.get("oversold", 30)
        self.overbought = self.config.get("overbought", 70)
    
    def generate_signals(self, data: pd.DataFrame) -> pd.Series:
        """
        ç”ŸæˆRSIä¿¡å·
        
        Parameters
        ----------
        data : pd.DataFrame
            ä»·æ ¼æ•°æ®
        
        Returns
        -------
        pd.Series
            äº¤æ˜“ä¿¡å·åºåˆ—
        """
        close = data["close"]
        
        # è®¡ç®—RSI
        delta = close.diff()
        gain = delta.where(delta > 0, 0.0)
        loss = (-delta).where(delta < 0, 0.0)
        
        avg_gain = gain.rolling(window=self.rsi_period, min_periods=1).mean()
        avg_loss = loss.rolling(window=self.rsi_period, min_periods=1).mean()
        
        rs = avg_gain / avg_loss.replace(0, np.inf)
        rsi = 100 - (100 / (1 + rs))
        
        # ç”Ÿæˆä¿¡å·
        signals = pd.Series(0, index=data.index)
        
        # è¶…å–ä¹°å…¥
        oversold_signal = (rsi < self.oversold) & (rsi.shift(1) >= self.oversold)
        signals[oversold_signal] = 1
        
        # è¶…ä¹°å–å‡º
        overbought_signal = (rsi > self.overbought) & (rsi.shift(1) <= self.overbought)
        signals[overbought_signal] = -1
        
        return signals
    
    def calculate_position_size(
        self,
        signal: TradeSignal,
        portfolio_value: float
    ) -> float:
        """è®¡ç®—ä»“ä½å¤§å°"""
        return portfolio_value * self._position_size * signal.strength


class CompositeStrategy(BaseStrategy):
    """
    ç»„åˆç­–ç•¥
    
    å°†å¤šä¸ªç­–ç•¥ç»„åˆåœ¨ä¸€èµ·ï¼Œé€šè¿‡åŠ æƒæŠ•ç¥¨ç”Ÿæˆç»¼åˆä¿¡å·ã€‚
    
    Parameters
    ----------
    strategies : List[Tuple[BaseStrategy, float]]
        ç­–ç•¥å’Œæƒé‡çš„åˆ—è¡¨
    """
    
    def __init__(
        self,
        name: str = "Composite Strategy",
        strategies: Optional[List[Tuple[BaseStrategy, float]]] = None,
        config: Optional[Dict[str, Any]] = None
    ) -> None:
        """
        åˆå§‹åŒ–ç»„åˆç­–ç•¥
        
        Parameters
        ----------
        name : str
            ç­–ç•¥åç§°
        strategies : Optional[List[Tuple[BaseStrategy, float]]]
            å­ç­–ç•¥å’Œæƒé‡åˆ—è¡¨
        config : Optional[Dict[str, Any]]
            é…ç½®å‚æ•°
        """
        super().__init__(name, config)
        self.strategies = strategies or []
        self.threshold = self.config.get("threshold", 0.5)
    
    def add_strategy(self, strategy: BaseStrategy, weight: float = 1.0) -> None:
        """
        æ·»åŠ å­ç­–ç•¥
        
        Parameters
        ----------
        strategy : BaseStrategy
            å­ç­–ç•¥å®ä¾‹
        weight : float
            ç­–ç•¥æƒé‡
        """
        self.strategies.append((strategy, weight))
        logger.info(f"æ·»åŠ å­ç­–ç•¥: {strategy.name}, æƒé‡: {weight}")
    
    def generate_signals(self, data: pd.DataFrame) -> pd.Series:
        """
        ç”Ÿæˆç»„åˆä¿¡å·
        
        Parameters
        ----------
        data : pd.DataFrame
            ä»·æ ¼æ•°æ®
        
        Returns
        -------
        pd.Series
            åŠ æƒç»„åˆä¿¡å·
        """
        if not self.strategies:
            return pd.Series(0, index=data.index)
        
        total_weight = sum(w for _, w in self.strategies)
        weighted_signals = pd.Series(0.0, index=data.index)
        
        for strategy, weight in self.strategies:
            signals = strategy.generate_signals(data)
            weighted_signals += signals * (weight / total_weight)
        
        # æ ¹æ®é˜ˆå€¼è½¬æ¢ä¸ºç¦»æ•£ä¿¡å·
        final_signals = pd.Series(0, index=data.index)
        final_signals[weighted_signals > self.threshold] = 1
        final_signals[weighted_signals < -self.threshold] = -1
        
        return final_signals
    
    def calculate_position_size(
        self,
        signal: TradeSignal,
        portfolio_value: float
    ) -> float:
        """è®¡ç®—ä»“ä½å¤§å°"""
        return portfolio_value * self._position_size * signal.strength


class MultiFactorStrategy(BaseStrategy):
    """
    å¤šå› å­é€‰è‚¡ç­–ç•¥
    
    åŸºäºä»·å€¼ã€è´¨é‡å’ŒåŠ¨é‡å› å­çš„ç»¼åˆæ‰“åˆ†è¿›è¡Œé€‰è‚¡ã€‚
    æ¯æœˆæœ€åä¸€ä¸ªäº¤æ˜“æ—¥è¿›è¡Œè°ƒä»“ï¼Œé€‰å–å¾—åˆ†æœ€é«˜çš„ Top N åªè‚¡ç¥¨ã€‚
    
    æ‰“åˆ†å…¬å¼: Total_Score = 0.4 * Value_Z + 0.4 * Quality_Z + 0.2 * Momentum_Z
    
    Parameters
    ----------
    name : str
        ç­–ç•¥åç§°
    config : Optional[Dict[str, Any]]
        é…ç½®å‚æ•°ï¼ŒåŒ…å«ï¼š
        - value_weight: ä»·å€¼å› å­æƒé‡ï¼Œé»˜è®¤0.4
        - quality_weight: è´¨é‡å› å­æƒé‡ï¼Œé»˜è®¤0.4
        - momentum_weight: åŠ¨é‡å› å­æƒé‡ï¼Œé»˜è®¤0.2
        - top_n: é€‰å–è‚¡ç¥¨æ•°é‡ï¼Œé»˜è®¤30
        - min_listing_days: æœ€å°ä¸Šå¸‚å¤©æ•°ï¼Œé»˜è®¤126ï¼ˆçº¦6ä¸ªæœˆï¼‰
        - value_col: ä»·å€¼å› å­åˆ—å
        - quality_col: è´¨é‡å› å­åˆ—å
        - momentum_col: åŠ¨é‡å› å­åˆ—å
    
    Attributes
    ----------
    value_weight : float
        ä»·å€¼å› å­æƒé‡
    quality_weight : float
        è´¨é‡å› å­æƒé‡
    momentum_weight : float
        åŠ¨é‡å› å­æƒé‡
    top_n : int
        é€‰å–è‚¡ç¥¨æ•°é‡
    min_listing_days : int
        æœ€å°ä¸Šå¸‚å¤©æ•°
    
    Examples
    --------
    >>> config = {
    ...     "value_weight": 0.4,
    ...     "quality_weight": 0.4,
    ...     "momentum_weight": 0.2,
    ...     "top_n": 30
    ... }
    >>> strategy = MultiFactorStrategy("Multi-Factor", config)
    >>> target_positions = strategy.generate_target_positions(factor_data)
    """
    
    def __init__(
        self,
        name: str = "Multi-Factor Strategy",
        config: Optional[Dict[str, Any]] = None
    ) -> None:
        """
        åˆå§‹åŒ–å¤šå› å­ç­–ç•¥
        
        Parameters
        ----------
        name : str
            ç­–ç•¥åç§°
        config : Optional[Dict[str, Any]]
            ç­–ç•¥é…ç½®å‚æ•°
        """
        super().__init__(name, config)
        
        # å› å­æƒé‡é…ç½®
        # æ¿€è¿›å‹å°å¸‚å€¼ç­–ç•¥é…ç½®ï¼š
        # - value_weight: å€Ÿç”¨ä½ç½®æ”¾å°å¸‚å€¼å› å­
        # - quality_weight: å€Ÿç”¨ä½ç½®æ”¾æ¢æ‰‹ç‡å› å­
        # - momentum_weight: RSI åŠ¨é‡å› å­
        # - size_weight: ç‹¬ç«‹çš„å°å¸‚å€¼å› å­æƒé‡ï¼ˆæ–°å¢ï¼‰
        self.value_weight: float = self.config.get("value_weight", 0.0)
        self.quality_weight: float = self.config.get("quality_weight", 0.3)
        self.momentum_weight: float = self.config.get("momentum_weight", 0.4)
        self.size_weight: float = self.config.get("size_weight", 0.3)  # æ–°å¢ï¼šå¸‚å€¼å› å­æƒé‡
        self.sentiment_weight: float = self.config.get("sentiment_weight", 0.3)  # æƒ…ç»ªè¿›æ”»å‹æƒé‡
        
        # é€‰è‚¡å‚æ•°é…ç½®
        self.top_n: int = self.config.get("top_n", 30)
        
        # 30ä¸‡å°èµ„é‡‘è´¦æˆ·é€‚é…ï¼šæœ€å¤§æŒä»“æ•°é‡é™åˆ¶ä¸º 8
        MAX_POSITIONS_LIMIT = 8
        if self.top_n > MAX_POSITIONS_LIMIT:
            logger.warning(
                f"é…ç½®çš„ top_n ({self.top_n}) è¶…è¿‡äº†å°èµ„é‡‘è´¦æˆ·é™åˆ¶ ({MAX_POSITIONS_LIMIT})ï¼Œ"
                f"å¼ºåˆ¶è°ƒæ•´ä¸º {MAX_POSITIONS_LIMIT}"
            )
            self.top_n = MAX_POSITIONS_LIMIT

        self.min_listing_days: int = self.config.get("min_listing_days", 126)  # çº¦6ä¸ªæœˆ
        
        # æ¿å—è¿‡æ»¤é…ç½®
        self._exclude_chinext: bool = self.config.get("exclude_chinext", False)  # æ’é™¤åˆ›ä¸šæ¿
        self._exclude_star: bool = self.config.get("exclude_star", False)  # æ’é™¤ç§‘åˆ›æ¿
        
        # å› å­åˆ—åé…ç½®ï¼ˆæ”¯æŒè‡ªå®šä¹‰åˆ—åï¼‰
        self.value_col: str = self.config.get("value_col", "value_zscore")
        self.quality_col: str = self.config.get("quality_col", "quality_zscore")
        self.momentum_col: str = self.config.get("momentum_col", "momentum_zscore")
        self.size_col: str = self.config.get("size_col", "small_cap_zscore")  # æ–°å¢ï¼šå¸‚å€¼å› å­åˆ—å
        
        # æ—¥æœŸå’Œè‚¡ç¥¨åˆ—åé…ç½®
        self.date_col: str = self.config.get("date_col", "date")
        self.stock_col: str = self.config.get("stock_col", "stock_code")
        
        # è°ƒä»“é¢‘ç‡é…ç½®: 'monthly' æˆ– 'weekly'
        self.rebalance_frequency: str = self.config.get("rebalance_frequency", "monthly")
        
        # ===== å†å¹³è¡¡ç¼“å†²åŒºï¼ˆRebalance Bufferï¼‰=====
        # ç”¨äºé¿å…å°èµ„é‡‘è´¦æˆ·å› å¾®å°è°ƒæ•´äº§ç”Ÿçš„æœ€ä½5å…ƒä½£é‡‘ç£¨æŸ
        # ä»…å½“ |w_new - w_old| > buffer_threshold æ—¶æ‰è°ƒæ•´ä»“ä½
        # ä¾‹ï¼š5%ç¼“å†²åŒº = 30ä¸‡ * 5% = 1.5ä¸‡ï¼ŒæŒ‰ä¸‡ä¸‰è®¡ç®—ä½£é‡‘4.5å…ƒï¼Œä¸è¶³æœ€ä½5å…ƒ
        self.rebalance_buffer: float = self.config.get("rebalance_buffer", 0.05)
        if self.rebalance_frequency not in ("monthly", "weekly"):
            logger.warning(
                f"ä¸æ”¯æŒçš„è°ƒä»“é¢‘ç‡ '{self.rebalance_frequency}'ï¼Œä½¿ç”¨é»˜è®¤ 'monthly'"
            )
            self.rebalance_frequency = "monthly"
        
        # éªŒè¯æƒé‡ä¹‹å’Œï¼ˆåŒ…å«æ–°å¢çš„ size_weightï¼‰
        # æ³¨æ„ï¼šsentiment_weight æ˜¯é¢å¤–çš„ Alpha å› å­æƒé‡ï¼Œä¸è®¡å…¥åŸºç¡€æƒé‡å½’ä¸€åŒ–
        # ç”±ç”¨æˆ·é…ç½®ä¿è¯åˆç†æ€§
        weight_sum = self.value_weight + self.quality_weight + self.momentum_weight + self.size_weight
        if abs(weight_sum - 1.0) > 1e-6:
            logger.warning(f"åŸºç¡€å› å­æƒé‡ä¹‹å’Œä¸º {weight_sum}ï¼Œå»ºè®®æƒé‡ä¹‹å’Œä¸º 1.0")
        
        # ===== LLM æƒ…ç»ªåˆ†æé…ç½® =====
        # ä»é…ç½®ä¸­è·å– LLM è®¾ç½®
        self._llm_config = self.config.get("llm", {})
        self._enable_sentiment_filter: bool = self._llm_config.get("enable_sentiment_filter", False)
        self._sentiment_threshold: float = self._llm_config.get("sentiment_threshold", -0.5)
        self._min_confidence: float = self._llm_config.get("min_confidence", 0.7)
        self._sentiment_buffer_multiplier: int = self._llm_config.get("sentiment_buffer_multiplier", 3)
        self._sentiment_engine = None
        
        # åˆå§‹åŒ–æƒ…ç»ªåˆ†æå¼•æ“ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self._enable_sentiment_filter:
            try:
                from src.features import SentimentEngine
                self._sentiment_engine = SentimentEngine(self._llm_config)
                logger.info(
                    f"æƒ…ç»ªåˆ†æè¿‡æ»¤å·²å¯ç”¨: threshold={self._sentiment_threshold}, "
                    f"min_confidence={self._min_confidence}, buffer_multiplier={self._sentiment_buffer_multiplier}"
                )
            except ImportError:
                logger.warning(
                    "æ— æ³•å¯¼å…¥ SentimentEngineï¼Œæƒ…ç»ªåˆ†æè¿‡æ»¤æœªå¯ç”¨ã€‚"
                    "è¯·ç¡®ä¿ src.features æ¨¡å—å¯ç”¨ã€‚"
                )
                self._enable_sentiment_filter = False
            except Exception as e:
                logger.warning(f"åˆå§‹åŒ– SentimentEngine å¤±è´¥: {e}")
                self._enable_sentiment_filter = False
        
        logger.info(
            f"å¤šå› å­ç­–ç•¥åˆå§‹åŒ–: ä»·å€¼æƒé‡={self.value_weight}, "
            f"è´¨é‡æƒé‡={self.quality_weight}, åŠ¨é‡æƒé‡={self.momentum_weight}, "
            f"å¸‚å€¼æƒé‡={self.size_weight}, æƒ…ç»ªæƒé‡={self.sentiment_weight}, "
            f"Top N={self.top_n}, è°ƒä»“é¢‘ç‡={self.rebalance_frequency}, "
            f"å†å¹³è¡¡ç¼“å†²åŒº={self.rebalance_buffer:.1%}, "
            f"æƒ…ç»ªè¿‡æ»¤={'å¯ç”¨' if self._enable_sentiment_filter else 'ç¦ç”¨'}"
        )
    
    def calculate_total_score(
        self,
        data: pd.DataFrame,
        sentiment_scores: Optional[pd.Series] = None
    ) -> pd.Series:
        """
        è®¡ç®—ç»¼åˆå› å­å¾—åˆ†
        
        æ¿€è¿›å‹å°å¸‚å€¼ç­–ç•¥å…¬å¼ï¼š
        Total_Score = value_weight * Value_Z + quality_weight * Quality_Z 
                    + momentum_weight * Momentum_Z + size_weight * Size_Z
        
        æƒ…ç»ªè¿›æ”»å‹ç­–ç•¥é¢å¤–åŠ åˆ†ï¼š
        Final_Score = Base_Score + sentiment_weight * Sentiment_Score * 3.0
        
        ç‰¹æ®Šå¤„ç†ï¼š
        - æ¢æ‰‹ç‡å› å­å¼•å…¥"è¿‡çƒ­æƒ©ç½š"ï¼šZ-Score > 2.0 æ—¶åå‘æ‰£åˆ†
        - æƒ…ç»ªå› å­é‡çº²å¯¹é½ï¼šä¹˜ä»¥ 3.0 æ”¾å¤§ç³»æ•°ä½¿å…¶ä¸æŠ€æœ¯å› å­åŒ¹é…
        
        Parameters
        ----------
        data : pd.DataFrame
            åŒ…å«å› å­ Z-Score çš„æ•°æ®æ¡†
        sentiment_scores : Optional[pd.Series]
            æƒ…ç»ªåˆ†æ•°åºåˆ—ï¼ˆèŒƒå›´ -1 åˆ° 1ï¼‰ï¼Œç´¢å¼•åº”ä¸ºè‚¡ç¥¨ä»£ç ã€‚
            å¦‚æœä¼ å…¥ï¼Œå°†ä¹˜ä»¥ sentiment_weight å’Œæ”¾å¤§ç³»æ•° 3.0 åŠ åˆ°æ€»åˆ†ä¸­ã€‚
        
        Returns
        -------
        pd.Series
            ç»¼åˆå¾—åˆ†åºåˆ—
        
        Notes
        -----
        - ç¼ºå¤±çš„å› å­å€¼ä¼šè¢«è§†ä¸º 0
        - ä½¿ç”¨å‘é‡åŒ–æ“ä½œè®¡ç®—å¾—åˆ†
        - æ¿€è¿›å‹ç­–ç•¥ä¸­ï¼Œvalue_col å¯æ˜ å°„åˆ° small_cap_zscore
        - quality_col å¯æ˜ å°„åˆ° turnover_5d_zscore
        - sentiment_scores æƒé‡å½’ä¸€åŒ–ç”±ç”¨æˆ·é…ç½®ä¿è¯
        - æ¢æ‰‹ç‡è¿‡çƒ­æƒ©ç½šé˜ˆå€¼ä¸º Z-Score = 2.0
        """
        total_score = pd.Series(0.0, index=data.index)
        
        # ä»·å€¼å› å­ï¼ˆæ¿€è¿›ç­–ç•¥ä¸­å¯ç”¨äºæ”¾ç½®å°å¸‚å€¼å› å­ï¼‰
        if self.value_col in data.columns and self.value_weight > 0:
            total_score += self.value_weight * data[self.value_col].fillna(0)
        elif self.value_weight > 0:
            logger.warning(f"æœªæ‰¾åˆ°ä»·å€¼å› å­åˆ—: {self.value_col}")
        
        # è´¨é‡å› å­ï¼ˆæ¢æ‰‹ç‡å› å­ï¼‰- å¼•å…¥"è¿‡çƒ­æƒ©ç½š"æœºåˆ¶
        # Z-Score > 2.0 è¡¨ç¤ºæåº¦æ´»è·ƒï¼Œè¿‡çƒ­åè€Œæ‰£åˆ†
        # score = z_score if z_score <= 2.0 else 2.0 - (z_score - 2.0) * 2
        if self.quality_col in data.columns and self.quality_weight > 0:
            raw_quality = data[self.quality_col].fillna(0)
            # å‘é‡åŒ–è®¡ç®—ï¼šè¿‡çƒ­æƒ©ç½š
            # å¯¹äº z > 2.0: score = 2.0 - (z - 2.0) * 2 = 4.0 - 2*z
            quality_score = np.where(
                raw_quality > 2.0,
                2.0 - (raw_quality - 2.0) * 2,  # è¿‡çƒ­æƒ©ç½š
                raw_quality  # æ­£å¸¸æƒ…å†µä¿æŒåŸå€¼
            )
            total_score += self.quality_weight * quality_score
            # è®°å½•è¿‡çƒ­è‚¡ç¥¨æ•°é‡
            overheat_count = (raw_quality > 2.0).sum()
            if overheat_count > 0:
                logger.debug(f"æ¢æ‰‹ç‡è¿‡çƒ­æƒ©ç½š: {overheat_count} åªè‚¡ç¥¨ Z-Score > 2.0")
        elif self.quality_weight > 0:
            logger.warning(f"æœªæ‰¾åˆ°è´¨é‡å› å­åˆ—: {self.quality_col}")
        
        # åŠ¨é‡å› å­
        if self.momentum_col in data.columns and self.momentum_weight > 0:
            total_score += self.momentum_weight * data[self.momentum_col].fillna(0)
        elif self.momentum_weight > 0:
            logger.warning(f"æœªæ‰¾åˆ°åŠ¨é‡å› å­åˆ—: {self.momentum_col}")
        
        # å¸‚å€¼å› å­ï¼ˆç‹¬ç«‹æƒé‡ï¼Œæ¿€è¿›å‹å°å¸‚å€¼ç­–ç•¥æ ¸å¿ƒå› å­ï¼‰
        if self.size_col in data.columns and self.size_weight > 0:
            total_score += self.size_weight * data[self.size_col].fillna(0)
        elif self.size_weight > 0:
            logger.warning(f"æœªæ‰¾åˆ°å¸‚å€¼å› å­åˆ—: {self.size_col}")
        
        # ===== æƒ…ç»ªè¿›æ”»å‹ç­–ç•¥ï¼šåŠ å…¥æƒ…ç»ªåˆ†æ•° =====
        # æƒ…ç»ªå› å­é‡çº²å¯¹é½ï¼šæƒ…ç»ªåˆ†æ•°èŒƒå›´ [-1, 1]ï¼ŒZ-Score é€šå¸¸åœ¨ [-3, 3]
        # ä¹˜ä»¥æ”¾å¤§ç³»æ•° 3.0 ä½¿å…¶å½±å“åŠ›ä¸æŠ€æœ¯å› å­åŒ¹é…
        SENTIMENT_SCALE_FACTOR = 3.0
        
        if sentiment_scores is not None and self.sentiment_weight > 0:
            # ç¡®å®šè‚¡ç¥¨ä»£ç åˆ—ç”¨äºå¯¹é½
            stock_col = self.stock_col if self.stock_col in data.columns else 'symbol'
            
            if stock_col in data.columns:
                # ä½¿ç”¨è‚¡ç¥¨ä»£ç å¯¹é½æƒ…ç»ªåˆ†æ•°
                aligned_sentiment = data[stock_col].map(sentiment_scores).fillna(0)
                # åº”ç”¨æ”¾å¤§ç³»æ•°è¿›è¡Œé‡çº²å¯¹é½
                scaled_sentiment = aligned_sentiment * SENTIMENT_SCALE_FACTOR
                total_score += self.sentiment_weight * scaled_sentiment
                logger.debug(
                    f"æƒ…ç»ªåˆ†æ•°å·²åŠ å…¥ç»¼åˆå¾—åˆ†: æƒé‡={self.sentiment_weight}, "
                    f"æ”¾å¤§ç³»æ•°={SENTIMENT_SCALE_FACTOR}, "
                    f"æœ‰æ•ˆè‚¡ç¥¨æ•°={aligned_sentiment.notna().sum()}"
                )
            else:
                # å°è¯•ä½¿ç”¨ç´¢å¼•å¯¹é½
                if isinstance(data.index, pd.MultiIndex):
                    stock_codes = data.index.get_level_values(-1)
                else:
                    stock_codes = data.index
                aligned_sentiment = stock_codes.to_series().map(sentiment_scores).fillna(0)
                aligned_sentiment.index = data.index
                # åº”ç”¨æ”¾å¤§ç³»æ•°è¿›è¡Œé‡çº²å¯¹é½
                scaled_sentiment = aligned_sentiment * SENTIMENT_SCALE_FACTOR
                total_score += self.sentiment_weight * scaled_sentiment
                logger.debug(
                    f"æƒ…ç»ªåˆ†æ•°å·²åŠ å…¥ç»¼åˆå¾—åˆ† (ç´¢å¼•å¯¹é½): æƒé‡={self.sentiment_weight}, "
                    f"æ”¾å¤§ç³»æ•°={SENTIMENT_SCALE_FACTOR}"
                )
        
        return total_score
    
    def get_month_end_dates(self, dates: pd.DatetimeIndex) -> pd.DatetimeIndex:
        """
        è·å–æ¯æœˆæœ€åä¸€ä¸ªäº¤æ˜“æ—¥
        
        Parameters
        ----------
        dates : pd.DatetimeIndex
            æ‰€æœ‰äº¤æ˜“æ—¥æœŸ
        
        Returns
        -------
        pd.DatetimeIndex
            æ¯æœˆæœ€åä¸€ä¸ªäº¤æ˜“æ—¥
        """
        dates_series = pd.Series(dates, index=dates)
        # æŒ‰å¹´æœˆåˆ†ç»„ï¼Œå–æ¯ç»„æœ€åä¸€ä¸ªæ—¥æœŸ
        month_end_dates = dates_series.groupby(
            [dates_series.index.year, dates_series.index.month]
        ).last()
        
        return pd.DatetimeIndex(month_end_dates.values)
    
    def get_week_end_dates(self, dates: pd.DatetimeIndex) -> pd.DatetimeIndex:
        """
        è·å–æ¯å‘¨æœ€åä¸€ä¸ªäº¤æ˜“æ—¥
        
        ç”¨äºå‘¨åº¦è°ƒä»“ç­–ç•¥ï¼Œæ›´å¿«æ•æ‰åŠ¨é‡å˜åŒ–ã€‚
        
        Parameters
        ----------
        dates : pd.DatetimeIndex
            æ‰€æœ‰äº¤æ˜“æ—¥æœŸ
        
        Returns
        -------
        pd.DatetimeIndex
            æ¯å‘¨æœ€åä¸€ä¸ªäº¤æ˜“æ—¥
        
        Notes
        -----
        ä½¿ç”¨ ISO å‘¨æ•°ï¼ˆå‘¨ä¸€å¼€å§‹ï¼Œå‘¨æ—¥ç»“æŸï¼‰è¿›è¡Œåˆ†ç»„ã€‚
        """
        dates_series = pd.Series(dates, index=dates)
        # æŒ‰å¹´-å‘¨åˆ†ç»„ï¼Œå–æ¯ç»„æœ€åä¸€ä¸ªæ—¥æœŸ
        # isocalendar è¿”å› (year, week, weekday)
        week_end_dates = dates_series.groupby(
            [dates_series.index.isocalendar().year, 
             dates_series.index.isocalendar().week]
        ).last()
        
        return pd.DatetimeIndex(week_end_dates.values)
    
    def get_rebalance_dates(
        self, 
        dates: pd.DatetimeIndex, 
        frequency: str = "monthly"
    ) -> pd.DatetimeIndex:
        """
        æ ¹æ®é¢‘ç‡è·å–è°ƒä»“æ—¥æœŸ
        
        Parameters
        ----------
        dates : pd.DatetimeIndex
            æ‰€æœ‰äº¤æ˜“æ—¥æœŸ
        frequency : str
            è°ƒä»“é¢‘ç‡ï¼Œå¯é€‰ 'monthly' æˆ– 'weekly'
        
        Returns
        -------
        pd.DatetimeIndex
            è°ƒä»“æ—¥æœŸ
        
        Raises
        ------
        ValueError
            å½“ frequency å‚æ•°ä¸åˆæ³•æ—¶
        """
        if frequency == "monthly":
            return self.get_month_end_dates(dates)
        elif frequency == "weekly":
            return self.get_week_end_dates(dates)
        else:
            raise ValueError(
                f"ä¸æ”¯æŒçš„è°ƒä»“é¢‘ç‡: {frequency}ï¼Œå¯é€‰ 'monthly' æˆ– 'weekly'"
            )
    
    # ===== å°èµ„é‡‘å®ç›˜ä¼˜åŒ–ï¼šæµåŠ¨æ€§ä¸å¯äº¤æ˜“æ€§è¿‡æ»¤å¸¸é‡ =====
    # æœ€ä½æ—¥æˆäº¤é¢ï¼ˆå…ƒï¼‰ï¼Œä½äºæ­¤å€¼çš„è‚¡ç¥¨æµåŠ¨æ€§ä¸è¶³
    MIN_DAILY_AMOUNT = 20_000_000  # 2000ä¸‡
    # æ¶¨åœåˆ¤æ–­é˜ˆå€¼ï¼ˆæ¶¨å¹… >= 9.5% è§†ä¸ºæ¶¨åœï¼‰
    LIMIT_UP_THRESHOLD = 0.095
    # è·Œåœåˆ¤æ–­é˜ˆå€¼ï¼ˆè·Œå¹… >= 9.5% è§†ä¸ºè·Œåœï¼‰
    LIMIT_DOWN_THRESHOLD = -0.095
    # ST/é€€å¸‚è‚¡å…³é”®å­—
    ST_KEYWORDS = ('ST', '*ST', 'é€€', 'S', 'PT')
    
    def filter_stocks(
        self,
        data: pd.DataFrame,
        date: pd.Timestamp
    ) -> pd.DataFrame:
        """
        æ ¹æ®æ¡ä»¶è¿‡æ»¤è‚¡ç¥¨ï¼ˆå¢å¼ºç‰ˆï¼šå°èµ„é‡‘å®ç›˜ä¼˜åŒ–ï¼‰
        
        é’ˆå¯¹æ¿€è¿›å‹å°å¸‚å€¼ç­–ç•¥çš„å¢å¼ºè¿‡æ»¤ï¼Œç¡®ä¿é€‰å‡ºçš„è‚¡ç¥¨ï¼š
        1. å¯äº¤æ˜“ï¼ˆéæ¶¨è·Œåœã€éSTï¼‰
        2. æœ‰æµåŠ¨æ€§ï¼ˆæˆäº¤é¢è¶³å¤Ÿï¼‰
        3. ä»·æ ¼é€‚ä¸­ï¼ˆèƒ½ä¹°å…¥è¶³å¤Ÿæ‰‹æ•°ï¼‰
        4. ä¸Šå¸‚è¶³å¤Ÿä¹…ï¼ˆéæ¬¡æ–°è‚¡ï¼‰
        
        è¿‡æ»¤æ¡ä»¶ï¼š
        1. å‰”é™¤æ¶¨è·Œåœè‚¡ç¥¨ (æ— æ³•ä¹°å…¥/å–å‡º)
        2. å‰”é™¤ä¸€å­—æ¶¨åœè‚¡ç¥¨ (High == Low ä¸”æ¶¨å¹… >= 9.5%)
        3. å‰”é™¤æµåŠ¨æ€§ä¸è¶³è‚¡ç¥¨ (æ—¥æˆäº¤é¢ < 2000ä¸‡)
        4. å‰”é™¤ ST/*ST/é€€å¸‚è‚¡ç¥¨ (é«˜é£é™©æ ‡çš„)
        5. å‰”é™¤é«˜ä»·è‚¡ (> 100å…ƒ)
        6. å‰”é™¤ä¸Šå¸‚ä¸æ»¡ 6 ä¸ªæœˆçš„è‚¡ç¥¨
        
        Parameters
        ----------
        data : pd.DataFrame
            å› å­æ•°æ®ï¼Œåº”åŒ…å«ä»¥ä¸‹åˆ—ï¼ˆéƒ¨åˆ†å¯é€‰ï¼‰ï¼š
            - close, high, low: ä»·æ ¼æ•°æ®
            - amount: æˆäº¤é¢
            - pct_change æˆ– pctChg: æ¶¨è·Œå¹…
            - name æˆ– stock_name: è‚¡ç¥¨åç§°ï¼ˆç”¨äºSTè¿‡æ»¤ï¼‰
            - is_limit: æ¶¨è·Œåœæ ‡å¿—
            - listing_days æˆ– list_date: ä¸Šå¸‚ä¿¡æ¯
        date : pd.Timestamp
            å½“å‰æ—¥æœŸ
        
        Returns
        -------
        pd.DataFrame
            è¿‡æ»¤åçš„æ•°æ®
        
        Notes
        -----
        å°èµ„é‡‘å®ç›˜ä¼˜åŒ–è¯´æ˜ï¼š
        - 30ä¸‡èµ„é‡‘æŒæœ‰3åªè‚¡ç¥¨ï¼Œæ¯åªçº¦10ä¸‡
        - æ—¥æˆäº¤é¢ < 2000ä¸‡çš„è‚¡ç¥¨ï¼Œ10ä¸‡èµ„é‡‘å¯èƒ½äº§ç”Ÿå‰§çƒˆæ»‘ç‚¹
        - ä¸€å­—æ¶¨åœè‚¡ç¥¨å®ç›˜æ— æ³•ä¹°å…¥ï¼Œå¿…é¡»å‰”é™¤
        - STè‚¡ç¥¨é£é™©æé«˜ï¼Œä¸é€‚åˆæ¿€è¿›ç­–ç•¥
        """
        # è·å–å½“æ—¥æ•°æ®
        if self.date_col in data.columns:
            day_data = data[data[self.date_col] == date].copy()
        elif isinstance(data.index, pd.DatetimeIndex):
            day_data = data.loc[data.index == date].copy()
        elif isinstance(data.index, pd.MultiIndex):
            # MultiIndex: (date, stock_code)
            if date in data.index.get_level_values(0):
                day_data = data.loc[date].copy()
            else:
                day_data = pd.DataFrame()
        else:
            logger.warning(f"æ— æ³•è·å–æ—¥æœŸ {date} çš„æ•°æ®")
            return pd.DataFrame()
        
        if day_data.empty:
            return day_data
        
        initial_count = len(day_data)
        filter_stats = {}  # è®°å½•å„è¿‡æ»¤æ¡ä»¶å‰”é™¤çš„æ•°é‡
        
        # ==========================================
        # è¿‡æ»¤æ¡ä»¶ 1: å‰”é™¤æ¶¨è·Œåœè‚¡ç¥¨ï¼ˆé€šç”¨ is_limit æ ‡å¿—ï¼‰
        # ==========================================
        if 'is_limit' in day_data.columns:
            before = len(day_data)
            day_data = day_data[~day_data['is_limit'].fillna(False)]
            filter_stats['is_limit'] = before - len(day_data)
        
        # ==========================================
        # è¿‡æ»¤æ¡ä»¶ 2: å‰”é™¤ä¸€å­—æ¶¨åœè‚¡ç¥¨ï¼ˆä¹°ä¸è¿›ï¼‰
        # åˆ¤æ–­æ¡ä»¶ï¼šHigh == Low ä¸” æ¶¨å¹… >= 9.5%
        # ==========================================
        if 'high' in day_data.columns and 'low' in day_data.columns:
            # è·å–æ¶¨è·Œå¹…åˆ—ï¼ˆå…¼å®¹å¤šç§åˆ—åï¼‰
            pct_col = None
            for col in ['pct_change', 'pctChg', 'change_pct', 'pct']:
                if col in day_data.columns:
                    pct_col = col
                    break
            
            if pct_col:
                # ä¸€å­—æ¶¨åœï¼šæœ€é«˜ä»· == æœ€ä½ä»· ä¸” æ¶¨å¹… >= 9.5%
                is_one_word_limit_up = (
                    (day_data['high'] == day_data['low']) & 
                    (day_data[pct_col] >= self.LIMIT_UP_THRESHOLD * 100)  # å‡è®¾ç™¾åˆ†æ¯”æ ¼å¼
                )
                
                # å¦‚æœæ¶¨è·Œå¹…æ˜¯å°æ•°æ ¼å¼ï¼ˆå¦‚ 0.095ï¼‰
                if day_data[pct_col].abs().max() < 1:
                    is_one_word_limit_up = (
                        (day_data['high'] == day_data['low']) & 
                        (day_data[pct_col] >= self.LIMIT_UP_THRESHOLD)
                    )
                
                before = len(day_data)
                day_data = day_data[~is_one_word_limit_up.fillna(False)]
                filter_stats['ä¸€å­—æ¶¨åœ'] = before - len(day_data)
        
        # ==========================================
        # è¿‡æ»¤æ¡ä»¶ 3: å‰”é™¤æµåŠ¨æ€§é»‘æ´ï¼ˆæ—¥æˆäº¤é¢ < 2000ä¸‡ï¼‰
        # ==========================================
        if 'amount' in day_data.columns:
            before = len(day_data)
            # æˆäº¤é¢å¯èƒ½æ˜¯ä¸‡å…ƒå•ä½ï¼Œç»Ÿä¸€è½¬æ¢
            amount_col = day_data['amount']
            # åˆ¤æ–­å•ä½ï¼šå¦‚æœæœ€å¤§å€¼ < 100ä¸‡ï¼Œå¯èƒ½æ˜¯ä¸‡å…ƒå•ä½
            if amount_col.max() < 1_000_000:
                # ä¸‡å…ƒå•ä½ï¼Œè½¬æ¢ä¸ºå…ƒ
                low_liquidity_mask = amount_col * 10000 < self.MIN_DAILY_AMOUNT
            else:
                # å…ƒå•ä½
                low_liquidity_mask = amount_col < self.MIN_DAILY_AMOUNT
            
            day_data = day_data[~low_liquidity_mask]
            filter_stats['æµåŠ¨æ€§ä¸è¶³'] = before - len(day_data)
        else:
            logger.debug("æ•°æ®ä¸­ç¼ºå°‘ 'amount' åˆ—ï¼Œè·³è¿‡æµåŠ¨æ€§è¿‡æ»¤")
        
        # ==========================================
        # è¿‡æ»¤æ¡ä»¶ 4: å‰”é™¤ ST/*ST/é€€å¸‚è‚¡ç¥¨
        # ==========================================
        name_col = None
        for col in ['name', 'stock_name', 'è‚¡ç¥¨åç§°', 'sec_name']:
            if col in day_data.columns:
                name_col = col
                break
        
        if name_col:
            before = len(day_data)
            # æ„å»º ST è¿‡æ»¤æ¡ä»¶
            st_mask = day_data[name_col].astype(str).apply(
                lambda x: any(kw in x for kw in self.ST_KEYWORDS)
            )
            day_data = day_data[~st_mask]
            filter_stats['ST/é€€å¸‚'] = before - len(day_data)
        
        # ==========================================
        # è¿‡æ»¤æ¡ä»¶ 5: å‰”é™¤é«˜ä»·è‚¡ (> 100å…ƒ)
        # ä¾æ®è§„åˆ™ï¼šç¡®ä¿æ¯åªè‚¡ç¥¨èƒ½ä¹°å…¥è‡³å°‘ 2-3 æ‰‹ï¼ˆ200-300è‚¡ï¼‰
        # 30ä¸‡èµ„é‡‘ï¼Œ3åªè‚¡ç¥¨ï¼Œæ¯åªçº¦10ä¸‡ï¼Œ100å…ƒè‚¡ç¥¨å¯ä¹°1000è‚¡
        # ==========================================
        MAX_PRICE_LIMIT = 100.0
        price_col = 'close'
        if price_col not in day_data.columns:
            price_col = next((col for col in ['price', 'close_price'] if col in day_data.columns), None)
        
        if price_col:
            before = len(day_data)
            high_price_mask = day_data[price_col] > MAX_PRICE_LIMIT
            day_data = day_data[~high_price_mask]
            filter_stats['é«˜ä»·è‚¡'] = before - len(day_data)
        else:
            logger.warning(f"æ•°æ®ä¸­ç¼ºå°‘ä»·æ ¼åˆ—ï¼Œæ— æ³•æ‰§è¡Œé«˜ä»·è‚¡è¿‡æ»¤")
        
        # ==========================================
        # è¿‡æ»¤æ¡ä»¶ 6: å‰”é™¤ä¸Šå¸‚ä¸æ»¡ 6 ä¸ªæœˆçš„è‚¡ç¥¨
        # ==========================================
        before = len(day_data)
        if 'listing_days' in day_data.columns:
            day_data = day_data[day_data['listing_days'] >= self.min_listing_days]
        elif 'list_date' in day_data.columns:
            list_dates = pd.to_datetime(day_data['list_date'])
            listing_days = (date - list_dates).dt.days
            day_data = day_data[listing_days >= self.min_listing_days]
        elif 'ipo_date' in day_data.columns:
            ipo_dates = pd.to_datetime(day_data['ipo_date'])
            listing_days = (date - ipo_dates).dt.days
            day_data = day_data[listing_days >= self.min_listing_days]
        filter_stats['æ¬¡æ–°è‚¡'] = before - len(day_data)
        
        # ==========================================
        # è¿‡æ»¤æ¡ä»¶ 7: å‰”é™¤åˆ›ä¸šæ¿è‚¡ç¥¨ï¼ˆå¯é…ç½®ï¼‰
        # åˆ›ä¸šæ¿ä»£ç ä»¥ 300xxx æˆ– 301xxx å¼€å¤´
        # ==========================================
        stock_col = self.stock_col if self.stock_col in day_data.columns else 'symbol'
        
        if self._exclude_chinext:
            if stock_col in day_data.columns:
                before = len(day_data)
                # åˆ›ä¸šæ¿è‚¡ç¥¨ä»£ç ä»¥ 300 æˆ– 301 å¼€å¤´
                chinext_mask = day_data[stock_col].astype(str).str[:3].isin(['300', '301'])
                day_data = day_data[~chinext_mask]
                filter_stats['åˆ›ä¸šæ¿'] = before - len(day_data)
            elif isinstance(day_data.index, pd.Index):
                before = len(day_data)
                chinext_mask = day_data.index.astype(str).str[:3].isin(['300', '301'])
                day_data = day_data[~chinext_mask]
                filter_stats['åˆ›ä¸šæ¿'] = before - len(day_data)
        
        # ==========================================
        # è¿‡æ»¤æ¡ä»¶ 8: å‰”é™¤ç§‘åˆ›æ¿è‚¡ç¥¨ï¼ˆå¯é…ç½®ï¼‰
        # ç§‘åˆ›æ¿ä»£ç ä»¥ 688xxx å¼€å¤´
        # ==========================================
        if self._exclude_star:
            if stock_col in day_data.columns:
                before = len(day_data)
                star_mask = day_data[stock_col].astype(str).str[:3] == '688'
                day_data = day_data[~star_mask]
                filter_stats['ç§‘åˆ›æ¿'] = before - len(day_data)
            elif isinstance(day_data.index, pd.Index):
                before = len(day_data)
                star_mask = day_data.index.astype(str).str[:3] == '688'
                day_data = day_data[~star_mask]
                filter_stats['ç§‘åˆ›æ¿'] = before - len(day_data)
        
        # ==========================================
        # æ³¨æ„ï¼šæƒ…ç»ªåˆ†æå·²ç§»è‡³ _apply_sentiment_filter æ–¹æ³•
        # é‡‡ç”¨ "Filter-Then-Analyze" æ¨¡å¼ï¼šä»…å¯¹ Top N * buffer çš„å€™é€‰è‚¡ç¥¨è¿›è¡Œæƒ…ç»ªåˆ†æ
        # è¿™æ˜¾è‘—å‡å°‘äº† LLM API è°ƒç”¨æ¬¡æ•°ï¼Œé™ä½æˆæœ¬å¹¶æé«˜æ•ˆç‡
        # ==========================================
        
        # æ±‡æ€»æ—¥å¿—
        total_filtered = initial_count - len(day_data)
        if total_filtered > 0:
            filter_detail = ", ".join(f"{k}:{v}" for k, v in filter_stats.items() if v > 0)
            logger.debug(
                f"æ—¥æœŸ {date.strftime('%Y-%m-%d')}: "
                f"è¿‡æ»¤ {total_filtered} åª ({filter_detail}), "
                f"å‰©ä½™ {len(day_data)}/{initial_count}"
            )
        else:
            logger.debug(f"æ—¥æœŸ {date.strftime('%Y-%m-%d')}: æ— è‚¡ç¥¨è¢«è¿‡æ»¤, å‰©ä½™ {len(day_data)}")
        
        return day_data
    
    def _apply_sentiment_filter(
        self,
        candidates: List[str],
        date: pd.Timestamp
    ) -> List[str]:
        """
        å¯¹é¢„é€‰å€™é€‰è‚¡ç¥¨åº”ç”¨ LLM æƒ…ç»ªåˆ†æè¿‡æ»¤
        
        é‡‡ç”¨ "Filter-Then-Analyze" æ¨¡å¼ï¼š
        ä»…å¯¹ Top N * buffer çš„å€™é€‰è‚¡ç¥¨è¿›è¡Œæƒ…ç»ªåˆ†æï¼Œè€Œéå…¨å¸‚åœºè‚¡ç¥¨ã€‚
        è¿™æ˜¾è‘—å‡å°‘äº† LLM API è°ƒç”¨æ¬¡æ•°ï¼Œé™ä½æˆæœ¬å¹¶æé«˜æ•ˆç‡ã€‚
        
        **å®‰å…¨ç­–ç•¥ (Fail-Closed)**:
        å½“ LLM æœåŠ¡ä¸å¯ç”¨æˆ–å‘ç”Ÿé”™è¯¯æ—¶ï¼Œç³»ç»Ÿé‡‡ç”¨å®‰å…¨ä¼˜å…ˆç­–ç•¥ï¼š
        - ç†”æ–­å™¨è§¦å‘: æŠ›å‡º LLMCircuitBreakerErrorï¼Œå®Œå…¨åœæ­¢äº¤æ˜“
        - å…¶ä»– LLM é”™è¯¯: è¿”å›ç©ºåˆ—è¡¨ï¼Œé˜»æ­¢ç”Ÿæˆä¹°å…¥ä¿¡å·
        è¿™é¿å…äº†åœ¨ LLM é£æ§ä¸å¯ç”¨æ—¶ä»äº§ç”Ÿä¹°å…¥ä¿¡å·çš„å±é™©æƒ…å†µã€‚
        
        Parameters
        ----------
        candidates : List[str]
            é¢„é€‰çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆé€šå¸¸ä¸º Top N * bufferï¼‰
        date : pd.Timestamp
            åˆ†ææ—¥æœŸ
        
        Returns
        -------
        List[str]
            é€šè¿‡æƒ…ç»ªè¿‡æ»¤çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨
        
        Raises
        ------
        LLMCircuitBreakerError
            å½“ LLM API è¿ç»­å¤±è´¥è¶…è¿‡é˜ˆå€¼æ—¶æŠ›å‡ºï¼Œåœæ­¢äº¤æ˜“
        
        Notes
        -----
        è¿‡æ»¤è§„åˆ™ï¼š
        1. score < sentiment_threshold: å‰”é™¤ï¼ˆè´Ÿé¢æƒ…ç»ªï¼‰
        2. confidence < min_confidence: å‰”é™¤å¹¶è®°å½•è­¦å‘Šï¼ˆä¸ç¡®å®šåˆ†æç»“æœï¼‰
        
        å¼‚å¸¸å¤„ç†ï¼ˆFail-Closed ç­–ç•¥ï¼‰ï¼š
        - LLMCircuitBreakerError: è®°å½• CRITICAL æ—¥å¿—å¹¶æŠ›å‡ºå¼‚å¸¸ï¼Œåœæ­¢äº¤æ˜“
        - å…¶ä»–å¼‚å¸¸: è®°å½• CRITICAL æ—¥å¿—å¹¶è¿”å›ç©ºåˆ—è¡¨ï¼Œé˜»æ­¢äº§ç”Ÿä¹°å…¥ä¿¡å·
        """
        if not candidates:
            return []
        
        if not self._enable_sentiment_filter or self._sentiment_engine is None:
            return candidates
        
        date_str = date.strftime('%Y-%m-%d') if hasattr(date, 'strftime') else str(date)
        
        try:
            # è°ƒç”¨æƒ…ç»ªåˆ†æå¼•æ“ï¼ˆè¿”å› DataFrameï¼‰
            sentiment_df = self._sentiment_engine.calculate_sentiment(candidates, date_str)
            
            if sentiment_df.empty:
                # æƒ…ç»ªåˆ†æè¿”å›ç©ºç»“æœä¹Ÿè§†ä¸ºå¼‚å¸¸æƒ…å†µ
                # Fail-Closed: è¿”å›ç©ºåˆ—è¡¨è€ŒéåŸå€™é€‰åˆ—è¡¨
                logger.critical(
                    f"â›” æƒ…ç»ªåˆ†æè¿”å›ç©ºç»“æœ ({date_str}), "
                    f"Fail-Closed: é˜»æ­¢æ‰€æœ‰ {len(candidates)} åªå€™é€‰è‚¡ç¥¨çš„ä¹°å…¥ä¿¡å·"
                )
                return []
            
            # è¿‡æ»¤é€»è¾‘
            # ä¸€ç¥¨å¦å†³é˜ˆå€¼ï¼šæƒ…ç»ªåˆ†æ•° < -0.5 çš„è‚¡ç¥¨ç›´æ¥å‰”é™¤
            VETO_THRESHOLD = -0.5
            
            filtered_candidates: List[str] = []
            low_confidence_count = 0
            negative_sentiment_count = 0
            vetoed_stocks: List[str] = []
            
            for _, row in sentiment_df.iterrows():
                stock_code = row["stock_code"]
                score = row["score"]
                confidence = row["confidence"]
                
                # è§„åˆ™1: ä¸€ç¥¨å¦å†³ - æƒ…ç»ªåˆ†æ•° < -0.5 ç›´æ¥å‰”é™¤
                if score < VETO_THRESHOLD:
                    negative_sentiment_count += 1
                    vetoed_stocks.append(stock_code)
                    logger.warning(
                        f"é£æ§å‰”é™¤: {stock_code} æƒ…ç»ªåˆ† {score:.2f} < {VETO_THRESHOLD}"
                    )
                    continue
                
                # è§„åˆ™2: æ£€æŸ¥ç½®ä¿¡åº¦
                if confidence < self._min_confidence:
                    low_confidence_count += 1
                    logger.warning(
                        f"Skipping {stock_code} due to low confidence: "
                        f"confidence={confidence:.2f} < min={self._min_confidence}"
                    )
                    continue
                
                # é€šè¿‡æ‰€æœ‰æ£€æŸ¥
                filtered_candidates.append(stock_code)
            
            # æ±‡æ€»æ—¥å¿—
            if vetoed_stocks:
                logger.warning(
                    f"ğŸš¨ æƒ…ç»ªé£æ§ä¸€ç¥¨å¦å†³: {len(vetoed_stocks)} åªè‚¡ç¥¨è¢«å‰”é™¤ "
                    f"(æƒ…ç»ªåˆ† < {VETO_THRESHOLD}): {vetoed_stocks}"
                )
            
            logger.info(
                f"æƒ…ç»ªè¿‡æ»¤å®Œæˆ ({date_str}): "
                f"è¾“å…¥ {len(candidates)} åª, "
                f"é€šè¿‡ {len(filtered_candidates)} åª, "
                f"ä¸€ç¥¨å¦å†³å‰”é™¤ {negative_sentiment_count} åª, "
                f"ä½ç½®ä¿¡åº¦å‰”é™¤ {low_confidence_count} åª"
            )
            
            return filtered_candidates
        
        except LLMCircuitBreakerError as e:
            # ===== ç†”æ–­å™¨è§¦å‘: åœæ­¢äº¤æ˜“ =====
            logger.critical(
                f"â›” LLM Circuit Breaker Triggered! Risk control failed. "
                f"HALTING TRADING SIGNALS. Error: {e}"
            )
            # ç›´æ¥æŠ›å‡ºå¼‚å¸¸ï¼Œå®Œå…¨åœæ­¢äº¤æ˜“æµç¨‹
            raise
        
        except Exception as e:
            # ===== å…¶ä»–å¼‚å¸¸: Fail-Closed ç­–ç•¥ =====
            # è¿”å›ç©ºåˆ—è¡¨è€ŒéåŸå€™é€‰åˆ—è¡¨ï¼Œé¿å…åœ¨ LLM é£æ§ä¸å¯ç”¨æ—¶äº§ç”Ÿä¹°å…¥ä¿¡å·
            logger.critical(
                f"â›” LLM Sentiment Analysis Failed ({date_str}): {e}. "
                f"Fail-Closed: é˜»æ­¢æ‰€æœ‰ {len(candidates)} åªå€™é€‰è‚¡ç¥¨çš„ä¹°å…¥ä¿¡å·. "
                f"åŸå› : LLM é£æ§ä¸å¯ç”¨æ—¶ä¸åº”äº§ç”Ÿäº¤æ˜“ä¿¡å·."
            )
            return []
    
    def select_top_stocks(
        self,
        data: pd.DataFrame,
        n: Optional[int] = None,
        date: Optional[pd.Timestamp] = None,
        use_sentiment_scoring: bool = True
    ) -> List[str]:
        """
        ä¸¤é˜¶æ®µé€‰è‚¡ï¼šæŠ€æœ¯é¢åˆç­› + æƒ…ç»ªé¢åŠ æˆ
        
        å®ç°"æƒ…ç»ªè¿›æ”»å‹"ç­–ç•¥çš„æ ¸å¿ƒé€‰è‚¡é€»è¾‘ï¼š
        
        **ç¬¬ä¸€é˜¶æ®µï¼ˆæŠ€æœ¯é¢åˆç­›ï¼‰**ï¼š
        ä»…æ ¹æ®æŠ€æœ¯å› å­ï¼ˆMomentum + Turnover + Size ç­‰ï¼‰è®¡ç®—åŸºç¡€å¾—åˆ†ï¼Œ
        é€‰å‡ºå‰ N * buffer_multiplier åªå€™é€‰è‚¡ç¥¨ã€‚
        
        **ç¬¬äºŒé˜¶æ®µï¼ˆæƒ…ç»ªé¢åŠ æˆï¼‰**ï¼š
        å¯¹å€™é€‰è‚¡è°ƒç”¨ LLM æƒ…ç»ªåˆ†æå¼•æ“ï¼Œè·å–æƒ…ç»ªåˆ†æ•°ï¼ˆ-1 åˆ° 1ï¼‰ã€‚
        
        **ç¬¬ä¸‰é˜¶æ®µï¼ˆæœ€ç»ˆæ’åï¼‰**ï¼š
        Final_Score = Base_Score + Sentiment_Weight * Sentiment_Score
        æ ¹æ®æœ€ç»ˆå¾—åˆ†é€‰å‡º Top Nã€‚
        
        Parameters
        ----------
        data : pd.DataFrame
            åŒ…å«å› å­æ•°æ®çš„ DataFrame
        n : Optional[int]
            é€‰å–æ•°é‡ï¼Œé»˜è®¤ä½¿ç”¨ self.top_n
        date : Optional[pd.Timestamp]
            åˆ†ææ—¥æœŸï¼Œç”¨äºæƒ…ç»ªåˆ†æã€‚å¦‚æœå¯ç”¨æƒ…ç»ªåˆ†æä½†æœªä¼ å…¥æ—¥æœŸï¼Œ
            åˆ™ä½¿ç”¨å½“å‰æ—¥æœŸæˆ–ä»æ•°æ®ä¸­æ¨æ–­ã€‚
        use_sentiment_scoring : bool
            æ˜¯å¦å¯ç”¨æƒ…ç»ªè¿›æ”»å‹åŠ åˆ†ã€‚é»˜è®¤ Trueã€‚
            è®¾ç½®ä¸º False å¯å¼ºåˆ¶ä½¿ç”¨çº¯æŠ€æœ¯é¢é€‰è‚¡ã€‚
        
        Returns
        -------
        List[str]
            é€‰ä¸­çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨
        
        Notes
        -----
        - å¦‚æœ LLM è°ƒç”¨å¤±è´¥ï¼Œè‡ªåŠ¨é™çº§ä¸ºä»…ä½¿ç”¨æŠ€æœ¯é¢å¾—åˆ†æ’åº
        - æƒ…ç»ªåˆ†æ•°èŒƒå›´ä¸º -1 åˆ° 1ï¼Œä¼šä¹˜ä»¥ sentiment_weight åŠ åˆ°åŸºç¡€åˆ†ä¸Š
        """
        n = n or self.top_n
        
        if data.empty:
            return []
        
        # ç¡®å®šè‚¡ç¥¨ä»£ç åˆ—
        stock_col = self.stock_col if self.stock_col in data.columns else 'symbol'
        
        # ==========================================
        # æ•°æ®é¢„å¤„ç†ï¼šç¡®ä¿æ¯åªè‚¡ç¥¨åªæœ‰ä¸€æ¡è®°å½•ï¼ˆä½¿ç”¨æœ€æ–°æ—¥æœŸï¼‰
        # ==========================================
        data = data.copy()
        
        # ç¡®å®šæ—¥æœŸåˆ—
        date_col_name = None
        if self.date_col in data.columns:
            date_col_name = self.date_col
        elif 'trade_date' in data.columns:
            date_col_name = 'trade_date'
        elif isinstance(data.index, pd.DatetimeIndex):
            data = data.reset_index()
            date_col_name = 'index' if 'index' in data.columns else data.columns[0]
        elif isinstance(data.index, pd.MultiIndex):
            data = data.reset_index()
            date_col_name = data.columns[0]
        
        # å»é‡ï¼šæ¯åªè‚¡ç¥¨åªä¿ç•™æœ€æ–°æ—¥æœŸçš„è®°å½•
        if stock_col in data.columns and date_col_name is not None:
            data = data.sort_values(date_col_name, ascending=False)
            data = data.drop_duplicates(subset=[stock_col], keep='first')
            logger.debug(f"æ•°æ®å»é‡å®Œæˆï¼šä¿ç•™ {len(data)} åªè‚¡ç¥¨çš„æœ€æ–°è®°å½•")
        
        # ==========================================
        # ç¬¬ä¸€é˜¶æ®µï¼šæŠ€æœ¯é¢åˆç­›ï¼ˆåŸºç¡€å¾—åˆ†ï¼‰
        # ==========================================
        data['base_score'] = self.calculate_total_score(data, sentiment_scores=None)
        
        # å‰”é™¤å¾—åˆ†ä¸º NaN çš„è‚¡ç¥¨
        valid_data = data.dropna(subset=['base_score'])
        
        if valid_data.empty:
            return []
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦è¿›è¡Œæƒ…ç»ªé¢åŠ æˆ
        should_use_sentiment = (
            use_sentiment_scoring
            and self._enable_sentiment_filter
            and self._sentiment_engine is not None
            and self.sentiment_weight > 0
        )
        
        if not should_use_sentiment:
            # çº¯æŠ€æœ¯é¢é€‰è‚¡ï¼šç›´æ¥è¿”å› Top N
            if stock_col not in valid_data.columns:
                if isinstance(valid_data.index, pd.MultiIndex):
                    top_stocks = valid_data.nlargest(n, 'base_score').index.get_level_values(-1).tolist()
                else:
                    top_stocks = valid_data.nlargest(n, 'base_score').index.tolist()
            else:
                top_stocks = valid_data.nlargest(n, 'base_score')[stock_col].tolist()
            # ç¡®ä¿å»é‡å¹¶ä¿æŒé¡ºåº
            top_stocks = list(dict.fromkeys(top_stocks))[:n]
            return top_stocks
        
        # ==========================================
        # ç¬¬ä¸€é˜¶æ®µï¼šé€‰å‡ºæ‰©å±•å€™é€‰åˆ—è¡¨ï¼ˆTop N * bufferï¼‰
        # ==========================================
        buffer_n = n * self._sentiment_buffer_multiplier
        
        if stock_col not in valid_data.columns:
            if isinstance(valid_data.index, pd.MultiIndex):
                pre_selected = valid_data.nlargest(buffer_n, 'base_score')
                pre_candidates = pre_selected.index.get_level_values(-1).tolist()
            else:
                pre_selected = valid_data.nlargest(buffer_n, 'base_score')
                pre_candidates = pre_selected.index.tolist()
        else:
            pre_selected = valid_data.nlargest(buffer_n, 'base_score')
            pre_candidates = pre_selected[stock_col].tolist()
        
        logger.debug(
            f"ç¬¬ä¸€é˜¶æ®µæŠ€æœ¯é¢åˆç­›: å…± {len(valid_data)} åªè‚¡ç¥¨ -> "
            f"é€‰å‡º {len(pre_candidates)} åªå€™é€‰è‚¡ (buffer={self._sentiment_buffer_multiplier}x)"
        )
        
        # ==========================================
        # ç¬¬äºŒé˜¶æ®µï¼šæƒ…ç»ªé¢åŠ æˆï¼ˆLLM åˆ†æï¼‰
        # ==========================================
        sentiment_scores: Optional[pd.Series] = None
        
        # ç¡®å®šåˆ†ææ—¥æœŸ
        if date is None:
            if self.date_col in data.columns:
                date = pd.to_datetime(data[self.date_col]).max()
            elif isinstance(data.index, pd.DatetimeIndex):
                date = data.index.max()
            elif isinstance(data.index, pd.MultiIndex):
                date = data.index.get_level_values(0).max()
            else:
                date = pd.Timestamp.now()
        
        date_str = date.strftime('%Y-%m-%d') if hasattr(date, 'strftime') else str(date)
        
        # ä¸€ç¥¨å¦å†³é˜ˆå€¼ï¼šæƒ…ç»ªåˆ†æ•° < -0.5 çš„è‚¡ç¥¨ç›´æ¥å‰”é™¤
        VETO_THRESHOLD = -0.5
        vetoed_stocks: List[str] = []
        
        try:
            # è°ƒç”¨æƒ…ç»ªåˆ†æå¼•æ“
            sentiment_df = self._sentiment_engine.calculate_sentiment(pre_candidates, date_str)
            
            if sentiment_df.empty:
                logger.warning(
                    f"æƒ…ç»ªåˆ†æè¿”å›ç©ºç»“æœ ({date_str}), "
                    f"é™çº§ä¸ºçº¯æŠ€æœ¯é¢é€‰è‚¡"
                )
            else:
                # ========== ä¸€ç¥¨å¦å†³é€»è¾‘ ==========
                # æƒ…ç»ªåˆ†æ•° < -0.5 çš„è‚¡ç¥¨ç›´æ¥ä»å€™é€‰åˆ—è¡¨ä¸­å‰”é™¤
                for _, row in sentiment_df.iterrows():
                    stock_code = row["stock_code"]
                    score = row["score"]
                    
                    if score < VETO_THRESHOLD:
                        vetoed_stocks.append(stock_code)
                        logger.warning(
                            f"é£æ§å‰”é™¤: {stock_code} æƒ…ç»ªåˆ† {score:.2f} < {VETO_THRESHOLD}"
                        )
                
                # æ±‡æ€»ä¸€ç¥¨å¦å†³æ—¥å¿—
                if vetoed_stocks:
                    logger.warning(
                        f"ğŸš¨ æƒ…ç»ªé£æ§ä¸€ç¥¨å¦å†³: {len(vetoed_stocks)} åªè‚¡ç¥¨è¢«å‰”é™¤ "
                        f"(æƒ…ç»ªåˆ† < {VETO_THRESHOLD}): {vetoed_stocks}"
                    )
                    # ä»å€™é€‰åˆ—è¡¨ä¸­ç§»é™¤è¢«å¦å†³çš„è‚¡ç¥¨
                    pre_candidates = [s for s in pre_candidates if s not in vetoed_stocks]
                
                # ========== æ„å»ºæƒ…ç»ªåˆ†æ•° Series ==========
                # ä»…å¯¹ score > 0 çš„è‚¡ç¥¨è¿›è¡ŒåŠ åˆ†ï¼Œscore <= 0 æ—¶ä¸åŠ åˆ†ï¼ˆè®¾ä¸º 0ï¼‰
                raw_scores = pd.Series(
                    sentiment_df['score'].values,
                    index=sentiment_df['stock_code'].values
                )
                
                # åªä¿ç•™æ­£åˆ†ç”¨äºåŠ åˆ†ï¼Œè´Ÿåˆ†å’Œé›¶åˆ†ä¸åŠ åˆ†ï¼ˆè®¾ä¸º0ï¼‰
                sentiment_scores = raw_scores.clip(lower=0)
                
                positive_count = (raw_scores > 0).sum()
                neutral_count = ((raw_scores <= 0) & (raw_scores >= VETO_THRESHOLD)).sum()
                
                logger.info(
                    f"æƒ…ç»ªåˆ†æå®Œæˆ ({date_str}): "
                    f"åŸå§‹ {len(raw_scores)} åª, "
                    f"æ­£é¢åŠ åˆ† {positive_count} åª, "
                    f"ä¸­æ€§ä¸åŠ åˆ† {neutral_count} åª, "
                    f"ä¸€ç¥¨å¦å†³ {len(vetoed_stocks)} åª"
                )
        
        except LLMCircuitBreakerError:
            # ç†”æ–­å™¨è§¦å‘ï¼šç›´æ¥æŠ›å‡ºï¼Œç”±ä¸Šå±‚å¤„ç†
            raise
        
        except Exception as e:
            # ===== LLM å¼‚å¸¸å¤„ç†ï¼šé™çº§ä¸ºçº¯æŠ€æœ¯é¢ =====
            logger.warning(
                f"âš ï¸ æƒ…ç»ªåˆ†æå¤±è´¥ ({date_str}): {e}. "
                f"é™çº§ä¸ºçº¯æŠ€æœ¯é¢é€‰è‚¡ï¼Œä¸é˜»æ–­äº¤æ˜“æµç¨‹ã€‚"
            )
            sentiment_scores = None
        
        # ==========================================
        # ç¬¬ä¸‰é˜¶æ®µï¼šæœ€ç»ˆæ’å
        # Final_Score = Base_Score + Sentiment_Weight * Sentiment_Score
        # æ³¨æ„ï¼šsentiment_scores å·²å¤„ç†ï¼Œä»…æ­£åˆ†ä¼šè¢«åŠ å…¥
        # ==========================================
        # ç­›é€‰å‡ºå€™é€‰è‚¡çš„æ•°æ®å­é›†ï¼ˆæ’é™¤è¢«ä¸€ç¥¨å¦å†³çš„è‚¡ç¥¨ï¼‰
        if stock_col in valid_data.columns:
            candidate_mask = valid_data[stock_col].isin(pre_candidates)
        else:
            if isinstance(valid_data.index, pd.MultiIndex):
                candidate_mask = valid_data.index.get_level_values(-1).isin(pre_candidates)
            else:
                candidate_mask = valid_data.index.isin(pre_candidates)
        
        candidate_data = valid_data[candidate_mask].copy()
        
        # è®¡ç®—æœ€ç»ˆå¾—åˆ†ï¼ˆåŒ…å«æƒ…ç»ªåˆ†æ•°ï¼Œä»…æ­£åˆ†åŠ åˆ†ï¼‰
        candidate_data['final_score'] = self.calculate_total_score(
            candidate_data,
            sentiment_scores=sentiment_scores
        )
        
        # é€‰å–æœ€ç»ˆ Top N
        if stock_col not in candidate_data.columns:
            if isinstance(candidate_data.index, pd.MultiIndex):
                top_stocks = candidate_data.nlargest(n, 'final_score').index.get_level_values(-1).tolist()
            else:
                top_stocks = candidate_data.nlargest(n, 'final_score').index.tolist()
        else:
            top_stocks = candidate_data.nlargest(n, 'final_score')[stock_col].tolist()
        
        # ç¡®ä¿å»é‡å¹¶ä¿æŒé¡ºåº
        top_stocks = list(dict.fromkeys(top_stocks))[:n]
        
        logger.debug(
            f"ç¬¬ä¸‰é˜¶æ®µæœ€ç»ˆæ’å: {len(pre_candidates)} åªå€™é€‰è‚¡ -> "
            f"é€‰å‡º {len(top_stocks)} åªç›®æ ‡è‚¡ç¥¨ "
            f"(ä¸€ç¥¨å¦å†³å‰”é™¤ {len(vetoed_stocks)} åª)"
        )
        
        return top_stocks
    
    def generate_target_positions(
        self,
        data: pd.DataFrame,
        start_date: Optional[pd.Timestamp] = None,
        end_date: Optional[pd.Timestamp] = None,
        benchmark_data: Optional[pd.DataFrame] = None
    ) -> pd.DataFrame:
        """
        ç”Ÿæˆç›®æ ‡æŒä»“çŸ©é˜µ
        
        æ¯æœˆæœ€åä¸€ä¸ªäº¤æ˜“æ—¥è¿›è¡Œè°ƒä»“ï¼Œé€‰å– Total_Score æœ€é«˜çš„ Top N åªè‚¡ç¥¨ã€‚
        
        Parameters
        ----------
        data : pd.DataFrame
            å› å­æ•°æ®ï¼Œå¿…é¡»åŒ…å«ï¼š
            - æ—¥æœŸåˆ—ï¼ˆdate æˆ– DatetimeIndexï¼‰
            - è‚¡ç¥¨ä»£ç åˆ—ï¼ˆstock_code æˆ– symbolï¼‰
            - ä»·å€¼å› å­ Z-Score åˆ—
            - è´¨é‡å› å­ Z-Score åˆ—
            - åŠ¨é‡å› å­ Z-Score åˆ—
            - is_limit: æ¶¨è·Œåœæ ‡å¿—ï¼ˆå¯é€‰ï¼‰
            - listing_days æˆ– list_date: ä¸Šå¸‚å¤©æ•°/æ—¥æœŸï¼ˆå¯é€‰ï¼‰
        start_date : Optional[pd.Timestamp]
            å¼€å§‹æ—¥æœŸ
        end_date : Optional[pd.Timestamp]
            ç»“æŸæ—¥æœŸ
        benchmark_data : Optional[pd.DataFrame]
            åŸºå‡†æŒ‡æ•°æ•°æ®ï¼ˆå¦‚æ²ªæ·±300ï¼‰ï¼Œç”¨äºå¤§ç›˜é£æ§ã€‚
            éœ€åŒ…å« 'close' åˆ—ï¼Œç´¢å¼•ä¸º DatetimeIndexã€‚
            å¦‚æœä¸º Noneï¼Œåˆ™è·³è¿‡å¤§ç›˜é£æ§é€»è¾‘ã€‚
        
        Returns
        -------
        pd.DataFrame
            å¸ƒå°”å‹ DataFrameï¼ŒIndex=Date, Columns=Symbol
            True ä»£è¡¨æŒæœ‰è¯¥è‚¡ç¥¨
        
        Examples
        --------
        >>> strategy = MultiFactorStrategy("MF", {"top_n": 30})
        >>> # ä¸å¯ç”¨å¤§ç›˜é£æ§
        >>> positions = strategy.generate_target_positions(factor_data)
        >>> 
        >>> # å¯ç”¨å¤§ç›˜é£æ§
        >>> hs300_data = data_loader.fetch_index_price("000300", "2020-01-01", "2024-12-31")
        >>> positions = strategy.generate_target_positions(factor_data, benchmark_data=hs300_data)
        >>> print(positions.sum(axis=1))  # æ¯æ—¥æŒä»“æ•°é‡
        """
        # ç¡®å®šæ—¥æœŸåˆ—
        if self.date_col in data.columns:
            dates_array = pd.to_datetime(data[self.date_col].unique())
        elif isinstance(data.index, pd.DatetimeIndex):
            dates_array = data.index.unique()
        elif isinstance(data.index, pd.MultiIndex):
            dates_array = data.index.get_level_values(0).unique()
        else:
            raise ValueError("æ— æ³•ç¡®å®šæ—¥æœŸåˆ—ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼æˆ–é…ç½® date_col")
        
        # ç¡®å®šè‚¡ç¥¨åˆ—
        stock_col = self.stock_col if self.stock_col in data.columns else 'symbol'
        if stock_col in data.columns:
            all_stocks = data[stock_col].unique()
        elif isinstance(data.index, pd.MultiIndex):
            all_stocks = data.index.get_level_values(-1).unique()
        else:
            raise ValueError("æ— æ³•ç¡®å®šè‚¡ç¥¨ä»£ç åˆ—ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼æˆ–é…ç½® stock_col")
        
        # æ’åºæ—¥æœŸ
        all_dates = pd.DatetimeIndex(sorted(dates_array))
        
        # åº”ç”¨æ—¥æœŸè¿‡æ»¤
        if start_date is not None:
            all_dates = all_dates[all_dates >= start_date]
        if end_date is not None:
            all_dates = all_dates[all_dates <= end_date]
        
        if all_dates.empty:
            logger.warning("è¿‡æ»¤åæ— æœ‰æ•ˆæ—¥æœŸ")
            return pd.DataFrame()
        
        # æ ¹æ®é…ç½®çš„é¢‘ç‡è·å–è°ƒä»“æ—¥æœŸ
        rebalance_dates = set(self.get_rebalance_dates(all_dates, self.rebalance_frequency))
        
        logger.info(
            f"è°ƒä»“æ—¥æœŸæ•°é‡: {len(rebalance_dates)} ({self.rebalance_frequency})"
        )

        # === å¤§ç›˜é£æ§å‡†å¤‡ï¼ˆæ¿€è¿›ç‰ˆï¼šMA60 + 20æ—¥è·Œå¹…åˆ¤æ–­ï¼‰===
        # æ¿€è¿›ç­–ç•¥ä½¿ç”¨æ›´å®½æ¾çš„é£æ§æ¡ä»¶ï¼Œé¿å…è¸ç©ºè¡Œæƒ…
        # é»˜è®¤ä¸º False (æ— é£é™©)
        market_risk_series = pd.Series(False, index=all_dates)
        
        if benchmark_data is not None and not benchmark_data.empty:
            try:
                index_df = benchmark_data.copy()
                
                # ç¡®ä¿ç´¢å¼•æ˜¯ DatetimeIndex
                if not isinstance(index_df.index, pd.DatetimeIndex):
                    if 'date' in index_df.columns:
                        index_df['date'] = pd.to_datetime(index_df['date'])
                        index_df = index_df.set_index('date')
                    else:
                        index_df.index = pd.to_datetime(index_df.index)
                
                index_df = index_df.sort_index()
                
                # ===== æ¿€è¿›ç‰ˆé£æ§ï¼šMA60ï¼ˆç‰›ç†Šçº¿ï¼‰+ 20æ—¥è·Œå¹… =====
                # è®¡ç®—60æ—¥å‡çº¿ï¼ˆç‰›ç†Šçº¿ï¼‰
                index_df['ma60'] = index_df['close'].rolling(window=60).mean()
                
                # è®¡ç®—20å¤©å‰è·Œå¹…
                # drop_20d = (close_today - close_20d_ago) / close_20d_ago
                drop_lookback = 20
                index_df['drop_20d'] = (
                    index_df['close'] - index_df['close'].shift(drop_lookback)
                ) / index_df['close'].shift(drop_lookback)
                
                # å¯¹é½åˆ°ç­–ç•¥æ—¥æœŸèŒƒå›´
                # ä½¿ç”¨ ffill å¡«å……éäº¤æ˜“æ—¥çš„ç©ºç¼º (å¦‚æœæœ‰çš„è¯)
                aligned_index = index_df.reindex(all_dates, method='ffill')
                
                # ===== è¶‹åŠ¿é£æ§æ¡ä»¶ï¼ˆOR é€»è¾‘ï¼‰=====
                # åŸè§„åˆ™ï¼ˆANDï¼‰: (Close < MA60) AND (20æ—¥è·Œå¹… > 5%)
                #   é—®é¢˜ï¼šç¼“æ…¢é˜´è·Œçš„ç†Šå¸‚ä¸­ä¸ä¼šè§¦å‘ï¼Œéå¸¸å±é™©
                # æ–°è§„åˆ™ï¼ˆORï¼‰: (Close < MA60) OR (20æ—¥è·Œå¹… > 5%)
                # 
                # é€»è¾‘è¯´æ˜ï¼š
                # 1. åªè¦è·Œç ´ MA60ï¼ˆç‰›ç†Šçº¿ï¼‰ï¼Œå°±è§¦å‘é£æ§
                # 2. æˆ–è€…å‘ç”Ÿæš´è·Œï¼ˆ20æ—¥è·Œå¹…è¶…5%ï¼‰ï¼Œä¹Ÿè§¦å‘é£æ§
                # 3. ä¸¤è€…æ»¡è¶³å…¶ä¸€å³ç©ºä»“ï¼Œæ›´åŠ å®‰å…¨
                drop_threshold = -0.05  # 20æ—¥è·Œå¹…é˜ˆå€¼ï¼ˆ-5%ï¼‰
                
                condition_below_ma60 = aligned_index['close'] < aligned_index['ma60']
                condition_crash = aligned_index['drop_20d'] < drop_threshold
                
                # ä½¿ç”¨ OR é€»è¾‘ï¼šåªè¦æ»¡è¶³å…¶ä¸€å³è§¦å‘é£æ§
                market_risk_series = (condition_below_ma60 | condition_crash).fillna(False)
                
                logger.info(
                    f"å·²ä½¿ç”¨è¶‹åŠ¿é£æ§ (OR é€»è¾‘): (Close < MA60) OR (20æ—¥è·Œå¹… < {drop_threshold:.0%})"
                )
                
            except Exception as e:
                logger.warning(f"è®¡ç®—å¤§ç›˜é£æ§æŒ‡æ ‡å¤±è´¥: {e}ï¼Œé£æ§åŠŸèƒ½æš‚æ—¶å¤±æ•ˆ")
        else:
            logger.debug("æœªä¼ å…¥åŸºå‡†æ•°æ®ï¼Œå¤§ç›˜é£æ§æœªå¯ç”¨")
        # ===========================
        
        # åˆå§‹åŒ–ç›®æ ‡æŒä»“çŸ©é˜µ
        target_positions = pd.DataFrame(
            False,
            index=all_dates,
            columns=sorted(all_stocks),
            dtype=bool
        )
        target_positions.index.name = 'date'
        target_positions.columns.name = 'symbol'
        
        # å½“å‰æŒä»“
        current_holdings: List[str] = []
        
        for date in all_dates:
            # 1. æ¯æ—¥é£æ§æ£€æŸ¥
            is_risk_triggered = market_risk_series.loc[date]
            
            # 2. è°ƒä»“é€»è¾‘ï¼ˆé‡‡ç”¨ä¸¤é˜¶æ®µé€‰è‚¡æ¨¡å¼ï¼šæŠ€æœ¯é¢åˆç­› + æƒ…ç»ªé¢åŠ æˆï¼‰
            if date in rebalance_dates:
                # è°ƒä»“æ—¥: é‡æ–°é€‰è‚¡ (æ— è®ºæ˜¯å¦æœ‰é£æ§ï¼Œéƒ½æ›´æ–°é€‰è‚¡åˆ—è¡¨ä»¥å¤‡åç”¨)
                filtered_data = self.filter_stocks(data, date)
                
                if not filtered_data.empty:
                    try:
                        # ä½¿ç”¨æ–°çš„ä¸¤é˜¶æ®µé€‰è‚¡æ–¹æ³•
                        # select_top_stocks å†…éƒ¨å·²å®ç°ï¼š
                        # 1. æŠ€æœ¯é¢åˆç­› -> Top N * buffer å€™é€‰è‚¡
                        # 2. æƒ…ç»ªåˆ†æè·å–æƒ…ç»ªåˆ†æ•°
                        # 3. æœ€ç»ˆæ’å = åŸºç¡€åˆ† + æƒ…ç»ªæƒé‡ * æƒ…ç»ªåˆ†
                        current_holdings = self.select_top_stocks(
                            filtered_data,
                            n=self.top_n,
                            date=date,
                            use_sentiment_scoring=True
                        )
                        
                        logger.debug(
                            f"è°ƒä»“æ—¥ {date.strftime('%Y-%m-%d')}: "
                            f"ä¸¤é˜¶æ®µé€‰è‚¡å®Œæˆ, é€‰ä¸­ {len(current_holdings)} åªè‚¡ç¥¨"
                        )
                    
                    except LLMCircuitBreakerError:
                        # ===== ç†”æ–­å™¨è§¦å‘: åœæ­¢äº¤æ˜“ =====
                        # ç›´æ¥æŠ›å‡ºï¼Œç”±è°ƒç”¨æ–¹å¤„ç†
                        raise
                else:
                    logger.warning(f"è°ƒä»“æ—¥ {date.strftime('%Y-%m-%d')}: æ— å¯é€‰è‚¡ç¥¨")
                    current_holdings = []
            
            # 3. é£æ§å¤„ç†
            if is_risk_triggered:
                # ä»…åœ¨è°ƒä»“æ—¥è®°å½•æ—¥å¿—ï¼Œé¿å…æ—¥å¿—çˆ†ç‚¸
                if date in rebalance_dates:
                    logger.warning(f"æ—¥æœŸ {date.strftime('%Y-%m-%d')}: å¤§ç›˜è·Œç ´20æ—¥å‡çº¿ï¼Œç³»ç»Ÿå¼ºåˆ¶ç©ºä»“")
                # è§¦å‘é£æ§æ—¶ï¼Œç›´æ¥è·³è¿‡æŒä»“è®¾ç½® (ä¿æŒä¸º False)
                continue
            
            # 4. è®¾ç½®å½“æ—¥æŒä»“ (å¦‚æœæ— é£æ§)
            for stock in current_holdings:
                if stock in target_positions.columns:
                    target_positions.loc[date, stock] = True
        
        # ç»Ÿè®¡ä¿¡æ¯
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_trades = (target_positions.astype(int).diff().abs().sum().sum()) // 2
        avg_holdings = target_positions.sum(axis=1).mean()
        logger.info(
            f"ç›®æ ‡æŒä»“çŸ©é˜µç”Ÿæˆå®Œæˆ: "
            f"æ—¥æœŸèŒƒå›´ {all_dates[0].strftime('%Y-%m-%d')} ~ {all_dates[-1].strftime('%Y-%m-%d')}, "
            f"å¹³å‡æŒä»“ {avg_holdings:.1f} åª, é¢„è®¡æ¢æ‰‹æ¬¡æ•° {total_trades:.0f}"
        )
        
        return target_positions
    
    def generate_signals(self, data: pd.DataFrame) -> pd.Series:
        """
        ç”Ÿæˆäº¤æ˜“ä¿¡å·ï¼ˆå…¼å®¹åŸºç±»æ¥å£ï¼‰
        
        å¯¹äºå¤šå› å­ç­–ç•¥ï¼Œä¸»è¦ä½¿ç”¨ generate_target_positions æ–¹æ³•ã€‚
        æ­¤æ–¹æ³•æä¾›ç®€åŒ–çš„å•è‚¡ç¥¨ä¿¡å·ç”Ÿæˆï¼Œç”¨äºå…¼å®¹åŸºç±»æ¥å£ã€‚
        
        Parameters
        ----------
        data : pd.DataFrame
            ä»·æ ¼å’Œå› å­æ•°æ®
        
        Returns
        -------
        pd.Series
            äº¤æ˜“ä¿¡å·åºåˆ—ï¼Œ1=ä¹°å…¥ï¼Œ-1=å–å‡ºï¼Œ0=æŒæœ‰
        """
        # æ£€æŸ¥æ˜¯å¦æœ‰æ‰€éœ€å› å­åˆ—
        has_factors = all(
            col in data.columns
            for col in [self.value_col, self.quality_col, self.momentum_col]
        )
        
        if not has_factors:
            logger.warning("æ•°æ®ä¸­ç¼ºå°‘å› å­åˆ—ï¼Œè¿”å›ç©ºä¿¡å·")
            return pd.Series(0, index=data.index)
        
        # è®¡ç®—ç»¼åˆå¾—åˆ†
        total_score = self.calculate_total_score(data)
        
        # åŸºäºåˆ†ä½æ•°ç”Ÿæˆä¿¡å·
        signals = pd.Series(0, index=data.index)
        
        # é«˜åˆ†ï¼ˆTop 10%ï¼‰ä¹°å…¥
        high_threshold = total_score.quantile(0.9)
        signals[total_score >= high_threshold] = 1
        
        # ä½åˆ†ï¼ˆBottom 10%ï¼‰å–å‡º
        low_threshold = total_score.quantile(0.1)
        signals[total_score <= low_threshold] = -1
        
        return signals
    
    def calculate_position_size(
        self,
        signal: TradeSignal,
        portfolio_value: float
    ) -> float:
        """
        è®¡ç®—ä»“ä½å¤§å°
        
        ä½¿ç”¨ç­‰æƒé‡åˆ†é…ç­–ç•¥ï¼Œæ¯åªè‚¡ç¥¨åˆ†é…ç›¸ç­‰çš„èµ„é‡‘ã€‚
        
        Parameters
        ----------
        signal : TradeSignal
            äº¤æ˜“ä¿¡å·
        portfolio_value : float
            ç»„åˆæ€»ä»·å€¼
        
        Returns
        -------
        float
            å»ºè®®ä»“ä½é‡‘é¢
        """
        # ç­‰æƒé‡åˆ†é…
        base_size = portfolio_value / self.top_n
        adjusted_size = base_size * signal.strength
        
        return adjusted_size
    
    def get_rebalance_summary(
        self,
        target_positions: pd.DataFrame
    ) -> pd.DataFrame:
        """
        è·å–è°ƒä»“æ±‡æ€»ä¿¡æ¯
        
        Parameters
        ----------
        target_positions : pd.DataFrame
            ç›®æ ‡æŒä»“çŸ©é˜µ
        
        Returns
        -------
        pd.DataFrame
            è°ƒä»“æ±‡æ€»ï¼ŒåŒ…å«æ¯ä¸ªè°ƒä»“æ—¥çš„ä¹°å…¥/å–å‡ºè‚¡ç¥¨æ•°é‡
        """
        if target_positions.empty:
            return pd.DataFrame()
        
        # è®¡ç®—æ¯æ—¥å˜åŒ–
        position_change = target_positions.astype(int).diff()
        
        # è·å–è°ƒä»“æ—¥
        rebalance_dates = self.get_month_end_dates(target_positions.index)
        
        summary_records = []
        
        for date in rebalance_dates:
            if date not in position_change.index:
                continue
            
            day_change = position_change.loc[date]
            
            # ä¹°å…¥è‚¡ç¥¨ï¼ˆ0 -> 1ï¼‰
            buy_stocks = day_change[day_change == 1].index.tolist()
            
            # å–å‡ºè‚¡ç¥¨ï¼ˆ1 -> 0ï¼‰
            sell_stocks = day_change[day_change == -1].index.tolist()
            
            # æŒæœ‰è‚¡ç¥¨
            hold_stocks = target_positions.loc[date][target_positions.loc[date]].index.tolist()
            
            summary_records.append({
                'date': date,
                'buy_count': len(buy_stocks),
                'sell_count': len(sell_stocks),
                'hold_count': len(hold_stocks),
                'buy_stocks': buy_stocks,
                'sell_stocks': sell_stocks,
            })
        
        return pd.DataFrame(summary_records)
    
    # ==================== æƒé‡ä¼˜åŒ– ====================
    
    def optimize_weights(
        self,
        prices: pd.DataFrame,
        selected_stocks: List[str],
        objective: str = "max_sharpe",
        risk_free_rate: float = 0.02,
        max_weight: Optional[float] = None,
        min_weight: float = 0.0,
        lookback_days: int = 252
    ) -> Dict[str, float]:
        """
        ä½¿ç”¨ PyPortfolioOpt ä¼˜åŒ–æŠ•èµ„ç»„åˆæƒé‡
        
        åŸºäºé€‰ä¸­è‚¡ç¥¨çš„å†å²ä»·æ ¼ï¼Œè®¡ç®—æœ€ä¼˜æƒé‡é…ç½®ã€‚
        
        Parameters
        ----------
        prices : pd.DataFrame
            ä»·æ ¼æ•°æ®ï¼Œç´¢å¼•ä¸ºæ—¥æœŸï¼Œåˆ—ä¸ºè‚¡ç¥¨ä»£ç 
        selected_stocks : List[str]
            é€‰ä¸­çš„è‚¡ç¥¨åˆ—è¡¨
        objective : str, optional
            ä¼˜åŒ–ç›®æ ‡ï¼Œå¯é€‰ï¼š
            - 'max_sharpe': æœ€å¤§å¤æ™®æ¯”ç‡ï¼ˆé»˜è®¤ï¼‰
            - 'min_volatility': æœ€å°æ³¢åŠ¨ç‡
        risk_free_rate : float, optional
            æ— é£é™©åˆ©ç‡ï¼Œé»˜è®¤0.02ï¼ˆ2%ï¼‰
        max_weight : Optional[float]
            å•åªè‚¡ç¥¨æœ€å¤§æƒé‡ï¼Œé»˜è®¤0.05ï¼ˆ5%ï¼‰
            å¦‚æœä¸ºNoneï¼Œä½¿ç”¨ 1/top_n æˆ– 0.05 ä¸­çš„è¾ƒå°å€¼
        min_weight : float, optional
            å•åªè‚¡ç¥¨æœ€å°æƒé‡ï¼Œé»˜è®¤0.0
        lookback_days : int, optional
            å›æº¯å¤©æ•°ç”¨äºè®¡ç®—åæ–¹å·®ï¼Œé»˜è®¤252
        
        Returns
        -------
        Dict[str, float]
            ä¼˜åŒ–åçš„æƒé‡å­—å…¸ï¼Œè‚¡ç¥¨ä»£ç  -> æƒé‡
        
        Examples
        --------
        >>> strategy = MultiFactorStrategy("MF", {"top_n": 30})
        >>> weights = strategy.optimize_weights(
        ...     prices_df, selected_stocks, objective='max_sharpe'
        ... )
        >>> print(weights)
        
        Notes
        -----
        - ä½¿ç”¨ Ledoit-Wolf å‹ç¼©åæ–¹å·®çŸ©é˜µä»¥æé«˜ç¨³å®šæ€§
        - å•åªè‚¡ç¥¨æƒé‡é»˜è®¤ä¸è¶…è¿‡ 5%
        - ä¼˜åŒ–å¤±è´¥æ—¶è¿”å›ç­‰æƒé‡åˆ†é…
        """
        try:
            from pypfopt import EfficientFrontier, risk_models, expected_returns
        except ImportError:
            logger.warning(
                "æœªå®‰è£… pypfoptï¼Œä½¿ç”¨ç­‰æƒé‡åˆ†é…ã€‚"
                "å®‰è£…å‘½ä»¤: pip install pyportfolioopt"
            )
            return self._equal_weights(selected_stocks)
        
        # è®¾ç½®é»˜è®¤æœ€å¤§æƒé‡
        if max_weight is None:
            max_weight = min(0.05, 1.0 / len(selected_stocks))
        
        # è¿‡æ»¤ä»·æ ¼æ•°æ®
        available_stocks = [s for s in selected_stocks if s in prices.columns]
        
        if len(available_stocks) < 2:
            logger.warning("å¯ç”¨è‚¡ç¥¨æ•°å°‘äº2ï¼Œä½¿ç”¨ç­‰æƒé‡åˆ†é…")
            return self._equal_weights(selected_stocks)
        
        # è·å–å›æº¯æœŸä»·æ ¼æ•°æ®
        stock_prices = prices[available_stocks].tail(lookback_days).dropna(axis=1)
        
        if stock_prices.shape[1] < 2:
            logger.warning("æœ‰æ•ˆä»·æ ¼æ•°æ®çš„è‚¡ç¥¨æ•°å°‘äº2ï¼Œä½¿ç”¨ç­‰æƒé‡åˆ†é…")
            return self._equal_weights(selected_stocks)
        
        try:
            # å¦‚æœä¼˜åŒ–ç›®æ ‡æ˜¯ç­‰æƒé‡ï¼Œç›´æ¥è¿”å›
            if objective == "equal_weight":
                logger.info("ä½¿ç”¨ç­‰æƒé‡åˆ†é…ç­–ç•¥")
                return self._equal_weights(selected_stocks)
            
            # è®¡ç®—é¢„æœŸæ”¶ç›Šç‡
            mu = expected_returns.mean_historical_return(stock_prices)
            
            # ä½¿ç”¨ Ledoit-Wolf å‹ç¼©åæ–¹å·®çŸ©é˜µ
            S = risk_models.CovarianceShrinkage(stock_prices).ledoit_wolf()
            
            # åˆ›å»ºæœ‰æ•ˆè¾¹ç•Œä¼˜åŒ–å™¨
            ef = EfficientFrontier(
                mu, S,
                weight_bounds=(min_weight, max_weight)
            )
            
            # æ‰§è¡Œä¼˜åŒ–
            if objective == "max_sharpe":
                weights = ef.max_sharpe(risk_free_rate=risk_free_rate)
            elif objective == "min_volatility":
                weights = ef.min_volatility()
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„ä¼˜åŒ–ç›®æ ‡: {objective}")
            
            # æ¸…ç†æƒé‡
            clean_weights = ef.clean_weights(cutoff=1e-4, rounding=4)
            
            # è·å–ç»©æ•ˆæŒ‡æ ‡
            performance = ef.portfolio_performance(
                verbose=False,
                risk_free_rate=risk_free_rate
            )
            
            logger.info(
                f"æƒé‡ä¼˜åŒ–å®Œæˆ [{objective}]: "
                f"é¢„æœŸæ”¶ç›Š {performance[0]:.2%}, "
                f"æ³¢åŠ¨ç‡ {performance[1]:.2%}, "
                f"å¤æ™®æ¯”ç‡ {performance[2]:.2f}"
            )
            
            return clean_weights
            
        except Exception as e:
            logger.warning(f"æƒé‡ä¼˜åŒ–å¤±è´¥: {e}ï¼Œä½¿ç”¨ç­‰æƒé‡åˆ†é…")
            return self._equal_weights(available_stocks)
    
    def _equal_weights(self, stocks: List[str]) -> Dict[str, float]:
        """
        ç”Ÿæˆç­‰æƒé‡åˆ†é…
        
        Parameters
        ----------
        stocks : List[str]
            è‚¡ç¥¨åˆ—è¡¨
        
        Returns
        -------
        Dict[str, float]
            ç­‰æƒé‡å­—å…¸
        """
        if not stocks:
            return {}
        weight = 1.0 / len(stocks)
        return {stock: weight for stock in stocks}
    
    def generate_target_weights(
        self,
        factor_data: pd.DataFrame,
        prices: pd.DataFrame,
        objective: str = "equal_weight",
        risk_free_rate: float = 0.02,
        max_weight: Optional[float] = None,
        start_date: Optional[pd.Timestamp] = None,
        end_date: Optional[pd.Timestamp] = None,
        current_holdings_weights: Optional[Dict[str, float]] = None,
        rebalance_threshold: Optional[float] = None,
        benchmark_data: Optional[pd.DataFrame] = None
    ) -> pd.DataFrame:
        """
        ç”Ÿæˆå¸¦æƒé‡çš„ç›®æ ‡æŒä»“çŸ©é˜µï¼ˆå«å†å¹³è¡¡ç¼“å†²åŒº + å¤§ç›˜é£æ§ï¼‰
        
        æ¯æœˆæœ€åä¸€ä¸ªäº¤æ˜“æ—¥è¿›è¡Œè°ƒä»“ï¼Œä½¿ç”¨ä¼˜åŒ–æƒé‡æˆ–ç­‰æƒé‡ã€‚
        ä¸ºé¿å…å°èµ„é‡‘è´¦æˆ·æ”¯ä»˜æœ€ä½5å…ƒä½£é‡‘çš„æˆæœ¬ï¼Œä»…å½“æƒé‡å˜åŒ–è¶…è¿‡é˜ˆå€¼æ—¶æ‰è°ƒæ•´ã€‚
        
        **å…³é”®ç‰¹æ€§**ï¼šå½“å¤§ç›˜ï¼ˆå¦‚æ²ªæ·±300ï¼‰è·Œç ´20æ—¥å‡çº¿ä¸”å‡çº¿å‘ä¸‹å€¾æ–œæ—¶ï¼Œ
        å¼ºåˆ¶æ¸…ä»“ä»¥è§„é¿ç³»ç»Ÿæ€§é£é™©ã€‚
        
        Parameters
        ----------
        factor_data : pd.DataFrame
            å› å­æ•°æ®
        prices : pd.DataFrame
            ä»·æ ¼æ•°æ®ï¼Œç´¢å¼•ä¸ºæ—¥æœŸï¼Œåˆ—ä¸ºè‚¡ç¥¨ä»£ç 
        objective : str, optional
            ä¼˜åŒ–ç›®æ ‡ï¼Œå¯é€‰:
            - 'equal_weight': ç­‰æƒé‡åˆ†é…ï¼ˆæ¨èå°èµ„é‡‘è´¦æˆ·ï¼Œé»˜è®¤ï¼‰
            - 'max_sharpe': æœ€å¤§å¤æ™®æ¯”ç‡
            - 'min_volatility': æœ€å°æ³¢åŠ¨ç‡
        risk_free_rate : float, optional
            æ— é£é™©åˆ©ç‡ï¼Œé»˜è®¤0.02
        max_weight : Optional[float]
            å•åªè‚¡ç¥¨æœ€å¤§æƒé‡ï¼Œé»˜è®¤æ ¹æ® top_n è®¡ç®—
        start_date : Optional[pd.Timestamp]
            å¼€å§‹æ—¥æœŸ
        end_date : Optional[pd.Timestamp]
            ç»“æŸæ—¥æœŸ
        current_holdings_weights : Optional[Dict[str, float]]
            å½“å‰æŒä»“æƒé‡å­—å…¸ï¼Œç”¨äºå†å¹³è¡¡ç¼“å†²åŒºè®¡ç®—ã€‚
            å¦‚æœä¸º Noneï¼Œåˆ™ä½¿ç”¨å‰ä¸€æ—¥çš„ç›®æ ‡æƒé‡ã€‚
        rebalance_threshold : Optional[float]
            å†å¹³è¡¡é˜ˆå€¼ï¼Œé»˜è®¤ä½¿ç”¨ self.rebalance_buffer (5%)ã€‚
            ä»…å½“ |new_weight - current_weight| > é˜ˆå€¼æ—¶æ‰è°ƒæ•´è¯¥è‚¡ç¥¨ä»“ä½ã€‚
            ç”¨äºé¿å…å°èµ„é‡‘è´¦æˆ·é¢‘ç¹äº¤æ˜“äº§ç”Ÿæœ€ä½5å…ƒä½£é‡‘ã€‚
        benchmark_data : Optional[pd.DataFrame]
            åŸºå‡†æŒ‡æ•°æ•°æ®ï¼ˆå¦‚æ²ªæ·±300ï¼‰ï¼Œç”¨äºå¤§ç›˜é£æ§ã€‚
            éœ€åŒ…å« 'close' åˆ—ï¼Œç´¢å¼•ä¸º DatetimeIndexã€‚
            å¦‚æœä¸º Noneï¼Œåˆ™è·³è¿‡å¤§ç›˜é£æ§é€»è¾‘ã€‚
        
        Returns
        -------
        pd.DataFrame
            æƒé‡ DataFrameï¼ŒIndex=Date, Columns=Symbol
            å€¼ä¸ºæƒé‡ï¼ˆ0-1ä¹‹é—´ï¼‰ï¼Œ0è¡¨ç¤ºä¸æŒæœ‰
        
        Notes
        -----
        å†å¹³è¡¡ç¼“å†²åŒºé€»è¾‘ï¼ˆé€‚ç”¨äº30ä¸‡å°èµ„é‡‘è´¦æˆ·ï¼‰ï¼š
        
        1. åŸºæœ¬è§„åˆ™ï¼š
           - è‹¥ |w_new - w_old| <= ç¼“å†²é˜ˆå€¼ï¼Œä¿æŒæ—§æƒé‡ä¸å˜
           - é¿å…å› å¾®å°è°ƒæ•´è§¦å‘"æœ€ä½5å…ƒä½£é‡‘"è§„åˆ™
           - ä¾‹ï¼š30ä¸‡èµ„é‡‘ï¼Œ5%æƒé‡ = 1.5ä¸‡ï¼ŒæŒ‰ä¸‡ä¸‰è®¡ç®—ä½£é‡‘ä»…4.5å…ƒï¼Œä¸è¶³æœ€ä½5å…ƒ
        
        2. ç‰¹æ®Šæƒ…å†µï¼ˆå§‹ç»ˆæ‰§è¡Œï¼Œä¸å—ç¼“å†²åŒºé™åˆ¶ï¼‰ï¼š
           - æ–°ä¹°å…¥ï¼šw_old = 0 ä¸” w_new > 0 â†’ å¿…é¡»æ‰§è¡Œä¹°å…¥
           - æ¸…ä»“å–å‡ºï¼šw_old > 0 ä¸” w_new = 0 â†’ å¿…é¡»æ‰§è¡Œå–å‡º
        
        3. å¤§ç›˜é£æ§è§„åˆ™ï¼ˆMarket Risk Controlï¼‰ï¼š
           - æ¡ä»¶ï¼š(Close < MA20) AND (MA20_Slope < 0)
           - è§¦å‘æ—¶ï¼šå¼ºåˆ¶æ¸…ç©ºæ‰€æœ‰ä»“ä½ï¼Œè·³è¿‡é€‰è‚¡é€»è¾‘
           - ç›®çš„ï¼šè§„é¿ç³»ç»Ÿæ€§ä¸‹è·Œé£é™©
        
        Examples
        --------
        >>> strategy = MultiFactorStrategy("MF", {"top_n": 5, "rebalance_buffer": 0.05})
        >>> # å¯ç”¨å¤§ç›˜é£æ§
        >>> hs300_data = data_loader.fetch_index_price("000300", "2020-01-01", "2024-12-31")
        >>> weights = strategy.generate_target_weights(
        ...     factor_data, prices_df, objective='equal_weight',
        ...     benchmark_data=hs300_data
        ... )
        >>> print(weights.sum(axis=1))  # æ¯æ—¥æƒé‡ä¹‹å’Œï¼ˆåº”æ¥è¿‘1ï¼Œé£æ§æ—¶ä¸º0ï¼‰
        """
        # ä½¿ç”¨é…ç½®çš„å†å¹³è¡¡é˜ˆå€¼ï¼Œæˆ–ä½¿ç”¨å‚æ•°è¦†ç›–
        buffer_threshold = rebalance_threshold if rebalance_threshold is not None else self.rebalance_buffer
        
        # è®¾ç½®é»˜è®¤æœ€å¤§æƒé‡
        if max_weight is None:
            max_weight = min(0.25, 1.0 / self.top_n)  # å¯¹äº5åªè‚¡ç¥¨ï¼Œæœ€å¤§æƒé‡0.25
        
        # ç¡®å®šæ—¥æœŸåˆ—
        if self.date_col in factor_data.columns:
            dates_array = pd.to_datetime(factor_data[self.date_col].unique())
        elif isinstance(factor_data.index, pd.DatetimeIndex):
            dates_array = factor_data.index.unique()
        elif isinstance(factor_data.index, pd.MultiIndex):
            dates_array = factor_data.index.get_level_values(0).unique()
        else:
            raise ValueError("æ— æ³•ç¡®å®šæ—¥æœŸåˆ—")
        
        # ç¡®å®šè‚¡ç¥¨åˆ—
        stock_col = self.stock_col if self.stock_col in factor_data.columns else 'symbol'
        if stock_col in factor_data.columns:
            all_stocks = factor_data[stock_col].unique()
        elif isinstance(factor_data.index, pd.MultiIndex):
            all_stocks = factor_data.index.get_level_values(-1).unique()
        else:
            raise ValueError("æ— æ³•ç¡®å®šè‚¡ç¥¨ä»£ç åˆ—")
        
        # æ’åºæ—¥æœŸ
        all_dates = pd.DatetimeIndex(sorted(dates_array))
        
        # åº”ç”¨æ—¥æœŸè¿‡æ»¤
        if start_date is not None:
            all_dates = all_dates[all_dates >= start_date]
        if end_date is not None:
            all_dates = all_dates[all_dates <= end_date]
        
        if all_dates.empty:
            logger.warning("è¿‡æ»¤åæ— æœ‰æ•ˆæ—¥æœŸ")
            return pd.DataFrame()
        
        # æ ¹æ®é…ç½®çš„é¢‘ç‡è·å–è°ƒä»“æ—¥æœŸ
        rebalance_dates = set(self.get_rebalance_dates(all_dates, self.rebalance_frequency))
        
        logger.info(
            f"è°ƒä»“æ—¥æœŸæ•°é‡: {len(rebalance_dates)} ({self.rebalance_frequency}), "
            f"å†å¹³è¡¡ç¼“å†²åŒº: {buffer_threshold:.1%}, ä¼˜åŒ–ç›®æ ‡: {objective}"
        )
        
        # ========================================
        # å¤§ç›˜é£æ§å‡†å¤‡ï¼ˆæ¿€è¿›ç‰ˆ Market Risk Controlï¼‰
        # ========================================
        # æ¿€è¿›ç­–ç•¥ä½¿ç”¨ MA60 + 20æ—¥è·Œå¹…åˆ¤æ–­ï¼Œé¿å…è¸ç©ºè¡Œæƒ…
        # é»˜è®¤ä¸º False (æ— é£é™©)
        market_risk_series = pd.Series(False, index=all_dates)
        risk_triggered_days = 0
        
        if benchmark_data is not None and not benchmark_data.empty:
            try:
                index_df = benchmark_data.copy()
                
                # ç¡®ä¿ç´¢å¼•æ˜¯ DatetimeIndex
                if not isinstance(index_df.index, pd.DatetimeIndex):
                    if 'date' in index_df.columns:
                        index_df['date'] = pd.to_datetime(index_df['date'])
                        index_df = index_df.set_index('date')
                    else:
                        index_df.index = pd.to_datetime(index_df.index)
                
                index_df = index_df.sort_index()
                
                # ===== æ¿€è¿›ç‰ˆé£æ§ï¼šMA60ï¼ˆç‰›ç†Šçº¿ï¼‰+ 20æ—¥è·Œå¹… =====
                # è®¡ç®—60æ—¥å‡çº¿ï¼ˆç‰›ç†Šçº¿ï¼‰
                index_df['ma60'] = index_df['close'].rolling(window=60).mean()
                
                # è®¡ç®—20å¤©å‰è·Œå¹…
                drop_lookback = 20
                index_df['drop_20d'] = (
                    index_df['close'] - index_df['close'].shift(drop_lookback)
                ) / index_df['close'].shift(drop_lookback)
                
                # å¯¹é½åˆ°ç­–ç•¥æ—¥æœŸèŒƒå›´ï¼ˆä½¿ç”¨ ffill å¡«å……éäº¤æ˜“æ—¥ï¼‰
                aligned_index = index_df.reindex(all_dates, method='ffill')
                
                # ===== æ¿€è¿›ç‰ˆé£æ§æ¡ä»¶ =====
                # (Close < MA60) AND (20æ—¥è·Œå¹… > 5%)
                # åªæœ‰ç¡®è®¤æš´è·Œè¶‹åŠ¿æ—¶æ‰è§¦å‘ç†”æ–­
                drop_threshold = -0.05  # 20æ—¥è·Œå¹…é˜ˆå€¼ï¼ˆ-5%ï¼‰
                
                condition_below_ma60 = aligned_index['close'] < aligned_index['ma60']
                condition_crash = aligned_index['drop_20d'] < drop_threshold
                
                market_risk_series = (condition_below_ma60 & condition_crash).fillna(False)
                risk_triggered_days = market_risk_series.sum()
                
                logger.info(
                    f"å¤§ç›˜é£æ§å·²å¯ç”¨ï¼ˆæ¿€è¿›ç‰ˆï¼‰: (Close < MA60) AND (20æ—¥è·Œå¹… < {drop_threshold:.0%}), "
                    f"é¢„è®¡è§¦å‘ {risk_triggered_days} å¤©"
                )
                
            except Exception as e:
                logger.warning(f"è®¡ç®—å¤§ç›˜é£æ§æŒ‡æ ‡å¤±è´¥: {e}ï¼Œé£æ§åŠŸèƒ½æš‚æ—¶å¤±æ•ˆ")
        else:
            logger.debug("æœªä¼ å…¥åŸºå‡†æ•°æ®ï¼Œå¤§ç›˜é£æ§æœªå¯ç”¨")
        
        # ========================================
        # åˆå§‹åŒ–æƒé‡çŸ©é˜µ
        # ========================================
        target_weights = pd.DataFrame(
            0.0,
            index=all_dates,
            columns=sorted(all_stocks),
            dtype=float
        )
        target_weights.index.name = 'date'
        target_weights.columns.name = 'symbol'
        
        # å½“å‰æƒé‡ï¼ˆç”¨äºå†å¹³è¡¡ç¼“å†²åŒºï¼‰
        current_weights: Dict[str, float] = current_holdings_weights.copy() if current_holdings_weights else {}
        
        # ç»Ÿè®¡
        skipped_adjustments = 0
        forced_executions = 0
        risk_clear_count = 0
        
        for date in all_dates:
            # ========================================
            # Step 1: æ¯æ—¥é£æ§æ£€æŸ¥
            # ========================================
            is_risk_triggered = market_risk_series.loc[date]
            
            if is_risk_triggered:
                # é£æ§è§¦å‘ï¼šå¼ºåˆ¶æ¸…ä»“
                if current_weights:
                    # ä»…åœ¨æœ‰æŒä»“æ—¶è®°å½•æ—¥å¿—ï¼Œé¿å…æ—¥å¿—çˆ†ç‚¸
                    logger.warning(
                        f"Market Risk Triggered on {date.strftime('%Y-%m-%d')}, "
                        f"clearing positions (æŒæœ‰ {len(current_weights)} åªè‚¡ç¥¨)"
                    )
                    risk_clear_count += 1
                
                # æ¸…ç©ºå½“å‰æƒé‡
                current_weights = {}
                
                # è·³è¿‡åç»­é€‰è‚¡é€»è¾‘ï¼Œç›´æ¥è¿›å…¥ä¸‹ä¸€å¤©
                # target_weights ä¿æŒä¸º 0ï¼ˆå·²åˆå§‹åŒ–ï¼‰
                continue
            
            # ========================================
            # Step 2: è°ƒä»“æ—¥é€»è¾‘ï¼ˆä»…åœ¨æ— é£æ§æ—¶æ‰§è¡Œï¼‰
            # é‡‡ç”¨ Filter-Then-Analyze æ¨¡å¼
            # ========================================
            if date in rebalance_dates:
                # è°ƒä»“æ—¥: é‡æ–°é€‰è‚¡å¹¶ä¼˜åŒ–æƒé‡
                filtered_data = self.filter_stocks(factor_data, date)
                
                if not filtered_data.empty:
                    # Step 2.1: è·å–æ‰©å±•å€™é€‰åˆ—è¡¨ï¼ˆTop N * bufferï¼‰
                    buffer_n = self.top_n * self._sentiment_buffer_multiplier
                    pre_candidates = self.select_top_stocks(filtered_data, n=buffer_n)
                    
                    # Step 2.2: åº”ç”¨æƒ…ç»ªè¿‡æ»¤ï¼ˆJust-in-Time åˆ†æï¼‰
                    # æ³¨æ„: _apply_sentiment_filter å†…éƒ¨å·²å®ç° Fail-Closed ç­–ç•¥
                    if self._enable_sentiment_filter and self._sentiment_engine is not None:
                        try:
                            final_candidates = self._apply_sentiment_filter(pre_candidates, date)
                        except LLMCircuitBreakerError:
                            # ===== ç†”æ–­å™¨è§¦å‘: åœæ­¢äº¤æ˜“ =====
                            # ç›´æ¥æŠ›å‡ºï¼Œç”±è°ƒç”¨æ–¹å¤„ç†
                            raise
                        # æ³¨æ„: å…¶ä»–å¼‚å¸¸å·²åœ¨ _apply_sentiment_filter ä¸­å¤„ç†ï¼Œ
                        # ä¼šè¿”å›ç©ºåˆ—è¡¨ï¼ˆFail-Closedï¼‰ï¼Œä¸ä¼šæŠ›å‡º
                    else:
                        final_candidates = pre_candidates
                    
                    # Step 2.3: æœ€ç»ˆé€‰å– Top N
                    selected_stocks = final_candidates[:self.top_n]
                    
                    logger.debug(
                        f"è°ƒä»“æ—¥ {date.strftime('%Y-%m-%d')}: "
                        f"é¢„é€‰ {len(pre_candidates)} åª -> "
                        f"æƒ…ç»ªè¿‡æ»¤å {len(final_candidates)} åª -> "
                        f"æœ€ç»ˆé€‰ä¸­ {len(selected_stocks)} åªè‚¡ç¥¨"
                    )
                    
                    if selected_stocks:
                        # æ ¹æ®ä¼˜åŒ–ç›®æ ‡è®¡ç®—æƒé‡
                        if objective == "equal_weight":
                            # ç­‰æƒé‡ï¼šå¯¹äºå°èµ„é‡‘è´¦æˆ·æ›´ç¨³å¥
                            new_weights = self._equal_weights(selected_stocks)
                        else:
                            # ä½¿ç”¨ä¼˜åŒ–æƒé‡
                            price_end_idx = prices.index.get_indexer([date], method='ffill')[0]
                            if price_end_idx >= 0:
                                historical_prices = prices.iloc[:price_end_idx + 1]
                                
                                new_weights = self.optimize_weights(
                                    historical_prices,
                                    selected_stocks,
                                    objective=objective,
                                    risk_free_rate=risk_free_rate,
                                    max_weight=max_weight
                                )
                            else:
                                new_weights = self._equal_weights(selected_stocks)
                        
                        # ===== å†å¹³è¡¡ç¼“å†²åŒºé€»è¾‘ï¼ˆå¢å¼ºç‰ˆï¼‰=====
                        # 
                        # è§„åˆ™ï¼š
                        # 1. æ–°ä¹°å…¥ï¼ˆw_old=0, w_new>0ï¼‰ï¼šå§‹ç»ˆæ‰§è¡Œ
                        # 2. æ¸…ä»“å–å‡ºï¼ˆw_old>0, w_new=0ï¼‰ï¼šå§‹ç»ˆæ‰§è¡Œ
                        # 3. è°ƒæ•´æŒä»“ï¼ˆw_old>0, w_new>0ï¼‰ï¼šä»…å½“å˜åŒ– > é˜ˆå€¼æ—¶æ‰§è¡Œ
                        
                        final_weights: Dict[str, float] = {}
                        
                        # è·å–æ‰€æœ‰æ¶‰åŠçš„è‚¡ç¥¨ï¼ˆæ–°é€‰ä¸­ + å½“å‰æŒæœ‰ï¼‰
                        all_involved_stocks = set(new_weights.keys()) | set(current_weights.keys())
                        
                        for stock in all_involved_stocks:
                            new_w = new_weights.get(stock, 0.0)
                            old_w = current_weights.get(stock, 0.0)
                            weight_change = abs(new_w - old_w)
                            
                            # åˆ¤æ–­äº¤æ˜“ç±»å‹
                            is_new_buy = (old_w == 0.0 and new_w > 0.0)
                            is_full_sell = (old_w > 0.0 and new_w == 0.0)
                            is_rebalance = (old_w > 0.0 and new_w > 0.0)
                            
                            if is_new_buy:
                                # æ–°ä¹°å…¥ï¼šå§‹ç»ˆæ‰§è¡Œ
                                final_weights[stock] = new_w
                                forced_executions += 1
                            elif is_full_sell:
                                # æ¸…ä»“å–å‡ºï¼šå§‹ç»ˆæ‰§è¡Œï¼ˆä¸åŠ å…¥ final_weightsï¼‰
                                forced_executions += 1
                                pass  # ä¸åŠ å…¥è¡¨ç¤ºæƒé‡ä¸º0
                            elif is_rebalance:
                                # è°ƒæ•´æŒä»“ï¼šåº”ç”¨ç¼“å†²åŒºé€»è¾‘
                                if weight_change > buffer_threshold:
                                    # å˜åŒ–è¶…è¿‡é˜ˆå€¼ï¼Œæ‰§è¡Œè°ƒæ•´
                                    final_weights[stock] = new_w
                                else:
                                    # å˜åŒ–æœªè¶…è¿‡é˜ˆå€¼ï¼Œä¿æŒåŸæƒé‡
                                    final_weights[stock] = old_w
                                    skipped_adjustments += 1
                        
                        # å½’ä¸€åŒ–æƒé‡ï¼ˆç¡®ä¿æ€»å’Œæ¥è¿‘1ï¼‰
                        weight_sum = sum(final_weights.values())
                        if weight_sum > 0:
                            final_weights = {k: v / weight_sum for k, v in final_weights.items()}
                        
                        current_weights = final_weights
                        
                        logger.debug(
                            f"è°ƒä»“æ—¥ {date.strftime('%Y-%m-%d')}: "
                            f"é€‰ä¸­ {len(selected_stocks)} åª, "
                            f"æœ€ç»ˆæŒä»“ {len(final_weights)} åª "
                            f"(è·³è¿‡: {skipped_adjustments}, å¼ºåˆ¶æ‰§è¡Œ: {forced_executions})"
                        )
                else:
                    logger.warning(f"è°ƒä»“æ—¥ {date.strftime('%Y-%m-%d')}: æ— å¯é€‰è‚¡ç¥¨")
                    current_weights = {}
            
            # ========================================
            # Step 3: è®¾ç½®å½“æ—¥æƒé‡
            # ========================================
            for stock, weight in current_weights.items():
                if stock in target_weights.columns:
                    target_weights.loc[date, stock] = weight
        
        # ========================================
        # ç»Ÿè®¡ä¿¡æ¯
        # ========================================
        avg_weight_sum = target_weights.sum(axis=1).mean()
        n_holdings = (target_weights > 0).sum(axis=1).mean()
        
        log_msg = (
            f"ç›®æ ‡æƒé‡çŸ©é˜µç”Ÿæˆå®Œæˆ: "
            f"å¹³å‡æŒä»“ {n_holdings:.1f} åª, "
            f"å¹³å‡æƒé‡å’Œ {avg_weight_sum:.4f}, "
            f"è·³è¿‡å¾®è°ƒ {skipped_adjustments} æ¬¡, "
            f"å¼ºåˆ¶æ‰§è¡Œ {forced_executions} æ¬¡ (ç¼“å†²åŒº: {buffer_threshold:.1%})"
        )
        
        if risk_clear_count > 0:
            log_msg += f", é£æ§æ¸…ä»“ {risk_clear_count} æ¬¡"
        
        logger.info(log_msg)
        
        return target_weights