#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Aè‚¡é‡åŒ–äº¤æ˜“ç³»ç»Ÿ - ä¸»å…¥å£

è¯¥æ¨¡å—ä½œä¸ºç³»ç»Ÿçš„ä¸»å…¥å£ç‚¹ï¼Œæä¾›æ¯æ—¥æ›´æ–°ã€å› å­è®¡ç®—ã€
è°ƒä»“ä¿¡å·ç”Ÿæˆå’ŒæŠ¥å‘Šè¾“å‡ºç­‰åŠŸèƒ½ã€‚

Usage
-----
    # è¿è¡Œæ¯æ—¥æ›´æ–°
    python main.py --daily-update
    # å¼ºåˆ¶è°ƒä»“ï¼ˆå¿½ç•¥æ—¥æœŸæ£€æŸ¥ï¼‰
    python main.py --daily-update --force-rebalance
    
    # ç”Ÿæˆå›æµ‹æŠ¥å‘Š
    python main.py --backtest --start 2023-01-01 --end 2024-01-01
"""
import argparse
import logging
import os
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
import json

import pandas as pd
import numpy as np

from src import (
    # æ•°æ®å¤„ç†
    AkshareDataLoader,
    AShareDataCleaner,
    DataLoader,
    # å› å­è®¡ç®—
    FactorCalculator,
    z_score_normalize,
    # ç­–ç•¥
    MultiFactorStrategy,
    MACrossStrategy,
    # å›æµ‹
    BacktestEngine,
    VBTProBacktester,
    # æƒé‡ä¼˜åŒ–
    optimize_weights,
    calculate_shrinkage_covariance,
    calculate_expected_returns_mean,
    # å·¥å…·
    setup_logging,
    load_config,
    send_pushplus_msg,
)

# å¯¼å…¥ LLM ç†”æ–­å™¨å¼‚å¸¸ï¼ˆç”¨äºé£æ§å¤„ç†ï¼‰
try:
    from src.llm_client import LLMCircuitBreakerError
except ImportError:
    # å®šä¹‰å›é€€ç±»ä»¥é¿å…å¯¼å…¥é”™è¯¯
    class LLMCircuitBreakerError(RuntimeError):
        """LLM ç†”æ–­å™¨è§¦å‘å¼‚å¸¸ï¼ˆå›é€€å®šä¹‰ï¼‰"""
        pass

# é…ç½®å¸¸é‡
CONFIG_PATH = Path("config/strategy_config.yaml")
DATA_RAW_PATH = Path("data/raw")
DATA_PROCESSED_PATH = Path("data/processed")
REPORTS_PATH = Path("reports")
LOGS_PATH = Path("logs")

# ç¡®ä¿ç›®å½•å­˜åœ¨
for path in [DATA_RAW_PATH, DATA_PROCESSED_PATH, REPORTS_PATH, LOGS_PATH]:
    path.mkdir(parents=True, exist_ok=True)


class DailyUpdateRunner:
    """
    æ¯æ—¥æ›´æ–°è¿è¡Œå™¨
    
    è´Ÿè´£æ‰§è¡Œæ¯æ—¥æ•°æ®æ›´æ–°ã€å› å­è®¡ç®—ã€è°ƒä»“ä¿¡å·ç”Ÿæˆå’ŒæŠ¥å‘Šè¾“å‡ºã€‚
    
    Parameters
    ----------
    config : Optional[Dict[str, Any]]
        é…ç½®å‚æ•°
    
    Attributes
    ----------
    config : Dict[str, Any]
        é…ç½®å‚æ•°
    data_loader : AkshareDataLoader
        æ•°æ®åŠ è½½å™¨
    strategy : MultiFactorStrategy
        å¤šå› å­ç­–ç•¥
    logger : logging.Logger
        æ—¥å¿—å™¨
    
    Examples
    --------
    >>> runner = DailyUpdateRunner()
    >>> runner.run_daily_update()
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None) -> None:
        """
        åˆå§‹åŒ–æ¯æ—¥æ›´æ–°è¿è¡Œå™¨
        
        Parameters
        ----------
        config : Optional[Dict[str, Any]]
            é…ç½®å‚æ•°
        """
        self.logger = logging.getLogger(__name__)
        
        # åŠ è½½é…ç½®
        if config is None:
            try:
                self.config = load_config(CONFIG_PATH)
            except FileNotFoundError:
                self.logger.warning(f"é…ç½®æ–‡ä»¶ {CONFIG_PATH} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                self.config = self._get_default_config()
        else:
            self.config = config
        
        # åˆå§‹åŒ–ç»„ä»¶
        self._init_components()
        
        # çŠ¶æ€å˜é‡
        self.today = pd.Timestamp.now().normalize()
        self.ohlcv_data: Optional[pd.DataFrame] = None
        self.financial_data: Optional[pd.DataFrame] = None
        self.industry_data: Optional[pd.DataFrame] = None
        self.factor_data: Optional[pd.DataFrame] = None
        self.benchmark_data: Optional[pd.DataFrame] = None  # åŸºå‡†æŒ‡æ•°æ•°æ®ï¼ˆç”¨äºå¤§ç›˜é£æ§ï¼‰
        self.current_positions: Dict[str, float] = {}
        self.target_positions: Dict[str, float] = {}
        
        # åŠ è½½å½“å‰æŒä»“
        self.load_current_holdings()
        
        self.logger.info("DailyUpdateRunner åˆå§‹åŒ–å®Œæˆ")

    def run_daily_update(self):
        """
        æ‰§è¡Œæ¯æ—¥æ•°æ®æ›´æ–°å’Œç­–ç•¥å›æµ‹çš„ä¸»æµç¨‹
        """
        self.logger.info("å¼€å§‹æ‰§è¡Œæ¯æ—¥æ›´æ–°ä»»åŠ¡...")

        # 1. è·å–æ•°æ® (ç¤ºä¾‹é€»è¾‘)
        # df = self.data_loader.get_data(...)

        # 2. æ‰§è¡Œç­–ç•¥
        # self.strategy.execute(df)

        self.logger.info("æ¯æ—¥æ›´æ–°ä»»åŠ¡å®Œæˆã€‚")
    
    def _get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "data": {
                "stock_pool": "hs300",  # æ²ªæ·±300æˆåˆ†è‚¡
                "start_date": "2020-01-01",
                "update_days": 5,  # æ¯æ¬¡æ›´æ–°æœ€è¿‘Nå¤©æ•°æ®
            },
            "strategy": {
                "name": "Multi-Factor Strategy",
                "value_weight": 0.0,
                "quality_weight": 0.0,
                "momentum_weight": 1.0,
                "top_n": 30,
                "min_listing_days": 126,
            },
            "portfolio": {
                "total_capital": 1000000,  # æ€»èµ„é‡‘100ä¸‡
                "max_weight": 0.05,  # å•è‚¡æœ€å¤§5%
                "risk_free_rate": 0.02,
                "optimization_objective": "max_sharpe",
            },
            "report": {
                "format": "markdown",  # markdown æˆ– html
                "output_dir": "reports",
            },
        }
    
    def _init_components(self) -> None:
        """åˆå§‹åŒ–å„ç»„ä»¶"""
        # æ ¹æ®é…ç½®é€‰æ‹©æ•°æ®æº
        data_source = self.config.get("data", {}).get("data_source", "akshare")
        
        if data_source == "tushare":
            # ä½¿ç”¨ Tushare æ•°æ®æºï¼ˆæ¨èï¼‰
            from src.tushare_loader import TushareDataLoader
            tushare_config = self.config.get("tushare", {})
            api_token = tushare_config.get("api_token") or os.environ.get("TUSHARE_TOKEN", "")
            
            if not api_token:
                self.logger.error(
                    "Tushare API Token æœªé…ç½®ï¼\n"
                    "è¯·åœ¨ config/strategy_config.yaml ä¸­è®¾ç½® tushare.api_token\n"
                    "æˆ–é€šè¿‡ç¯å¢ƒå˜é‡ TUSHARE_TOKEN è®¾ç½®"
                )
                raise ValueError("Tushare API Token æœªé…ç½®")
            
            self.tushare_loader = TushareDataLoader(
                api_token=api_token,
                cache_dir=tushare_config.get("cache_dir", "data/tushare_cache")
            )
            self.data_source = "tushare"
            self.logger.info("ä½¿ç”¨ Tushare æ•°æ®æº")
        else:
            # ä½¿ç”¨ AkShare æ•°æ®æºï¼ˆå…¼å®¹æ—§ä»£ç ï¼‰
            self.data_loader = AkshareDataLoader(self.config)
            self.data_source = "akshare"
            self.logger.info("ä½¿ç”¨ AkShare æ•°æ®æº")
        
        self.data_cleaner = AShareDataCleaner()
        
        # å¢å¼ºç‰ˆæ•°æ®åŠ è½½å™¨ï¼ˆç”¨äºè·å–è´¢åŠ¡æ•°æ®ï¼Œå…¼å®¹æ—§ä»£ç ï¼‰
        self.financial_loader = DataLoader(
            output_dir=str(DATA_RAW_PATH),
            max_workers=3,
            retry_times=3
        )
        
        # ç­–ç•¥
        strategy_config = self.config.get("strategy", {})
        llm_config = self.config.get("llm", {})
        
        self.strategy = MultiFactorStrategy(
            name=strategy_config.get("name", "Multi-Factor Strategy"),
            config={
                # å› å­æƒé‡é…ç½®ï¼ˆä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
                "value_weight": strategy_config.get("value_weight", 0.0),
                "quality_weight": strategy_config.get("quality_weight", 0.3),
                "momentum_weight": strategy_config.get("momentum_weight", 0.4),
                "size_weight": strategy_config.get("size_weight", 0.3),
                "sentiment_weight": strategy_config.get("sentiment_weight", 0.0),  # æƒ…ç»ªå› å­æƒé‡
                "top_n": strategy_config.get("top_n", 3),
                "min_listing_days": strategy_config.get("min_listing_days", 126),
                # æ¿å—è¿‡æ»¤é…ç½®
                "exclude_chinext": strategy_config.get("exclude_chinext", False),  # æ’é™¤åˆ›ä¸šæ¿
                "exclude_star": strategy_config.get("exclude_star", False),  # æ’é™¤ç§‘åˆ›æ¿
                # å› å­åˆ—åé…ç½®ï¼ˆä»é…ç½®æ–‡ä»¶è¯»å–ï¼Œæ”¯æŒæ¿€è¿›å‹å°å¸‚å€¼ç­–ç•¥ï¼‰
                "value_col": strategy_config.get("value_col", "small_cap_zscore"),
                "quality_col": strategy_config.get("quality_col", "turnover_5d_zscore"),
                "momentum_col": strategy_config.get("momentum_col", "rsi_20_zscore"),
                "size_col": strategy_config.get("size_col", "small_cap_zscore"),
                # è°ƒä»“é…ç½®
                "rebalance_frequency": strategy_config.get("rebalance_frequency", "weekly"),
                "rebalance_buffer": strategy_config.get("rebalance_buffer", 0.02),
                # [NEW] æŒè‚¡æƒ¯æ€§åŠ åˆ†
                "holding_bonus": strategy_config.get("holding_bonus", 0.0),
                # [NEW] å¤§ç›˜é£æ§é…ç½®
                "market_risk": self.config.get("risk", {}).get("market_risk", {}),
                # LLM æƒ…ç»ªåˆ†æé…ç½®
                "llm": llm_config,
            }
        )
    
    def load_current_holdings(self) -> None:
        """
        åŠ è½½å½“å‰æŒä»“
        
        ä» data/processed/real_holdings.json æ–‡ä»¶è¯»å–æŒä»“æ•°æ®ã€‚
        å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆå§‹åŒ–ä¸ºç©ºå­—å…¸ã€‚
        
        Notes
        -----
        è¿™æ˜¯ä¸€ä¸ªåŠè‡ªåŠ¨ç³»ç»Ÿï¼Œç”¨æˆ·å¯ä»¥æ‰‹åŠ¨ä¿®æ”¹ real_holdings.json 
        æ–‡ä»¶æ¥æ ¡å‡†å®é™…æŒä»“ã€‚
        """
        holdings_path = DATA_PROCESSED_PATH / "real_holdings.json"
        
        if holdings_path.exists():
            try:
                with open(holdings_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # æå– positions å­—æ®µ
                self.current_positions = data.get("positions", {})
                
                # ç¡®ä¿å€¼ä¸º float ç±»å‹
                self.current_positions = {
                    str(k): float(v) for k, v in self.current_positions.items()
                }
                
                self.logger.info(
                    f"å·²åŠ è½½æŒä»“æ•°æ®: {len(self.current_positions)} åªè‚¡ç¥¨, "
                    f"æ€»å¸‚å€¼ Â¥{sum(self.current_positions.values()):,.0f}"
                )
                
                # æ‰“å°æŒä»“æ˜ç»†ï¼ˆè°ƒè¯•ç”¨ï¼‰
                if self.current_positions:
                    self.logger.debug(f"æŒä»“æ˜ç»†: {list(self.current_positions.keys())[:5]}...")
                    
            except json.JSONDecodeError as e:
                self.logger.warning(f"æŒä»“æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}ï¼Œåˆå§‹åŒ–ä¸ºç©ºæŒä»“")
                self.current_positions = {}
            except Exception as e:
                self.logger.warning(f"åŠ è½½æŒä»“æ–‡ä»¶å¤±è´¥: {e}ï¼Œåˆå§‹åŒ–ä¸ºç©ºæŒä»“")
                self.current_positions = {}
        else:
            self.logger.info("æŒä»“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆå§‹åŒ–ä¸ºç©ºæŒä»“")
            self.current_positions = {}
    
    def save_current_holdings(
        self,
        buy_orders: Dict[str, float],
        sell_orders: Dict[str, float]
    ) -> None:
        """
        ä¿å­˜å½“å‰æŒä»“
        
        æ ¹æ®ä¹°å…¥å’Œå–å‡ºè®¢å•æ›´æ–°æŒä»“ï¼Œå¹¶ä¿å­˜åˆ° data/processed/real_holdings.jsonã€‚
        
        Parameters
        ----------
        buy_orders : Dict[str, float]
            ä¹°å…¥è®¢å• {è‚¡ç¥¨ä»£ç : é‡‘é¢}
        sell_orders : Dict[str, float]
            å–å‡ºè®¢å• {è‚¡ç¥¨ä»£ç : é‡‘é¢}
        
        Notes
        -----
        æ›´æ–°é€»è¾‘: new_holdings = current + buy - sell
        
        è¿™æ˜¯ä¸€ä¸ªåŠè‡ªåŠ¨ç³»ç»Ÿï¼Œæˆ‘ä»¬å‡è®¾ç”¨æˆ·å®Œå…¨æ‰§è¡Œäº†ä¿¡å·ã€‚
        å®é™…æ“ä½œä¸­ï¼Œç”¨æˆ·å¯èƒ½éœ€è¦æ‰‹åŠ¨ä¿®æ”¹è¿™ä¸ª json æ–‡ä»¶æ¥æ ¡å‡†å®é™…æŒä»“ã€‚
        """
        # å¤åˆ¶å½“å‰æŒä»“
        new_positions = self.current_positions.copy()
        
        # å¤„ç†ä¹°å…¥è®¢å•
        for stock, amount in buy_orders.items():
            if stock in new_positions:
                new_positions[stock] += amount
            else:
                new_positions[stock] = amount
        
        # å¤„ç†å–å‡ºè®¢å•
        for stock, amount in sell_orders.items():
            if stock in new_positions:
                new_positions[stock] -= amount
                # å¦‚æœæŒä»“ä¸º0æˆ–è´Ÿæ•°ï¼Œåˆ é™¤è¯¥è‚¡ç¥¨
                if new_positions[stock] <= 0:
                    del new_positions[stock]
        
        # å‡†å¤‡ä¿å­˜çš„æ•°æ®
        holdings_data = {
            "update_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "update_date": self.today.strftime("%Y-%m-%d"),
            "positions": new_positions,
            "total_value": sum(new_positions.values()),
            "num_stocks": len(new_positions),
            "note": "æ­¤æ–‡ä»¶ç”±ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆï¼Œå‡è®¾ç”¨æˆ·å®Œå…¨æ‰§è¡Œäº†äº¤æ˜“ä¿¡å·ã€‚å¦‚éœ€æ ¡å‡†å®é™…æŒä»“ï¼Œè¯·æ‰‹åŠ¨ä¿®æ”¹ã€‚"
        }
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        holdings_path = DATA_PROCESSED_PATH / "real_holdings.json"
        
        try:
            with open(holdings_path, 'w', encoding='utf-8') as f:
                json.dump(holdings_data, f, ensure_ascii=False, indent=2)
            
            self.logger.info(
                f"æŒä»“å·²æ›´æ–°å¹¶ä¿å­˜: {len(new_positions)} åªè‚¡ç¥¨, "
                f"æ€»å¸‚å€¼ Â¥{sum(new_positions.values()):,.0f}"
            )
            
            # æ›´æ–°å†…å­˜ä¸­çš„æŒä»“
            self.current_positions = new_positions
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜æŒä»“æ–‡ä»¶å¤±è´¥: {e}")
    
    def update_market_data(self) -> bool:
        """
        æ›´æ–°å¸‚åœºæ•°æ®ï¼ˆå¸¦ç¼“å­˜æ£€æŸ¥ï¼‰
        
        æ”¯æŒ Tushare å’Œ AkShare ä¸¤ç§æ•°æ®æºã€‚
        
        Returns
        -------
        bool
            æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        self.logger.info("å¼€å§‹æ›´æ–°å¸‚åœºæ•°æ®...")
        
        try:
            # æ£€æŸ¥ä»Šæ—¥ç¼“å­˜
            ohlcv_path = DATA_RAW_PATH / f"ohlcv_{self.today.strftime('%Y%m%d')}.parquet"
            if ohlcv_path.exists():
                try:
                    self.ohlcv_data = pd.read_parquet(ohlcv_path)
                    if not self.ohlcv_data.empty:
                        self.logger.info(f"ğŸ“‚ ä½¿ç”¨ç¼“å­˜æ•°æ®: {ohlcv_path.name}ï¼Œå…± {len(self.ohlcv_data)} æ¡è®°å½•")
                        return True
                except Exception as e:
                    self.logger.warning(f"è¯»å–ç¼“å­˜å¤±è´¥: {e}ï¼Œå°†é‡æ–°ä¸‹è½½")
            
            data_config = self.config.get("data", {})
            stock_pool = data_config.get("stock_pool", "hs300")
            
            # ç¡®å®šæ—¥æœŸèŒƒå›´
            end_date = self.today.strftime("%Y%m%d")
            update_days = data_config.get("update_days", 5)
            start_date = (self.today - timedelta(days=update_days * 2)).strftime("%Y%m%d")
            
            # æ ¹æ®æ•°æ®æºé€‰æ‹©ä¸åŒçš„è·å–æ–¹å¼
            if self.data_source == "tushare":
                return self._update_market_data_tushare(stock_pool, start_date, end_date)
            else:
                return self._update_market_data_akshare(stock_pool, start_date, end_date)
            
        except Exception as e:
            self.logger.error(f"æ›´æ–°å¸‚åœºæ•°æ®å¤±è´¥: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return False
    
    def _update_market_data_tushare(
        self,
        stock_pool: str,
        start_date: str,
        end_date: str
    ) -> bool:
        """ä½¿ç”¨ Tushare æ›´æ–°å¸‚åœºæ•°æ®"""
        self.logger.info(f"ä½¿ç”¨ Tushare è·å– {stock_pool} æ•°æ®...")
        
        # è·å–è‚¡ç¥¨åˆ—è¡¨ï¼ˆæ ¹æ® stock_pool ç±»å‹é€‰æ‹©ä¸åŒæ–¹æ³•ï¼‰
        if stock_pool == "all":
            # å…¨å¸‚åœºæ¨¡å¼ï¼šè·å–æ‰€æœ‰ä¸Šå¸‚è‚¡ç¥¨
            self.logger.info("å…¨å¸‚åœºæ¨¡å¼ï¼šè·å–æ‰€æœ‰ä¸Šå¸‚è‚¡ç¥¨...")
            stock_list = self.tushare_loader.fetch_all_stocks()
            if not stock_list:
                self.logger.error("æ— æ³•è·å–å…¨å¸‚åœºè‚¡ç¥¨åˆ—è¡¨")
                return False
            self.logger.warning(
                f"âš ï¸ å…¨å¸‚åœºæ¨¡å¼ï¼šå…± {len(stock_list)} åªè‚¡ç¥¨ï¼Œ"
                f"æ•°æ®ä¸‹è½½å’Œè®¡ç®—å°†è€—æ—¶è¾ƒé•¿ï¼Œè¯·è€å¿ƒç­‰å¾…"
            )
        else:
            # æŒ‡æ•°æˆåˆ†è‚¡æ¨¡å¼
            stock_list = self.tushare_loader.fetch_index_constituents(stock_pool)
            if not stock_list:
                self.logger.error(f"æ— æ³•è·å– {stock_pool} æˆåˆ†è‚¡åˆ—è¡¨")
                return False
        
        self.logger.info(f"è‚¡ç¥¨æ± : {stock_pool}, è‚¡ç¥¨æ•°é‡: {len(stock_list)}")
        
        # æ‰¹é‡è·å–æ—¥çº¿æ•°æ®
        self.ohlcv_data = self.tushare_loader.fetch_daily_data_batch(
            stock_list, start_date, end_date
        )
        
        if self.ohlcv_data is None or self.ohlcv_data.empty:
            self.logger.error("æœªè·å–åˆ°ä»»ä½• OHLCV æ•°æ®")
            return False
        
        self.logger.info(f"OHLCV æ•°æ®æ›´æ–°å®Œæˆï¼Œå…± {len(self.ohlcv_data)} æ¡è®°å½•")
        
        # ä¿å­˜æ•°æ®
        ohlcv_path = DATA_RAW_PATH / f"ohlcv_{self.today.strftime('%Y%m%d')}.parquet"
        self.ohlcv_data.to_parquet(ohlcv_path)
        self.logger.info(f"OHLCV æ•°æ®å·²ä¿å­˜è‡³ {ohlcv_path}")
        
        # ä¿å­˜æˆåˆ†è‚¡åˆ—è¡¨ä¾›åç»­ä½¿ç”¨
        self._current_stock_list = stock_list
        
        return True
    
    def _update_market_data_akshare(
        self,
        stock_pool: str,
        start_date: str,
        end_date: str
    ) -> bool:
        """ä½¿ç”¨ AkShare æ›´æ–°å¸‚åœºæ•°æ®ï¼ˆå…¼å®¹æ—§ä»£ç ï¼‰"""
        # è·å–è‚¡ç¥¨åˆ—è¡¨ï¼ˆæ”¯æŒä¸»è¦æŒ‡æ•°æˆåˆ†è‚¡ï¼‰
        stock_pool_to_index = {
            "hs300": "000300",
            "zz500": "000905",
            "zz1000": "000852",
            "sz50": "000016",
            "cyb50": "399673",
        }
        
        if stock_pool in stock_pool_to_index:
            index_code = stock_pool_to_index[stock_pool]
            stock_list = self.data_loader.get_stock_list(index_code)
        elif stock_pool == "all":
            self.logger.warning("å…¨å¸‚åœºæ¨¡å¼ç½‘ç»œä¾èµ–è¾ƒé«˜ï¼Œå»ºè®®ä½¿ç”¨æŒ‡æ•°æˆåˆ†è‚¡æ¨¡å¼")
            stock_list = self.data_loader.get_stock_list()
        else:
            self.logger.warning(f"æœªçŸ¥çš„è‚¡ç¥¨æ±  '{stock_pool}'ï¼Œä½¿ç”¨é»˜è®¤æ²ªæ·±300")
            stock_list = self.data_loader.get_stock_list("000300")
        
        self.logger.info(f"è‚¡ç¥¨æ± : {stock_pool}, è‚¡ç¥¨æ•°é‡: {len(stock_list)}")
        
        # ä¸‹è½½OHLCVæ•°æ®
        ohlcv_list = []
        total_stocks = len(stock_list)
        for i, stock in enumerate(stock_list):
            try:
                df = self.data_loader.fetch_daily_data(stock, start_date, end_date)
                if df is not None and not df.empty:
                    if isinstance(df.index, pd.DatetimeIndex):
                        df = df.reset_index(names=['date'])
                    df['stock_code'] = stock
                    ohlcv_list.append(df)
            except Exception as e:
                self.logger.debug(f"è·å– {stock} æ•°æ®å¤±è´¥: {e}")
            
            if (i + 1) % 50 == 0 or (i + 1) == total_stocks:
                self.logger.info(f"å·²å¤„ç† {i + 1}/{total_stocks} åªè‚¡ç¥¨")
        
        if ohlcv_list:
            self.ohlcv_data = pd.concat(ohlcv_list, ignore_index=True)
            self.logger.info(f"OHLCV æ•°æ®æ›´æ–°å®Œæˆï¼Œå…± {len(self.ohlcv_data)} æ¡è®°å½•")
        else:
            self.logger.warning("æœªè·å–åˆ°ä»»ä½• OHLCV æ•°æ®")
            return False
        
        # ä¿å­˜æ•°æ®
        ohlcv_path = DATA_RAW_PATH / f"ohlcv_{self.today.strftime('%Y%m%d')}.parquet"
        self.ohlcv_data.to_parquet(ohlcv_path)
        self.logger.info(f"OHLCV æ•°æ®å·²ä¿å­˜è‡³ {ohlcv_path}")
        
        return True
    
    def update_financial_data(self) -> bool:
        """
        æ›´æ–°è´¢åŠ¡æ•°æ®ï¼ˆå®ç›˜å®‰å…¨ç‰ˆï¼Œå¸¦ç¼“å­˜æ£€æŸ¥ï¼‰
        
        ä½¿ç”¨ DataLoader.fetch_financial_indicator è·å–çœŸå®çš„ PEã€PBã€ROE ç­‰æ•°æ®ã€‚
        é‡‡ç”¨ Fail Fast æœºåˆ¶ï¼Œç¡®ä¿å®ç›˜å®‰å…¨ï¼š
        - ä¸ä½¿ç”¨ä»»ä½•è™šå‡/å¤‡ç”¨æ•°æ®å¡«å……
        - å¤±è´¥è‚¡ç¥¨æ ‡è®°ä¸ºæ— æ•ˆï¼Œä»é€‰è‚¡æ± ä¸­å‰”é™¤
        - å¤±è´¥ç‡è¶…è¿‡é˜ˆå€¼æ—¶ç»ˆæ­¢ç¨‹åºå¹¶æŠ¥è­¦
        
        Returns
        -------
        bool
            æ›´æ–°æ˜¯å¦æˆåŠŸ
        
        Raises
        ------
        RuntimeError
            å½“è´¢åŠ¡æ•°æ®è·å–å¤±è´¥ç‡è¶…è¿‡ 30% æ—¶
        """
        self.logger.info("å¼€å§‹æ›´æ–°è´¢åŠ¡æ•°æ®ï¼ˆå®ç›˜å®‰å…¨æ¨¡å¼ï¼‰...")
        
        # æ£€æŸ¥ä»Šæ—¥ç¼“å­˜
        financial_path = DATA_RAW_PATH / f"financial_{self.today.strftime('%Y%m%d')}.parquet"
        if financial_path.exists():
            try:
                self.financial_data = pd.read_parquet(financial_path)
                if not self.financial_data.empty:
                    self.logger.info(f"ğŸ“‚ ä½¿ç”¨ç¼“å­˜æ•°æ®: {financial_path.name}ï¼Œå…± {len(self.financial_data)} æ¡è®°å½•")
                    return True
            except Exception as e:
                self.logger.warning(f"è¯»å–ç¼“å­˜å¤±è´¥: {e}ï¼Œå°†é‡æ–°ä¸‹è½½")
        
        # æ ¹æ®æ•°æ®æºé€‰æ‹©ä¸åŒçš„è·å–æ–¹å¼
        if self.data_source == "tushare":
            return self._update_financial_data_tushare()
        else:
            return self._update_financial_data_akshare()
    
    def _update_financial_data_tushare(self) -> bool:
        """ä½¿ç”¨ Tushare æ›´æ–°è´¢åŠ¡æ•°æ®"""
        try:
            if self.ohlcv_data is None:
                self.logger.warning("OHLCV æ•°æ®ä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆè´¢åŠ¡æ•°æ®")
                return False
            
            stocks = self.ohlcv_data['stock_code'].unique().tolist()
            total_stocks = len(stocks)
            self.logger.info(f"ä½¿ç”¨ Tushare è·å– {total_stocks} åªè‚¡ç¥¨çš„è´¢åŠ¡æ•°æ®...")
            
            # æ–¹å¼1ï¼šä½¿ç”¨ daily_basic ä¸€æ¬¡è·å–å…¨å¸‚åœºä¼°å€¼æ•°æ®ï¼ˆé«˜æ•ˆï¼‰
            self.logger.info("è·å–æ¯æ—¥åŸºç¡€æŒ‡æ ‡ (PE, PB, å¸‚å€¼)...")
            basic_df = self.tushare_loader.fetch_daily_basic(stock_list=stocks)
            
            if basic_df is not None and not basic_df.empty:
                self.logger.info(f"æ¯æ—¥åŸºç¡€æŒ‡æ ‡è·å–æˆåŠŸ: {len(basic_df)} æ¡")
            else:
                self.logger.warning("æ¯æ—¥åŸºç¡€æŒ‡æ ‡è·å–å¤±è´¥ï¼Œå°†é€åªè·å–")
                basic_df = pd.DataFrame()
            
            # æ–¹å¼2ï¼šæ‰¹é‡è·å–è´¢åŠ¡æŒ‡æ ‡ï¼ˆROE ç­‰ï¼‰
            self.logger.info("è·å–è´¢åŠ¡æŒ‡æ ‡ (ROE, æ¯›åˆ©ç‡ç­‰)...")
            fina_df = self.tushare_loader.fetch_financial_batch(stocks, show_progress=True)
            
            # åˆå¹¶æ•°æ®ï¼ˆé¿å…é‡å¤åˆ—ï¼‰
            if not basic_df.empty:
                if not fina_df.empty:
                    # ä» fina_df ä¸­åªå– basic_df ä¸­ä¸å­˜åœ¨çš„åˆ— + stock_code
                    fina_cols = ['stock_code', 'roe', 'roe_dt']
                    # æ£€æŸ¥æ˜¯å¦æœ‰ gross_margin/net_marginï¼Œä¸” basic_df ä¸­æ²¡æœ‰
                    for col in ['gross_margin', 'net_margin']:
                        if col in fina_df.columns and col not in basic_df.columns:
                            fina_cols.append(col)
                    
                    # ç¡®ä¿åªé€‰æ‹©å­˜åœ¨çš„åˆ—
                    fina_cols = [c for c in fina_cols if c in fina_df.columns]
                    
                    merged_df = basic_df.merge(
                        fina_df[fina_cols],
                        on='stock_code',
                        how='left'
                    )
                else:
                    merged_df = basic_df
            elif not fina_df.empty:
                merged_df = fina_df
            else:
                self.logger.error("æ— æ³•è·å–ä»»ä½•è´¢åŠ¡æ•°æ®")
                return False
            
            # å»é™¤é‡å¤åˆ—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            merged_df = merged_df.loc[:, ~merged_df.columns.duplicated()]
            
            # æ ‡å‡†åŒ–åˆ—å
            if 'stock_code' not in merged_df.columns and 'ts_code' in merged_df.columns:
                merged_df['stock_code'] = merged_df['ts_code'].str[:6]
            
            # æ·»åŠ æ•°æ®æœ‰æ•ˆæ€§æ ‡è®°
            mv_cols = [c for c in ['circ_mv', 'total_mv'] if c in merged_df.columns]
            if mv_cols:
                merged_df['data_valid'] = merged_df[mv_cols].notna().any(axis=1)
            else:
                merged_df['data_valid'] = True
            
            # ä¼°ç®—ä¸Šå¸‚å¤©æ•°
            merged_df['listing_days'] = merged_df['stock_code'].apply(self._estimate_listing_days)
            
            self.financial_data = merged_df
            self._excluded_stocks = set()
            
            # ä¿å­˜æ•°æ®
            financial_path = DATA_RAW_PATH / f"financial_{self.today.strftime('%Y%m%d')}.parquet"
            self.financial_data.to_parquet(financial_path)
            
            valid_count = self.financial_data['data_valid'].sum()
            self.logger.info(
                f"âœ… è´¢åŠ¡æ•°æ®æ›´æ–°å®Œæˆ (Tushare):\n"
                f"   æ€»è®°å½•: {len(self.financial_data)}\n"
                f"   æœ‰æ•ˆæ•°æ®: {valid_count}\n"
                f"   PEæœ‰æ•ˆ: {self.financial_data['pe_ttm'].notna().sum()}\n"
                f"   ROEæœ‰æ•ˆ: {self.financial_data['roe'].notna().sum() if 'roe' in self.financial_data.columns else 0}"
            )
            
            return True
            
        except Exception as e:
            self.logger.error(f"Tushare è´¢åŠ¡æ•°æ®è·å–å¤±è´¥: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return False
    
    def _update_financial_data_akshare(self) -> bool:
        """ä½¿ç”¨ AkShare æ›´æ–°è´¢åŠ¡æ•°æ®ï¼ˆå…¼å®¹æ—§ä»£ç ï¼‰"""
        # å¤±è´¥ç‡é˜ˆå€¼ï¼ˆè¶…è¿‡æ­¤æ¯”ä¾‹å°†è§¦å‘ Critical Errorï¼‰
        FAILURE_THRESHOLD = 0.30  # 30%
        
        try:
            if self.ohlcv_data is None:
                self.logger.warning("OHLCV æ•°æ®ä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆè´¢åŠ¡æ•°æ®")
                return False
            
            stocks = self.ohlcv_data['stock_code'].unique().tolist()
            total_stocks = len(stocks)
            self.logger.info(f"éœ€è·å– {total_stocks} åªè‚¡ç¥¨çš„è´¢åŠ¡æ•°æ®")
            
            # é¢„å…ˆè·å–å…¨å¸‚åœºæ•°æ®å¹¶ç¼“å­˜ï¼ˆé¿å…ä¸ºæ¯åªè‚¡ç¥¨é‡å¤è¯·æ±‚ï¼‰
            self.logger.info("é¢„è·å–å…¨å¸‚åœºè¡Œæƒ…æ•°æ®ä»¥åŠ é€Ÿè´¢åŠ¡æŒ‡æ ‡è·å–...")
            spot_data_available = False
            try:
                spot_df = self.financial_loader._get_spot_data_cached()
                spot_data_available = spot_df is not None and not spot_df.empty
                if spot_data_available:
                    self.logger.info("âœ… å…¨å¸‚åœºè¡Œæƒ…æ•°æ®å°±ç»ª")
            except Exception as e:
                self.logger.warning(f"é¢„è·å–å…¨å¸‚åœºæ•°æ®å¤±è´¥: {e}")
            
            # å¦‚æœå…¨å¸‚åœºæ•°æ®è·å–å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨å†å²è´¢åŠ¡æ•°æ®ä½œä¸ºå¤‡ä»½
            if not spot_data_available:
                fallback_df = self._load_fallback_financial_data(stocks)
                if fallback_df is not None:
                    self.logger.info(f"âš ï¸ ä½¿ç”¨å†å²è´¢åŠ¡æ•°æ®ä½œä¸ºå¤‡ä»½ï¼ˆ{len(fallback_df)} æ¡ï¼‰")
                    self.financial_data = fallback_df
                    self._excluded_stocks = set()
                    return True
                self.logger.warning("æ— å¯ç”¨çš„å†å²è´¢åŠ¡æ•°æ®å¤‡ä»½ï¼Œå°†å°è¯•é€åªè‚¡ç¥¨è·å–")
            
            # ä½¿ç”¨çœŸå®æ•°æ®æ¥å£è·å–è´¢åŠ¡æŒ‡æ ‡
            financial_records = []
            failed_stocks = []
            
            import time
            
            for i, stock in enumerate(stocks):
                try:
                    # è°ƒç”¨ DataLoader.fetch_financial_indicator è·å–çœŸå®æ•°æ®
                    fin_df = self.financial_loader.fetch_financial_indicator(stock)
                    
                    if fin_df is not None and not fin_df.empty:
                        # æå–æœ€æ–°çš„è´¢åŠ¡æŒ‡æ ‡
                        if isinstance(fin_df, pd.DataFrame) and len(fin_df) > 0:
                            latest = fin_df.iloc[-1] if len(fin_df) > 1 else fin_df.iloc[0]
                            
                            # æ„å»ºè´¢åŠ¡è®°å½•
                            circ_mv = self._safe_get_value(latest, ['circ_mv', 'æµé€šå¸‚å€¼'], default=np.nan)
                            total_mv = self._safe_get_value(latest, ['total_mv', 'æ€»å¸‚å€¼'], default=np.nan)
                            
                            # æ£€æŸ¥å…³é”®å­—æ®µæ˜¯å¦æœ‰æ•ˆï¼ˆæµé€šå¸‚å€¼å¯¹å°å¸‚å€¼ç­–ç•¥è‡³å…³é‡è¦ï¼‰
                            has_valid_mv = pd.notna(circ_mv) or pd.notna(total_mv)
                            
                            record = {
                                'stock_code': stock,
                                'pe_ttm': self._safe_get_value(latest, ['pe_ttm', 'pe', 'å¸‚ç›ˆç‡'], default=np.nan),
                                'pb': self._safe_get_value(latest, ['pb', 'å¸‚å‡€ç‡'], default=np.nan),
                                'dividend_yield': self._safe_get_value(latest, ['dividend_yield', 'dv_ratio', 'è‚¡æ¯ç‡'], default=np.nan),
                                'ps_ttm': self._safe_get_value(latest, ['ps_ttm', 'ps', 'å¸‚é”€ç‡'], default=np.nan),
                                'roe': self._safe_get_value(latest, ['roe', 'roe_ttm'], default=np.nan),
                                'total_mv': total_mv,
                                'circ_mv': circ_mv,
                                # æ ‡è®°æ•°æ®æ˜¯å¦æœ‰æ•ˆï¼ˆç”¨äºåç»­è¿‡æ»¤ï¼‰
                                'data_valid': has_valid_mv,
                            }
                            
                            # ä¼°ç®—ä¸Šå¸‚å¤©æ•°
                            record['listing_days'] = self._estimate_listing_days(stock)
                            
                            financial_records.append(record)
                            
                            if has_valid_mv:
                                self.logger.debug(
                                    f"âœ“ {stock} è´¢åŠ¡æ•°æ®æœ‰æ•ˆ: "
                                    f"circ_mv={circ_mv/1e8:.2f}äº¿" if pd.notna(circ_mv) else f"âœ“ {stock} è´¢åŠ¡æ•°æ®è·å–æˆåŠŸ"
                                )
                            else:
                                # æ•°æ®è·å–æˆåŠŸä½†ç¼ºå°‘å…³é”®å­—æ®µï¼Œæ ‡è®°ä¸ºå¤±è´¥
                                self.logger.warning(
                                    f"âš  {stock} ç¼ºå°‘å…³é”®å¸‚å€¼æ•°æ®ï¼Œå°†ä»é€‰è‚¡æ± ä¸­å‰”é™¤"
                                )
                                failed_stocks.append(stock)
                        else:
                            self.logger.warning(f"âš  {stock} è´¢åŠ¡æ•°æ®ä¸ºç©ºï¼Œå°†ä»é€‰è‚¡æ± ä¸­å‰”é™¤")
                            failed_stocks.append(stock)
                    else:
                        self.logger.warning(f"âš  {stock} æ— æ³•è·å–è´¢åŠ¡æ•°æ®ï¼Œå°†ä»é€‰è‚¡æ± ä¸­å‰”é™¤")
                        failed_stocks.append(stock)
                        
                except Exception as e:
                    self.logger.warning(f"âš  {stock} è´¢åŠ¡æ•°æ®è·å–å¼‚å¸¸: {e}ï¼Œå°†ä»é€‰è‚¡æ± ä¸­å‰”é™¤")
                    failed_stocks.append(stock)
                
                # è¿›åº¦æ—¥å¿—
                if (i + 1) % 10 == 0:
                    current_failure_rate = len(failed_stocks) / (i + 1)
                    self.logger.info(
                        f"è´¢åŠ¡æ•°æ®è·å–è¿›åº¦: {i + 1}/{total_stocks} | "
                        f"å¤±è´¥: {len(failed_stocks)} ({current_failure_rate:.1%})"
                    )
                
                # æ·»åŠ å»¶æ—¶é¿å…è¯·æ±‚è¿‡å¿«ï¼ˆå·²æœ‰ç¼“å­˜æ—¶å¯å‡å°‘å»¶æ—¶ï¼‰
                time.sleep(0.05)
            
            # ========== Fail Fast æ£€æŸ¥ ==========
            failure_rate = len(failed_stocks) / total_stocks if total_stocks > 0 else 0
            
            if failure_rate > FAILURE_THRESHOLD:
                error_msg = (
                    f"ğŸš¨ CRITICAL ERROR: è´¢åŠ¡æ•°æ®è·å–å¤±è´¥ç‡è¿‡é«˜!\n"
                    f"   å¤±è´¥æ•°é‡: {len(failed_stocks)}/{total_stocks} ({failure_rate:.1%})\n"
                    f"   é˜ˆå€¼: {FAILURE_THRESHOLD:.0%}\n"
                    f"   å¤±è´¥è‚¡ç¥¨ç¤ºä¾‹: {failed_stocks[:10]}...\n"
                    f"   ä¸ºç¡®ä¿å®ç›˜å®‰å…¨ï¼Œç¨‹åºç»ˆæ­¢ã€‚è¯·æ£€æŸ¥æ•°æ®æºæˆ–ç½‘ç»œè¿æ¥ã€‚"
                )
                self.logger.critical(error_msg)
                
                # å°è¯•å‘é€æŠ¥è­¦é€šçŸ¥
                try:
                    token = os.environ.get("PUSHPLUS_TOKEN", "")
                    if not token:
                        token = self.config.get("notification", {}).get("pushplus_token", "")
                    if token:
                        send_pushplus_msg(
                            token=token,
                            title="ğŸš¨ é‡åŒ–ç³»ç»Ÿ Critical Error",
                            content=error_msg.replace("\n", "<br>"),
                            template="html"
                        )
                except Exception:
                    pass
                
                raise RuntimeError(error_msg)
            
            # ========== å¤„ç†å¤±è´¥è‚¡ç¥¨ï¼ˆä¸ä½¿ç”¨ Fallbackï¼Œä»…è®°å½•ï¼‰ ==========
            if failed_stocks:
                self.logger.warning(
                    f"ğŸ“Š è´¢åŠ¡æ•°æ®è·å–ç»“æœ:\n"
                    f"   æˆåŠŸ: {total_stocks - len(failed_stocks)}/{total_stocks}\n"
                    f"   å¤±è´¥: {len(failed_stocks)}/{total_stocks} ({failure_rate:.1%})\n"
                    f"   âš  å¤±è´¥è‚¡ç¥¨å°†è¢«æ’é™¤åœ¨é€‰è‚¡æ± ä¹‹å¤–ï¼ˆä¸ä½¿ç”¨è™šå‡æ•°æ®å¡«å……ï¼‰"
                )
                
                # ä¿å­˜å¤±è´¥è‚¡ç¥¨åˆ—è¡¨ä¾›åç»­è¿‡æ»¤ä½¿ç”¨
                self._excluded_stocks = set(failed_stocks)
            else:
                self._excluded_stocks = set()
            
            if not financial_records:
                self.logger.error("æœªè·å–åˆ°ä»»ä½•æœ‰æ•ˆè´¢åŠ¡æ•°æ®")
                return False
            
            self.financial_data = pd.DataFrame(financial_records)
            
            # æ•°æ®æ¸…æ´—ï¼šå¤„ç†å¼‚å¸¸å€¼
            self._clean_financial_data()
            
            # è·å–è¡Œä¸šæ•°æ®
            self.industry_data = self._fetch_industry_data(stocks)
            
            # ç»Ÿè®¡æœ‰æ•ˆæ•°æ®
            valid_count = self.financial_data['data_valid'].sum() if 'data_valid' in self.financial_data.columns else len(self.financial_data)
            
            self.logger.info(
                f"âœ… è´¢åŠ¡æ•°æ®æ›´æ–°å®Œæˆ:\n"
                f"   æ€»è®°å½•: {len(self.financial_data)}\n"
                f"   æœ‰æ•ˆæ•°æ®: {valid_count}\n"
                f"   å·²å‰”é™¤: {len(failed_stocks)} åªè‚¡ç¥¨"
            )
            
            # ä¿å­˜æ•°æ®
            financial_path = DATA_RAW_PATH / f"financial_{self.today.strftime('%Y%m%d')}.parquet"
            self.financial_data.to_parquet(financial_path)
            self.logger.info(f"è´¢åŠ¡æ•°æ®å·²ä¿å­˜è‡³ {financial_path}")
            
            return True
            
        except RuntimeError:
            # Critical Errorï¼Œç›´æ¥å‘ä¸ŠæŠ›å‡º
            raise
        except Exception as e:
            self.logger.error(f"æ›´æ–°è´¢åŠ¡æ•°æ®å¤±è´¥: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return False
    
    def _safe_get_value(
        self,
        data: pd.Series,
        keys: List[str],
        default: Any = np.nan
    ) -> Any:
        """
        å®‰å…¨åœ°ä» Series ä¸­è·å–å€¼
        
        Parameters
        ----------
        data : pd.Series
            æ•°æ®åºåˆ—
        keys : List[str]
            å¯èƒ½çš„é”®ååˆ—è¡¨
        default : Any
            é»˜è®¤å€¼
        
        Returns
        -------
        Any
            è·å–åˆ°çš„å€¼æˆ–é»˜è®¤å€¼
        """
        for key in keys:
            if key in data.index:
                val = data[key]
                if pd.notna(val):
                    try:
                        return float(val)
                    except (ValueError, TypeError):
                        continue
        return default
    
    def _load_fallback_financial_data(
        self, 
        required_stocks: List[str]
    ) -> Optional[pd.DataFrame]:
        """
        åŠ è½½å†å²è´¢åŠ¡æ•°æ®ä½œä¸ºç½‘ç»œå¤±è´¥æ—¶çš„å¤‡ä»½
        
        æŒ‰æ—¥æœŸå€’åºæŸ¥æ‰¾æœ€è¿‘çš„è´¢åŠ¡æ•°æ®æ–‡ä»¶ï¼Œè¿‡æ»¤å‡ºå½“å‰éœ€è¦çš„è‚¡ç¥¨ã€‚
        
        Parameters
        ----------
        required_stocks : List[str]
            éœ€è¦è´¢åŠ¡æ•°æ®çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨
        
        Returns
        -------
        Optional[pd.DataFrame]
            å†å²è´¢åŠ¡æ•°æ®ï¼Œå¦‚æœæ— å¯ç”¨æ•°æ®è¿”å› None
        """
        # æŸ¥æ‰¾å†å²è´¢åŠ¡æ•°æ®æ–‡ä»¶
        financial_files = sorted(
            DATA_RAW_PATH.glob("financial_*.parquet"),
            reverse=True  # æœ€æ–°çš„ä¼˜å…ˆ
        )
        
        if not financial_files:
            self.logger.warning("æœªæ‰¾åˆ°å†å²è´¢åŠ¡æ•°æ®æ–‡ä»¶")
            return None
        
        # å°è¯•åŠ è½½æœ€è¿‘çš„æ–‡ä»¶
        for file_path in financial_files[:5]:  # æœ€å¤šå°è¯•5ä¸ªæ–‡ä»¶
            try:
                df = pd.read_parquet(file_path)
                
                if df.empty or 'stock_code' not in df.columns:
                    continue
                
                # è¿‡æ»¤å‡ºéœ€è¦çš„è‚¡ç¥¨
                required_set = set(required_stocks)
                df_filtered = df[df['stock_code'].isin(required_set)]
                
                if len(df_filtered) == 0:
                    continue
                
                coverage = len(df_filtered) / len(required_set)
                file_date = file_path.stem.replace("financial_", "")
                
                self.logger.info(
                    f"ğŸ“‚ åŠ è½½å†å²è´¢åŠ¡æ•°æ®: {file_path.name}\n"
                    f"   æ•°æ®æ—¥æœŸ: {file_date}\n"
                    f"   è¦†ç›–ç‡: {len(df_filtered)}/{len(required_set)} ({coverage:.1%})"
                )
                
                # è¦†ç›–ç‡å¤ªä½åˆ™è·³è¿‡
                if coverage < 0.5:
                    self.logger.warning(f"è¦†ç›–ç‡è¿‡ä½ ({coverage:.1%})ï¼Œå°è¯•å…¶ä»–æ–‡ä»¶")
                    continue
                
                return df_filtered
                
            except Exception as e:
                self.logger.debug(f"åŠ è½½ {file_path} å¤±è´¥: {e}")
                continue
        
        return None
    
    def _estimate_listing_days(self, stock: str) -> int:
        """
        ä¼°ç®—è‚¡ç¥¨ä¸Šå¸‚å¤©æ•°ï¼ˆå¿«é€Ÿç‰ˆæœ¬ï¼‰
        
        ä½¿ç”¨è‚¡ç¥¨ä»£ç å‰ç¼€å¿«é€Ÿä¼°ç®—ï¼Œé¿å…é€åª API è°ƒç”¨ã€‚
        æ²ªæ·±300æˆåˆ†è‚¡é€šå¸¸éƒ½æ˜¯ä¸Šå¸‚å¤šå¹´çš„è“ç­¹è‚¡ã€‚
        
        Parameters
        ----------
        stock : str
            è‚¡ç¥¨ä»£ç 
        
        Returns
        -------
        int
            ä¼°ç®—çš„ä¸Šå¸‚å¤©æ•°
        """
        # å¯¹äºæ²ªæ·±300æˆåˆ†è‚¡ï¼Œé»˜è®¤å‡è®¾ä¸Šå¸‚è¶…è¿‡2å¹´ï¼ˆç¬¦åˆåŸºæœ¬æ¡ä»¶ï¼‰
        # è¿™é¿å…äº†é€åªè°ƒç”¨ API çš„æ€§èƒ½é—®é¢˜
        return 1000  # é»˜è®¤è¿”å›è¾ƒå¤§å€¼ï¼Œè¡¨ç¤ºå·²ä¸Šå¸‚è¾ƒé•¿æ—¶é—´
    
    def _generate_fallback_financial_data(self, stocks: List[str]) -> List[Dict[str, Any]]:
        """
        [å·²åºŸå¼ƒ] ä¸ºè·å–å¤±è´¥çš„è‚¡ç¥¨ç”Ÿæˆå¤‡ç”¨è´¢åŠ¡æ•°æ®
        
        æ­¤æ–¹æ³•å·²è¢«åºŸå¼ƒï¼Œå®ç›˜ç¯å¢ƒä¸‹ç¦æ­¢ä½¿ç”¨è™šå‡æ•°æ®å¡«å……ã€‚
        è°ƒç”¨æ­¤æ–¹æ³•å°†æŠ›å‡º RuntimeErrorã€‚
        
        Parameters
        ----------
        stocks : List[str]
            è‚¡ç¥¨ä»£ç åˆ—è¡¨
        
        Returns
        -------
        List[Dict[str, Any]]
            ä¸ä¼šè¿”å›ï¼Œç›´æ¥æŠ›å‡ºå¼‚å¸¸
        
        Raises
        ------
        RuntimeError
            å§‹ç»ˆæŠ›å‡ºï¼Œç¦æ­¢ä½¿ç”¨å¤‡ç”¨æ•°æ®
        
        Notes
        -----
        å®ç›˜å®‰å…¨ç­–ç•¥ï¼š
        - å¤±è´¥è‚¡ç¥¨åº”ç›´æ¥ä»é€‰è‚¡æ± ä¸­å‰”é™¤ï¼Œè€Œéç”¨è™šå‡æ•°æ®å¡«å……
        - ä½¿ç”¨ä¸­ä½æ•°/é»˜è®¤å€¼å¡«å……å¯èƒ½å¯¼è‡´é€‰è‚¡å¤±çœŸï¼Œé€ æˆå®ç›˜äºæŸ
        - æ­£ç¡®åšæ³•ï¼šåœ¨ calculate_factors æ—¶è¿‡æ»¤æ‰ data_valid=False çš„è‚¡ç¥¨
        """
        error_msg = (
            f"ğŸš¨ å®‰å…¨è­¦å‘Š: ç¦æ­¢ä½¿ç”¨å¤‡ç”¨è´¢åŠ¡æ•°æ®!\n"
            f"   è¯·æ±‚å¡«å…… {len(stocks)} åªè‚¡ç¥¨çš„è™šå‡æ•°æ®ã€‚\n"
            f"   å®ç›˜ç¯å¢ƒä¸‹ï¼Œè¿™å¯èƒ½å¯¼è‡´ä¸¥é‡çš„é€‰è‚¡å¤±çœŸã€‚\n"
            f"   æ­£ç¡®åšæ³•ï¼šå°†è¿™äº›è‚¡ç¥¨ä»é€‰è‚¡æ± ä¸­å‰”é™¤ã€‚\n"
            f"   è‚¡ç¥¨åˆ—è¡¨: {stocks[:5]}..."
        )
        self.logger.critical(error_msg)
        raise RuntimeError(error_msg)
    
    def _clean_financial_data(self) -> None:
        """
        æ¸…æ´—è´¢åŠ¡æ•°æ®
        
        å¤„ç†å¼‚å¸¸å€¼å’Œç¼ºå¤±å€¼ã€‚
        """
        if self.financial_data is None or self.financial_data.empty:
            return
        
        # PE å¼‚å¸¸å€¼å¤„ç†ï¼šè´Ÿå€¼è®¾ä¸º NaNï¼Œè¶…å¤§å€¼æˆªæ–­
        if 'pe_ttm' in self.financial_data.columns:
            self.financial_data.loc[self.financial_data['pe_ttm'] <= 0, 'pe_ttm'] = np.nan
            self.financial_data.loc[self.financial_data['pe_ttm'] > 500, 'pe_ttm'] = 500
        
        # PB å¼‚å¸¸å€¼å¤„ç†
        if 'pb' in self.financial_data.columns:
            self.financial_data.loc[self.financial_data['pb'] <= 0, 'pb'] = np.nan
            self.financial_data.loc[self.financial_data['pb'] > 50, 'pb'] = 50
        
        # ROE å¼‚å¸¸å€¼å¤„ç†
        if 'roe' in self.financial_data.columns:
            self.financial_data.loc[self.financial_data['roe'] < -1, 'roe'] = -1
            self.financial_data.loc[self.financial_data['roe'] > 1, 'roe'] = 1
        
        # è‚¡æ¯ç‡å¼‚å¸¸å€¼å¤„ç†
        if 'dividend_yield' in self.financial_data.columns:
            self.financial_data.loc[self.financial_data['dividend_yield'] < 0, 'dividend_yield'] = 0
            self.financial_data.loc[self.financial_data['dividend_yield'] > 0.20, 'dividend_yield'] = 0.20
        
        self.logger.debug("è´¢åŠ¡æ•°æ®æ¸…æ´—å®Œæˆ")
    
    def _fetch_industry_data(self, stocks: List[str]) -> pd.DataFrame:
        """
        è·å–è¡Œä¸šåˆ†ç±»æ•°æ®
        
        Parameters
        ----------
        stocks : List[str]
            è‚¡ç¥¨ä»£ç åˆ—è¡¨
        
        Returns
        -------
        pd.DataFrame
            è¡Œä¸šåˆ†ç±»æ•°æ®
        """
        self.logger.info("è·å–è¡Œä¸šåˆ†ç±»æ•°æ®...")
        
        try:
            import akshare as ak
            
            # å°è¯•è·å–ç”³ä¸‡è¡Œä¸šåˆ†ç±»
            industry_df = ak.stock_board_industry_name_em()
            
            if industry_df is not None and not industry_df.empty:
                # æ„å»ºè‚¡ç¥¨åˆ°è¡Œä¸šçš„æ˜ å°„
                stock_industry = {}
                
                for _, row in industry_df.iterrows():
                    industry_name = row.get('æ¿å—åç§°', '')
                    industry_code = row.get('æ¿å—ä»£ç ', '')
                    
                    try:
                        # è·å–è¯¥è¡Œä¸šçš„æˆåˆ†è‚¡
                        cons_df = ak.stock_board_industry_cons_em(symbol=industry_name)
                        if cons_df is not None and not cons_df.empty:
                            code_col = 'ä»£ç ' if 'ä»£ç ' in cons_df.columns else cons_df.columns[0]
                            for stock_code in cons_df[code_col]:
                                if stock_code in stocks:
                                    stock_industry[stock_code] = industry_name
                    except Exception:
                        continue
                
                if stock_industry:
                    result = pd.DataFrame([
                        {'stock_code': k, 'sw_industry_l1': v}
                        for k, v in stock_industry.items()
                    ])
                    
                    # è¡¥å……æœªæ‰¾åˆ°çš„è‚¡ç¥¨
                    missing_stocks = set(stocks) - set(stock_industry.keys())
                    if missing_stocks:
                        missing_df = pd.DataFrame({
                            'stock_code': list(missing_stocks),
                            'sw_industry_l1': 'å…¶ä»–'
                        })
                        result = pd.concat([result, missing_df], ignore_index=True)
                    
                    self.logger.info(f"è¡Œä¸šåˆ†ç±»æ•°æ®è·å–æˆåŠŸï¼Œå…± {len(result)} æ¡è®°å½•")
                    return result
            
        except Exception as e:
            self.logger.warning(f"è·å–çœŸå®è¡Œä¸šæ•°æ®å¤±è´¥: {e}ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
        
        # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨æ¨¡æ‹Ÿè¡Œä¸šæ•°æ®
        industries = ['é“¶è¡Œ', 'éé“¶é‡‘è', 'é£Ÿå“é¥®æ–™', 'åŒ»è¯ç”Ÿç‰©', 'ç”µå­', 
                     'è®¡ç®—æœº', 'å®¶ç”¨ç”µå™¨', 'æ±½è½¦', 'æˆ¿åœ°äº§', 'å»ºç­‘ææ–™']
        
        return pd.DataFrame({
            'stock_code': list(stocks),
            'sw_industry_l1': np.random.choice(industries, len(stocks))
        })
    
    def update_benchmark_data(self) -> bool:
        """
        æ›´æ–°åŸºå‡†æŒ‡æ•°æ•°æ®ï¼ˆç”¨äºå¤§ç›˜é£æ§ï¼‰
        
        è·å–æ²ªæ·±300æŒ‡æ•°æ•°æ®ï¼Œç”¨äºè®¡ç®—MA20é£æ§æŒ‡æ ‡ã€‚
        
        Returns
        -------
        bool
            æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        self.logger.info("å¼€å§‹æ›´æ–°åŸºå‡†æŒ‡æ•°æ•°æ®ï¼ˆæ²ªæ·±300ï¼‰...")
        
        try:
            data_config = self.config.get("data", {})
            start_date = data_config.get("start_date", "2020-01-01")
            end_date = self.today.strftime("%Y-%m-%d")
            
            # ä½¿ç”¨ DataLoader è·å–æ²ªæ·±300æŒ‡æ•°æ•°æ®
            self.benchmark_data = self.financial_loader.fetch_index_price(
                index_code="000300",
                start_date=start_date,
                end_date=end_date
            )
            
            if self.benchmark_data is not None and not self.benchmark_data.empty:
                self.logger.info(
                    f"åŸºå‡†æŒ‡æ•°æ•°æ®æ›´æ–°å®Œæˆï¼Œå…± {len(self.benchmark_data)} æ¡è®°å½•ï¼Œ"
                    f"æ—¥æœŸèŒƒå›´: {self.benchmark_data.index[0].strftime('%Y-%m-%d')} ~ "
                    f"{self.benchmark_data.index[-1].strftime('%Y-%m-%d')}"
                )
                return True
            else:
                self.logger.warning("æœªè·å–åˆ°åŸºå‡†æŒ‡æ•°æ•°æ®ï¼Œå¤§ç›˜é£æ§å°†ä¸ç”Ÿæ•ˆ")
                return False
                
        except Exception as e:
            self.logger.warning(f"æ›´æ–°åŸºå‡†æŒ‡æ•°æ•°æ®å¤±è´¥: {e}ï¼Œå¤§ç›˜é£æ§å°†ä¸ç”Ÿæ•ˆ")
            self.benchmark_data = None
            return False
    
    def is_market_risk_triggered(self) -> bool:
        """
        æ£€æŸ¥å¤§ç›˜é£æ§æ˜¯å¦è§¦å‘
        
        ä»é…ç½®æ–‡ä»¶è¯»å–é£æ§å‚æ•°ï¼š
        - ma_period: å‡çº¿å‘¨æœŸï¼ˆé»˜è®¤60ï¼Œå³MA60ç‰›ç†Šçº¿ï¼‰
        - drop_threshold: è·Œå¹…é˜ˆå€¼ï¼ˆé»˜è®¤0.05ï¼Œå³5%ï¼‰
        - drop_lookback: è·Œå¹…å›æº¯å¤©æ•°ï¼ˆé»˜è®¤20ï¼‰
        
        é£æ§è§¦å‘æ¡ä»¶ï¼ˆæ»¡è¶³ä»»ä¸€å³è§¦å‘ï¼ŒOR é€»è¾‘ï¼‰ï¼š
        1. æ”¶ç›˜ä»· < MA{ma_period}ï¼ˆè·Œç ´å‡çº¿ï¼‰
        2. ï¼ˆå¯é€‰ï¼‰è¿‘{drop_lookback}æ—¥è·Œå¹… > {drop_threshold}
        
        Returns
        -------
        bool
            True è¡¨ç¤ºé£æ§è§¦å‘ï¼ˆåº”ç©ºä»“ï¼‰ï¼ŒFalse è¡¨ç¤ºæ­£å¸¸
        
        Notes
        -----
        é£æ§å‚æ•°ä» config['risk']['market_risk'] ä¸­è¯»å–ï¼Œæ”¯æŒåŠ¨æ€é…ç½®ã€‚
        ä½¿ç”¨ OR é€»è¾‘å¯é¿å…ç¼“æ…¢é˜´è·Œçš„ç†Šå¸‚ä¸­æ— æ³•è§¦å‘é£æ§çš„é—®é¢˜ã€‚
        """
        # è¯»å–é£æ§é…ç½®
        risk_config = self.config.get("risk", {})
        market_risk_config = risk_config.get("market_risk", {})
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨é£æ§
        if not market_risk_config.get("enabled", True):
            self.logger.debug("å¤§ç›˜é£æ§å·²ç¦ç”¨")
            return False
        
        # è¯»å–é£æ§å‚æ•°ï¼ˆä»é…ç½®æ–‡ä»¶ï¼Œæ”¯æŒåŠ¨æ€è°ƒæ•´ï¼‰
        ma_period = market_risk_config.get("ma_period", 60)  # é»˜è®¤ä½¿ç”¨ MA60
        drop_threshold = market_risk_config.get("drop_threshold", 0.05)  # é»˜è®¤ 5%
        drop_lookback = market_risk_config.get("drop_lookback", 20)  # é»˜è®¤ 20 å¤©
        
        if self.benchmark_data is None or self.benchmark_data.empty:
            self.logger.debug("æ— åŸºå‡†æ•°æ®ï¼Œé£æ§æ£€æŸ¥è·³è¿‡")
            return False
        
        try:
            # è·å–è¶³å¤Ÿçš„å†å²æ•°æ®ç”¨äºè®¡ç®—å‡çº¿
            required_days = max(ma_period, drop_lookback) + 1
            latest_data = self.benchmark_data.tail(required_days)
            
            if len(latest_data) < ma_period:
                self.logger.debug(
                    f"åŸºå‡†æ•°æ®ä¸è¶³ {ma_period} å¤©ï¼ˆå½“å‰ {len(latest_data)} å¤©ï¼‰ï¼Œ"
                    f"é£æ§æ£€æŸ¥è·³è¿‡"
                )
                return False
            
            # è®¡ç®—ç§»åŠ¨å¹³å‡çº¿ï¼ˆä½¿ç”¨é…ç½®çš„å‘¨æœŸï¼‰
            ma_value = latest_data['close'].tail(ma_period).mean()
            latest_close = latest_data['close'].iloc[-1]
            
            # æ¡ä»¶1ï¼šè·Œç ´å‡çº¿
            is_below_ma = latest_close < ma_value
            
            # æ¡ä»¶2ï¼šè®¡ç®—è¿‘æœŸè·Œå¹…ï¼ˆå¯é€‰æ¡ä»¶ï¼‰
            is_drop_exceeded = False
            recent_drop = 0.0
            
            if drop_threshold > 0 and len(latest_data) >= drop_lookback:
                lookback_data = latest_data.tail(drop_lookback)
                if len(lookback_data) >= 2:
                    start_price = lookback_data['close'].iloc[0]
                    end_price = lookback_data['close'].iloc[-1]
                    recent_drop = (end_price - start_price) / start_price
                    is_drop_exceeded = recent_drop < -drop_threshold
            
            # ç»¼åˆåˆ¤æ–­ï¼šè·Œç ´å‡çº¿ æˆ– è·Œå¹…è¶…è¿‡é˜ˆå€¼ï¼ˆä»»ä¸€æ»¡è¶³å³è§¦å‘é£æ§ï¼‰
            # åŸé€»è¾‘ä½¿ç”¨ ANDï¼Œä¼šå¯¼è‡´ç¼“æ…¢é˜´è·Œæ—¶æ— æ³•è§¦å‘ï¼Œéå¸¸å±é™©
            # æ–°é€»è¾‘ä½¿ç”¨ ORï¼šåªè¦è·Œç ´å‡çº¿ï¼Œæˆ–è€…å‘ç”Ÿæš´è·Œï¼Œéƒ½è§†ä¸ºé£é™©
            if drop_threshold > 0:
                is_triggered = is_below_ma or is_drop_exceeded
            else:
                is_triggered = is_below_ma
            
            # ä¼˜åŒ–çš„æ—¥å¿—è¾“å‡º
            ma_label = f"MA{ma_period}"
            deviation_pct = (latest_close - ma_value) / ma_value * 100
            
            if is_triggered:
                self.logger.warning(
                    f"ğŸš¨ å¤§ç›˜é£æ§è§¦å‘!\n"
                    f"   å½“å‰ç‚¹ä½: {latest_close:.2f} | {ma_label}: {ma_value:.2f} | "
                    f"åç¦»: {deviation_pct:+.2f}%\n"
                    f"   è¿‘{drop_lookback}æ—¥è·Œå¹…: {recent_drop*100:+.2f}% | "
                    f"é˜ˆå€¼: -{drop_threshold*100:.1f}%"
                )
            else:
                status = "âœ…" if latest_close >= ma_value else "âš ï¸"
                self.logger.info(
                    f"{status} å¤§ç›˜é£æ§æ£€æŸ¥: "
                    f"ç‚¹ä½ {latest_close:.2f} vs {ma_label} {ma_value:.2f} "
                    f"(åç¦» {deviation_pct:+.2f}%) | "
                    f"è¿‘{drop_lookback}æ—¥å˜åŒ–: {recent_drop*100:+.2f}%"
                )
                
                # å¦‚æœæ¥è¿‘è§¦å‘æ¡ä»¶ï¼Œé¢å¤–è­¦å‘Š
                if is_below_ma and not is_drop_exceeded:
                    self.logger.warning(
                        f"   âš ï¸ å·²è·Œç ´ {ma_label}ï¼Œä½†è·Œå¹… ({recent_drop*100:+.2f}%) "
                        f"æœªè¾¾é˜ˆå€¼ (-{drop_threshold*100:.1f}%)ï¼Œç»§ç»­è§‚å¯Ÿ"
                    )
            
            return is_triggered
            
        except Exception as e:
            self.logger.warning(f"é£æ§æ£€æŸ¥å¤±è´¥: {e}")
            import traceback
            self.logger.debug(traceback.format_exc())
            return False
    
    def calculate_factors(self) -> bool:
        """
        è®¡ç®—å› å­æ•°æ®ï¼ˆå®ç›˜å®‰å…¨ç‰ˆï¼‰
        
        åŒ…å«ä»¥ä¸‹å®‰å…¨æœºåˆ¶ï¼š
        - è¿‡æ»¤æ‰è´¢åŠ¡æ•°æ®è·å–å¤±è´¥çš„è‚¡ç¥¨
        - å°†æ— æ•ˆæ•°æ®çš„è‚¡ç¥¨å› å­å¾—åˆ†è®¾ä¸º -infï¼Œç¡®ä¿ä¸ä¼šè¢«é€‰ä¸­
        
        Returns
        -------
        bool
            è®¡ç®—æ˜¯å¦æˆåŠŸ
        """
        self.logger.info("å¼€å§‹è®¡ç®—å› å­ï¼ˆå®ç›˜å®‰å…¨æ¨¡å¼ï¼‰...")
        
        try:
            # å³ä½¿è´¢åŠ¡æ•°æ®æ›´æ–°å¤±è´¥ï¼Œå¦‚æœOHLCVæ•°æ®å­˜åœ¨ï¼Œä»ç»§ç»­æ‰§è¡Œå› å­è®¡ç®—
            if self.ohlcv_data is None:
                self.logger.warning("æ•°æ®ä¸å®Œæ•´ï¼Œæ— æ³•è®¡ç®—å› å­")
                return False
            
            # å¦‚æœè´¢åŠ¡æ•°æ®ä¸ºç©ºï¼Œå°è¯•ä½¿ç”¨ç©ºDataFrameç»§ç»­
            if self.financial_data is None:
                self.logger.warning("è´¢åŠ¡æ•°æ®ä¸ºç©ºï¼Œå°†è·³è¿‡è´¢åŠ¡å› å­è®¡ç®—")
                self.financial_data = pd.DataFrame()

            # å‡†å¤‡æ•°æ®
            ohlcv = self.ohlcv_data.copy()
            
            # ========== åˆ—åæ ‡å‡†åŒ–ï¼ˆå…¼å®¹ Tushare åŸå§‹æ ¼å¼ï¼‰ ==========
            column_mapping = {
                'trade_date': 'date',
                'vol': 'volume',
                'pct_chg': 'pct_change',
            }
            ohlcv.rename(columns=column_mapping, inplace=True)
            
            # ç¡®ä¿æ—¥æœŸåˆ—å­˜åœ¨ï¼ˆå¤„ç† DatetimeIndex å’Œå„ç§åˆ—åæƒ…å†µï¼‰
            if 'date' not in ohlcv.columns:
                if 'trade_date' in ohlcv.columns:
                    ohlcv['date'] = pd.to_datetime(ohlcv['trade_date'])
                elif 'æ—¥æœŸ' in ohlcv.columns:
                    ohlcv['date'] = pd.to_datetime(ohlcv['æ—¥æœŸ'])
                elif isinstance(ohlcv.index, pd.DatetimeIndex):
                    ohlcv = ohlcv.reset_index()
                    # é‡å‘½åç´¢å¼•åˆ—ä¸º 'date'
                    if ohlcv.columns[0] in ['index', 'date', 'æ—¥æœŸ']:
                        ohlcv.rename(columns={ohlcv.columns[0]: 'date'}, inplace=True)
                    else:
                        ohlcv['date'] = ohlcv.index
                else:
                    self.logger.warning("æ— æ³•æ‰¾åˆ°æ—¥æœŸåˆ—ï¼Œå°è¯•ä»æ•°æ®ç»“æ„æ¨æ–­...")
                    # å°è¯•é‡ç½®ç´¢å¼•
                    ohlcv = ohlcv.reset_index()
                    if 'index' in ohlcv.columns:
                        ohlcv.rename(columns={'index': 'date'}, inplace=True)
            
            # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
            required_cols = ['close', 'stock_code']
            missing_cols = [c for c in required_cols if c not in ohlcv.columns]
            if missing_cols:
                self.logger.error(f"OHLCV æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
                self.logger.info(f"å½“å‰åˆ—å: {ohlcv.columns.tolist()}")
                return False
            
            # ç¡®ä¿ date åˆ—æ˜¯ datetime ç±»å‹
            if 'date' in ohlcv.columns:
                ohlcv['date'] = pd.to_datetime(ohlcv['date'])
            
            # ========== å®ç›˜å®‰å…¨ï¼šè¿‡æ»¤æ‰è¢«æ’é™¤çš„è‚¡ç¥¨ ==========
            excluded_stocks = getattr(self, '_excluded_stocks', set())
            if excluded_stocks:
                original_count = len(ohlcv['stock_code'].unique())
                ohlcv = ohlcv[~ohlcv['stock_code'].isin(excluded_stocks)]
                filtered_count = len(ohlcv['stock_code'].unique())
                self.logger.info(
                    f"ğŸ›¡ï¸ å®‰å…¨è¿‡æ»¤: å·²å‰”é™¤ {original_count - filtered_count} åª"
                    f"è´¢åŠ¡æ•°æ®æ— æ•ˆçš„è‚¡ç¥¨ï¼ˆå‰©ä½™ {filtered_count} åªï¼‰"
                )
            
            # åˆå¹¶è´¢åŠ¡æ•°æ® (ä»…åœ¨è´¢åŠ¡æ•°æ®å­˜åœ¨æ—¶åˆå¹¶ï¼Œé¿å…ç¡¬ä¾èµ–)
            if self.financial_data is not None and not self.financial_data.empty:
                # åªåˆå¹¶æœ‰æ•ˆæ•°æ®
                valid_financial = self.financial_data.copy()
                if 'data_valid' in valid_financial.columns:
                    invalid_count = (~valid_financial['data_valid']).sum()
                    if invalid_count > 0:
                        self.logger.warning(
                            f"ğŸ›¡ï¸ è´¢åŠ¡æ•°æ®ä¸­æœ‰ {invalid_count} æ¡æ— æ•ˆè®°å½•ï¼Œå°†è¢«æ ‡è®°"
                        )
                
                # ç§»é™¤è´¢åŠ¡æ•°æ®ä¸­ä¸ OHLCV é‡å¤çš„åˆ—ï¼ˆé¿å…åˆå¹¶å†²çªï¼‰
                ohlcv_cols = set(ohlcv.columns) - {'stock_code'}  # æ’é™¤ stock_codeï¼Œå®ƒéœ€è¦ä¿ç•™ç”¨äºåˆå¹¶
                cols_to_keep = [c for c in valid_financial.columns if c not in ohlcv_cols]
                valid_financial = valid_financial[cols_to_keep]
                
                factor_data = ohlcv.merge(
                    valid_financial,
                    on='stock_code',
                    how='left'
                )
            else:
                factor_data = ohlcv.copy()
            
            # åˆå¹¶è¡Œä¸šæ•°æ®
            if self.industry_data is not None:
                factor_data = factor_data.merge(
                    self.industry_data,
                    on='stock_code',
                    how='left'
                )
            
            # ==================== å› å­è®¡ç®— ====================
            # æ ¹æ®ç­–ç•¥é…ç½®åŠ¨æ€è®¡ç®—æ‰€éœ€å› å­
            
            # 1. åŠ¨é‡å› å­ RSI_20ï¼ˆæ‰€æœ‰ç­–ç•¥é€šç”¨ï¼‰
            factor_data['rsi_20'] = factor_data.groupby('stock_code')['close'].transform(
                lambda x: self._calculate_rsi(x, 20)
            )
            
            # 1.5. åŠ¨é‡å› å­ ROC_20ï¼ˆ20æ—¥å˜åŠ¨ç‡ï¼‰
            factor_data['roc_20'] = factor_data.groupby('stock_code')['close'].transform(
                lambda x: x.pct_change(20) * 100  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
            )
            
            # 2. å°å¸‚å€¼å› å­ small_capï¼ˆæ¿€è¿›å‹ç­–ç•¥ä½¿ç”¨ï¼‰
            # small_cap = -log(æµé€šå¸‚å€¼)ï¼Œå¸‚å€¼è¶Šå°åˆ†æ•°è¶Šé«˜
            if 'circ_mv' in factor_data.columns:
                factor_data['small_cap'] = -np.log(factor_data['circ_mv'].replace(0, np.nan))
                factor_data['small_cap'] = factor_data['small_cap'].replace([np.inf, -np.inf], np.nan)
            elif 'total_mv' in factor_data.columns:
                factor_data['small_cap'] = -np.log(factor_data['total_mv'].replace(0, np.nan))
                factor_data['small_cap'] = factor_data['small_cap'].replace([np.inf, -np.inf], np.nan)
            else:
                factor_data['small_cap'] = np.nan
            
            # 3. æ¢æ‰‹ç‡å› å­ turnover_5dï¼ˆæ¿€è¿›å‹ç­–ç•¥ä½¿ç”¨ï¼‰
            # æ”¯æŒå¤šç§åˆ—åï¼šturnï¼ˆAkShare spot_emï¼‰æˆ– turnoverï¼ˆå…¶ä»–æ•°æ®æºï¼‰
            turn_col = None
            if 'turn' in factor_data.columns:
                turn_col = 'turn'
            elif 'turnover' in factor_data.columns:
                turn_col = 'turnover'
            elif 'turnover_rate' in factor_data.columns:
                turn_col = 'turnover_rate'
            
            if turn_col is not None:
                factor_data['turnover_5d'] = factor_data.groupby('stock_code')[turn_col].transform(
                    lambda x: x.rolling(5, min_periods=1).mean()
                )
                self.logger.debug(f"ä½¿ç”¨ '{turn_col}' åˆ—è®¡ç®—æ¢æ‰‹ç‡å› å­")
            else:
                factor_data['turnover_5d'] = np.nan
                self.logger.warning("æœªæ‰¾åˆ°æ¢æ‰‹ç‡åˆ— (turn/turnover/turnover_rate)ï¼Œæ¢æ‰‹ç‡å› å­å°†ä¸º NaN")
            
            # ========== HS300 æ·±åº¦ä»·å€¼ç­–ç•¥å› å­ ==========
            # ä½¿ç”¨ FactorCalculator çš„æ–¹æ³•è®¡ç®—å¤åˆå› å­
            from src.features import FactorCalculator
            
            # 4.1 å¤åˆä»·å€¼å› å­ï¼ˆEP + BPï¼‰
            try:
                # åˆ›å»ºä¸´æ—¶ FactorCalculator å®ä¾‹
                temp_ohlcv = factor_data[['stock_code', 'close', 'open', 'high', 'low', 'volume']].copy()
                if 'date' in factor_data.columns:
                    temp_ohlcv['date'] = factor_data['date']
                    temp_ohlcv = temp_ohlcv.set_index('date')
                
                temp_fin = factor_data[['stock_code', 'pe_ttm', 'pb', 'roe']].copy() if all(
                    col in factor_data.columns for col in ['pe_ttm', 'pb']
                ) else pd.DataFrame()
                
                if not temp_fin.empty:
                    # æ‰‹åŠ¨è°ƒç”¨ä»·å€¼å› å­è®¡ç®—é€»è¾‘ï¼ˆä¸åˆ›å»ºå®Œæ•´ FactorCalculatorï¼‰
                    # EP Ratio = 1 / PE_TTM
                    pe_ttm = pd.to_numeric(factor_data['pe_ttm'], errors='coerce')
                    pe_ttm = pe_ttm.replace(0, np.nan).where(pe_ttm > 0, np.nan)
                    factor_data['ep_ratio'] = 1.0 / pe_ttm
                    factor_data['ep_ratio'] = factor_data['ep_ratio'].replace([np.inf, -np.inf], np.nan)
                    
                    # BP Ratio = 1 / PB
                    pb = pd.to_numeric(factor_data['pb'], errors='coerce')
                    pb = pb.replace(0, np.nan).where(pb > 0, np.nan)
                    factor_data['bp_ratio'] = 1.0 / pb
                    factor_data['bp_ratio'] = factor_data['bp_ratio'].replace([np.inf, -np.inf], np.nan)
                    
                    self.logger.debug(f"ä»·å€¼å› å­è®¡ç®—å®Œæˆ: EPæœ‰æ•ˆ={factor_data['ep_ratio'].notna().mean():.1%}, BPæœ‰æ•ˆ={factor_data['bp_ratio'].notna().mean():.1%}")
                else:
                    factor_data['ep_ratio'] = np.nan
                    factor_data['bp_ratio'] = np.nan
                    self.logger.warning("è´¢åŠ¡æ•°æ®ç¼ºå°‘ pe_ttm/pb åˆ—ï¼Œä»·å€¼å› å­å°†ä¸º NaN")
            except Exception as e:
                self.logger.warning(f"å¤åˆä»·å€¼å› å­è®¡ç®—å¤±è´¥: {e}")
                factor_data['ep_ratio'] = np.nan
                factor_data['bp_ratio'] = np.nan
            
            # 4.2 ä¼ ç»Ÿ EP_TTM
            if 'pe_ttm' in factor_data.columns:
                factor_data['ep_ttm'] = 1.0 / factor_data['pe_ttm'].replace(0, np.nan)
                factor_data['ep_ttm'] = factor_data['ep_ttm'].replace([np.inf, -np.inf], np.nan)
            else:
                factor_data['ep_ttm'] = np.nan
            
            # æ–°å¢ï¼šROC_20 åŠ¨é‡å› å­è®¡ç®—
            # ä½¿ç”¨ numba åŠ é€Ÿçš„ roc æ–¹æ³•ï¼ˆå¦‚æœ features æ¨¡å—æœ‰æä¾›ï¼Œå¦åˆ™ä½¿ç”¨ pandasï¼‰
            # è¿™é‡Œç®€å•ä½¿ç”¨ pandas å®ç°
            try:
                # å…¼å®¹æ—§é€»è¾‘ï¼šå¦‚æœä¹‹å‰è®¡ç®—è¿‡ï¼Œè¿™é‡Œä¸ä¼šæŠ¥é”™ä½†ä¹Ÿä¸ä¼šè¦†ç›–ï¼ˆé™¤éä½¿ç”¨ assignï¼‰
                # æ³¨æ„ï¼šcalculate_factors ä¸­çš„ factor_data æ˜¯åˆå¹¶äº† financial_data çš„å¤§è¡¨
                # åº”è¯¥æŒ‰ stock_code åˆ†ç»„è®¡ç®—
                factor_data['roc_20'] = factor_data.groupby('stock_code')['close'].transform(
                    lambda x: x.pct_change(20) * 100
                )
                self.logger.debug(f"æ‰‹åŠ¨è®¡ç®— roc_20 å®Œæˆ (calculate_factors)ï¼Œæœ‰æ•ˆç‡: {factor_data['roc_20'].notna().mean():.1%}")
            except Exception as e:
                self.logger.warning(f"æ‰‹åŠ¨è®¡ç®— roc_20 å¤±è´¥ (calculate_factors): {e}")
                factor_data['roc_20'] = np.nan

            # 5. è´¨é‡å› å­ç»„ï¼ˆROE ç›ˆåˆ©èƒ½åŠ›ï¼‰
            # 5.1 ROE å› å­ï¼ˆç›´æ¥ä½¿ç”¨ï¼Œè¶Šé«˜è¶Šå¥½ï¼‰
            if 'roe' in factor_data.columns:
                # ROE å·²ç»å­˜åœ¨ï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®
                factor_data['roe'] = pd.to_numeric(factor_data['roe'], errors='coerce')
                factor_data['roe_stability'] = factor_data['roe']
                self.logger.debug(f"ROE å› å­å°±ç»ªï¼Œæœ‰æ•ˆç‡: {factor_data['roe'].notna().mean():.1%}")
            else:
                factor_data['roe'] = np.nan
                factor_data['roe_stability'] = np.nan
                self.logger.warning("è´¢åŠ¡æ•°æ®ä¸­æœªæ‰¾åˆ° ROE åˆ—ï¼Œè´¨é‡å› å­å°†ä¸º NaN")
            
            # 6. ç‰¹è´¨æ³¢åŠ¨ç‡ IVOLï¼ˆé£é™©å› å­ï¼‰
            factor_data['ivol'] = factor_data.groupby('stock_code')['close'].transform(
                lambda x: x.pct_change().rolling(20).std() * np.sqrt(252)
            )
            # é‡å‘½åä¸ºä¸å›æµ‹ä¸€è‡´çš„åˆ—å
            factor_data['ivol_20'] = factor_data['ivol']
            
            # 7. Sharpe åŠ¨é‡å› å­ï¼ˆæ ¸å¿ƒåŠ¨é‡å› å­ï¼‰
            # sharpe_20 = 20æ—¥æ”¶ç›Š / 20æ—¥æ³¢åŠ¨ç‡
            def _calc_sharpe(close_series: pd.Series, period: int) -> pd.Series:
                """è®¡ç®— Sharpe é£æ ¼åŠ¨é‡å› å­"""
                returns = close_series.pct_change()
                mean_ret = returns.rolling(period, min_periods=max(5, period // 2)).mean()
                std_ret = returns.rolling(period, min_periods=max(5, period // 2)).std()
                # é¿å…é™¤é›¶
                sharpe = mean_ret / (std_ret + 1e-8)
                return sharpe
            
            factor_data['sharpe_20'] = factor_data.groupby('stock_code')['close'].transform(
                lambda x: _calc_sharpe(x, 20)
            )
            factor_data['sharpe_60'] = factor_data.groupby('stock_code')['close'].transform(
                lambda x: _calc_sharpe(x, 60)
            )
            self.logger.debug(f"Sharpe å› å­è®¡ç®—å®Œæˆ: sharpe_20 æœ‰æ•ˆç‡ {factor_data['sharpe_20'].notna().mean():.1%}, sharpe_60 æœ‰æ•ˆç‡ {factor_data['sharpe_60'].notna().mean():.1%}")
            
            # ==================== Z-Score æ ‡å‡†åŒ– ====================
            date_col = 'date' if 'date' in factor_data.columns else 'trade_date'
            
            # å¯¹æ‰€æœ‰è®¡ç®—çš„å› å­è¿›è¡Œ Z-Score æ ‡å‡†åŒ–
            factor_cols_to_normalize = [
                'rsi_20', 'roc_20', 'small_cap', 'turnover_5d', 
                'ep_ttm', 'ep_ratio', 'bp_ratio',          # ä»·å€¼å› å­
                'roe_stability', 'roe',                    # è´¨é‡å› å­
                'ivol_20', 'sharpe_20', 'sharpe_60'        # åŠ¨é‡/é£é™©å› å­
            ]
            # åªæ ‡å‡†åŒ–å­˜åœ¨ä¸”æœ‰æ•ˆçš„å› å­åˆ—
            valid_factor_cols = [
                col for col in factor_cols_to_normalize 
                if col in factor_data.columns and factor_data[col].notna().any()
            ]
            
            self.logger.info(f"å‡†å¤‡æ ‡å‡†åŒ–çš„å› å­åˆ—: {valid_factor_cols}")
            if 'roc_20' not in valid_factor_cols:
                self.logger.warning(f"roc_20 ä¸åœ¨æ ‡å‡†åŒ–åˆ—è¡¨ä¸­! Columns: {factor_data.columns.tolist()}")
                if 'roc_20' in factor_data.columns:
                    self.logger.warning(f"roc_20 æ•°æ®æ¦‚è§ˆ: {factor_data['roc_20'].describe()}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è¡Œä¸šå­—æ®µï¼Œå†³å®šæ˜¯å¦è¿›è¡Œè¡Œä¸šä¸­æ€§åŒ–
            has_industry = 'sw_industry_l1' in factor_data.columns and factor_data['sw_industry_l1'].notna().any()
            
            factor_data = z_score_normalize(
                factor_data,
                factor_cols=valid_factor_cols,
                date_col=date_col,
                industry_col='sw_industry_l1' if has_industry else None,
                industry_neutral=has_industry
            )
            
            if has_industry:
                self.logger.info(f"å·²æ ‡å‡†åŒ–å› å­ï¼ˆè¡Œä¸šä¸­æ€§åŒ–ï¼‰: {valid_factor_cols}")
            else:
                self.logger.info(f"å·²æ ‡å‡†åŒ–å› å­ï¼ˆå¸‚åœºä¸­æ€§åŒ–ï¼‰: {valid_factor_cols}")
            
            # ==================== å› å­åˆ«åæ˜ å°„ ====================
            # å°†æ ‡å‡†åŒ–åçš„å› å­æ˜ å°„åˆ°ç­–ç•¥é…ç½®ä½¿ç”¨çš„åˆ—å
            # æ”¯æŒå¤šç§ç­–ç•¥é…ç½®ï¼šä¸­è¯1000åŠ¨é‡ç­–ç•¥ã€HS300ä»·å€¼ç­–ç•¥ç­‰
            factor_alias_mapping = {
                # åŠ¨é‡å› å­åˆ«å
                'sharpe_20_zscore': 'sharpe_20_zscore',
                'sharpe_60_zscore': 'sharpe_60_zscore',
                'momentum_zscore': 'roc_20_zscore',  # é»˜è®¤åŠ¨é‡å› å­
                # è´¨é‡å› å­åˆ«å
                'ivol_zscore': 'ivol_20_zscore',  # ä½æ³¢åŠ¨è´¨é‡å› å­
                'quality_zscore': 'roe_stability_zscore',  # é»˜è®¤è´¨é‡å› å­
                'roe_zscore': 'roe_zscore',  # ROE è´¨é‡å› å­ï¼ˆHS300ä»·å€¼ç­–ç•¥ï¼‰
                'turnover_5d_zscore': 'turnover_5d_zscore',
                # ä»·å€¼å› å­åˆ«å
                'value_zscore': 'ep_ttm_zscore',  # å•ä¸€ä»·å€¼å› å­
                'ep_zscore': 'ep_ratio_zscore',  # EP ä»·å€¼å› å­
                'bp_zscore': 'bp_ratio_zscore',  # BP ä»·å€¼å› å­
                # å°å¸‚å€¼å› å­åˆ«å
                'size_zscore': 'small_cap_zscore',
            }
            
            # è®¡ç®—å¤åˆä»·å€¼å› å­ï¼ˆEP + BP çš„åŠ æƒå¹³å‡ï¼‰
            ep_col = 'ep_ratio_zscore' if 'ep_ratio_zscore' in factor_data.columns else None
            bp_col = 'bp_ratio_zscore' if 'bp_ratio_zscore' in factor_data.columns else None
            
            if ep_col and bp_col:
                ep_valid = factor_data[ep_col].notna() & (factor_data[ep_col] != 0)
                bp_valid = factor_data[bp_col].notna() & (factor_data[bp_col] != 0)
                
                if ep_valid.any() and bp_valid.any():
                    factor_data['value_composite_zscore'] = (
                        0.5 * factor_data[ep_col].fillna(0) + 
                        0.5 * factor_data[bp_col].fillna(0)
                    )
                    self.logger.debug("å¤åˆä»·å€¼å› å­ value_composite_zscore è®¡ç®—å®Œæˆ")
                elif ep_valid.any():
                    factor_data['value_composite_zscore'] = factor_data[ep_col].fillna(0)
                    self.logger.debug("å¤åˆä»·å€¼å› å­ä½¿ç”¨ EP å•å› å­")
                elif bp_valid.any():
                    factor_data['value_composite_zscore'] = factor_data[bp_col].fillna(0)
                    self.logger.debug("å¤åˆä»·å€¼å› å­ä½¿ç”¨ BP å•å› å­")
                else:
                    factor_data['value_composite_zscore'] = 0.0
                    self.logger.warning("æ— æ³•è®¡ç®—å¤åˆä»·å€¼å› å­ï¼ˆEP/BP æ•°æ®å‡æ— æ•ˆï¼‰")
            else:
                factor_data['value_composite_zscore'] = 0.0
                self.logger.warning("ç¼ºå°‘ ep_ratio_zscore/bp_ratio_zscoreï¼Œå¤åˆä»·å€¼å› å­ä¸º 0")
            
            # ==================== è®¡ç®— Alpha å› å­ï¼ˆé‡ä»·é…åˆï¼‰====================
            # ç‰›å¸‚è¿›æ”»å‹ç­–ç•¥æ ¸å¿ƒå› å­
            alpha_enabled = False
            try:
                # Alpha_001: (Close - VWAP) / VWAPï¼Œæ­£å€¼è¡¨ç¤ºæ”¶ç›˜ä»·é«˜äºå‡ä»·
                if 'amount' in factor_data.columns and 'volume' in factor_data.columns:
                    vwap = factor_data['amount'] / factor_data['volume'].replace(0, np.nan)
                    factor_data['alpha_001'] = (factor_data['close'] - vwap) / vwap.replace(0, np.nan)
                    factor_data['alpha_001'] = factor_data['alpha_001'].replace([np.inf, -np.inf], np.nan)
                    
                    # å¯¹ Alpha_001 è¿›è¡Œ Z-Score æ ‡å‡†åŒ–ï¼ˆæ¨ªæˆªé¢ï¼‰
                    if 'date' in factor_data.columns:
                        factor_data['alpha_001_zscore'] = factor_data.groupby('date')['alpha_001'].transform(
                            lambda x: (x - x.mean()) / (x.std() + 1e-8)
                        ).fillna(0)
                    else:
                        factor_data['alpha_001_zscore'] = (
                            (factor_data['alpha_001'] - factor_data['alpha_001'].mean()) / 
                            (factor_data['alpha_001'].std() + 1e-8)
                        ).fillna(0)
                    
                    alpha_enabled = True
                    self.logger.info("Alpha_001 å› å­ï¼ˆé‡ä»·é…åˆï¼‰è®¡ç®—å®Œæˆ")
                else:
                    factor_data['alpha_001_zscore'] = 0.0
                    self.logger.warning("ç¼ºå°‘ amount/volume åˆ—ï¼ŒAlpha_001 å› å­è®¾ä¸º 0")
            except Exception as e:
                factor_data['alpha_001_zscore'] = 0.0
                self.logger.warning(f"Alpha_001 å› å­è®¡ç®—å¤±è´¥: {e}")
            
            # ==================== è®¡ç®—å¤åˆåŠ¨é‡å› å­ momentum_composite_zscore ====================
            # ç‰›å¸‚è¿›æ”»å‹é…æ–¹: 40% ROC (æ¶¨å¹…) + 30% Sharpe (ç¨³å¥) + 30% Alpha001 (é‡ä»·é…åˆ)
            roc_col = 'roc_20_zscore' if 'roc_20_zscore' in factor_data.columns else None
            sharpe_col = 'sharpe_20_zscore' if 'sharpe_20_zscore' in factor_data.columns else None
            alpha_col = 'alpha_001_zscore' if alpha_enabled else None
            
            if roc_col and sharpe_col and alpha_col:
                # å®Œæ•´é…æ–¹: 40% ROC + 30% Sharpe + 30% Alpha001
                factor_data['momentum_composite_zscore'] = (
                    0.4 * factor_data[roc_col].fillna(0) +
                    0.3 * factor_data[sharpe_col].fillna(0) +
                    0.3 * factor_data[alpha_col].fillna(0)
                )
                self.logger.info("ğŸš€ å¤åˆåŠ¨é‡å› å­è®¡ç®—å®Œæˆ: 40% ROC + 30% Sharpe + 30% Alpha001")
            elif roc_col and sharpe_col:
                # å¤‡é€‰é…æ–¹: 60% ROC + 40% Sharpe
                factor_data['momentum_composite_zscore'] = (
                    0.6 * factor_data[roc_col].fillna(0) +
                    0.4 * factor_data[sharpe_col].fillna(0)
                )
                self.logger.info("å¤åˆåŠ¨é‡å› å­è®¡ç®—å®Œæˆ: 60% ROC + 40% Sharpeï¼ˆæ—  Alphaï¼‰")
            elif roc_col:
                factor_data['momentum_composite_zscore'] = factor_data[roc_col].fillna(0)
                self.logger.warning("å¤åˆåŠ¨é‡å› å­ä½¿ç”¨ ROC å•å› å­")
            else:
                factor_data['momentum_composite_zscore'] = 0.0
                self.logger.warning("æ— æ³•è®¡ç®—å¤åˆåŠ¨é‡å› å­ï¼ˆç¼ºå°‘å¿…è¦å› å­ï¼‰")
            
            for alias, source in factor_alias_mapping.items():
                if source in factor_data.columns and alias not in factor_data.columns:
                    factor_data[alias] = factor_data[source]
                    self.logger.debug(f"åˆ›å»ºå› å­åˆ«å: {alias} <- {source}")
            
            self.logger.info(f"å› å­åˆ«åæ˜ å°„å®Œæˆï¼Œå¯ç”¨å› å­åˆ—: {[c for c in factor_data.columns if c.endswith('_zscore')]}")
            
            self.factor_data = factor_data
            
            # ä¿å­˜å› å­æ•°æ®
            factor_path = DATA_PROCESSED_PATH / f"factors_{self.today.strftime('%Y%m%d')}.parquet"
            self.factor_data.to_parquet(factor_path)
            
            self.logger.info(f"å› å­è®¡ç®—å®Œæˆï¼Œå…± {len(self.factor_data)} æ¡è®°å½•")
            return True
            
        except Exception as e:
            self.logger.error(f"è®¡ç®—å› å­å¤±è´¥: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return False
    
    @staticmethod
    def _calculate_rsi(series: pd.Series, period: int = 20) -> pd.Series:
        """è®¡ç®— RSI æŒ‡æ ‡"""
        delta = series.diff()
        gain = delta.where(delta > 0, 0.0)
        loss = (-delta).where(delta < 0, 0.0)
        
        avg_gain = gain.ewm(alpha=1.0/period, min_periods=period, adjust=False).mean()
        avg_loss = loss.ewm(alpha=1.0/period, min_periods=period, adjust=False).mean()
        
        rs = avg_gain / avg_loss.replace(0, np.nan)
        rsi = 100.0 - (100.0 / (1.0 + rs))
        
        return rsi
    
    def is_rebalance_day(self, date: Optional[pd.Timestamp] = None) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦ä¸ºè°ƒä»“æ—¥ï¼ˆæœˆæœ«æœ€åä¸€ä¸ªäº¤æ˜“æ—¥ï¼‰
        
        Parameters
        ----------
        date : Optional[pd.Timestamp]
            æ£€æŸ¥æ—¥æœŸï¼Œé»˜è®¤ä¸ºä»Šæ—¥
        
        Returns
        -------
        bool
            æ˜¯å¦ä¸ºè°ƒä»“æ—¥
        """
        if date is None:
            date = self.today
        
        # è·å–æœ¬æœˆæ‰€æœ‰äº¤æ˜“æ—¥
        if self.ohlcv_data is not None:
            # ä¼˜å…ˆä½¿ç”¨ DatetimeIndexï¼Œå…¶æ¬¡ä½¿ç”¨ date/trade_date åˆ—
            if isinstance(self.ohlcv_data.index, pd.DatetimeIndex):
                trading_dates = self.ohlcv_data.index.unique()
            elif 'date' in self.ohlcv_data.columns:
                trading_dates = pd.to_datetime(self.ohlcv_data['date'].unique())
            elif 'trade_date' in self.ohlcv_data.columns:
                trading_dates = pd.to_datetime(self.ohlcv_data['trade_date'].unique())
            else:
                self.logger.warning("ohlcv_data ä¸­æœªæ‰¾åˆ°æ—¥æœŸåˆ—æˆ– DatetimeIndexï¼Œä½¿ç”¨ç®€åŒ–åˆ¤æ–­")
                trading_dates = None
            
            # ç­›é€‰æœ¬æœˆäº¤æ˜“æ—¥
            if trading_dates is not None:
                month_dates = trading_dates[
                    (trading_dates.year == date.year) & 
                    (trading_dates.month == date.month)
                ]
                
                if len(month_dates) > 0:
                    last_trading_day = month_dates.max()
                    is_last_day = date >= last_trading_day
                    self.logger.info(
                        f"æœ¬æœˆæœ€åäº¤æ˜“æ—¥: {last_trading_day.strftime('%Y-%m-%d')}, "
                        f"ä»Šæ—¥: {date.strftime('%Y-%m-%d')}, æ˜¯å¦è°ƒä»“æ—¥: {is_last_day}"
                    )
                    return is_last_day
        
        # ç®€åŒ–åˆ¤æ–­ï¼šæœˆæœ«æœ€å3å¤©è§†ä¸ºè°ƒä»“æ—¥
        next_month = (date.replace(day=28) + timedelta(days=4)).replace(day=1)
        days_to_month_end = (next_month - date).days
        
        is_month_end = days_to_month_end <= 3
        self.logger.info(f"è·æœˆæœ« {days_to_month_end} å¤©ï¼Œæ˜¯å¦è°ƒä»“æ—¥: {is_month_end}")
        
        return is_month_end
    
    def generate_target_positions(self) -> bool:
        """
        ç”Ÿæˆç›®æ ‡æŒä»“ï¼ˆå®ç›˜å®‰å…¨ç‰ˆï¼‰
        
        åŒ…å«ä»¥ä¸‹å®‰å…¨æœºåˆ¶ï¼š
        1. å¤§ç›˜é£æ§ï¼šå½“å¤§ç›˜è·Œç ´MA{n}ä¸”è·Œå¹…è¶…é˜ˆå€¼æ—¶ï¼Œå¼ºåˆ¶ç©ºä»“
        2. æ•°æ®éªŒè¯ï¼šç¡®ä¿æ‰€é€‰è‚¡ç¥¨éƒ½æœ‰æœ‰æ•ˆçš„è´¢åŠ¡æ•°æ®
        3. ç»“æœæ ¡éªŒï¼šä¿å­˜çš„ JSON æ–‡ä»¶æ˜ç¡®æ ‡è®°é£æ§çŠ¶æ€
        
        Returns
        -------
        bool
            ç”Ÿæˆæ˜¯å¦æˆåŠŸ
        """
        self.logger.info("å¼€å§‹ç”Ÿæˆç›®æ ‡æŒä»“ï¼ˆå®ç›˜å®‰å…¨æ¨¡å¼ï¼‰...")
        
        try:
            # === å¤§ç›˜é£æ§æ£€æŸ¥ ===
            if self.is_market_risk_triggered():
                self.logger.warning("ğŸš¨ å¤§ç›˜é£æ§è§¦å‘ï¼Œç³»ç»Ÿå¼ºåˆ¶ç©ºä»“ï¼")
                self.target_positions = {}
                
                # è¯»å–é£æ§é…ç½®ç”¨äºè®°å½•
                risk_config = self.config.get("risk", {})
                market_risk_config = risk_config.get("market_risk", {})
                ma_period = market_risk_config.get("ma_period", 60)
                drop_threshold = market_risk_config.get("drop_threshold", 0.05)
                
                # ä¿å­˜ç©ºä»“çŠ¶æ€
                portfolio_config = self.config.get("portfolio", {})
                total_capital = portfolio_config.get("total_capital", 1000000)
                
                positions_path = DATA_PROCESSED_PATH / f"target_positions_{self.today.strftime('%Y%m%d')}.json"
                
                # æ„å»ºç©ºä»“ JSONï¼ˆå®ç›˜ä¿æŠ¤ï¼šç¡®ä¿ positions ä¸ºç©ºå­—å…¸ï¼‰
                empty_position_data = {
                    'date': self.today.strftime('%Y-%m-%d'),
                    'positions': {},  # å…³é”®ï¼šç¡®ä¿ä¸ºç©ºå­—å…¸
                    'weights': {},    # å…³é”®ï¼šç¡®ä¿ä¸ºç©ºå­—å…¸
                    'total_capital': total_capital,
                    'market_risk_triggered': True,  # å…³é”®ï¼šæ ‡è®°é£æ§è§¦å‘
                    'reason': f'å¤§ç›˜è·Œç ´MA{ma_period}æˆ–è·Œå¹…è¶…{drop_threshold*100:.0f}%ï¼Œè§¦å‘é£æ§',
                    'risk_params': {
                        'ma_period': ma_period,
                        'drop_threshold': drop_threshold,
                    },
                    'action': 'CLEAR_ALL_POSITIONS',  # æ˜ç¡®æŒ‡ä»¤
                    'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                }
                
                with open(positions_path, 'w', encoding='utf-8') as f:
                    json.dump(empty_position_data, f, ensure_ascii=False, indent=2)
                
                self.logger.info(
                    f"âœ… å·²ä¿å­˜ç©ºä»“ç›®æ ‡æŒä»“ï¼ˆé£æ§è§¦å‘ï¼‰\n"
                    f"   æ–‡ä»¶: {positions_path}\n"
                    f"   positions: {{}}\n"
                    f"   market_risk_triggered: True"
                )
                return True
            # =====================
            
            if self.factor_data is None:
                self.logger.warning("å› å­æ•°æ®ä¸ºç©ºï¼Œæ— æ³•ç”ŸæˆæŒä»“")
                return False
            
            # è·å–æœ€æ–°æ—¥æœŸçš„æ•°æ®
            date_col = 'date' if 'date' in self.factor_data.columns else 'trade_date'
            latest_date = pd.to_datetime(self.factor_data[date_col]).max()
            
            latest_data = self.factor_data[
                pd.to_datetime(self.factor_data[date_col]) == latest_date
            ].copy()
            
            self.logger.info(f"æœ€æ–°æ•°æ®æ—¥æœŸ: {latest_date.strftime('%Y-%m-%d')}, è‚¡ç¥¨æ•°: {len(latest_data)}")
            
            # è¿‡æ»¤è‚¡ç¥¨
            filtered_data = self.strategy.filter_stocks(latest_data, latest_date)
            
            if filtered_data.empty:
                self.logger.warning("è¿‡æ»¤åæ— å¯é€‰è‚¡ç¥¨")
                return False
            
            # é€‰å– Top N è‚¡ç¥¨
            selected_stocks = self.strategy.select_top_stocks(filtered_data)
            
            # ========== å®ç›˜å®‰å…¨ï¼šéªŒè¯æ‰€é€‰è‚¡ç¥¨æ•°æ®æœ‰æ•ˆæ€§ ==========
            excluded_stocks = getattr(self, '_excluded_stocks', set())
            invalid_selected = [s for s in selected_stocks if s in excluded_stocks]
            
            if invalid_selected:
                self.logger.error(
                    f"ğŸš¨ å®‰å…¨è­¦å‘Š: é€‰ä¸­çš„è‚¡ç¥¨ä¸­åŒ…å«æ— æ•ˆæ•°æ®è‚¡ç¥¨: {invalid_selected}\n"
                    f"   è¿™äº›è‚¡ç¥¨å°†è¢«ç§»é™¤ã€‚"
                )
                selected_stocks = [s for s in selected_stocks if s not in excluded_stocks]
            
            if not selected_stocks:
                self.logger.error("è¿‡æ»¤æ— æ•ˆæ•°æ®åæ— å¯é€‰è‚¡ç¥¨ï¼Œå–æ¶ˆæœ¬æ¬¡è°ƒä»“")
                return False
            
            self.logger.info(f"é€‰ä¸­ {len(selected_stocks)} åªè‚¡ç¥¨: {selected_stocks[:5]}...")
            
            # è®¡ç®—ç»¼åˆå¾—åˆ†ç”¨äºå±•ç¤º
            filtered_data['total_score'] = self.strategy.calculate_total_score(filtered_data)
            
            # ä¼˜åŒ–æƒé‡
            portfolio_config = self.config.get("portfolio", {})
            total_capital = portfolio_config.get("total_capital", 1000000)
            max_weight = portfolio_config.get("max_weight", 0.05)
            objective = portfolio_config.get("optimization_objective", "max_sharpe")
            
            # å‡†å¤‡ä»·æ ¼æ•°æ®ç”¨äºä¼˜åŒ–
            if self.ohlcv_data is not None:
                price_pivot = self.ohlcv_data.pivot_table(
                    index='date' if 'date' in self.ohlcv_data.columns else 'trade_date',
                    columns='stock_code',
                    values='close'
                )
                
                # ä¼˜åŒ–æƒé‡
                weights = self.strategy.optimize_weights(
                    price_pivot,
                    selected_stocks,
                    objective=objective,
                    max_weight=max_weight
                )
            else:
                # æ— ä»·æ ¼æ•°æ®æ—¶ä½¿ç”¨ç­‰æƒé‡
                weights = {stock: 1.0 / len(selected_stocks) for stock in selected_stocks}
            
            # è®¡ç®—ç›®æ ‡æŒä»“ï¼ˆé‡‘é¢ï¼‰
            self.target_positions = {
                stock: weight * total_capital
                for stock, weight in weights.items()
                if weight > 0.0001
            }
            
            self.logger.info(f"ç›®æ ‡æŒä»“ç”Ÿæˆå®Œæˆï¼Œå…± {len(self.target_positions)} åªè‚¡ç¥¨")
            
            # ä¿å­˜ç›®æ ‡æŒä»“
            positions_path = DATA_PROCESSED_PATH / f"target_positions_{self.today.strftime('%Y%m%d')}.json"
            with open(positions_path, 'w', encoding='utf-8') as f:
                json.dump({
                    'date': self.today.strftime('%Y-%m-%d'),
                    'positions': self.target_positions,
                    'weights': weights,
                    'total_capital': total_capital,
                    'market_risk_triggered': False,
                }, f, ensure_ascii=False, indent=2)
            
            return True
        
        except LLMCircuitBreakerError as e:
            # ===== LLM ç†”æ–­å™¨è§¦å‘: é£æ§åœæ­¢äº¤æ˜“ =====
            self.logger.critical(
                f"â›” LLM Circuit Breaker Triggered! Risk control failed. "
                f"HALTING ALL TRADING SIGNALS."
            )
            self.logger.critical(f"Error details: {e}")
            
            # ä¿å­˜é£æ§åœæ­¢çŠ¶æ€æ–‡ä»¶
            self.target_positions = {}
            
            portfolio_config = self.config.get("portfolio", {})
            total_capital = portfolio_config.get("total_capital", 1000000)
            
            positions_path = DATA_PROCESSED_PATH / f"target_positions_{self.today.strftime('%Y%m%d')}.json"
            
            # æ„å»ºé£æ§åœæ­¢ JSONï¼ˆæ˜ç¡®æ ‡è®° LLM ç†”æ–­çŠ¶æ€ï¼‰
            halt_position_data = {
                'date': self.today.strftime('%Y-%m-%d'),
                'positions': {},  # å…³é”®ï¼šç¡®ä¿ä¸ºç©ºå­—å…¸ï¼Œä¸äº§ç”Ÿä»»ä½•ä¹°å…¥ä¿¡å·
                'weights': {},    # å…³é”®ï¼šç¡®ä¿ä¸ºç©ºå­—å…¸
                'total_capital': total_capital,
                'market_risk_triggered': False,
                'llm_circuit_breaker_triggered': True,  # å…³é”®ï¼šæ ‡è®° LLM ç†”æ–­è§¦å‘
                'reason': f'LLM Circuit Breaker Triggered: {str(e)[:200]}',
                'action': 'HALT_ALL_TRADING',  # æ˜ç¡®æŒ‡ä»¤ï¼šåœæ­¢æ‰€æœ‰äº¤æ˜“
                'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            }
            
            with open(positions_path, 'w', encoding='utf-8') as f:
                json.dump(halt_position_data, f, ensure_ascii=False, indent=2)
            
            self.logger.critical(
                f"âœ… å·²ä¿å­˜é£æ§åœæ­¢çŠ¶æ€æ–‡ä»¶\n"
                f"   æ–‡ä»¶: {positions_path}\n"
                f"   positions: {{}}\n"
                f"   llm_circuit_breaker_triggered: True\n"
                f"   action: HALT_ALL_TRADING"
            )
            
            # è¿”å› False è¡¨ç¤ºç”Ÿæˆå¤±è´¥ï¼Œè°ƒç”¨æ–¹åº”åœæ­¢åç»­æµç¨‹
            return False
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆç›®æ ‡æŒä»“å¤±è´¥: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return False
    
    def calculate_trade_orders(self) -> Tuple[Dict[str, float], Dict[str, float]]:
        """
        è®¡ç®—äº¤æ˜“è®¢å•
        
        Returns
        -------
        Tuple[Dict[str, float], Dict[str, float]]
            (ä¹°å…¥è®¢å•, å–å‡ºè®¢å•)ï¼Œé”®ä¸ºè‚¡ç¥¨ä»£ç ï¼Œå€¼ä¸ºé‡‘é¢
        """
        buy_orders: Dict[str, float] = {}
        sell_orders: Dict[str, float] = {}
        
        # å½“å‰æŒä»“è‚¡ç¥¨
        current_stocks = set(self.current_positions.keys())
        # ç›®æ ‡æŒä»“è‚¡ç¥¨
        target_stocks = set(self.target_positions.keys())
        
        # éœ€è¦å–å‡ºçš„è‚¡ç¥¨
        stocks_to_sell = current_stocks - target_stocks
        for stock in stocks_to_sell:
            sell_orders[stock] = self.current_positions[stock]
        
        # éœ€è¦ä¹°å…¥çš„è‚¡ç¥¨
        stocks_to_buy = target_stocks - current_stocks
        for stock in stocks_to_buy:
            buy_orders[stock] = self.target_positions[stock]
        
        # éœ€è¦è°ƒæ•´çš„è‚¡ç¥¨
        stocks_to_adjust = current_stocks & target_stocks
        for stock in stocks_to_adjust:
            current = self.current_positions[stock]
            target = self.target_positions[stock]
            diff = target - current
            
            if diff > 100:  # ä¹°å…¥é˜ˆå€¼
                buy_orders[stock] = diff
            elif diff < -100:  # å–å‡ºé˜ˆå€¼
                sell_orders[stock] = -diff
        
        return buy_orders, sell_orders
    
    def generate_report(
        self,
        buy_orders: Dict[str, float],
        sell_orders: Dict[str, float],
        format: str = "markdown"
    ) -> str:
        """
        ç”Ÿæˆäº¤æ˜“æŠ¥å‘Š
        
        Parameters
        ----------
        buy_orders : Dict[str, float]
            ä¹°å…¥è®¢å•
        sell_orders : Dict[str, float]
            å–å‡ºè®¢å•
        format : str
            æŠ¥å‘Šæ ¼å¼ï¼Œ'markdown' æˆ– 'html'
        
        Returns
        -------
        str
            æŠ¥å‘Šå†…å®¹
        """
        report_date = self.today.strftime('%Y-%m-%d')
        
        if format == "markdown":
            return self._generate_markdown_report(buy_orders, sell_orders, report_date)
        elif format == "html":
            return self._generate_html_report(buy_orders, sell_orders, report_date)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æŠ¥å‘Šæ ¼å¼: {format}")
    
    def _get_latest_prices(self) -> Dict[str, float]:
        """è·å–æ‰€æœ‰è‚¡ç¥¨çš„æœ€æ–°æ”¶ç›˜ä»·"""
        if self.ohlcv_data is None or self.ohlcv_data.empty:
            self.logger.warning("ohlcv_data ä¸ºç©ºï¼Œæ— æ³•è·å–æœ€æ–°ä»·æ ¼")
            return {}
            
        try:
            # ç¡®å®šæ—¥æœŸåˆ—
            date_col = next((col for col in ['date', 'trade_date', 'timestamp'] if col in self.ohlcv_data.columns), None)
            
            # ç¡®å®šè‚¡ç¥¨ä»£ç åˆ—
            stock_col = next((col for col in ['stock_code', 'symbol', 'code', 'ts_code'] if col in self.ohlcv_data.columns), None)
            
            # ç¡®å®šæ”¶ç›˜ä»·åˆ—
            price_col = next((col for col in ['close', 'close_price'] if col in self.ohlcv_data.columns), None)
            
            if not date_col or not price_col:
                self.logger.warning(f"ç¼ºå°‘å¿…è¦åˆ—: date_col={date_col}, price_col={price_col}")
                return {}

            df = self.ohlcv_data.copy()
            
            # å¦‚æœæ²¡æœ‰è‚¡ç¥¨ä»£ç åˆ—ï¼Œå°è¯•ä»ç´¢å¼•è·å–
            if not stock_col:
                if isinstance(df.index, pd.MultiIndex):
                    # å‡è®¾ MultiIndex æ˜¯ (date, stock_code) æˆ– (stock_code, date)
                    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œæš‚ä¸æ”¯æŒ MultiIndex è‡ªåŠ¨æ¨æ–­ï¼Œå»ºè®® Reset Index
                    df = df.reset_index()
                    stock_col = next((col for col in ['stock_code', 'symbol', 'code', 'ts_code'] if col in df.columns), None)
            
            if not stock_col:
                self.logger.warning("æ— æ³•æ‰¾åˆ°è‚¡ç¥¨ä»£ç åˆ—")
                return {}
                
            # è·å–æ¯ä¸ªè‚¡ç¥¨çš„æœ€åä¸€æ¡è®°å½•
            # å…ˆæŒ‰æ—¥æœŸæ’åº
            df_sorted = df.sort_values(by=date_col)
            latest_prices = df_sorted.groupby(stock_col)[price_col].last().to_dict()
            
            self.logger.info(f"å·²è·å– {len(latest_prices)} åªè‚¡ç¥¨çš„æœ€æ–°ä»·æ ¼")
            return latest_prices
        except Exception as e:
            self.logger.warning(f"è·å–æœ€æ–°ä»·æ ¼æ˜ å°„å¤±è´¥: {e}")
            return {}

    def _generate_markdown_report(
        self,
        buy_orders: Dict[str, float],
        sell_orders: Dict[str, float],
        report_date: str
    ) -> str:
        """ç”Ÿæˆ Markdown æ ¼å¼æŠ¥å‘Š"""
        latest_prices = self._get_latest_prices()

        lines = [
            f"# æ¯æ—¥è°ƒä»“æŠ¥å‘Š",
            f"",
            f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"",
            f"**æŠ¥å‘Šæ—¥æœŸ**: {report_date}",
            f"",
            f"---",
            f"",
        ]
        
        # ç­–ç•¥ä¿¡æ¯
        lines.extend([
            f"## ç­–ç•¥ä¿¡æ¯",
            f"",
            f"| å‚æ•° | å€¼ |",
            f"|------|-----|",
            f"| ç­–ç•¥åç§° | {self.strategy.name} |",
            f"| ä»·å€¼å› å­æƒé‡ | {self.strategy.value_weight:.0%} |",
            f"| è´¨é‡å› å­æƒé‡ | {self.strategy.quality_weight:.0%} |",
            f"| åŠ¨é‡å› å­æƒé‡ | {self.strategy.momentum_weight:.0%} |",
            f"| é€‰è‚¡æ•°é‡ | {self.strategy.top_n} |",
            f"",
        ])
        
        # æŒä»“æ±‡æ€»
        portfolio_config = self.config.get("portfolio", {})
        total_capital = portfolio_config.get("total_capital", 1000000)
        
        lines.extend([
            f"## æŒä»“æ±‡æ€»",
            f"",
            f"| æŒ‡æ ‡ | æ•°å€¼ |",
            f"|------|------|",
            f"| æ€»èµ„é‡‘ | Â¥{total_capital:,.0f} |",
            f"| ç›®æ ‡æŒä»“æ•° | {len(self.target_positions)} |",
            f"| ä¹°å…¥è‚¡ç¥¨æ•° | {len(buy_orders)} |",
            f"| å–å‡ºè‚¡ç¥¨æ•° | {len(sell_orders)} |",
            f"",
        ])
        
        # ä¹°å…¥æ¸…å•
        lines.extend([
            f"## ğŸ“ˆ æ˜æ—¥éœ€ä¹°å…¥",
            f"",
        ])
        
        if buy_orders:
            lines.extend([
                f"| è‚¡ç¥¨ä»£ç  | ä¹°å…¥é‡‘é¢ |",
                f"|----------|----------|",
            ])
            
            for stock, amount in sorted(buy_orders.items(), key=lambda x: -x[1]):
                lines.append(f"| {stock} | Â¥{amount:,.0f} |")
            
            lines.append(f"")
            lines.append(f"**ä¹°å…¥æ€»é‡‘é¢**: Â¥{sum(buy_orders.values()):,.0f}")
        else:
            lines.append(f"*æ— éœ€ä¹°å…¥*")
        
        lines.append(f"")
        
        # å–å‡ºæ¸…å•
        lines.extend([
            f"## ğŸ“‰ æ˜æ—¥éœ€å–å‡º",
            f"",
        ])
        
        if sell_orders:
            lines.extend([
                f"| è‚¡ç¥¨ä»£ç  | å–å‡ºé‡‘é¢ |",
                f"|----------|----------|",
            ])
            
            for stock, amount in sorted(sell_orders.items(), key=lambda x: -x[1]):
                lines.append(f"| {stock} | Â¥{amount:,.0f} |")
            
            lines.append(f"")
            lines.append(f"**å–å‡ºæ€»é‡‘é¢**: Â¥{sum(sell_orders.values()):,.0f}")
        else:
            lines.append(f"*æ— éœ€å–å‡º*")
        
        lines.append(f"")
        
        # ç›®æ ‡æŒä»“æ˜ç»†
        lines.extend([
            f"## ç›®æ ‡æŒä»“æ˜ç»†",
            f"",
            f"| è‚¡ç¥¨ä»£ç  | ç›®æ ‡é‡‘é¢ | æƒé‡ |",
            f"|----------|----------|------|",
        ])
        
        total_target = sum(self.target_positions.values()) if self.target_positions else 1
        for stock, amount in sorted(self.target_positions.items(), key=lambda x: -x[1]):
            weight = amount / total_target
            lines.append(f"| {stock} | Â¥{amount:,.0f} | {weight:.2%} |")
        
        lines.extend([
            f"",
            f"---",
            f"",
            f"*æœ¬æŠ¥å‘Šç”± Aè‚¡é‡åŒ–äº¤æ˜“ç³»ç»Ÿ è‡ªåŠ¨ç”Ÿæˆ*",
        ])
        
        return "\n".join(lines)
    
    def _generate_html_report(
        self,
        buy_orders: Dict[str, float],
        sell_orders: Dict[str, float],
        report_date: str
    ) -> str:
        """ç”Ÿæˆ HTML æ ¼å¼æŠ¥å‘Š"""
        latest_prices = self._get_latest_prices()
        portfolio_config = self.config.get("portfolio", {})
        total_capital = portfolio_config.get("total_capital", 1000000)
        
        # ä¹°å…¥è¡¨æ ¼è¡Œ
        buy_rows = ""
        for stock, amount in sorted(buy_orders.items(), key=lambda x: -x[1]):
            buy_rows += f"""
                <tr>
                    <td>{stock}</td>
                    <td>Â¥{amount:,.0f}</td>
                </tr>
            """
        
        # å–å‡ºè¡¨æ ¼è¡Œ
        sell_rows = ""
        for stock, amount in sorted(sell_orders.items(), key=lambda x: -x[1]):
            sell_rows += f"""
                <tr>
                    <td>{stock}</td>
                    <td>Â¥{amount:,.0f}</td>
                </tr>
            """
        
        # æŒä»“è¡¨æ ¼è¡Œ
        position_rows = ""
        total_target = sum(self.target_positions.values()) if self.target_positions else 1
        for stock, amount in sorted(self.target_positions.items(), key=lambda x: -x[1]):
            weight = amount / total_target
            position_rows += f"""
                <tr>
                    <td>{stock}</td>
                    <td>Â¥{amount:,.0f}</td>
                    <td>{weight:.2%}</td>
                </tr>
            """
        
        html = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>æ¯æ—¥è°ƒä»“æŠ¥å‘Š - {report_date}</title>
    <style>
        * {{
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            color: #eee;
            min-height: 100vh;
            padding: 2rem;
        }}
        .container {{
            max-width: 1000px;
            margin: 0 auto;
        }}
        h1 {{
            font-size: 2.5rem;
            margin-bottom: 0.5rem;
            background: linear-gradient(90deg, #00d9ff, #00ff88);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }}
        .meta {{
            color: #888;
            margin-bottom: 2rem;
        }}
        .card {{
            background: rgba(255, 255, 255, 0.05);
            border-radius: 12px;
            padding: 1.5rem;
            margin-bottom: 1.5rem;
            border: 1px solid rgba(255, 255, 255, 0.1);
        }}
        .card h2 {{
            font-size: 1.3rem;
            margin-bottom: 1rem;
            color: #00d9ff;
        }}
        .card.buy h2 {{
            color: #00ff88;
        }}
        .card.sell h2 {{
            color: #ff6b6b;
        }}
        .stats {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 1rem;
        }}
        .stat {{
            text-align: center;
            padding: 1rem;
            background: rgba(0, 217, 255, 0.1);
            border-radius: 8px;
        }}
        .stat-value {{
            font-size: 1.5rem;
            font-weight: bold;
            color: #00d9ff;
        }}
        .stat-label {{
            font-size: 0.85rem;
            color: #888;
            margin-top: 0.25rem;
        }}
        table {{
            width: 100%;
            border-collapse: collapse;
        }}
        th, td {{
            padding: 0.75rem;
            text-align: left;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }}
        th {{
            color: #888;
            font-weight: 500;
        }}
        tr:hover {{
            background: rgba(255, 255, 255, 0.03);
        }}
        .total {{
            margin-top: 1rem;
            padding-top: 1rem;
            border-top: 2px solid rgba(255, 255, 255, 0.1);
            font-weight: bold;
        }}
        .buy-total {{
            color: #00ff88;
        }}
        .sell-total {{
            color: #ff6b6b;
        }}
        .footer {{
            text-align: center;
            color: #666;
            margin-top: 2rem;
            font-size: 0.85rem;
        }}
        .empty {{
            text-align: center;
            color: #666;
            padding: 2rem;
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ“Š æ¯æ—¥è°ƒä»“æŠ¥å‘Š</h1>
        <p class="meta">æŠ¥å‘Šæ—¥æœŸ: {report_date} | ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        
        <div class="card">
            <h2>ç­–ç•¥æ¦‚è§ˆ</h2>
            <div class="stats">
                <div class="stat">
                    <div class="stat-value">Â¥{total_capital:,.0f}</div>
                    <div class="stat-label">æ€»èµ„é‡‘</div>
                </div>
                <div class="stat">
                    <div class="stat-value">{len(self.target_positions)}</div>
                    <div class="stat-label">ç›®æ ‡æŒä»“æ•°</div>
                </div>
                <div class="stat">
                    <div class="stat-value">{len(buy_orders)}</div>
                    <div class="stat-label">ä¹°å…¥è‚¡ç¥¨æ•°</div>
                </div>
                <div class="stat">
                    <div class="stat-value">{len(sell_orders)}</div>
                    <div class="stat-label">å–å‡ºè‚¡ç¥¨æ•°</div>
                </div>
            </div>
        </div>
        
        <div class="card buy">
            <h2>ğŸ“ˆ æ˜æ—¥éœ€ä¹°å…¥</h2>
            {f'''
            <table>
                <thead>
                    <tr>
                        <th>è‚¡ç¥¨ä»£ç </th>
                        <th>ä¹°å…¥é‡‘é¢</th>
                    </tr>
                </thead>
                <tbody>
                    {buy_rows}
                </tbody>
            </table>
            <p class="total buy-total">ä¹°å…¥æ€»é‡‘é¢: Â¥{sum(buy_orders.values()):,.0f}</p>
            ''' if buy_orders else '<p class="empty">æ— éœ€ä¹°å…¥</p>'}
        </div>
        
        <div class="card sell">
            <h2>ğŸ“‰ æ˜æ—¥éœ€å–å‡º</h2>
            {f'''
            <table>
                <thead>
                    <tr>
                        <th>è‚¡ç¥¨ä»£ç </th>
                        <th>å–å‡ºé‡‘é¢</th>
                    </tr>
                </thead>
                <tbody>
                    {sell_rows}
                </tbody>
            </table>
            <p class="total sell-total">å–å‡ºæ€»é‡‘é¢: Â¥{sum(sell_orders.values()):,.0f}</p>
            ''' if sell_orders else '<p class="empty">æ— éœ€å–å‡º</p>'}
        </div>
        
        <div class="card">
            <h2>ğŸ“‹ ç›®æ ‡æŒä»“æ˜ç»†</h2>
            <table>
                <thead>
                    <tr>
                        <th>è‚¡ç¥¨ä»£ç </th>
                        <th>ç›®æ ‡é‡‘é¢</th>
                        <th>æƒé‡</th>
                    </tr>
                </thead>
                <tbody>
                    {position_rows}
                </tbody>
            </table>
        </div>
        
        <p class="footer">æœ¬æŠ¥å‘Šç”± Aè‚¡é‡åŒ–äº¤æ˜“ç³»ç»Ÿ è‡ªåŠ¨ç”Ÿæˆ</p>
    </div>
</body>
</html>
        """
        
        return html
    
    def save_report(self, report_content: str, format: str = "markdown") -> Path:
        """
        ä¿å­˜æŠ¥å‘Š
        
        Parameters
        ----------
        report_content : str
            æŠ¥å‘Šå†…å®¹
        format : str
            æŠ¥å‘Šæ ¼å¼
        
        Returns
        -------
        Path
            æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        extension = "md" if format == "markdown" else "html"
        report_path = REPORTS_PATH / f"daily_report_{self.today.strftime('%Y%m%d')}.{extension}"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        self.logger.info(f"æŠ¥å‘Šå·²ä¿å­˜è‡³ {report_path}")
        return report_path


def _format_orders_for_push(
    buy_orders: Dict[str, float],
    sell_orders: Dict[str, float],
    target_positions: Dict[str, float],
    report_date: str,
    market_risk_triggered: bool = False
) -> str:
    """
    å°†äº¤æ˜“è®¢å•æ ¼å¼åŒ–ä¸º PushPlus æ¨é€å†…å®¹ï¼ˆHTMLæ ¼å¼ï¼‰
    
    Parameters
    ----------
    buy_orders : Dict[str, float]
        ä¹°å…¥è®¢å• {è‚¡ç¥¨ä»£ç : é‡‘é¢}
    sell_orders : Dict[str, float]
        å–å‡ºè®¢å• {è‚¡ç¥¨ä»£ç : é‡‘é¢}
    target_positions : Dict[str, float]
        ç›®æ ‡æŒä»“ {è‚¡ç¥¨ä»£ç : é‡‘é¢}
    report_date : str
        æŠ¥å‘Šæ—¥æœŸ
    market_risk_triggered : bool
        å¤§ç›˜é£æ§æ˜¯å¦è§¦å‘
    
    Returns
    -------
    str
        HTML æ ¼å¼çš„æ¨é€å†…å®¹
    """
    lines = []
    
    # æ ·å¼
    lines.append("""
    <style>
        body { font-family: -apple-system, sans-serif; padding: 10px; }
        .header { color: #333; border-bottom: 2px solid #667eea; padding-bottom: 10px; }
        .section { margin: 15px 0; }
        .section-title { color: #667eea; font-size: 16px; font-weight: bold; margin-bottom: 8px; }
        .buy { color: #00aa00; }
        .sell { color: #ff4444; }
        .warning { color: #ff8800; background: #fff3cd; padding: 10px; border-radius: 5px; }
        .item { padding: 5px 0; border-bottom: 1px solid #eee; }
        .amount { float: right; font-weight: bold; }
        .summary { background: #f8f9fa; padding: 10px; border-radius: 5px; margin-top: 15px; }
        .no-action { color: #888; text-align: center; padding: 20px; }
    </style>
    """)
    
    # æ ‡é¢˜
    lines.append(f'<div class="header"><h2>ğŸ“Š æ¯æ—¥äº¤æ˜“è®¡åˆ’</h2><p>æ—¥æœŸ: {report_date}</p></div>')
    
    # å¤§ç›˜é£æ§è­¦å‘Š
    if market_risk_triggered:
        lines.append('''
        <div class="warning">
            âš ï¸ <strong>å¤§ç›˜é£æ§è§¦å‘</strong><br>
            æ²ªæ·±300è·Œç ´20æ—¥å‡çº¿ï¼Œç³»ç»Ÿå¼ºåˆ¶ç©ºä»“ï¼
        </div>
        ''')
    
    # åˆ¤æ–­æ˜¯å¦æœ‰æ“ä½œ
    has_orders = bool(buy_orders) or bool(sell_orders)
    
    if not has_orders:
        lines.append('''
        <div class="no-action">
            <p>âœ… ä»Šæ—¥æ— äº¤æ˜“æ“ä½œ</p>
            <p style="font-size: 12px; color: #aaa;">æŒä»“ä¿æŒä¸å˜</p>
        </div>
        ''')
    else:
        # ä¹°å…¥æ¸…å•
        if buy_orders:
            lines.append('<div class="section">')
            lines.append(f'<div class="section-title buy">ğŸ“ˆ æ˜æ—¥éœ€ä¹°å…¥ ({len(buy_orders)}åª)</div>')
            
            for stock, amount in sorted(buy_orders.items(), key=lambda x: -x[1]):
                shares = int(amount / 10 / 100) * 100  # ä¼°ç®—è‚¡æ•°
                lines.append(f'''
                <div class="item">
                    <span>{stock}</span>
                    <span class="amount buy">Â¥{amount:,.0f}</span>
                    <span style="color:#888; font-size:12px;"> (~{shares}è‚¡)</span>
                </div>
                ''')
            
            total_buy = sum(buy_orders.values())
            lines.append(f'<div style="text-align:right; margin-top:8px;"><strong>åˆè®¡: Â¥{total_buy:,.0f}</strong></div>')
            lines.append('</div>')
        
        # å–å‡ºæ¸…å•
        if sell_orders:
            lines.append('<div class="section">')
            lines.append(f'<div class="section-title sell">ğŸ“‰ æ˜æ—¥éœ€å–å‡º ({len(sell_orders)}åª)</div>')
            
            for stock, amount in sorted(sell_orders.items(), key=lambda x: -x[1]):
                shares = int(amount / 10 / 100) * 100
                lines.append(f'''
                <div class="item">
                    <span>{stock}</span>
                    <span class="amount sell">Â¥{amount:,.0f}</span>
                    <span style="color:#888; font-size:12px;"> (~{shares}è‚¡)</span>
                </div>
                ''')
            
            total_sell = sum(sell_orders.values())
            lines.append(f'<div style="text-align:right; margin-top:8px;"><strong>åˆè®¡: Â¥{total_sell:,.0f}</strong></div>')
            lines.append('</div>')
    
    # æŒä»“æ±‡æ€»
    lines.append('<div class="summary">')
    lines.append(f'<strong>ç›®æ ‡æŒä»“: {len(target_positions)} åªè‚¡ç¥¨</strong>')
    if target_positions:
        total_value = sum(target_positions.values())
        lines.append(f'<br>æ€»å¸‚å€¼: Â¥{total_value:,.0f}')
        
        # æ˜¾ç¤ºå‰5åªæŒä»“
        top_5 = sorted(target_positions.items(), key=lambda x: -x[1])[:5]
        lines.append('<br><span style="font-size:12px; color:#666;">Top 5: ')
        lines.append(', '.join([f'{s}({w/total_value:.1%})' for s, w in top_5]))
        lines.append('</span>')
    lines.append('</div>')
    
    # æ—¶é—´æˆ³
    lines.append(f'<p style="text-align:center; color:#aaa; font-size:11px; margin-top:15px;">ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}</p>')
    
    return '\n'.join(lines)


def _send_daily_notification(
    runner: "DailyUpdateRunner",
    buy_orders: Dict[str, float],
    sell_orders: Dict[str, float],
    config: Dict[str, Any]
) -> None:
    """
    å‘é€æ¯æ—¥äº¤æ˜“é€šçŸ¥åˆ°å¾®ä¿¡
    
    Parameters
    ----------
    runner : DailyUpdateRunner
        è¿è¡Œå™¨å®ä¾‹
    buy_orders : Dict[str, float]
        ä¹°å…¥è®¢å•
    sell_orders : Dict[str, float]
        å–å‡ºè®¢å•
    config : Dict[str, Any]
        é…ç½®
    """
    logger = logging.getLogger(__name__)
    
    # è·å– PushPlus Token
    # ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œå…¶æ¬¡ä»é…ç½®æ–‡ä»¶è¯»å–
    token = os.environ.get("PUSHPLUS_TOKEN", "")
    
    if not token:
        token = config.get("notification", {}).get("pushplus_token", "")
    
    if not token:
        logger.debug("æœªé…ç½® PUSHPLUS_TOKENï¼Œè·³è¿‡å¾®ä¿¡æ¨é€")
        return
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºé£æ§è§¦å‘çš„ç©ºä»“
    market_risk_triggered = False
    positions_path = DATA_PROCESSED_PATH / f"target_positions_{runner.today.strftime('%Y%m%d')}.json"
    if positions_path.exists():
        try:
            with open(positions_path, 'r', encoding='utf-8') as f:
                pos_data = json.load(f)
                market_risk_triggered = pos_data.get("market_risk_triggered", False)
        except Exception:
            pass
    
    # æ ¼å¼åŒ–æ¨é€å†…å®¹
    report_date = runner.today.strftime('%Y-%m-%d')
    content = _format_orders_for_push(
        buy_orders=buy_orders,
        sell_orders=sell_orders,
        target_positions=runner.target_positions,
        report_date=report_date,
        market_risk_triggered=market_risk_triggered
    )
    
    # æ„å»ºæ ‡é¢˜
    if market_risk_triggered:
        title = f"âš ï¸ é£æ§è§¦å‘ - {report_date}"
    elif buy_orders or sell_orders:
        title = f"ğŸ“Š äº¤æ˜“è®¡åˆ’ - {report_date}"
    else:
        title = f"âœ… æ— æ“ä½œ - {report_date}"
    
    # å‘é€æ¶ˆæ¯
    success = send_pushplus_msg(
        token=token,
        title=title,
        content=content,
        template="html"
    )
    
    if success:
        logger.info("æ¯æ—¥äº¤æ˜“è®¡åˆ’å·²æ¨é€è‡³å¾®ä¿¡")
    else:
        logger.warning("å¾®ä¿¡æ¨é€å¤±è´¥ï¼Œè¯·æ£€æŸ¥ PUSHPLUS_TOKEN é…ç½®")


def run_daily_update(
    force_rebalance: bool = False,
    config: Optional[Dict[str, Any]] = None,
    no_llm: bool = False
) -> bool:
    """
    è¿è¡Œæ¯æ—¥æ›´æ–°æµç¨‹
    
    æµç¨‹ï¼š
    1. è°ƒç”¨ DataLoader æ›´æ–°è‡³ä»Šæ—¥çš„æœ€æ–°æ•°æ®
    2. è°ƒç”¨ FactorCalculator æ›´æ–°å› å­æ•°æ®
    3. æ›´æ–°åŸºå‡†æŒ‡æ•°æ•°æ®ï¼ˆç”¨äºå¤§ç›˜é£æ§ï¼‰
    4. æ£€æŸ¥ä»Šæ—¥æ˜¯å¦ä¸ºæœˆåº•ï¼ˆè°ƒä»“æ—¥ï¼‰ã€‚å¦‚æœæ˜¯ï¼Œè¿è¡Œ MultiFactorStrategy ç”Ÿæˆæ–°çš„ç›®æ ‡æŒä»“åˆ—è¡¨
    5. è°ƒç”¨ optimize_weights è®¡ç®—æ¯åªæŒä»“è‚¡çš„å…·ä½“è‚¡æ•°
    6. ç”ŸæˆæŠ¥å‘Š
    
    Parameters
    ----------
    force_rebalance : bool
        æ˜¯å¦å¼ºåˆ¶è°ƒä»“ï¼ˆå¿½ç•¥æ—¥æœŸæ£€æŸ¥ï¼‰
    config : Optional[Dict[str, Any]]
        é…ç½®å‚æ•°
    no_llm : bool
        æ˜¯å¦ç¦ç”¨ LLM é£æ§
    
    Returns
    -------
    bool
        è¿è¡Œæ˜¯å¦æˆåŠŸ
    """
    logger = logging.getLogger(__name__)
    logger.info("=" * 60)
    logger.info("å¼€å§‹æ¯æ—¥æ›´æ–°æµç¨‹")
    if no_llm:
        logger.info("å‚æ•°è®¾ç½®: ç¦ç”¨ LLM é£æ§")
    logger.info("=" * 60)
    
    try:
        # åˆå§‹åŒ–è¿è¡Œå™¨
        runner = DailyUpdateRunner(config)
        
        # å¤„ç† LLM ç¦ç”¨
        if no_llm:
            if "llm" in runner.config:
                runner.config["llm"] = {}
                # åŒæ—¶ä¹Ÿæ›´æ–° runner å†…éƒ¨å¯èƒ½å·²ç»åˆå§‹åŒ–çš„ç»„ä»¶é…ç½®
                # æ³¨æ„ï¼šDailyUpdateRunner åˆå§‹åŒ–æ—¶å·²ç»ç”¨ config åˆå§‹åŒ–äº†ç»„ä»¶
                # æ‰€ä»¥æœ€å¥½æ˜¯å…ˆä¿®æ”¹ config å†åˆå§‹åŒ– runnerï¼Œæˆ–è€… config ä¼ é€’ None å¹¶åœ¨å†…éƒ¨å¤„ç†
                # ç”±äº runner å·²ç»åˆå§‹åŒ–ï¼Œæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨é€šè¿‡ runner ä¿®æ”¹
                pass
            
            # ç”±äº runner å·²ç»åˆå§‹åŒ–ï¼Œæˆ‘ä»¬éœ€è¦é‡æ–°åˆå§‹åŒ–å—å½±å“çš„ç»„ä»¶
            # æˆ–è€…æ›´å¥½çš„æ–¹å¼æ˜¯åœ¨ DailyUpdateRunner å†…éƒ¨å¤„ç† no_llm
            # è¿™é‡Œä¸ºäº†ç®€å•ï¼Œç›´æ¥ä¿®æ”¹ configï¼Œå¹¶é‡æ–°åˆå§‹åŒ– feature_calculator
            runner.config["llm"] = {}
            runner._init_components()  # é‡æ–°åˆå§‹åŒ–ç»„ä»¶ä»¥åº”ç”¨æ–°é…ç½®

        
        # Step 1: æ›´æ–°å¸‚åœºæ•°æ®
        logger.info("Step 1/8: æ›´æ–°å¸‚åœºæ•°æ®")
        if not runner.update_market_data():
            logger.error("å¸‚åœºæ•°æ®æ›´æ–°å¤±è´¥")
            return False
        
        # Step 2: æ›´æ–°è´¢åŠ¡æ•°æ®
        logger.info("Step 2/8: æ›´æ–°è´¢åŠ¡æ•°æ®")
        if not runner.update_financial_data():
            logger.error("è´¢åŠ¡æ•°æ®æ›´æ–°å¤±è´¥")
            return False
        
        # Step 3: æ›´æ–°åŸºå‡†æŒ‡æ•°æ•°æ®ï¼ˆç”¨äºå¤§ç›˜é£æ§ï¼‰
        logger.info("Step 3/8: æ›´æ–°åŸºå‡†æŒ‡æ•°æ•°æ®ï¼ˆå¤§ç›˜é£æ§ï¼‰")
        runner.update_benchmark_data()  # å³ä½¿å¤±è´¥ä¹Ÿç»§ç»­ï¼Œåªæ˜¯é£æ§ä¸ç”Ÿæ•ˆ
        
        # Step 4: è®¡ç®—å› å­
        logger.info("Step 4/8: è®¡ç®—å› å­æ•°æ®")
        if not runner.calculate_factors():
            logger.error("å› å­è®¡ç®—å¤±è´¥")
            return False
        
        # Step 5: æ£€æŸ¥æ˜¯å¦è°ƒä»“æ—¥
        is_rebalance = force_rebalance or runner.is_rebalance_day()
        
        if is_rebalance:
            logger.info("Step 5/8: ç”Ÿæˆç›®æ ‡æŒä»“ï¼ˆè°ƒä»“æ—¥ï¼‰")
            if not runner.generate_target_positions():
                logger.error("ç›®æ ‡æŒä»“ç”Ÿæˆå¤±è´¥")
                return False
        else:
            logger.info("Step 5/8: éè°ƒä»“æ—¥ï¼Œè·³è¿‡æŒä»“ç”Ÿæˆ")
            runner.target_positions = runner.current_positions.copy()
        
        # Step 6: ç”ŸæˆæŠ¥å‘Š
        logger.info("Step 6/8: ç”Ÿæˆäº¤æ˜“æŠ¥å‘Š")
        buy_orders, sell_orders = runner.calculate_trade_orders()
        
        report_config = runner.config.get("report", {})
        report_format = report_config.get("format", "markdown")
        
        # ç”Ÿæˆä¸¤ç§æ ¼å¼çš„æŠ¥å‘Š
        for fmt in ["markdown", "html"]:
            report_content = runner.generate_report(buy_orders, sell_orders, format=fmt)
            runner.save_report(report_content, format=fmt)
        
        # Step 7: æ›´æ–°å¹¶ä¿å­˜æŒä»“
        logger.info("Step 7/8: æ›´æ–°æŒä»“è®°å½•")
        runner.save_current_holdings(buy_orders, sell_orders)
        
        # Step 8: å‘é€å¾®ä¿¡æ¨é€é€šçŸ¥
        logger.info("Step 8/8: å‘é€å¾®ä¿¡é€šçŸ¥")
        _send_daily_notification(
            runner=runner,
            buy_orders=buy_orders,
            sell_orders=sell_orders,
            config=runner.config
        )
        
        logger.info("=" * 60)
        logger.info("æ¯æ—¥æ›´æ–°æµç¨‹å®Œæˆ")
        logger.info("=" * 60)
        
        # æ‰“å°æ‘˜è¦
        logger.info(f"ç›®æ ‡æŒä»“: {len(runner.target_positions)} åªè‚¡ç¥¨")
        logger.info(f"éœ€ä¹°å…¥: {len(buy_orders)} åªï¼Œé‡‘é¢ Â¥{sum(buy_orders.values()):,.0f}")
        logger.info(f"éœ€å–å‡º: {len(sell_orders)} åªï¼Œé‡‘é¢ Â¥{sum(sell_orders.values()):,.0f}")
        
        return True
        
    except Exception as e:
        logger.error(f"æ¯æ—¥æ›´æ–°æµç¨‹å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False


def _load_backtest_financial_data(
    stock_list: List[str],
    start_date: str,
    end_date: str,
    data_loader: "DataLoader"
) -> pd.DataFrame:
    """
    åŠ è½½å›æµ‹ç”¨å†å²è´¢åŠ¡æ•°æ®ï¼ˆç‰¹åˆ«æ˜¯æµé€šå¸‚å€¼ circ_mvï¼‰
    
    ä¼˜å…ˆä»æœ¬åœ° parquet æ–‡ä»¶åŠ è½½ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™å°è¯•åœ¨çº¿è·å–ã€‚
    
    Parameters
    ----------
    stock_list : List[str]
        è‚¡ç¥¨ä»£ç åˆ—è¡¨
    start_date : str
        å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
    end_date : str
        ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
    data_loader : DataLoader
        æ•°æ®åŠ è½½å™¨å®ä¾‹
    
    Returns
    -------
    pd.DataFrame
        è´¢åŠ¡æ•°æ®ï¼ŒåŒ…å« date, stock_code, circ_mv, total_mv ç­‰å­—æ®µ
    
    Raises
    ------
    FileNotFoundError
        å½“æœ¬åœ°æ— è´¢åŠ¡æ•°æ®ä¸”æ— æ³•åœ¨çº¿è·å–æ—¶
    """
    logger = logging.getLogger(__name__)
    logger.info(f"åŠ è½½å›æµ‹è´¢åŠ¡æ•°æ®: {len(stock_list)} åªè‚¡ç¥¨, {start_date} ~ {end_date}")
    
    financial_records = []
    failed_stocks = []
    
    # å°è¯•ä»æœ¬åœ°åŠ è½½å·²ä¿å­˜çš„è´¢åŠ¡æ•°æ®
    local_financial_path = DATA_RAW_PATH / "financial_data.parquet"
    if local_financial_path.exists():
        try:
            local_df = pd.read_parquet(local_financial_path)
            logger.info(f"ä»æœ¬åœ°åŠ è½½è´¢åŠ¡æ•°æ®: {len(local_df)} æ¡è®°å½•")
            
            # è¿‡æ»¤æ—¥æœŸèŒƒå›´å’Œè‚¡ç¥¨åˆ—è¡¨
            if 'date' in local_df.columns:
                local_df['date'] = pd.to_datetime(local_df['date'])
                start_dt = pd.to_datetime(start_date)
                end_dt = pd.to_datetime(end_date)
                local_df = local_df[
                    (local_df['date'] >= start_dt) & 
                    (local_df['date'] <= end_dt) &
                    (local_df['stock_code'].isin(stock_list))
                ]
                
                if not local_df.empty and 'circ_mv' in local_df.columns:
                    logger.info(f"æœ¬åœ°è´¢åŠ¡æ•°æ®è¿‡æ»¤å: {len(local_df)} æ¡è®°å½•")
                    return local_df
        except Exception as e:
            logger.warning(f"åŠ è½½æœ¬åœ°è´¢åŠ¡æ•°æ®å¤±è´¥: {e}")
    
    # å°è¯•æŸ¥æ‰¾æŒ‰æ—¥æœŸä¿å­˜çš„è´¢åŠ¡æ•°æ®æ–‡ä»¶
    financial_files = list(DATA_RAW_PATH.glob("financial_*.parquet"))
    if financial_files:
        logger.info(f"æ‰¾åˆ° {len(financial_files)} ä¸ªè´¢åŠ¡æ•°æ®æ–‡ä»¶ï¼Œå°è¯•åŠ è½½...")
        all_financial_data = []
        
        for fpath in financial_files:
            try:
                df = pd.read_parquet(fpath)
                if 'stock_code' in df.columns:
                    # ä»æ–‡ä»¶åæå–æ—¥æœŸ
                    date_str = fpath.stem.replace("financial_", "")
                    if len(date_str) == 8:
                        df['data_date'] = pd.to_datetime(date_str, format='%Y%m%d')
                    all_financial_data.append(df)
            except Exception as e:
                logger.debug(f"åŠ è½½ {fpath} å¤±è´¥: {e}")
        
        if all_financial_data:
            combined_df = pd.concat(all_financial_data, ignore_index=True)
            if 'circ_mv' in combined_df.columns or 'total_mv' in combined_df.columns:
                logger.info(f"åˆå¹¶è´¢åŠ¡æ•°æ®: {len(combined_df)} æ¡è®°å½•")
                return combined_df
    
    # åœ¨çº¿è·å–è´¢åŠ¡æŒ‡æ ‡ï¼ˆä»…è·å–å½“å‰å¿«ç…§ï¼Œç”¨äºè¿‘æœŸå›æµ‹ï¼‰
    logger.warning("æœ¬åœ°æ— å†å²è´¢åŠ¡æ•°æ®ï¼Œå°è¯•åœ¨çº¿è·å–å½“å‰è´¢åŠ¡æŒ‡æ ‡...")
    logger.warning("æ³¨æ„ï¼šåœ¨çº¿è·å–çš„è´¢åŠ¡æ•°æ®ä¸ºå½“å‰å¿«ç…§ï¼Œå¯èƒ½å¯¼è‡´å›æµ‹å­˜åœ¨å‰è§†åå·®")
    
    import time
    for i, stock in enumerate(stock_list):
        try:
            fin_df = data_loader.fetch_financial_indicator(stock)
            
            if fin_df is not None and not fin_df.empty:
                # æå–å¸‚å€¼æ•°æ®
                if isinstance(fin_df, pd.DataFrame) and len(fin_df) > 0:
                    latest = fin_df.iloc[-1] if len(fin_df) > 1 else fin_df.iloc[0]
                    
                    # è·å–æµé€šå¸‚å€¼
                    circ_mv = None
                    total_mv = None
                    
                    for col in ['circ_mv', 'æµé€šå¸‚å€¼']:
                        if col in latest.index:
                            circ_mv = latest[col]
                            break
                    
                    for col in ['total_mv', 'æ€»å¸‚å€¼']:
                        if col in latest.index:
                            total_mv = latest[col]
                            break
                    
                    if circ_mv is not None or total_mv is not None:
                        financial_records.append({
                            'stock_code': stock,
                            'circ_mv': circ_mv if circ_mv is not None else total_mv,
                            'total_mv': total_mv if total_mv is not None else circ_mv,
                            'pe_ttm': latest.get('pe_ttm', np.nan),
                            'pb': latest.get('pb', np.nan),
                        })
                    else:
                        failed_stocks.append(stock)
                else:
                    failed_stocks.append(stock)
            else:
                failed_stocks.append(stock)
                
        except Exception as e:
            logger.debug(f"è·å– {stock} è´¢åŠ¡æ•°æ®å¤±è´¥: {e}")
            failed_stocks.append(stock)
        
        # è¿›åº¦æ—¥å¿—
        if (i + 1) % 20 == 0:
            logger.info(f"è´¢åŠ¡æ•°æ®è·å–è¿›åº¦: {i + 1}/{len(stock_list)}")
        
        # å»¶æ—¶é¿å…è¯·æ±‚è¿‡å¿«
        if (i + 1) % 5 == 0:
            time.sleep(0.5)
    
    if not financial_records:
        error_msg = (
            "æ— æ³•è·å–è´¢åŠ¡æ•°æ®ï¼ˆæµé€šå¸‚å€¼ circ_mvï¼‰ã€‚\n"
            "å°å¸‚å€¼ç­–ç•¥å›æµ‹éœ€è¦å†å²å¸‚å€¼æ•°æ®ã€‚è¯·å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤ä¸‹è½½æ•°æ®ï¼š\n"
            "  python tools/download_financial_data.py --start {start} --end {end}\n"
            "æˆ–åœ¨ data/raw/ ç›®å½•ä¸‹æ”¾ç½®åŒ…å« circ_mv å­—æ®µçš„ financial_data.parquet æ–‡ä»¶ã€‚"
        ).format(start=start_date, end=end_date)
        
        logger.error(error_msg)
        raise FileNotFoundError(error_msg)
    
    financial_df = pd.DataFrame(financial_records)
    
    if failed_stocks:
        logger.warning(
            f"éƒ¨åˆ†è‚¡ç¥¨è´¢åŠ¡æ•°æ®è·å–å¤±è´¥: {len(failed_stocks)}/{len(stock_list)}, "
            f"æˆåŠŸ: {len(financial_records)}"
        )
    
    logger.info(f"è´¢åŠ¡æ•°æ®åŠ è½½å®Œæˆ: {len(financial_df)} åªè‚¡ç¥¨")
    return financial_df


def _generate_backtest_factor_data(
    price_data_dict: Dict[str, pd.DataFrame],
    close_df: pd.DataFrame,
    strategy_config: Dict[str, Any],
    financial_data: Optional[pd.DataFrame] = None
) -> pd.DataFrame:
    """
    ç”Ÿæˆå›æµ‹ç”¨å› å­æ•°æ®ï¼ˆå¢å¼ºç‰ˆï¼‰
    
    è®¡ç®—ä»¥ä¸‹å› å­ï¼š
    - momentum_zscore: åŸºäº RSI_20 çš„åŠ¨é‡å› å­
    - small_cap: å°å¸‚å€¼å› å­ = -log(circ_mv)ï¼Œå¸‚å€¼è¶Šå°åˆ†æ•°è¶Šé«˜
    - small_cap_zscore: å°å¸‚å€¼å› å­çš„ Z-Score æ ‡å‡†åŒ–
    - turnover_5d: 5æ—¥å¹³å‡æ¢æ‰‹ç‡
    - value_zscore, quality_zscore: è´¢åŠ¡å› å­ï¼ˆéœ€è¦è´¢åŠ¡æ•°æ®ï¼‰
    
    Parameters
    ----------
    price_data_dict : Dict[str, pd.DataFrame]
        è‚¡ç¥¨ä»·æ ¼æ•°æ®å­—å…¸ {stock_code: DataFrame}
    close_df : pd.DataFrame
        æ”¶ç›˜ä»·çŸ©é˜µ (Index=æ—¥æœŸ, Columns=è‚¡ç¥¨ä»£ç )
    strategy_config : Dict[str, Any]
        ç­–ç•¥é…ç½®
    financial_data : Optional[pd.DataFrame]
        è´¢åŠ¡æ•°æ®ï¼ŒåŒ…å« stock_code, circ_mv ç­‰å­—æ®µ
    
    Returns
    -------
    pd.DataFrame
        å› å­æ•°æ®ï¼ŒåŒ…å« date, stock_code åŠå„ç±»å› å­åˆ—
    
    Notes
    -----
    å¦‚æœæä¾›äº† financial_data ä¸”åŒ…å« circ_mvï¼Œå°†æ­£ç¡®è®¡ç®— small_cap å› å­ã€‚
    å¦åˆ™ small_cap ç›¸å…³å› å­å°†è¢«è®¾ç½®ä¸º NaNï¼Œå¹¶è®°å½•è­¦å‘Šã€‚
    """
    logger = logging.getLogger(__name__)
    
    has_financial = (
        financial_data is not None and 
        not financial_data.empty and 
        'circ_mv' in financial_data.columns
    )
    
    if has_financial:
        logger.info("ç”Ÿæˆå›æµ‹å› å­æ•°æ®ï¼ˆå«è´¢åŠ¡å› å­ï¼šsmall_cap, valueï¼‰...")
    else:
        logger.info(
            "ç”Ÿæˆå›æµ‹å› å­æ•°æ®ï¼šå°†ä½¿ç”¨ã€Œæ¢æ‰‹ç‡å€’æ¨å¸‚å€¼ã€æ–¹æ³•ä¼°ç®—æµé€šå¸‚å€¼ï¼Œ"
            "å…¬å¼: estimated_circ_mv = amount / (turnover / 100)"
        )
        logger.warning(
            "æ³¨æ„ï¼šä¼°ç®—å¸‚å€¼ä»…ä¾›å›æµ‹å‚è€ƒï¼Œå®é™…å¸‚å€¼ä»¥è´¢åŠ¡æ•°æ®ä¸ºå‡†"
        )
    
    factor_records = []
    
    # æ„å»ºè´¢åŠ¡æ•°æ®æ˜ å°„ {stock_code: {circ_mv, pe_ttm, ...}}
    financial_map: Dict[str, Dict[str, Any]] = {}
    if has_financial:
        for _, row in financial_data.iterrows():
            stock_code = row.get('stock_code', '')
            if stock_code:
                financial_map[stock_code] = {
                    'circ_mv': row.get('circ_mv', np.nan),
                    'total_mv': row.get('total_mv', np.nan),
                    'pe_ttm': row.get('pe_ttm', np.nan),
                    'pb': row.get('pb', np.nan),
                }
    
    # è®¡ç®— RSI_20 for æ¯åªè‚¡ç¥¨
    def calculate_rsi(series: pd.Series, period: int = 20) -> pd.Series:
        """è®¡ç®— RSI æŒ‡æ ‡"""
        delta = series.diff()
        gain = delta.where(delta > 0, 0.0)
        loss = (-delta).where(delta < 0, 0.0)
        
        avg_gain = gain.ewm(alpha=1.0/period, min_periods=period, adjust=False).mean()
        avg_loss = loss.ewm(alpha=1.0/period, min_periods=period, adjust=False).mean()
        
        rs = avg_gain / avg_loss.replace(0, np.nan)
        rsi = 100.0 - (100.0 / (1.0 + rs))
        
        return rsi
    
    for stock_code, df in price_data_dict.items():
        if df is None or df.empty or 'close' not in df.columns:
            continue
        
        # ç¡®ä¿ç´¢å¼•æ˜¯æ—¥æœŸç±»å‹
        df = df.copy()
        if not isinstance(df.index, pd.DatetimeIndex):
            df.index = pd.to_datetime(df.index)
        
        # è®¡ç®— RSI_20
        rsi_20 = calculate_rsi(df['close'], period=20)
        
        # è®¡ç®— Sharpe_20 (æ–°åŠ¨é‡å› å­)
        # æ»šåŠ¨å¹´åŒ–å¤æ™®æ¯”ç‡ = (mean(returns) / std(returns)) * sqrt(252)
        sharpe_20 = pd.Series(np.nan, index=df.index)
        sharpe_60 = pd.Series(np.nan, index=df.index)
        if 'close' in df.columns:
            returns = df['close'].pct_change()
            # min_periods=10: è‡³å°‘éœ€è¦åŠä¸ªçª—å£çš„æ•°æ®
            mean_ret = returns.rolling(20, min_periods=10).mean()
            std_ret = returns.rolling(20, min_periods=10).std()
            sharpe_20 = (mean_ret / std_ret.replace(0, np.nan)) * np.sqrt(252)
            
            # [NEW] Sharpe_60: æ›´å¹³æ»‘çš„é•¿å‘¨æœŸåŠ¨é‡å› å­
            mean_ret_60 = returns.rolling(60, min_periods=30).mean()
            std_ret_60 = returns.rolling(60, min_periods=30).std()
            sharpe_60 = (mean_ret_60 / std_ret_60.replace(0, np.nan)) * np.sqrt(252)

        # è®¡ç®— ROC_20 (åŠ¨é‡å› å­)
        roc_20 = pd.Series(np.nan, index=df.index)
        if 'close' in df.columns:
            # 20æ—¥å˜åŠ¨ç‡ = (Today - 20DaysAgo) / 20DaysAgo * 100
            roc_20 = df['close'].pct_change(20) * 100
        
        # è®¡ç®— 5 æ—¥å¹³å‡æ¢æ‰‹ç‡
        turnover_5d = pd.Series(np.nan, index=df.index)
        if 'turnover' in df.columns:
            turnover_5d = df['turnover'].rolling(5, min_periods=1).mean()
        
        # [Added] é¢„è®¡ç®— IVOL_20 (ç‰¹è´¨æ³¢åŠ¨ç‡)
        ivol_20 = pd.Series(np.nan, index=df.index)
        if 'close' in df.columns:
             # è®¡ç®—æ—¥æ”¶ç›Šç‡
             daily_ret = df['close'].pct_change()
             # æ»šåŠ¨æ ‡å‡†å·® * å¹´åŒ–å› å­
             ivol_20 = daily_ret.rolling(20, min_periods=5).std() * np.sqrt(252)

        # è·å–è´¢åŠ¡æ•°æ®ï¼ˆä½œä¸ºä¼˜å…ˆä½¿ç”¨çš„é™æ€å¸‚å€¼ï¼‰
        fin_data = financial_map.get(stock_code, {})
        static_circ_mv = fin_data.get('circ_mv', np.nan)
        pe_ttm = fin_data.get('pe_ttm', np.nan)
        
        # è®¡ç®—ä¼°ç®—æµé€šå¸‚å€¼åºåˆ—ï¼ˆåŸºäºæ¢æ‰‹ç‡å€’æ¨ï¼‰
        # å…¬å¼: estimated_circ_mv = amount / (turnover / 100)
        # å«ä¹‰: æ¢æ‰‹ç‡ = æˆäº¤é‡ / æµé€šè‚¡æœ¬ï¼Œæˆäº¤é¢ â‰ˆ æˆäº¤é‡ * å½“æ—¥å‡ä»·
        #       æ‰€ä»¥: æµé€šå¸‚å€¼ â‰ˆ æˆäº¤é¢ / æ¢æ‰‹ç‡
        has_turnover = 'turnover' in df.columns
        has_amount = 'amount' in df.columns
        
        estimated_circ_mv_series = pd.Series(np.nan, index=df.index)
        if has_turnover and has_amount:
            # æ¢æ‰‹ç‡è½¬ä¸ºå°æ•° (turnover å•ä½æ˜¯ç™¾åˆ†æ¯”ï¼Œå¦‚ 3.5 è¡¨ç¤º 3.5%)
            turnover_pct = df['turnover'] / 100.0
            # é¿å…é™¤ä»¥é›¶æˆ–æå°å€¼
            safe_turnover = turnover_pct.replace(0, np.nan)
            safe_turnover = safe_turnover.where(safe_turnover >= 0.0001, np.nan)
            # è®¡ç®—ä¼°ç®—æµé€šå¸‚å€¼ (å•ä½ä¸ amount ä¸€è‡´ï¼Œé€šå¸¸æ˜¯å…ƒ)
            estimated_circ_mv_series = df['amount'] / safe_turnover
        
        # è®¡ç®— EP_TTM (ä»·å€¼å› å­)
        if pd.notna(pe_ttm) and pe_ttm > 0:
            ep_ttm = 1.0 / pe_ttm
        else:
            ep_ttm = np.nan
        
        for date in df.index:
            rsi_val = rsi_20.get(date, np.nan) if date in rsi_20.index else np.nan
            turnover_val = turnover_5d.get(date, np.nan) if date in turnover_5d.index else np.nan
            close_price = df.loc[date, 'close'] if date in df.index else np.nan
            
            # è·å–å½“å¤©çš„ä¼°ç®—å¸‚å€¼
            estimated_circ_mv = estimated_circ_mv_series.get(date, np.nan)
            
            # ä¼˜å…ˆçº§ï¼š1. è´¢åŠ¡æ•°æ®ä¸­çš„ circ_mv  2. æ¢æ‰‹ç‡ä¼°ç®—çš„å¸‚å€¼  3. NaN
            if pd.notna(static_circ_mv) and static_circ_mv > 0:
                circ_mv = static_circ_mv
            elif pd.notna(estimated_circ_mv) and estimated_circ_mv > 0:
                circ_mv = estimated_circ_mv
            else:
                circ_mv = np.nan
            
            # è®¡ç®— small_cap å› å­ï¼š-log(circ_mv)
            # å¸‚å€¼è¶Šå°ï¼Œ-log(å¸‚å€¼) è¶Šå¤§ï¼Œå¾—åˆ†è¶Šé«˜
            if pd.notna(circ_mv) and circ_mv > 0:
                small_cap = -np.log(circ_mv)
            else:
                small_cap = np.nan
            
            # è®¡ç®— ROE ç¨³å®šæ€§ï¼ˆç®€åŒ–ç‰ˆï¼šç”¨ PE çš„å€’æ•°ä½œä¸º ROE ä»£ç†ï¼Œè®¡ç®—å…¶æ³¢åŠ¨ç‡ï¼‰
            # æ³¨æ„ï¼šå‡†ç¡®çš„ roe_stability éœ€è¦å­£åº¦è´¢åŠ¡æ•°æ®ï¼Œè¿™é‡Œä»…ä½œå ä½
            # å®é™…ç”Ÿäº§ä¸­åº”åœ¨ data_loader åŠ è½½å®Œæ•´çš„å­£åº¦ ROE æ•°æ®
            roe_proxy = ep_ttm  # å‡è®¾ EP â‰ˆ ROE (åœ¨ PB=1 æ—¶æˆç«‹)
            roe_stability = roe_proxy if pd.notna(roe_proxy) else 0.0
            
            factor_records.append({
                'date': date,
                'stock_code': stock_code,
                'close': close_price,
                'rsi_20': rsi_val,
                'sharpe_20': sharpe_20.get(date, np.nan) if date in sharpe_20.index else np.nan,
                'sharpe_60': sharpe_60.get(date, np.nan) if date in sharpe_60.index else np.nan,
                'roc_20': roc_20.get(date, np.nan) if date in roc_20.index else np.nan,
                'turnover_5d': turnover_val,
                # å°å¸‚å€¼å› å­ï¼ˆæ ¸å¿ƒï¼‰
                'small_cap': small_cap,
                'circ_mv': circ_mv,
                # ä»·å€¼å› å­
                'ep_ttm': ep_ttm,
                # è´¨é‡å› å­ (æ–°å¢)
                'roe_stability': roe_stability,
                # æ–°å¢å› å­ï¼šç‰¹è´¨æ³¢åŠ¨ç‡ (IVOL)
                'ivol_20': ivol_20.get(date, np.nan) if date in ivol_20.index else np.nan, 
                # ä¼°ç®—ä¸Šå¸‚å¤©æ•°ï¼ˆé»˜è®¤è¶³å¤Ÿé•¿ä»¥é€šè¿‡è¿‡æ»¤ï¼‰
                'listing_days': 1000,
                # æ¶¨è·Œåœæ ‡å¿—ï¼ˆç®€åŒ–ï¼šé»˜è®¤æ— æ¶¨è·Œåœï¼‰
                'is_limit': False,
            })
    
    if not factor_records:
        logger.warning("æ— æ³•ç”Ÿæˆå› å­æ•°æ®")
        return pd.DataFrame()
    
    factor_df = pd.DataFrame(factor_records)
    
    # Z-Score æ ‡å‡†åŒ–ï¼ˆæŒ‰æ—¥æœŸåˆ†ç»„ï¼‰
    def zscore_by_date(group: pd.DataFrame, col: str) -> pd.Series:
        """æŒ‰æ—¥æœŸåˆ†ç»„è®¡ç®— Z-Score"""
        valid_vals = group[col].dropna()
        if len(valid_vals) < 2:
            return pd.Series(np.nan, index=group.index)
        
        mean_val = valid_vals.mean()
        std_val = valid_vals.std()
        if std_val > 0:
            return (group[col] - mean_val) / std_val
        else:
            return pd.Series(0.0, index=group.index)
    
    # è®¡ç®— RSI Z-Scoreï¼ˆåŠ¨é‡å› å­ï¼‰
    factor_df['momentum_zscore'] = factor_df.groupby('date', group_keys=False).apply(
        lambda g: zscore_by_date(g, 'rsi_20'), include_groups=False
    ).reset_index(level=0, drop=True)
    
    # [Added] è®¡ç®— Sharpe_20 Z-Score (æ–°çš„æ ¸å¿ƒåŠ¨é‡å› å­)
    if 'sharpe_20' in factor_df.columns:
        factor_df['sharpe_20_zscore'] = factor_df.groupby('date', group_keys=False).apply(
            lambda g: zscore_by_date(g, 'sharpe_20'), include_groups=False
        ).reset_index(level=0, drop=True)
        logger.info(f"sharpe_20_zscore ç”Ÿæˆå®Œæˆï¼Œæœ‰æ•ˆç‡: {factor_df['sharpe_20_zscore'].notna().mean():.1%}")
    else:
        # å¦‚æœ features.py è¿˜æ²¡è®¡ç®— sharpe_20ï¼Œåˆ™å°è¯•è®¡ç®—å®ƒï¼ˆé’ˆå¯¹å›æµ‹æ¨¡å¼å› å­æœªæ›´æ–°çš„æƒ…å†µï¼‰
        logger.warning("Warning: 'sharpe_20' not found in features, skipping z-score calculation")
        factor_df['sharpe_20_zscore'] = np.nan

    # [NEW] è®¡ç®— Sharpe_60 Z-Score (é•¿å‘¨æœŸåŠ¨é‡å› å­ - æ›´ç¨³å®š)
    if 'sharpe_60' in factor_df.columns:
        factor_df['sharpe_60_zscore'] = factor_df.groupby('date', group_keys=False).apply(
            lambda g: zscore_by_date(g, 'sharpe_60'), include_groups=False
        ).reset_index(level=0, drop=True)
        logger.info(f"sharpe_60_zscore ç”Ÿæˆå®Œæˆï¼Œæœ‰æ•ˆç‡: {factor_df['sharpe_60_zscore'].notna().mean():.1%}")
    else:
        factor_df['sharpe_60_zscore'] = np.nan
        logger.warning("Warning: 'sharpe_60' not found, long-term momentum unavailable")

    # è®¡ç®— ROC_20 Z-Score (å…¼å®¹æ—§ç‰ˆåŠ¨é‡å› å­)
    if 'roc_20' in factor_df.columns:
        factor_df['roc_20_zscore'] = factor_df.groupby('date', group_keys=False).apply(
            lambda g: zscore_by_date(g, 'roc_20'), include_groups=False
        ).reset_index(level=0, drop=True)
        logger.info(f"roc_20_zscore ç”Ÿæˆå®Œæˆï¼Œæœ‰æ•ˆç‡: {factor_df['roc_20_zscore'].notna().mean():.1%}")
    else:
        factor_df['roc_20_zscore'] = np.nan
        logger.warning("æ— æ³•è®¡ç®— roc_20_zscore: roc_20 åˆ—ç¼ºå¤±")

    # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„ small_cap æ•°æ®ï¼ˆæ¥è‡ªè´¢åŠ¡æ•°æ®æˆ–æ¢æ‰‹ç‡ä¼°ç®—ï¼‰
    has_valid_small_cap = factor_df['small_cap'].notna().any()
    
    # è®¡ç®— Small Cap Z-Scoreï¼ˆå°å¸‚å€¼å› å­ï¼‰
    if has_valid_small_cap:
        factor_df['small_cap_zscore'] = factor_df.groupby('date', group_keys=False).apply(
            lambda g: zscore_by_date(g, 'small_cap'), include_groups=False
        ).reset_index(level=0, drop=True)
        
        # è®¡ç®—æ¢æ‰‹ç‡ Z-Score
        factor_df['turnover_5d_zscore'] = factor_df.groupby('date', group_keys=False).apply(
            lambda g: zscore_by_date(g, 'turnover_5d'), include_groups=False
        ).reset_index(level=0, drop=True)
        
        # [Added] è®¡ç®— ROE ç¨³å®šæ€§ Z-Score (æ–°çš„è´¨é‡å› å­)
        # å¦‚æœè´¢åŠ¡æ•°æ®ä¸­åŒ…å« roe_stability (éœ€åœ¨ features.py è®¡ç®—)ï¼Œè¿™é‡Œè¿›è¡Œæ ‡å‡†åŒ–
        if 'roe_stability' in factor_df.columns:
            factor_df['roe_stability_zscore'] = factor_df.groupby('date', group_keys=False).apply(
                lambda g: zscore_by_date(g, 'roe_stability'), include_groups=False
            ).reset_index(level=0, drop=True)
        else:
            # å¦‚æœä¸Šæ¸¸æœªè®¡ç®— roe_stabilityï¼Œæš‚æ—¶ç”¨ roe (ep_ttmçš„å€’æ•°è¿‘ä¼¼) æˆ–è®¾ä¸º 0
            # è¿™é‡Œä¸ºäº†ä¸æŠ¥é”™ï¼Œå…ˆè®¾ä¸º 0ï¼Œåç»­éœ€åœ¨ features.py ç¡®ä¿è®¡ç®—
            factor_df['roe_stability_zscore'] = 0.0
            logger.warning("Warning: 'roe_stability' not found, quality factor set to 0")

        # [Added] è®¡ç®— IVOL Z-Score (ä½æ³¢å› å­)
        # IVOL è¶Šä½è¶Šå¥½ï¼Œå› æ­¤å–è´Ÿå·
        if 'ivol_20' in factor_df.columns:
             # æ³¨æ„ï¼šIVOLå¯èƒ½ä¸º0æˆ–NaNï¼Œéœ€è¦å¤„ç†
            factor_df['ivol_20'] = factor_df['ivol_20'].replace(0, np.nan)
            factor_df['ivol_zscore'] = factor_df.groupby('date', group_keys=False).apply(
                lambda g: zscore_by_date(g, 'ivol_20'), include_groups=False
            ).reset_index(level=0, drop=True)
            # åè½¬å› å­æ–¹å‘ï¼šæ³¢åŠ¨ç‡è¶Šä½åˆ†è¶Šé«˜
            factor_df['ivol_zscore'] = -factor_df['ivol_zscore']
        else:
            factor_df['ivol_zscore'] = 0.0

        # è®¡ç®—ä»·å€¼å› å­ Z-Scoreï¼ˆéœ€è¦è´¢åŠ¡æ•°æ®ï¼‰
        if has_financial:
            factor_df['value_zscore'] = factor_df.groupby('date', group_keys=False).apply(
                lambda g: zscore_by_date(g, 'ep_ttm'), include_groups=False
            ).reset_index(level=0, drop=True)
        else:
            factor_df['value_zscore'] = np.nan
            
        if not has_financial:
            logger.info(
                "å·²é€šè¿‡æ¢æ‰‹ç‡å€’æ¨å¸‚å€¼è®¡ç®— small_cap_zscoreï¼Œ"
                f"æœ‰æ•ˆè®°å½•æ•°: {factor_df['small_cap_zscore'].notna().sum()}"
            )
    else:
        # æ—¢æ— è´¢åŠ¡æ•°æ®ä¹Ÿæ— æ¢æ‰‹ç‡ä¼°ç®—æ—¶è®¾ç½®ä¸º NaN
        factor_df['small_cap_zscore'] = np.nan
        factor_df['turnover_5d_zscore'] = np.nan
        factor_df['value_zscore'] = np.nan
        
        logger.warning(
            "è­¦å‘Šï¼šæ— è´¢åŠ¡æ•°æ®ä¸”æ— æ³•é€šè¿‡æ¢æ‰‹ç‡ä¼°ç®—å¸‚å€¼ï¼Œsmall_cap_zscore è®¾ç½®ä¸º NaNã€‚"
            "å›æµ‹ç»“æœå°†ä»…åŸºäºåŠ¨é‡å› å­ï¼ˆRSIï¼‰ï¼Œæ— æ³•ä½“ç°å°å¸‚å€¼ç­–ç•¥æ•ˆæœã€‚"
        )
    
    # è´¨é‡å› å­ï¼ˆéœ€è¦æ›´å¤šè´¢åŠ¡æ•°æ®ï¼Œæš‚æ—¶è®¾ä¸º NaNï¼‰
    factor_df['quality_zscore'] = np.nan
    
    # å¡«å……åŠ¨é‡å› å­çš„ NaN
    factor_df['momentum_zscore'] = factor_df['momentum_zscore'].fillna(0.0)
    
    # ==================== è®¡ç®— Alpha å› å­ï¼ˆé‡ä»·é…åˆï¼‰====================
    # ç”¨äºå›æµ‹çš„ Alpha_001 å› å­
    # Alpha_001 = (Close - VWAP) / VWAP
    alpha_enabled = False
    alpha_records = []
    
    try:
        for stock_code, stock_df in price_data_dict.items():
            if 'amount' in stock_df.columns and 'volume' in stock_df.columns:
                vwap = stock_df['amount'] / stock_df['volume'].replace(0, np.nan)
                alpha_001 = (stock_df['close'] - vwap) / vwap.replace(0, np.nan)
                alpha_001 = alpha_001.replace([np.inf, -np.inf], np.nan)
                
                for date in stock_df.index:
                    if pd.notna(alpha_001.get(date)):
                        alpha_records.append({
                            'date': date,
                            'stock_code': stock_code,
                            'alpha_001': alpha_001[date]
                        })
        
        if alpha_records:
            alpha_df = pd.DataFrame(alpha_records)
            factor_df = factor_df.merge(alpha_df, on=['date', 'stock_code'], how='left')
            
            # Z-Score æ ‡å‡†åŒ–
            factor_df['alpha_001_zscore'] = factor_df.groupby('date', group_keys=False).apply(
                lambda g: zscore_by_date(g, 'alpha_001'), include_groups=False
            ).reset_index(level=0, drop=True).fillna(0)
            
            alpha_enabled = True
            logger.info("Alpha_001 å› å­ï¼ˆé‡ä»·é…åˆï¼‰è®¡ç®—å®Œæˆ")
        else:
            factor_df['alpha_001_zscore'] = 0.0
            logger.warning("æ— æ³•è®¡ç®— Alpha_001 å› å­ï¼šç¼ºå°‘ amount/volume æ•°æ®")
    except Exception as e:
        factor_df['alpha_001_zscore'] = 0.0
        logger.warning(f"Alpha_001 å› å­è®¡ç®—å¤±è´¥: {e}")
    
    # ==================== è®¡ç®—å¤åˆåŠ¨é‡å› å­ momentum_composite_zscore ====================
    # ç‰›å¸‚è¿›æ”»å‹é…æ–¹: 40% ROC + 30% Sharpe + 30% Alpha001
    roc_col = 'roc_20_zscore' if 'roc_20_zscore' in factor_df.columns else None
    sharpe_col = 'sharpe_20_zscore' if 'sharpe_20_zscore' in factor_df.columns else None
    alpha_col = 'alpha_001_zscore' if alpha_enabled else None
    
    if roc_col and sharpe_col and alpha_col:
        factor_df['momentum_composite_zscore'] = (
            0.4 * factor_df[roc_col].fillna(0) +
            0.3 * factor_df[sharpe_col].fillna(0) +
            0.3 * factor_df[alpha_col].fillna(0)
        )
        logger.info("ğŸš€ å¤åˆåŠ¨é‡å› å­è®¡ç®—å®Œæˆ: 40% ROC + 30% Sharpe + 30% Alpha001")
    elif roc_col and sharpe_col:
        factor_df['momentum_composite_zscore'] = (
            0.6 * factor_df[roc_col].fillna(0) +
            0.4 * factor_df[sharpe_col].fillna(0)
        )
        logger.info("å¤åˆåŠ¨é‡å› å­è®¡ç®—å®Œæˆ: 60% ROC + 40% Sharpeï¼ˆæ—  Alphaï¼‰")
    elif roc_col:
        factor_df['momentum_composite_zscore'] = factor_df[roc_col].fillna(0)
        logger.warning("å¤åˆåŠ¨é‡å› å­ä½¿ç”¨ ROC å•å› å­")
    else:
        factor_df['momentum_composite_zscore'] = factor_df['momentum_zscore'].fillna(0)
        logger.warning("å¤åˆåŠ¨é‡å› å­ä½¿ç”¨ RSI ä½œä¸ºåå¤‡")
    
    # ç»Ÿè®¡æœ‰æ•ˆçš„å°å¸‚å€¼å› å­æ•°é‡
    valid_small_cap = factor_df['small_cap_zscore'].notna().sum()
    total_records = len(factor_df)
    
    logger.info(
        f"å› å­æ•°æ®ç”Ÿæˆå®Œæˆ: {total_records} æ¡è®°å½•, "
        f"{factor_df['stock_code'].nunique()} åªè‚¡ç¥¨, "
        f"{factor_df['date'].nunique()} ä¸ªäº¤æ˜“æ—¥"
    )
    
    if has_financial:
        logger.info(
            f"å°å¸‚å€¼å› å­ (small_cap_zscore) æœ‰æ•ˆç‡: "
            f"{valid_small_cap}/{total_records} ({valid_small_cap/total_records:.1%})"
        )
    
    return factor_df


def run_backtest(
    start_date: str,
    end_date: str,
    config: Optional[Dict[str, Any]] = None,
    strategy_type: str = "multi_factor",
    no_llm: bool = False
) -> bool:
    """
    è¿è¡Œç­–ç•¥å›æµ‹
    
    ä½¿ç”¨ BacktestEngine + MultiFactorStrategy å¯¹æŒ‡å®šæ—¶é—´æ®µçš„å†å²æ•°æ®è¿›è¡Œå›æµ‹ã€‚
    æ”¯æŒå¤§ç›˜é£æ§ï¼ˆé€šè¿‡ benchmark_data ä¼ å…¥åŸºå‡†æŒ‡æ•°æ•°æ®ï¼‰ã€‚
    
    Parameters
    ----------
    start_date : str
        å›æµ‹å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
    end_date : str
        å›æµ‹ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
    config : Optional[Dict[str, Any]]
        å›æµ‹é…ç½®å‚æ•°
    strategy_type : str
        ç­–ç•¥ç±»å‹: 'multi_factor', 'ma_cross'
    no_llm : bool
        æ˜¯å¦ç¦ç”¨ LLM é£æ§
    
    Returns
    -------
    bool
        å›æµ‹æ˜¯å¦æˆåŠŸ
    
    Notes
    -----
    å›æµ‹æµç¨‹ï¼š
    1. åŠ è½½å†å² OHLCV æ•°æ®
    2. å‡†å¤‡ä»·æ ¼çŸ©é˜µ
    3. åŠ è½½å†å²è´¢åŠ¡æ•°æ®ï¼ˆç‰¹åˆ«æ˜¯æµé€šå¸‚å€¼ circ_mvï¼Œç”¨äºå°å¸‚å€¼å› å­ï¼‰
    4. è·å–åŸºå‡†æŒ‡æ•°æ•°æ®ï¼ˆç”¨äºå¤§ç›˜é£æ§ï¼‰
    5. ç”Ÿæˆå› å­æ•°æ®ï¼ˆå« small_cap = -log(circ_mv)ï¼Œmomentum ç­‰ï¼‰
    6. ä½¿ç”¨ BacktestEngine æ‰§è¡Œæƒé‡é©±åŠ¨å›æµ‹
    7. ç”Ÿæˆå›æµ‹æŠ¥å‘Š
    
    å°å¸‚å€¼ç­–ç•¥è¦æ±‚ï¼š
    - éœ€è¦æœ¬åœ°å­˜å‚¨çš„è´¢åŠ¡æ•°æ®æ–‡ä»¶ï¼ˆdata/raw/financial_*.parquetï¼‰
    - è´¢åŠ¡æ•°æ®éœ€åŒ…å« circ_mvï¼ˆæµé€šå¸‚å€¼ï¼‰å­—æ®µ
    - å¦‚æœæ— è´¢åŠ¡æ•°æ®ï¼Œç­–ç•¥ä¼šè‡ªåŠ¨é€€åŒ–ä¸ºçº¯åŠ¨é‡ç­–ç•¥
    """
    logger = logging.getLogger(__name__)
    logger.info("=" * 60)
    logger.info(f"å¼€å§‹å›æµ‹: {start_date} ~ {end_date}")
    logger.info("ä½¿ç”¨å¼•æ“: BacktestEngine (æƒé‡é©±åŠ¨ + å¤§ç›˜é£æ§)")
    if no_llm:
        logger.info("å‚æ•°è®¾ç½®: ç¦ç”¨ LLM é£æ§")
    logger.info("=" * 60)
    
    try:
        # ========================================
        # Step 0: åŠ è½½é…ç½®
        # ========================================
        if config is None:
            try:
                config = load_config(CONFIG_PATH)
            except FileNotFoundError:
                logger.warning(f"é…ç½®æ–‡ä»¶ {CONFIG_PATH} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                config = {}
        
        # å¤„ç† LLM ç¦ç”¨
        if no_llm:
            config["llm"] = {}
        
        # æå–é…ç½®
        backtest_config = config.get("backtest", {})
        portfolio_config = config.get("portfolio", {})
        strategy_config = config.get("strategy", {})
        data_config = config.get("data", {})
        
        initial_capital = portfolio_config.get("total_capital", 300000)
        commission = config.get("trading", {}).get("commission_rate", 0.0003)
        slippage = config.get("trading", {}).get("slippage", 0.001)
        risk_free_rate = portfolio_config.get("risk_free_rate", 0.02)
        optimization_objective = portfolio_config.get("optimization_objective", "equal_weight")
        
        # åŸºå‡†æŒ‡æ•°ä»£ç ï¼ˆé»˜è®¤ä¸­è¯500ï¼‰
        benchmark_code = backtest_config.get("benchmark", "000905")
        
        logger.info(f"å›æµ‹é…ç½®: åˆå§‹èµ„é‡‘=Â¥{initial_capital:,.0f}, åŸºå‡†={benchmark_code}")
        
        # ========================================
        # Step 1: åŠ è½½å†å²æ•°æ®
        # ========================================
        logger.info("Step 1/7: åŠ è½½å†å² OHLCV æ•°æ®")
        
        data_loader = DataLoader(output_dir=str(DATA_RAW_PATH))
        
        # è·å–è‚¡ç¥¨åˆ—è¡¨ï¼ˆæ ¹æ®é…ç½®é€‰æ‹©è‚¡ç¥¨æ± ï¼‰
        stock_pool = data_config.get("stock_pool", "zz500")
        
        # å°è¯•è·å–æŒ‡å®šè‚¡ç¥¨æ± çš„æˆåˆ†è‚¡
        # æ³¨æ„ï¼šDataLoader ç›®å‰åªå®ç°äº† get_hs300_constituents
        # å¯¹äºä¸­è¯500ç­‰å…¶ä»–æŒ‡æ•°ï¼Œä½¿ç”¨ AkShare ç›´æ¥è·å–
        stock_list = []
        
        if stock_pool == "zz500":
            # å°è¯•ä½¿ç”¨ AkShare ç›´æ¥è·å–ä¸­è¯500æˆåˆ†è‚¡
            try:
                import akshare as ak
                df = ak.index_stock_cons(symbol="000905")
                if df is not None and not df.empty:
                    code_col = next((c for c in df.columns if 'ä»£ç ' in c), None)
                    if code_col:
                        stock_list = df[code_col].tolist()
                        logger.info(f"è·å–ä¸­è¯500æˆåˆ†è‚¡æˆåŠŸï¼Œå…± {len(stock_list)} åª")
            except Exception as e:
                logger.warning(f"è·å–ä¸­è¯500æˆåˆ†è‚¡å¤±è´¥: {e}")
            
            if not stock_list:
                logger.warning("æ— æ³•è·å–ä¸­è¯500æˆåˆ†è‚¡ï¼Œå°è¯•è·å–æ²ªæ·±300")
                stock_list = data_loader.get_hs300_constituents()
        elif stock_pool == "hs300":
            stock_list = data_loader.get_hs300_constituents()
        elif stock_pool == "zz1000":
            # è·å–ä¸­è¯1000æˆåˆ†è‚¡
            try:
                import akshare as ak
                df = ak.index_stock_cons(symbol="000852")
                if df is not None and not df.empty:
                    code_col = next((c for c in df.columns if 'ä»£ç ' in c), None)
                    if code_col:
                        stock_list = df[code_col].tolist()
                        logger.info(f"è·å–ä¸­è¯1000æˆåˆ†è‚¡æˆåŠŸï¼Œå…± {len(stock_list)} åª")
            except Exception as e:
                logger.warning(f"è·å–ä¸­è¯1000æˆåˆ†è‚¡å¤±è´¥: {e}")
                
            if not stock_list:
                logger.warning("æ— æ³•è·å–ä¸­è¯1000æˆåˆ†è‚¡ï¼Œå°è¯•ä»æœ¬åœ°ç¼“å­˜åŠ è½½æˆ–ä½¿ç”¨ç¤ºä¾‹è‚¡ç¥¨")
                # TODO: å®ç°æœ¬åœ°ç¼“å­˜åŠ è½½é€»è¾‘
        else:
            stock_list = data_loader.get_hs300_constituents()
        
        if not stock_list:
            logger.warning("æ— æ³•è·å–æˆåˆ†è‚¡åˆ—è¡¨ï¼Œä½¿ç”¨ç¤ºä¾‹è‚¡ç¥¨")
            stock_list = ["000001", "000002", "600519", "601318", "000858",
                         "000063", "000651", "000725", "002415", "600036"]
        
        # é™åˆ¶å›æµ‹è‚¡ç¥¨æ•°é‡ï¼ˆé¿å…è¿‡é•¿æ—¶é—´ï¼‰
        max_stocks = backtest_config.get("max_stocks", 100)
        stock_list = stock_list[:max_stocks]
        logger.info(f"è‚¡ç¥¨æ± : {stock_pool}, å›æµ‹è‚¡ç¥¨æ•°é‡: {len(stock_list)}")
        
        # ä¸‹è½½å†å²æ•°æ®
        price_data_dict: Dict[str, pd.DataFrame] = {}
        start_fmt = start_date.replace("-", "")
        end_fmt = end_date.replace("-", "")
        
        # [OPTIMIZED] ä¼˜å…ˆä»æœ¬åœ°ç¼“å­˜åŠ è½½æ•°æ®
        # è·¯å¾„: data/lake/daily/{stock}.parquet
        local_cache_dir = Path("data/lake/daily")
        loaded_from_cache = 0
        
        for i, stock in enumerate(stock_list):
            df = None
            try:
                # 1. å°è¯•è¯»å–æœ¬åœ°ç¼“å­˜
                cache_file = local_cache_dir / f"{stock}.parquet"
                if cache_file.exists():
                    try:
                        cached_df = pd.read_parquet(cache_file)
                        
                        # å¤„ç†æ—¥æœŸï¼šå¯èƒ½åœ¨ 'date' åˆ—æˆ–ä½œä¸º index
                        if 'date' not in cached_df.columns:
                            # æ—¥æœŸå¯èƒ½æ˜¯ indexï¼Œå°è¯• reset_index
                            if isinstance(cached_df.index, pd.DatetimeIndex):
                                cached_df = cached_df.reset_index()
                                cached_df.columns = ['date'] + list(cached_df.columns[1:])
                            elif cached_df.index.name == 'date' or cached_df.index.name == 'trade_date':
                                cached_df = cached_df.reset_index()
                        
                        # ç¡®ä¿ date åˆ—å­˜åœ¨
                        if not cached_df.empty and 'date' in cached_df.columns:
                            cached_df['date'] = pd.to_datetime(cached_df['date'])
                            cache_start = cached_df['date'].min()
                            cache_end = cached_df['date'].max()
                            req_start = pd.to_datetime(start_date)
                            req_end = pd.to_datetime(end_date)
                            
                            # [FIX] æ”¾å®½æ—¥æœŸæ£€æŸ¥ï¼šå…è®¸ 7 å¤©çš„è¯¯å·®ï¼ˆå¤„ç†èŠ‚å‡æ—¥å’Œæ•°æ®å»¶è¿Ÿï¼‰
                            # å› ä¸ºå®é™…äº¤æ˜“æ—¥å¯èƒ½æ¯”æ—¥å†æ—¥å°‘
                            tolerance = pd.Timedelta(days=7)
                            if cache_start <= req_start and cache_end >= (req_end - tolerance):
                                # ç­›é€‰æ—¶é—´æ®µ
                                df = cached_df[(cached_df['date'] >= req_start) & (cached_df['date'] <= cache_end)].copy()
                                if not df.empty:
                                    df = df.set_index('date').sort_index()
                                    loaded_from_cache += 1
                    except Exception as e:
                        logger.debug(f"è¯»å–æœ¬åœ°ç¼“å­˜ {stock} å¤±è´¥: {e}")

                # 2. å¦‚æœæœ¬åœ°æ²¡æœ‰æˆ–ä¸æ»¡è¶³ï¼Œåˆ™ä¸‹è½½
                if df is None or df.empty:
                    df = data_loader.fetch_daily_price(stock, start_fmt, end_fmt)
                    
                    # [NEW] ä¸‹è½½æˆåŠŸåä¿å­˜åˆ°æœ¬åœ°ç¼“å­˜
                    if df is not None and not df.empty:
                        try:
                            local_cache_dir.mkdir(parents=True, exist_ok=True)
                            # ä¿å­˜æ—¶å°† index è½¬ä¸º date åˆ—
                            save_df = df.reset_index()
                            save_df.columns = ['date'] + list(save_df.columns[1:])
                            save_df.to_parquet(cache_file, index=False)
                        except Exception as e:
                            logger.debug(f"ä¿å­˜ç¼“å­˜ {stock} å¤±è´¥: {e}")
                
                if df is not None and not df.empty:
                    price_data_dict[stock] = df
            except Exception as e:
                logger.debug(f"è·å– {stock} æ•°æ®å¤±è´¥: {e}")
            
            if (i + 1) % 100 == 0:
                logger.info(f"æ•°æ®åŠ è½½è¿›åº¦: {i + 1}/{len(stock_list)} (ç¼“å­˜å‘½ä¸­: {loaded_from_cache})")
        
        if not price_data_dict:
            logger.error("æœªè·å–åˆ°ä»»ä½•å†å²æ•°æ®")
            return False
        
        logger.info(f"æˆåŠŸåŠ è½½ {len(price_data_dict)} åªè‚¡ç¥¨çš„å†å²æ•°æ®")
        
        # ========================================
        # Step 2: å‡†å¤‡ä»·æ ¼çŸ©é˜µ
        # ========================================
        logger.info("Step 2/7: å‡†å¤‡ä»·æ ¼çŸ©é˜µ")
        
        # æ„å»ºæ”¶ç›˜ä»· DataFrame (è¡Œ=æ—¥æœŸ, åˆ—=è‚¡ç¥¨)
        close_prices = {}
        for stock, df in price_data_dict.items():
            if 'close' in df.columns:
                close_prices[stock] = df['close']
        
        close_df = pd.DataFrame(close_prices)
        close_df.index = pd.to_datetime(close_df.index)
        close_df = close_df.sort_index()
        
        # å¡«å……ç¼ºå¤±å€¼
        close_df = close_df.ffill().bfill()
        
        logger.info(f"ä»·æ ¼çŸ©é˜µ: {close_df.shape[0]} å¤© x {close_df.shape[1]} åªè‚¡ç¥¨")
        
        # ========================================
        # Step 3: åŠ è½½å†å²è´¢åŠ¡æ•°æ®ï¼ˆå…³é”®ï¼šå°å¸‚å€¼å› å­éœ€è¦ circ_mvï¼‰
        # ========================================
        logger.info("Step 3/7: åŠ è½½å†å²è´¢åŠ¡æ•°æ®ï¼ˆæµé€šå¸‚å€¼ circ_mvï¼‰")
        
        financial_data: Optional[pd.DataFrame] = None
        has_financial_data = False
        
        try:
            financial_data = _load_backtest_financial_data(
                stock_list=list(price_data_dict.keys()),
                start_date=start_date,
                end_date=end_date,
                data_loader=data_loader
            )
            
            if financial_data is not None and not financial_data.empty:
                has_financial_data = 'circ_mv' in financial_data.columns
                logger.info(
                    f"è´¢åŠ¡æ•°æ®åŠ è½½æˆåŠŸ: {len(financial_data)} æ¡è®°å½•, "
                    f"circ_mv å¯ç”¨: {has_financial_data}"
                )
            else:
                logger.warning("è´¢åŠ¡æ•°æ®ä¸ºç©º")
                
        except FileNotFoundError as e:
            logger.error(f"è´¢åŠ¡æ•°æ®åŠ è½½å¤±è´¥: {e}")
            logger.error("å°å¸‚å€¼ç­–ç•¥å›æµ‹éœ€è¦è´¢åŠ¡æ•°æ®ã€‚å¦‚æœæ‚¨åªæƒ³è¿è¡ŒåŠ¨é‡ç­–ç•¥ï¼Œè¯·ç»§ç»­ï¼›å¦åˆ™è¯·å…ˆå‡†å¤‡è´¢åŠ¡æ•°æ®ã€‚")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œå…è®¸ç»§ç»­ï¼ˆé€€åŒ–ä¸ºçº¯åŠ¨é‡ç­–ç•¥ï¼‰
            financial_data = None
        except Exception as e:
            logger.warning(f"åŠ è½½è´¢åŠ¡æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}ï¼Œå°†ä½¿ç”¨çº¯åŠ¨é‡ç­–ç•¥")
            financial_data = None
        
        # ========================================
        # Step 4: è·å–åŸºå‡†æŒ‡æ•°æ•°æ®ï¼ˆç”¨äºå¤§ç›˜é£æ§ï¼‰
        # ========================================
        logger.info(f"Step 4/7: è·å–åŸºå‡†æŒ‡æ•°æ•°æ® ({benchmark_code})")
        
        benchmark_data: Optional[pd.DataFrame] = None
        
        try:
            benchmark_data = data_loader.fetch_index_price(
                index_code=benchmark_code,
                start_date=start_date,
                end_date=end_date
            )
            
            if benchmark_data is not None and not benchmark_data.empty:
                logger.info(
                    f"åŸºå‡†æŒ‡æ•°æ•°æ®è·å–æˆåŠŸ: {len(benchmark_data)} æ¡è®°å½•, "
                    f"æ—¥æœŸèŒƒå›´: {benchmark_data.index[0].strftime('%Y-%m-%d')} ~ "
                    f"{benchmark_data.index[-1].strftime('%Y-%m-%d')}"
                )
            else:
                logger.warning("åŸºå‡†æŒ‡æ•°æ•°æ®ä¸ºç©ºï¼Œå¤§ç›˜é£æ§å°†ä¸ç”Ÿæ•ˆ")
                benchmark_data = None
                
        except Exception as e:
            logger.warning(f"è·å–åŸºå‡†æŒ‡æ•°æ•°æ®å¤±è´¥: {e}ï¼Œå¤§ç›˜é£æ§å°†ä¸ç”Ÿæ•ˆ")
            benchmark_data = None
        
        # ========================================
        # Step 5: ç”Ÿæˆå› å­æ•°æ®ï¼ˆå«å°å¸‚å€¼å› å­ï¼‰
        # ========================================
        if has_financial_data:
            logger.info("Step 5/7: ç”Ÿæˆå› å­æ•°æ®ï¼ˆå«å°å¸‚å€¼å› å­ small_capï¼‰")
        else:
            logger.warning("Step 5/7: ç”Ÿæˆå› å­æ•°æ®ï¼ˆæ— è´¢åŠ¡æ•°æ®ï¼Œä»…åŠ¨é‡å› å­ï¼‰")
        
        factor_data = _generate_backtest_factor_data(
            price_data_dict=price_data_dict,
            close_df=close_df,
            strategy_config=strategy_config,
            financial_data=financial_data
        )
        
        if factor_data.empty:
            logger.error("å› å­æ•°æ®ç”Ÿæˆå¤±è´¥")
            return False
        
        # ========================================
        # Step 6: åˆå§‹åŒ–ç­–ç•¥å’Œå¼•æ“ï¼Œæ‰§è¡Œå›æµ‹
        # ========================================
        logger.info("Step 6/7: åˆå§‹åŒ–ç­–ç•¥å’Œå¼•æ“ï¼Œæ‰§è¡Œå›æµ‹")
        
        if strategy_type == "multi_factor":
            # å¤šå› å­ç­–ç•¥
            # ä»é…ç½®è¯»å–å› å­æƒé‡
            value_weight = strategy_config.get("value_weight", 0.0)
            quality_weight = strategy_config.get("quality_weight", 0.0)
            momentum_weight = strategy_config.get("momentum_weight", 1.0)
            size_weight = strategy_config.get("size_weight", 0.0)
            
            # æ ¹æ®è´¢åŠ¡æ•°æ®å¯ç”¨æ€§è°ƒæ•´ç­–ç•¥é…ç½®
            if has_financial_data:
                # è´¢åŠ¡æ•°æ®å¯ç”¨ï¼Œå¯ä»¥ä½¿ç”¨å°å¸‚å€¼ç­–ç•¥
                logger.info("è´¢åŠ¡æ•°æ®å¯ç”¨ï¼Œå¯ç”¨å°å¸‚å€¼å› å­ (small_cap)")
                
                # å¦‚æœé…ç½®äº† size_weight æˆ–ç­–ç•¥éœ€è¦å°å¸‚å€¼å› å­
                if size_weight > 0 or strategy_config.get("use_small_cap", True):
                    # ä½¿ç”¨å°å¸‚å€¼å› å­
                    value_col = strategy_config.get("value_col", "small_cap_zscore")
                    size_col = strategy_config.get("size_col", "small_cap_zscore")
                else:
                    value_col = strategy_config.get("value_col", "value_zscore")
                    size_col = strategy_config.get("size_col", "small_cap_zscore")
            else:
                # æ— è´¢åŠ¡æ•°æ®ï¼Œé€€åŒ–ä¸ºçº¯åŠ¨é‡ç­–ç•¥
                logger.warning(
                    f"æ— è´¢åŠ¡æ•°æ®ï¼Œå°å¸‚å€¼å› å­ä¸å¯ç”¨ã€‚"
                    f"è‡ªåŠ¨è°ƒæ•´ä¸ºçº¯åŠ¨é‡ç­–ç•¥ (momentum=1.0)"
                )
                # å¼ºåˆ¶è°ƒæ•´æƒé‡
                if value_weight > 0 or size_weight > 0:
                    logger.warning(
                        f"åŸé…ç½®æƒé‡ (value={value_weight}, size={size_weight}) "
                        f"å› ç¼ºå°‘è´¢åŠ¡æ•°æ®è¢«ç½®ä¸º 0"
                    )
                value_weight = 0.0
                size_weight = 0.0
                quality_weight = 0.0
                momentum_weight = 1.0
                value_col = "value_zscore"
                size_col = "small_cap_zscore"
            
            strategy = MultiFactorStrategy(
                name="Multi-Factor Backtest" + (" (å°å¸‚å€¼å¢å¼º)" if has_financial_data else " (çº¯åŠ¨é‡)"),
                config={
                    "value_weight": value_weight,
                    "quality_weight": quality_weight,
                    "momentum_weight": momentum_weight,
                    "size_weight": size_weight,
                    "top_n": strategy_config.get("top_n", 5),
                    "min_listing_days": strategy_config.get("min_listing_days", 126),
                    "rebalance_frequency": strategy_config.get("rebalance_frequency", "monthly"),
                    "rebalance_buffer": strategy_config.get("rebalance_buffer", 0.05),
                    # [NEW] æŒè‚¡æƒ¯æ€§åŠ åˆ†
                    "holding_bonus": strategy_config.get("holding_bonus", 0.0),
                    # [NEW] å¤§ç›˜é£æ§é…ç½®ï¼ˆä» risk éƒ¨åˆ†è¯»å–ï¼‰
                    "market_risk": config.get("risk", {}).get("market_risk", {}),
                    # å› å­åˆ—åé…ç½®
                    "value_col": value_col,
                    "quality_col": strategy_config.get("quality_col", "quality_zscore"),
                    "momentum_col": strategy_config.get("momentum_col", "momentum_zscore"),
                    "size_col": size_col,
                    "date_col": "date",
                    "stock_col": "stock_code",
                }
            )
            logger.info(
                f"ä½¿ç”¨å¤šå› å­ç­–ç•¥: value={value_weight}, quality={quality_weight}, "
                f"momentum={momentum_weight}, size={size_weight}, top_n={strategy.top_n}"
            )
            if has_financial_data:
                logger.info(f"å› å­åˆ—: value_col={value_col}, size_col={size_col}")
        else:
            # å‡çº¿äº¤å‰ç­–ç•¥ï¼ˆä¸æ”¯æŒæƒé‡é©±åŠ¨å›æµ‹ï¼Œä½¿ç”¨ç®€åŒ–é€»è¾‘ï¼‰
            strategy = MACrossStrategy(
                name="MA Cross Backtest",
                config={
                    "short_window": 5,
                    "long_window": 20,
                }
            )
            logger.info("ä½¿ç”¨å‡çº¿äº¤å‰ç­–ç•¥")
            logger.warning("å‡çº¿ç­–ç•¥æš‚ä¸æ”¯æŒæƒé‡é©±åŠ¨å›æµ‹ï¼Œä½¿ç”¨ç®€åŒ–é€»è¾‘")
        
        # åˆå§‹åŒ– BacktestEngine
        backtest_engine = BacktestEngine(config={
            "initial_capital": initial_capital,
            "commission": commission,
            "slippage": slippage,
            "risk_free_rate": risk_free_rate,
        })
        
        logger.info(
            f"BacktestEngine åˆå§‹åŒ–: åˆå§‹èµ„é‡‘=Â¥{initial_capital:,.0f}, "
            f"ä½£é‡‘={commission*10000:.1f}â€±, æ»‘ç‚¹={slippage*100:.2f}%"
        )
        
        # æ‰§è¡Œå›æµ‹ï¼ˆæƒé‡é©±åŠ¨æ¨¡å¼ï¼‰
        if strategy_type == "multi_factor":
            logger.info("æ‰§è¡Œæƒé‡é©±åŠ¨å›æµ‹...")
            
            result = backtest_engine.run(
                strategy=strategy,
                price_data=close_df,
                factor_data=factor_data,
                objective=optimization_objective,
                benchmark_data=benchmark_data  # ä¼ å…¥åŸºå‡†æ•°æ®ç”¨äºå¤§ç›˜é£æ§
            )
            
            total_return = result.total_return
            annual_return = result.annual_return
            sharpe_ratio = result.sharpe_ratio
            max_drawdown = result.max_drawdown
            total_trades = result.total_trades
            win_rate = result.win_rate
            
        else:
            # MA Cross ç­–ç•¥ä½¿ç”¨ç®€åŒ–å›æµ‹
            logger.warning("MA Cross ç­–ç•¥ä½¿ç”¨ç®€åŒ–å›æµ‹é€»è¾‘")
            
            # ä½¿ç”¨ç¬¬ä¸€åªè‚¡ç¥¨è¿›è¡Œå•è‚¡ç¥¨å›æµ‹æ¼”ç¤º
            stock_code = list(price_data_dict.keys())[0]
            single_price_df = price_data_dict[stock_code]
            
            # ç”Ÿæˆä¿¡å·
            signals = strategy.generate_signals(single_price_df)
            
            # ç®€åŒ–è®¡ç®—æ”¶ç›Š
            returns = single_price_df['close'].pct_change()
            strategy_returns = returns * signals.shift(1)
            
            total_return = (1 + strategy_returns).prod() - 1
            annual_return = (1 + total_return) ** (252 / len(strategy_returns)) - 1
            sharpe_ratio = strategy_returns.mean() / strategy_returns.std() * np.sqrt(252) if strategy_returns.std() > 0 else 0
            
            cum_returns = (1 + strategy_returns).cumprod()
            peak = cum_returns.expanding().max()
            drawdown = (cum_returns - peak) / peak
            max_drawdown = abs(drawdown.min())
            
            total_trades = (signals.diff().abs() > 0).sum()
            win_rate = (strategy_returns > 0).sum() / len(strategy_returns) if len(strategy_returns) > 0 else 0
        
        # ========================================
        # Step 7: ç”Ÿæˆå›æµ‹æŠ¥å‘Š
        # ========================================
        logger.info("Step 7/7: ç”Ÿæˆå›æµ‹æŠ¥å‘Š")
        
        report_content = _generate_backtest_report(
            start_date=start_date,
            end_date=end_date,
            strategy_name=strategy.name,
            total_return=total_return,
            annual_return=annual_return,
            sharpe_ratio=sharpe_ratio,
            max_drawdown=max_drawdown,
            initial_capital=initial_capital,
            num_stocks=len(close_df.columns),
        )
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = REPORTS_PATH / f"backtest_{start_date}_{end_date}.html"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logger.info(f"å›æµ‹æŠ¥å‘Šå·²ä¿å­˜è‡³ {report_path}")
        
        # ========================================
        # æ‰“å°å›æµ‹ç»“æœæ‘˜è¦
        # ========================================
        logger.info("=" * 60)
        logger.info("å›æµ‹ç»“æœæ‘˜è¦")
        logger.info("=" * 60)
        logger.info(f"å›æµ‹å¼•æ“:    BacktestEngine (æƒé‡é©±åŠ¨ + å¤§ç›˜é£æ§)")
        logger.info(f"ç­–ç•¥åç§°:    {strategy.name}")
        logger.info(f"å›æµ‹åŒºé—´:    {start_date} ~ {end_date}")
        logger.info(f"è‚¡ç¥¨æ± :      {stock_pool} ({len(close_df.columns)} åªè‚¡ç¥¨)")
        logger.info(f"è´¢åŠ¡æ•°æ®:    {'âœ“ å·²åŠ è½½ (small_cap å› å­å¯ç”¨)' if has_financial_data else 'âœ— æœªåŠ è½½ (çº¯åŠ¨é‡ç­–ç•¥)'}")
        logger.info(f"åŸºå‡†æŒ‡æ•°:    {benchmark_code} {'âœ“ å·²å¯ç”¨é£æ§' if benchmark_data is not None else 'âœ— é£æ§æœªå¯ç”¨'}")
        logger.info("-" * 60)
        logger.info(f"åˆå§‹èµ„é‡‘:    Â¥{initial_capital:,.0f}")
        logger.info(f"æ€»æ”¶ç›Šç‡:    {total_return:.2%}")
        logger.info(f"å¹´åŒ–æ”¶ç›Š:    {annual_return:.2%}")
        logger.info(f"å¤æ™®æ¯”ç‡:    {sharpe_ratio:.2f}")
        logger.info(f"æœ€å¤§å›æ’¤:    {max_drawdown:.2%}")
        if strategy_type == "multi_factor":
            logger.info(f"æ€»äº¤æ˜“æ¬¡æ•°:  {total_trades}")
            logger.info(f"èƒœç‡:        {win_rate:.2%}")
        logger.info("=" * 60)
        
        return True
        
    except Exception as e:
        logger.error(f"å›æµ‹å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False


def _generate_backtest_report(
    start_date: str,
    end_date: str,
    strategy_name: str,
    total_return: float,
    annual_return: float,
    sharpe_ratio: float,
    max_drawdown: float,
    initial_capital: float,
    num_stocks: int,
) -> str:
    """
    ç”Ÿæˆå›æµ‹æŠ¥å‘Š HTML
    
    Parameters
    ----------
    start_date : str
        å¼€å§‹æ—¥æœŸ
    end_date : str
        ç»“æŸæ—¥æœŸ
    strategy_name : str
        ç­–ç•¥åç§°
    total_return : float
        æ€»æ”¶ç›Šç‡
    annual_return : float
        å¹´åŒ–æ”¶ç›Šç‡
    sharpe_ratio : float
        å¤æ™®æ¯”ç‡
    max_drawdown : float
        æœ€å¤§å›æ’¤
    initial_capital : float
        åˆå§‹èµ„é‡‘
    num_stocks : int
        è‚¡ç¥¨æ•°é‡
    
    Returns
    -------
    str
        HTML æŠ¥å‘Šå†…å®¹
    """
    final_capital = initial_capital * (1 + total_return)
    profit = final_capital - initial_capital
    
    # è¯„çº§
    if sharpe_ratio >= 2.0:
        rating = "â­â­â­â­â­ ä¼˜ç§€"
        rating_color = "#00ff88"
    elif sharpe_ratio >= 1.5:
        rating = "â­â­â­â­ è‰¯å¥½"
        rating_color = "#88ff00"
    elif sharpe_ratio >= 1.0:
        rating = "â­â­â­ ä¸€èˆ¬"
        rating_color = "#ffff00"
    elif sharpe_ratio >= 0.5:
        rating = "â­â­ è¾ƒå·®"
        rating_color = "#ff8800"
    else:
        rating = "â­ å·®"
        rating_color = "#ff4444"
    
    html = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>å›æµ‹æŠ¥å‘Š - {strategy_name}</title>
    <style>
        * {{
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            background: linear-gradient(135deg, #0f0f23 0%, #1a1a3e 50%, #0f0f23 100%);
            color: #eee;
            min-height: 100vh;
            padding: 2rem;
        }}
        .container {{
            max-width: 1100px;
            margin: 0 auto;
        }}
        h1 {{
            font-size: 2.5rem;
            margin-bottom: 0.5rem;
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }}
        .meta {{
            color: #888;
            margin-bottom: 2rem;
            font-size: 1.1rem;
        }}
        .rating {{
            display: inline-block;
            padding: 0.5rem 1rem;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 20px;
            color: {rating_color};
            font-weight: bold;
            margin-left: 1rem;
        }}
        .card {{
            background: rgba(255, 255, 255, 0.05);
            border-radius: 16px;
            padding: 2rem;
            margin-bottom: 1.5rem;
            border: 1px solid rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
        }}
        .card h2 {{
            font-size: 1.4rem;
            margin-bottom: 1.5rem;
            color: #667eea;
        }}
        .stats-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 1.5rem;
        }}
        .stat {{
            text-align: center;
            padding: 1.5rem;
            background: linear-gradient(135deg, rgba(102, 126, 234, 0.2), rgba(118, 75, 162, 0.2));
            border-radius: 12px;
            border: 1px solid rgba(102, 126, 234, 0.3);
        }}
        .stat-value {{
            font-size: 2rem;
            font-weight: bold;
            margin-bottom: 0.5rem;
        }}
        .stat-value.positive {{
            color: #00ff88;
        }}
        .stat-value.negative {{
            color: #ff6b6b;
        }}
        .stat-value.neutral {{
            color: #667eea;
        }}
        .stat-label {{
            font-size: 0.9rem;
            color: #888;
        }}
        .info-table {{
            width: 100%;
            border-collapse: collapse;
        }}
        .info-table tr {{
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }}
        .info-table td {{
            padding: 1rem;
        }}
        .info-table td:first-child {{
            color: #888;
            width: 40%;
        }}
        .info-table td:last-child {{
            font-weight: 500;
        }}
        .footer {{
            text-align: center;
            color: #666;
            margin-top: 3rem;
            font-size: 0.9rem;
        }}
        .highlight {{
            background: linear-gradient(90deg, #667eea, #764ba2);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            font-weight: bold;
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ“ˆ ç­–ç•¥å›æµ‹æŠ¥å‘Š</h1>
        <p class="meta">
            {strategy_name}
            <span class="rating">{rating}</span>
        </p>
        
        <div class="card">
            <h2>æ ¸å¿ƒæŒ‡æ ‡</h2>
            <div class="stats-grid">
                <div class="stat">
                    <div class="stat-value {'positive' if total_return >= 0 else 'negative'}">{total_return:+.2%}</div>
                    <div class="stat-label">æ€»æ”¶ç›Šç‡</div>
                </div>
                <div class="stat">
                    <div class="stat-value {'positive' if annual_return >= 0 else 'negative'}">{annual_return:+.2%}</div>
                    <div class="stat-label">å¹´åŒ–æ”¶ç›Š</div>
                </div>
                <div class="stat">
                    <div class="stat-value neutral">{sharpe_ratio:.2f}</div>
                    <div class="stat-label">å¤æ™®æ¯”ç‡</div>
                </div>
                <div class="stat">
                    <div class="stat-value negative">{max_drawdown:.2%}</div>
                    <div class="stat-label">æœ€å¤§å›æ’¤</div>
                </div>
            </div>
        </div>
        
        <div class="card">
            <h2>èµ„é‡‘å˜åŒ–</h2>
            <div class="stats-grid">
                <div class="stat">
                    <div class="stat-value neutral">Â¥{initial_capital:,.0f}</div>
                    <div class="stat-label">åˆå§‹èµ„é‡‘</div>
                </div>
                <div class="stat">
                    <div class="stat-value {'positive' if profit >= 0 else 'negative'}">Â¥{final_capital:,.0f}</div>
                    <div class="stat-label">æœ€ç»ˆèµ„é‡‘</div>
                </div>
                <div class="stat">
                    <div class="stat-value {'positive' if profit >= 0 else 'negative'}">{'+'if profit >= 0 else ''}Â¥{profit:,.0f}</div>
                    <div class="stat-label">ç›ˆäºé‡‘é¢</div>
                </div>
            </div>
        </div>
        
        <div class="card">
            <h2>å›æµ‹ä¿¡æ¯</h2>
            <table class="info-table">
                <tr>
                    <td>ç­–ç•¥åç§°</td>
                    <td>{strategy_name}</td>
                </tr>
                <tr>
                    <td>å›æµ‹åŒºé—´</td>
                    <td>{start_date} ~ {end_date}</td>
                </tr>
                <tr>
                    <td>è‚¡ç¥¨æ•°é‡</td>
                    <td>{num_stocks} åª</td>
                </tr>
                <tr>
                    <td>æŠ¥å‘Šç”Ÿæˆæ—¶é—´</td>
                    <td>{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</td>
                </tr>
            </table>
        </div>
        
        <p class="footer">
            æœ¬æŠ¥å‘Šç”± <span class="highlight">Aè‚¡é‡åŒ–äº¤æ˜“ç³»ç»Ÿ</span> è‡ªåŠ¨ç”Ÿæˆ<br>
            ä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®
        </p>
    </div>
</body>
</html>
    """
    
    return html


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="Aè‚¡é‡åŒ–äº¤æ˜“ç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
    python main.py --daily-update              # è¿è¡Œæ¯æ—¥æ›´æ–°
    python main.py --daily-update --force      # å¼ºåˆ¶è°ƒä»“
    python main.py --backtest                  # è¿è¡Œå›æµ‹ï¼ˆé»˜è®¤å¤šå› å­ç­–ç•¥ï¼‰
    python main.py --backtest --strategy ma    # è¿è¡Œå›æµ‹ï¼ˆå‡çº¿ç­–ç•¥ï¼‰
    python main.py --backtest --start 2022-01-01 --end 2023-12-31
        """
    )
    
    parser.add_argument(
        "--daily-update", "-d",
        action="store_true",
        help="è¿è¡Œæ¯æ—¥æ›´æ–°æµç¨‹"
    )
    
    parser.add_argument(
        "--force-rebalance", "-f",
        action="store_true",
        help="å¼ºåˆ¶è°ƒä»“ï¼ˆå¿½ç•¥æ—¥æœŸæ£€æŸ¥ï¼‰"
    )
    
    parser.add_argument(
        "--backtest", "-b",
        action="store_true",
        help="è¿è¡Œå›æµ‹"
    )
    
    parser.add_argument(
        "--strategy", "-s",
        type=str,
        default="multi_factor",
        choices=["multi_factor", "ma_cross"],
        help="å›æµ‹ç­–ç•¥ç±»å‹: multi_factor(å¤šå› å­), ma_cross(å‡çº¿äº¤å‰)"
    )
    
    parser.add_argument(
        "--start",
        type=str,
        default="2023-01-01",
        help="å›æµ‹å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)"
    )
    
    parser.add_argument(
        "--end",
        type=str,
        default="2024-01-01",
        help="å›æµ‹ç»“æŸæ—¥æœŸ (YYYY-MM-DD)"
    )
    
    parser.add_argument(
        "--log-level",
        type=str,
        default="INFO",
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        help="æ—¥å¿—çº§åˆ«"
    )
    
    parser.add_argument(
        "--no-llm",
        action="store_true",
        help="ç¦ç”¨ LLM é£æ§åŠŸèƒ½ï¼ˆå¼ºåˆ¶è¦†ç›–é…ç½®ï¼‰"
    )
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    log_level = getattr(logging, args.log_level)
    log_file = LOGS_PATH / f"quant_{datetime.now().strftime('%Y%m%d')}.log"
    setup_logging(level=log_level, log_file=str(log_file))
    
    logger = logging.getLogger(__name__)
    logger.info("Aè‚¡é‡åŒ–äº¤æ˜“ç³»ç»Ÿå¯åŠ¨")
    
    if args.daily_update:
        success = run_daily_update(
            force_rebalance=args.force_rebalance,
            no_llm=args.no_llm
        )
        exit(0 if success else 1)
    
    elif args.backtest:
        logger.info(f"å›æµ‹æ¨¡å¼: {args.start} ~ {args.end}, ç­–ç•¥: {args.strategy}")
        success = run_backtest(
            start_date=args.start,
            end_date=args.end,
            strategy_type=args.strategy,
            no_llm=args.no_llm
        )
        exit(0 if success else 1)
    
    else:
        parser.print_help()
        exit(0)


if __name__ == "__main__":
    main()

