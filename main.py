#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Aè‚¡é‡åŒ–äº¤æ˜“ç³»ç»Ÿ - ä¸»å…¥å£

è¯¥æ¨¡å—ä½œä¸ºç³»ç»Ÿçš„ä¸»å…¥å£ç‚¹ï¼Œæä¾›æ¯æ—¥æ›´æ–°ã€å› å­è®¡ç®—ã€
è°ƒä»“ä¿¡å·ç”Ÿæˆå’ŒæŠ¥å‘Šè¾“å‡ºç­‰åŠŸèƒ½ã€‚

Usage
-----
    # è¿è¡Œæ¯æ—¥æ›´æ–°
    python main.py --daily-update
    # å¼ºåˆ¶è°ƒä»“ï¼ˆå¿½ç•¥æ—¥æœŸæ£€æŸ¥ï¼‰
    python main.py --daily-update --force-rebalance
    
    # ç”Ÿæˆå›æµ‹æŠ¥å‘Š
    python main.py --backtest --start 2023-01-01 --end 2024-01-01
"""
import argparse
import logging
import os
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
import json

import pandas as pd
import numpy as np

from src import (
    # æ•°æ®å¤„ç†
    AShareDataCleaner,
    DataLoader,
    TushareDataLoader,
    create_tushare_loader,
    # å› å­è®¡ç®—
    FactorCalculator,
    z_score_normalize,
    # ç­–ç•¥
    MultiFactorStrategy,
    MACrossStrategy,
    # å›æµ‹
    BacktestEngine,
    VBTProBacktester,
    # æƒé‡ä¼˜åŒ–
    optimize_weights,
    calculate_shrinkage_covariance,
    calculate_expected_returns_mean,
    # å·¥å…·
    setup_logging,
    load_config,
    send_pushplus_msg,
)

# å¯¼å…¥å› å­ IC è®¡ç®—å‡½æ•°
try:
    from src.features import calculate_factor_ic, calculate_forward_returns
except ImportError:
    calculate_factor_ic = None
    calculate_forward_returns = None

# å¯¼å…¥ LLM ç†”æ–­å™¨å¼‚å¸¸ï¼ˆç”¨äºé£æ§å¤„ç†ï¼‰
try:
    from src.llm_client import LLMCircuitBreakerError
except ImportError:
    # å®šä¹‰å›é€€ç±»ä»¥é¿å…å¯¼å…¥é”™è¯¯
    class LLMCircuitBreakerError(RuntimeError):
        """LLM ç†”æ–­å™¨è§¦å‘å¼‚å¸¸ï¼ˆå›é€€å®šä¹‰ï¼‰"""
        pass

# é…ç½®å¸¸é‡
CONFIG_PATH = Path("config/strategy_config.yaml")
DATA_RAW_PATH = Path("data/raw")
DATA_PROCESSED_PATH = Path("data/processed")
REPORTS_PATH = Path("reports")
LOGS_PATH = Path("logs")


def is_trading_day(
    date: Optional[pd.Timestamp] = None,
    tushare_loader: Optional["TushareDataLoader"] = None,
    config: Optional[Dict[str, Any]] = None
) -> bool:
    """
    æ£€æŸ¥æŒ‡å®šæ—¥æœŸæ˜¯å¦ä¸ºAè‚¡äº¤æ˜“æ—¥
    
    ä½¿ç”¨ Tushare äº¤æ˜“æ—¥å†è¿›è¡Œåˆ¤æ–­ï¼Œé¿å…å‘¨æœ«å’ŒèŠ‚å‡æ—¥è¯¯è§¦å‘æ›´æ–°æµç¨‹ã€‚
    
    Parameters
    ----------
    date : Optional[pd.Timestamp]
        è¦æ£€æŸ¥çš„æ—¥æœŸï¼Œé»˜è®¤ä¸ºä»Šå¤©
    tushare_loader : Optional[TushareDataLoader]
        Tushare æ•°æ®åŠ è½½å™¨å®ä¾‹
    config : Optional[Dict[str, Any]]
        é…ç½®å‚æ•°
    
    Returns
    -------
    bool
        True è¡¨ç¤ºæ˜¯äº¤æ˜“æ—¥ï¼ŒFalse è¡¨ç¤ºéäº¤æ˜“æ—¥
    
    Notes
    -----
    - ä¼˜å…ˆä½¿ç”¨ Tushare äº¤æ˜“æ—¥å†
    - å¦‚æœ Tushare ä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€å•çš„å‘¨æœ«åˆ¤æ–­ä½œä¸ºå›é€€
    """
    logger = logging.getLogger(__name__)
    
    if date is None:
        date = pd.Timestamp.now().normalize()
    elif isinstance(date, str):
        date = pd.Timestamp(date).normalize()
    else:
        date = date.normalize()
    
    # æ£€æŸ¥é…ç½®æ˜¯å¦å¯ç”¨äº¤æ˜“æ—¥å†æ ¡éªŒ
    if config is not None:
        calendar_config = config.get("trading_calendar", {})
        if not calendar_config.get("check_enabled", True):
            logger.debug("äº¤æ˜“æ—¥å†æ ¡éªŒå·²ç¦ç”¨ï¼Œé»˜è®¤è§†ä¸ºäº¤æ˜“æ—¥")
            return True
    
    # æ–¹æ³•1: ä½¿ç”¨ Tushare äº¤æ˜“æ—¥å†
    if tushare_loader is not None:
        try:
            # è·å–äº¤æ˜“æ—¥å†
            trade_date_str = date.strftime("%Y%m%d")
            
            # Tushare è·å–äº¤æ˜“æ—¥å† (trade_cal)
            if hasattr(tushare_loader, 'pro') and tushare_loader.pro is not None:
                # è·å–å½“æœˆçš„äº¤æ˜“æ—¥å†
                start_date = date.replace(day=1).strftime("%Y%m%d")
                end_date = (date + pd.DateOffset(months=1)).replace(day=1).strftime("%Y%m%d")
                
                cal_df = tushare_loader.pro.trade_cal(
                    exchange='SSE',
                    start_date=start_date,
                    end_date=end_date,
                    fields='cal_date,is_open'
                )
                
                if cal_df is not None and not cal_df.empty:
                    # æ£€æŸ¥æŒ‡å®šæ—¥æœŸæ˜¯å¦ä¸ºäº¤æ˜“æ—¥
                    day_info = cal_df[cal_df['cal_date'] == trade_date_str]
                    if not day_info.empty:
                        is_open = day_info.iloc[0]['is_open'] == 1
                        if not is_open:
                            logger.info(f"{date.strftime('%Y-%m-%d')} éäº¤æ˜“æ—¥ï¼ˆTushare äº¤æ˜“æ—¥å†ï¼‰")
                        return is_open
        except Exception as e:
            logger.warning(f"Tushare äº¤æ˜“æ—¥å†è·å–å¤±è´¥: {e}ï¼Œä½¿ç”¨å›é€€åˆ¤æ–­")
    
    # æ–¹æ³•2: å›é€€åˆ°ç®€å•å‘¨æœ«åˆ¤æ–­
    # å‘¨å…­=5, å‘¨æ—¥=6
    if date.dayofweek >= 5:
        logger.info(f"{date.strftime('%Y-%m-%d')} éäº¤æ˜“æ—¥ï¼ˆå‘¨æœ«ï¼‰")
        return False
    
    # å¦‚æœæ— æ³•ç¡®å®šï¼Œé»˜è®¤è§†ä¸ºäº¤æ˜“æ—¥
    logger.debug(f"{date.strftime('%Y-%m-%d')} é»˜è®¤è§†ä¸ºäº¤æ˜“æ—¥")
    return True


# ç¡®ä¿ç›®å½•å­˜åœ¨
for path in [DATA_RAW_PATH, DATA_PROCESSED_PATH, REPORTS_PATH, LOGS_PATH]:
    path.mkdir(parents=True, exist_ok=True)


class DailyUpdateRunner:
    """
    æ¯æ—¥æ›´æ–°è¿è¡Œå™¨
    
    è´Ÿè´£æ‰§è¡Œæ¯æ—¥æ•°æ®æ›´æ–°ã€å› å­è®¡ç®—ã€è°ƒä»“ä¿¡å·ç”Ÿæˆå’ŒæŠ¥å‘Šè¾“å‡ºã€‚
    
    Parameters
    ----------
    config : Optional[Dict[str, Any]]
        é…ç½®å‚æ•°
    
    Attributes
    ----------
    config : Dict[str, Any]
        é…ç½®å‚æ•°
    tushare_loader : TushareDataLoader
        Tushare æ•°æ®åŠ è½½å™¨
    strategy : MultiFactorStrategy
        å¤šå› å­ç­–ç•¥
    logger : logging.Logger
        æ—¥å¿—å™¨
    
    Examples
    --------
    >>> runner = DailyUpdateRunner()
    >>> runner.run_daily_update()
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None) -> None:
        """
        åˆå§‹åŒ–æ¯æ—¥æ›´æ–°è¿è¡Œå™¨
        
        Parameters
        ----------
        config : Optional[Dict[str, Any]]
            é…ç½®å‚æ•°
        """
        self.logger = logging.getLogger(__name__)
        
        # åŠ è½½é…ç½®
        if config is None:
            try:
                self.config = load_config(CONFIG_PATH)
            except FileNotFoundError:
                self.logger.warning(f"é…ç½®æ–‡ä»¶ {CONFIG_PATH} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                self.config = self._get_default_config()
        else:
            self.config = config
        
        # åˆå§‹åŒ–ç»„ä»¶
        self._init_components()
        
        # çŠ¶æ€å˜é‡
        self.today = pd.Timestamp.now().normalize()
        self.ohlcv_data: Optional[pd.DataFrame] = None
        self.financial_data: Optional[pd.DataFrame] = None
        self.industry_data: Optional[pd.DataFrame] = None
        self.factor_data: Optional[pd.DataFrame] = None
        self.benchmark_data: Optional[pd.DataFrame] = None  # åŸºå‡†æŒ‡æ•°æ•°æ®ï¼ˆç”¨äºå¤§ç›˜é£æ§ï¼‰
        self.current_positions: Dict[str, float] = {}
        self.target_positions: Dict[str, float] = {}
        
        # åŠ è½½å½“å‰æŒä»“
        self.load_current_holdings()
        
        self.logger.info("DailyUpdateRunner åˆå§‹åŒ–å®Œæˆ")

    def run_daily_update(self):
        """
        æ‰§è¡Œæ¯æ—¥æ•°æ®æ›´æ–°å’Œç­–ç•¥å›æµ‹çš„ä¸»æµç¨‹
        """
        self.logger.info("å¼€å§‹æ‰§è¡Œæ¯æ—¥æ›´æ–°ä»»åŠ¡...")

        # 1. è·å–æ•°æ® (ç¤ºä¾‹é€»è¾‘)
        # df = self.data_loader.get_data(...)

        # 2. æ‰§è¡Œç­–ç•¥
        # self.strategy.execute(df)

        self.logger.info("æ¯æ—¥æ›´æ–°ä»»åŠ¡å®Œæˆã€‚")
    
    def _get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "data": {
                "stock_pool": "hs300",  # æ²ªæ·±300æˆåˆ†è‚¡
                "start_date": "2020-01-01",
                "update_days": 5,  # æ¯æ¬¡æ›´æ–°æœ€è¿‘Nå¤©æ•°æ®
            },
            "strategy": {
                "name": "Multi-Factor Strategy",
                "value_weight": 0.0,
                "quality_weight": 0.0,
                "momentum_weight": 1.0,
                "top_n": 30,
                "min_listing_days": 126,
            },
            "portfolio": {
                "total_capital": 1000000,  # æ€»èµ„é‡‘100ä¸‡
                "max_weight": 0.05,  # å•è‚¡æœ€å¤§5%
                "risk_free_rate": 0.02,
                "optimization_objective": "max_sharpe",
            },
            "report": {
                "format": "markdown",  # markdown æˆ– html
                "output_dir": "reports",
            },
        }
    
    def _init_components(self) -> None:
        """åˆå§‹åŒ–å„ç»„ä»¶"""
        # ç»Ÿä¸€ä½¿ç”¨ Tushare æ•°æ®æº
        tushare_config = self.config.get("tushare", {})
        api_token = tushare_config.get("api_token") or os.environ.get("TUSHARE_TOKEN", "")
        
        if not api_token:
            self.logger.error(
                "Tushare API Token æœªé…ç½®ï¼\n"
                "è¯·åœ¨ config/strategy_config.yaml ä¸­è®¾ç½® tushare.api_token\n"
                "æˆ–é€šè¿‡ç¯å¢ƒå˜é‡ TUSHARE_TOKEN è®¾ç½®"
            )
            raise ValueError("Tushare API Token æœªé…ç½®")
        
        self.tushare_loader = TushareDataLoader(
            api_token=api_token,
            cache_dir=tushare_config.get("cache_dir", "data/tushare_cache")
        )
        self.data_source = "tushare"
        self.logger.info("ä½¿ç”¨ Tushare Pro æ•°æ®æº")
        
        self.data_cleaner = AShareDataCleaner()
        
        # å¢å¼ºç‰ˆæ•°æ®åŠ è½½å™¨ï¼ˆç”¨äºè·å–è´¢åŠ¡æ•°æ®ï¼Œå…¼å®¹æ—§ä»£ç ï¼‰
        self.financial_loader = DataLoader(
            output_dir=str(DATA_RAW_PATH),
            max_workers=3,
            retry_times=3
        )
        
        # ç­–ç•¥
        strategy_config = self.config.get("strategy", {})
        llm_config = self.config.get("llm", {})
        
        self.strategy = MultiFactorStrategy(
            name=strategy_config.get("name", "Multi-Factor Strategy"),
            config={
                # å› å­æƒé‡é…ç½®ï¼ˆä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
                "value_weight": strategy_config.get("value_weight", 0.0),
                "quality_weight": strategy_config.get("quality_weight", 0.3),
                "momentum_weight": strategy_config.get("momentum_weight", 0.4),
                "size_weight": strategy_config.get("size_weight", 0.3),
                "sentiment_weight": strategy_config.get("sentiment_weight", 0.0),  # æƒ…ç»ªå› å­æƒé‡
                "top_n": strategy_config.get("top_n", 3),
                "min_listing_days": strategy_config.get("min_listing_days", 126),
                # æ¿å—è¿‡æ»¤é…ç½®
                "exclude_chinext": strategy_config.get("exclude_chinext", False),  # æ’é™¤åˆ›ä¸šæ¿
                "exclude_star": strategy_config.get("exclude_star", False),  # æ’é™¤ç§‘åˆ›æ¿
                # å› å­åˆ—åé…ç½®ï¼ˆä»é…ç½®æ–‡ä»¶è¯»å–ï¼Œæ”¯æŒæ¿€è¿›å‹å°å¸‚å€¼ç­–ç•¥ï¼‰
                "value_col": strategy_config.get("value_col", "small_cap_zscore"),
                "quality_col": strategy_config.get("quality_col", "turnover_5d_zscore"),
                "momentum_col": strategy_config.get("momentum_col", "rsi_20_zscore"),
                "size_col": strategy_config.get("size_col", "small_cap_zscore"),
                # è°ƒä»“é…ç½®
                "rebalance_frequency": strategy_config.get("rebalance_frequency", "weekly"),
                "rebalance_buffer": strategy_config.get("rebalance_buffer", 0.02),
                # [NEW] æŒè‚¡æƒ¯æ€§åŠ åˆ†
                "holding_bonus": strategy_config.get("holding_bonus", 0.0),
                # [NEW] å¤§ç›˜é£æ§é…ç½®
                "market_risk": self.config.get("risk", {}).get("market_risk", {}),
                # LLM æƒ…ç»ªåˆ†æé…ç½®
                "llm": llm_config,
            }
        )
    
    def load_current_holdings(self) -> None:
        """
        åŠ è½½å½“å‰æŒä»“
        
        ä» data/processed/real_holdings.json æ–‡ä»¶è¯»å–æŒä»“æ•°æ®ã€‚
        å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆå§‹åŒ–ä¸ºç©ºå­—å…¸ã€‚
        
        Notes
        -----
        è¿™æ˜¯ä¸€ä¸ªåŠè‡ªåŠ¨ç³»ç»Ÿï¼Œç”¨æˆ·å¯ä»¥æ‰‹åŠ¨ä¿®æ”¹ real_holdings.json 
        æ–‡ä»¶æ¥æ ¡å‡†å®é™…æŒä»“ã€‚
        """
        holdings_path = DATA_PROCESSED_PATH / "real_holdings.json"
        
        if holdings_path.exists():
            try:
                with open(holdings_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # æå– positions å­—æ®µ
                self.current_positions = data.get("positions", {})
                
                # ç¡®ä¿å€¼ä¸º float ç±»å‹
                self.current_positions = {
                    str(k): float(v) for k, v in self.current_positions.items()
                }
                
                self.logger.info(
                    f"å·²åŠ è½½æŒä»“æ•°æ®: {len(self.current_positions)} åªè‚¡ç¥¨, "
                    f"æ€»å¸‚å€¼ Â¥{sum(self.current_positions.values()):,.0f}"
                )
                
                # æ‰“å°æŒä»“æ˜ç»†ï¼ˆè°ƒè¯•ç”¨ï¼‰
                if self.current_positions:
                    self.logger.debug(f"æŒä»“æ˜ç»†: {list(self.current_positions.keys())[:5]}...")
                    
            except json.JSONDecodeError as e:
                self.logger.warning(f"æŒä»“æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}ï¼Œåˆå§‹åŒ–ä¸ºç©ºæŒä»“")
                self.current_positions = {}
            except Exception as e:
                self.logger.warning(f"åŠ è½½æŒä»“æ–‡ä»¶å¤±è´¥: {e}ï¼Œåˆå§‹åŒ–ä¸ºç©ºæŒä»“")
                self.current_positions = {}
        else:
            self.logger.info("æŒä»“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆå§‹åŒ–ä¸ºç©ºæŒä»“")
            self.current_positions = {}
    
    def save_current_holdings(
        self,
        buy_orders: Dict[str, float],
        sell_orders: Dict[str, float]
    ) -> None:
        """
        ä¿å­˜å½“å‰æŒä»“
        
        æ ¹æ®ä¹°å…¥å’Œå–å‡ºè®¢å•æ›´æ–°æŒä»“ï¼Œå¹¶ä¿å­˜åˆ° data/processed/real_holdings.jsonã€‚
        
        Parameters
        ----------
        buy_orders : Dict[str, float]
            ä¹°å…¥è®¢å• {è‚¡ç¥¨ä»£ç : é‡‘é¢}
        sell_orders : Dict[str, float]
            å–å‡ºè®¢å• {è‚¡ç¥¨ä»£ç : é‡‘é¢}
        
        Notes
        -----
        æ›´æ–°é€»è¾‘: new_holdings = current + buy - sell
        
        è¿™æ˜¯ä¸€ä¸ªåŠè‡ªåŠ¨ç³»ç»Ÿï¼Œæˆ‘ä»¬å‡è®¾ç”¨æˆ·å®Œå…¨æ‰§è¡Œäº†ä¿¡å·ã€‚
        å®é™…æ“ä½œä¸­ï¼Œç”¨æˆ·å¯èƒ½éœ€è¦æ‰‹åŠ¨ä¿®æ”¹è¿™ä¸ª json æ–‡ä»¶æ¥æ ¡å‡†å®é™…æŒä»“ã€‚
        """
        # å¤åˆ¶å½“å‰æŒä»“
        new_positions = self.current_positions.copy()
        
        # å¤„ç†ä¹°å…¥è®¢å•
        for stock, amount in buy_orders.items():
            if stock in new_positions:
                new_positions[stock] += amount
            else:
                new_positions[stock] = amount
        
        # å¤„ç†å–å‡ºè®¢å•
        for stock, amount in sell_orders.items():
            if stock in new_positions:
                new_positions[stock] -= amount
                # å¦‚æœæŒä»“ä¸º0æˆ–è´Ÿæ•°ï¼Œåˆ é™¤è¯¥è‚¡ç¥¨
                if new_positions[stock] <= 0:
                    del new_positions[stock]
        
        # å‡†å¤‡ä¿å­˜çš„æ•°æ®
        holdings_data = {
            "update_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "update_date": self.today.strftime("%Y-%m-%d"),
            "positions": new_positions,
            "total_value": sum(new_positions.values()),
            "num_stocks": len(new_positions),
            "note": "æ­¤æ–‡ä»¶ç”±ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆï¼Œå‡è®¾ç”¨æˆ·å®Œå…¨æ‰§è¡Œäº†äº¤æ˜“ä¿¡å·ã€‚å¦‚éœ€æ ¡å‡†å®é™…æŒä»“ï¼Œè¯·æ‰‹åŠ¨ä¿®æ”¹ã€‚"
        }
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        holdings_path = DATA_PROCESSED_PATH / "real_holdings.json"
        
        try:
            with open(holdings_path, 'w', encoding='utf-8') as f:
                json.dump(holdings_data, f, ensure_ascii=False, indent=2)
            
            self.logger.info(
                f"æŒä»“å·²æ›´æ–°å¹¶ä¿å­˜: {len(new_positions)} åªè‚¡ç¥¨, "
                f"æ€»å¸‚å€¼ Â¥{sum(new_positions.values()):,.0f}"
            )
            
            # æ›´æ–°å†…å­˜ä¸­çš„æŒä»“
            self.current_positions = new_positions
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜æŒä»“æ–‡ä»¶å¤±è´¥: {e}")
    
    def update_market_data(self) -> bool:
        """
        æ›´æ–°å¸‚åœºæ•°æ®ï¼ˆå¸¦ç¼“å­˜æ£€æŸ¥ï¼‰
        
        ä½¿ç”¨ Tushare Pro è·å–å¸‚åœºæ•°æ®ã€‚
        
        Returns
        -------
        bool
            æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        self.logger.info("å¼€å§‹æ›´æ–°å¸‚åœºæ•°æ®...")
        
        try:
            # æ£€æŸ¥ä»Šæ—¥ç¼“å­˜
            ohlcv_path = DATA_RAW_PATH / f"ohlcv_{self.today.strftime('%Y%m%d')}.parquet"
            if ohlcv_path.exists():
                try:
                    self.ohlcv_data = pd.read_parquet(ohlcv_path)
                    if not self.ohlcv_data.empty:
                        self.logger.info(f"ğŸ“‚ ä½¿ç”¨ç¼“å­˜æ•°æ®: {ohlcv_path.name}ï¼Œå…± {len(self.ohlcv_data)} æ¡è®°å½•")
                        return True
                except Exception as e:
                    self.logger.warning(f"è¯»å–ç¼“å­˜å¤±è´¥: {e}ï¼Œå°†é‡æ–°ä¸‹è½½")
            
            data_config = self.config.get("data", {})
            stock_pool = data_config.get("stock_pool", "hs300")
            
            # ç¡®å®šæ—¥æœŸèŒƒå›´
            end_date = self.today.strftime("%Y%m%d")
            update_days = data_config.get("update_days", 5)
            start_date = (self.today - timedelta(days=update_days * 2)).strftime("%Y%m%d")
            
            # ä½¿ç”¨ Tushare è·å–æ•°æ®
            return self._update_market_data_tushare(stock_pool, start_date, end_date)
            
        except Exception as e:
            self.logger.error(f"æ›´æ–°å¸‚åœºæ•°æ®å¤±è´¥: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return False
    
    def _update_market_data_tushare(
        self,
        stock_pool: str,
        start_date: str,
        end_date: str
    ) -> bool:
        """ä½¿ç”¨ Tushare æ›´æ–°å¸‚åœºæ•°æ®"""
        self.logger.info(f"ä½¿ç”¨ Tushare è·å– {stock_pool} æ•°æ®...")
        
        # è·å–è‚¡ç¥¨åˆ—è¡¨ï¼ˆæ ¹æ® stock_pool ç±»å‹é€‰æ‹©ä¸åŒæ–¹æ³•ï¼‰
        if stock_pool == "all":
            # å…¨å¸‚åœºæ¨¡å¼ï¼šè·å–æ‰€æœ‰ä¸Šå¸‚è‚¡ç¥¨
            self.logger.info("å…¨å¸‚åœºæ¨¡å¼ï¼šè·å–æ‰€æœ‰ä¸Šå¸‚è‚¡ç¥¨...")
            stock_list = self.tushare_loader.fetch_all_stocks()
            if not stock_list:
                self.logger.error("æ— æ³•è·å–å…¨å¸‚åœºè‚¡ç¥¨åˆ—è¡¨")
                return False
            self.logger.warning(
                f"âš ï¸ å…¨å¸‚åœºæ¨¡å¼ï¼šå…± {len(stock_list)} åªè‚¡ç¥¨ï¼Œ"
                f"æ•°æ®ä¸‹è½½å’Œè®¡ç®—å°†è€—æ—¶è¾ƒé•¿ï¼Œè¯·è€å¿ƒç­‰å¾…"
            )
        else:
            # æŒ‡æ•°æˆåˆ†è‚¡æ¨¡å¼
            stock_list = self.tushare_loader.fetch_index_constituents(stock_pool)
            if not stock_list:
                self.logger.error(f"æ— æ³•è·å– {stock_pool} æˆåˆ†è‚¡åˆ—è¡¨")
                return False
        
        self.logger.info(f"è‚¡ç¥¨æ± : {stock_pool}, è‚¡ç¥¨æ•°é‡: {len(stock_list)}")
        
        # æ‰¹é‡è·å–æ—¥çº¿æ•°æ®
        self.ohlcv_data = self.tushare_loader.fetch_daily_data_batch(
            stock_list, start_date, end_date
        )
        
        if self.ohlcv_data is None or self.ohlcv_data.empty:
            self.logger.error("æœªè·å–åˆ°ä»»ä½• OHLCV æ•°æ®")
            return False
        
        self.logger.info(f"OHLCV æ•°æ®æ›´æ–°å®Œæˆï¼Œå…± {len(self.ohlcv_data)} æ¡è®°å½•")
        
        # ä¿å­˜æ•°æ®
        ohlcv_path = DATA_RAW_PATH / f"ohlcv_{self.today.strftime('%Y%m%d')}.parquet"
        self.ohlcv_data.to_parquet(ohlcv_path)
        self.logger.info(f"OHLCV æ•°æ®å·²ä¿å­˜è‡³ {ohlcv_path}")
        
        # ä¿å­˜æˆåˆ†è‚¡åˆ—è¡¨ä¾›åç»­ä½¿ç”¨
        self._current_stock_list = stock_list
        
        return True
    
    def update_financial_data(self) -> bool:
        """
        æ›´æ–°è´¢åŠ¡æ•°æ®ï¼ˆå®ç›˜å®‰å…¨ç‰ˆï¼Œå¸¦ç¼“å­˜æ£€æŸ¥ï¼‰
        
        ä½¿ç”¨ DataLoader.fetch_financial_indicator è·å–çœŸå®çš„ PEã€PBã€ROE ç­‰æ•°æ®ã€‚
        é‡‡ç”¨ Fail Fast æœºåˆ¶ï¼Œç¡®ä¿å®ç›˜å®‰å…¨ï¼š
        - ä¸ä½¿ç”¨ä»»ä½•è™šå‡/å¤‡ç”¨æ•°æ®å¡«å……
        - å¤±è´¥è‚¡ç¥¨æ ‡è®°ä¸ºæ— æ•ˆï¼Œä»é€‰è‚¡æ± ä¸­å‰”é™¤
        - å¤±è´¥ç‡è¶…è¿‡é˜ˆå€¼æ—¶ç»ˆæ­¢ç¨‹åºå¹¶æŠ¥è­¦
        
        Returns
        -------
        bool
            æ›´æ–°æ˜¯å¦æˆåŠŸ
        
        Raises
        ------
        RuntimeError
            å½“è´¢åŠ¡æ•°æ®è·å–å¤±è´¥ç‡è¶…è¿‡ 30% æ—¶
        """
        self.logger.info("å¼€å§‹æ›´æ–°è´¢åŠ¡æ•°æ®ï¼ˆå®ç›˜å®‰å…¨æ¨¡å¼ï¼‰...")
        
        # æ£€æŸ¥ä»Šæ—¥ç¼“å­˜
        financial_path = DATA_RAW_PATH / f"financial_{self.today.strftime('%Y%m%d')}.parquet"
        if financial_path.exists():
            try:
                self.financial_data = pd.read_parquet(financial_path)
                if not self.financial_data.empty:
                    self.logger.info(f"ğŸ“‚ ä½¿ç”¨ç¼“å­˜æ•°æ®: {financial_path.name}ï¼Œå…± {len(self.financial_data)} æ¡è®°å½•")
                    return True
            except Exception as e:
                self.logger.warning(f"è¯»å–ç¼“å­˜å¤±è´¥: {e}ï¼Œå°†é‡æ–°ä¸‹è½½")
        
        # ä½¿ç”¨ Tushare è·å–è´¢åŠ¡æ•°æ®
        return self._update_financial_data_tushare()
    
    def _update_financial_data_tushare(self) -> bool:
        """ä½¿ç”¨ Tushare æ›´æ–°è´¢åŠ¡æ•°æ®"""
        try:
            if self.ohlcv_data is None:
                self.logger.warning("OHLCV æ•°æ®ä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆè´¢åŠ¡æ•°æ®")
                return False
            
            stocks = self.ohlcv_data['stock_code'].unique().tolist()
            total_stocks = len(stocks)
            self.logger.info(f"ä½¿ç”¨ Tushare è·å– {total_stocks} åªè‚¡ç¥¨çš„è´¢åŠ¡æ•°æ®...")
            
            # æ–¹å¼1ï¼šä½¿ç”¨ daily_basic ä¸€æ¬¡è·å–å…¨å¸‚åœºä¼°å€¼æ•°æ®ï¼ˆé«˜æ•ˆï¼‰
            self.logger.info("è·å–æ¯æ—¥åŸºç¡€æŒ‡æ ‡ (PE, PB, å¸‚å€¼)...")
            basic_df = self.tushare_loader.fetch_daily_basic(stock_list=stocks)
            
            if basic_df is not None and not basic_df.empty:
                self.logger.info(f"æ¯æ—¥åŸºç¡€æŒ‡æ ‡è·å–æˆåŠŸ: {len(basic_df)} æ¡")
            else:
                self.logger.warning("æ¯æ—¥åŸºç¡€æŒ‡æ ‡è·å–å¤±è´¥ï¼Œå°†é€åªè·å–")
                basic_df = pd.DataFrame()
            
            # æ–¹å¼2ï¼šæ‰¹é‡è·å–è´¢åŠ¡æŒ‡æ ‡ï¼ˆROE ç­‰ï¼‰
            self.logger.info("è·å–è´¢åŠ¡æŒ‡æ ‡ (ROE, æ¯›åˆ©ç‡ç­‰)...")
            fina_df = self.tushare_loader.fetch_financial_batch(stocks, show_progress=True)
            
            # åˆå¹¶æ•°æ®ï¼ˆé¿å…é‡å¤åˆ—ï¼‰
            if not basic_df.empty:
                if not fina_df.empty:
                    # ä» fina_df ä¸­åªå– basic_df ä¸­ä¸å­˜åœ¨çš„åˆ— + stock_code
                    fina_cols = ['stock_code', 'roe', 'roe_dt']
                    # æ£€æŸ¥æ˜¯å¦æœ‰ gross_margin/net_marginï¼Œä¸” basic_df ä¸­æ²¡æœ‰
                    for col in ['gross_margin', 'net_margin']:
                        if col in fina_df.columns and col not in basic_df.columns:
                            fina_cols.append(col)
                    
                    # ç¡®ä¿åªé€‰æ‹©å­˜åœ¨çš„åˆ—
                    fina_cols = [c for c in fina_cols if c in fina_df.columns]
                    
                    merged_df = basic_df.merge(
                        fina_df[fina_cols],
                        on='stock_code',
                        how='left'
                    )
                else:
                    merged_df = basic_df
            elif not fina_df.empty:
                merged_df = fina_df
            else:
                self.logger.error("æ— æ³•è·å–ä»»ä½•è´¢åŠ¡æ•°æ®")
                return False
            
            # å»é™¤é‡å¤åˆ—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            merged_df = merged_df.loc[:, ~merged_df.columns.duplicated()]
            
            # æ ‡å‡†åŒ–åˆ—å
            if 'stock_code' not in merged_df.columns and 'ts_code' in merged_df.columns:
                merged_df['stock_code'] = merged_df['ts_code'].str[:6]
            
            # æ·»åŠ æ•°æ®æœ‰æ•ˆæ€§æ ‡è®°
            mv_cols = [c for c in ['circ_mv', 'total_mv'] if c in merged_df.columns]
            if mv_cols:
                merged_df['data_valid'] = merged_df[mv_cols].notna().any(axis=1)
            else:
                merged_df['data_valid'] = True
            
            # ä¼°ç®—ä¸Šå¸‚å¤©æ•°
            merged_df['listing_days'] = merged_df['stock_code'].apply(self._estimate_listing_days)
            
            self.financial_data = merged_df
            self._excluded_stocks = set()
            
            # ä¿å­˜æ•°æ®
            financial_path = DATA_RAW_PATH / f"financial_{self.today.strftime('%Y%m%d')}.parquet"
            self.financial_data.to_parquet(financial_path)
            
            valid_count = self.financial_data['data_valid'].sum()
            self.logger.info(
                f"âœ… è´¢åŠ¡æ•°æ®æ›´æ–°å®Œæˆ (Tushare):\n"
                f"   æ€»è®°å½•: {len(self.financial_data)}\n"
                f"   æœ‰æ•ˆæ•°æ®: {valid_count}\n"
                f"   PEæœ‰æ•ˆ: {self.financial_data['pe_ttm'].notna().sum()}\n"
                f"   ROEæœ‰æ•ˆ: {self.financial_data['roe'].notna().sum() if 'roe' in self.financial_data.columns else 0}"
            )
            
            return True
            
        except Exception as e:
            self.logger.error(f"Tushare è´¢åŠ¡æ•°æ®è·å–å¤±è´¥: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return False
    
    def _safe_get_value(
        self,
        data: pd.Series,
        keys: List[str],
        default: Any = np.nan
    ) -> Any:
        """
        å®‰å…¨åœ°ä» Series ä¸­è·å–å€¼
        
        Parameters
        ----------
        data : pd.Series
            æ•°æ®åºåˆ—
        keys : List[str]
            å¯èƒ½çš„é”®ååˆ—è¡¨
        default : Any
            é»˜è®¤å€¼
        
        Returns
        -------
        Any
            è·å–åˆ°çš„å€¼æˆ–é»˜è®¤å€¼
        """
        for key in keys:
            if key in data.index:
                val = data[key]
                if pd.notna(val):
                    try:
                        return float(val)
                    except (ValueError, TypeError):
                        continue
        return default
    
    def _load_fallback_financial_data(
        self, 
        required_stocks: List[str]
    ) -> Optional[pd.DataFrame]:
        """
        åŠ è½½å†å²è´¢åŠ¡æ•°æ®ä½œä¸ºç½‘ç»œå¤±è´¥æ—¶çš„å¤‡ä»½
        
        æŒ‰æ—¥æœŸå€’åºæŸ¥æ‰¾æœ€è¿‘çš„è´¢åŠ¡æ•°æ®æ–‡ä»¶ï¼Œè¿‡æ»¤å‡ºå½“å‰éœ€è¦çš„è‚¡ç¥¨ã€‚
        
        Parameters
        ----------
        required_stocks : List[str]
            éœ€è¦è´¢åŠ¡æ•°æ®çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨
        
        Returns
        -------
        Optional[pd.DataFrame]
            å†å²è´¢åŠ¡æ•°æ®ï¼Œå¦‚æœæ— å¯ç”¨æ•°æ®è¿”å› None
        """
        # æŸ¥æ‰¾å†å²è´¢åŠ¡æ•°æ®æ–‡ä»¶
        financial_files = sorted(
            DATA_RAW_PATH.glob("financial_*.parquet"),
            reverse=True  # æœ€æ–°çš„ä¼˜å…ˆ
        )
        
        if not financial_files:
            self.logger.warning("æœªæ‰¾åˆ°å†å²è´¢åŠ¡æ•°æ®æ–‡ä»¶")
            return None
        
        # å°è¯•åŠ è½½æœ€è¿‘çš„æ–‡ä»¶
        for file_path in financial_files[:5]:  # æœ€å¤šå°è¯•5ä¸ªæ–‡ä»¶
            try:
                df = pd.read_parquet(file_path)
                
                if df.empty or 'stock_code' not in df.columns:
                    continue
                
                # è¿‡æ»¤å‡ºéœ€è¦çš„è‚¡ç¥¨
                required_set = set(required_stocks)
                df_filtered = df[df['stock_code'].isin(required_set)]
                
                if len(df_filtered) == 0:
                    continue
                
                coverage = len(df_filtered) / len(required_set)
                file_date = file_path.stem.replace("financial_", "")
                
                self.logger.info(
                    f"ğŸ“‚ åŠ è½½å†å²è´¢åŠ¡æ•°æ®: {file_path.name}\n"
                    f"   æ•°æ®æ—¥æœŸ: {file_date}\n"
                    f"   è¦†ç›–ç‡: {len(df_filtered)}/{len(required_set)} ({coverage:.1%})"
                )
                
                # è¦†ç›–ç‡å¤ªä½åˆ™è·³è¿‡
                if coverage < 0.5:
                    self.logger.warning(f"è¦†ç›–ç‡è¿‡ä½ ({coverage:.1%})ï¼Œå°è¯•å…¶ä»–æ–‡ä»¶")
                    continue
                
                return df_filtered
                
            except Exception as e:
                self.logger.debug(f"åŠ è½½ {file_path} å¤±è´¥: {e}")
                continue
        
        return None
    
    def _estimate_listing_days(self, stock: str) -> int:
        """
        ä¼°ç®—è‚¡ç¥¨ä¸Šå¸‚å¤©æ•°ï¼ˆå¿«é€Ÿç‰ˆæœ¬ï¼‰
        
        ä½¿ç”¨è‚¡ç¥¨ä»£ç å‰ç¼€å¿«é€Ÿä¼°ç®—ï¼Œé¿å…é€åª API è°ƒç”¨ã€‚
        æ²ªæ·±300æˆåˆ†è‚¡é€šå¸¸éƒ½æ˜¯ä¸Šå¸‚å¤šå¹´çš„è“ç­¹è‚¡ã€‚
        
        Parameters
        ----------
        stock : str
            è‚¡ç¥¨ä»£ç 
        
        Returns
        -------
        int
            ä¼°ç®—çš„ä¸Šå¸‚å¤©æ•°
        """
        # å¯¹äºæ²ªæ·±300æˆåˆ†è‚¡ï¼Œé»˜è®¤å‡è®¾ä¸Šå¸‚è¶…è¿‡2å¹´ï¼ˆç¬¦åˆåŸºæœ¬æ¡ä»¶ï¼‰
        # è¿™é¿å…äº†é€åªè°ƒç”¨ API çš„æ€§èƒ½é—®é¢˜
        return 1000  # é»˜è®¤è¿”å›è¾ƒå¤§å€¼ï¼Œè¡¨ç¤ºå·²ä¸Šå¸‚è¾ƒé•¿æ—¶é—´
    
    def _generate_fallback_financial_data(self, stocks: List[str]) -> List[Dict[str, Any]]:
        """
        [å·²åºŸå¼ƒ] ä¸ºè·å–å¤±è´¥çš„è‚¡ç¥¨ç”Ÿæˆå¤‡ç”¨è´¢åŠ¡æ•°æ®
        
        æ­¤æ–¹æ³•å·²è¢«åºŸå¼ƒï¼Œå®ç›˜ç¯å¢ƒä¸‹ç¦æ­¢ä½¿ç”¨è™šå‡æ•°æ®å¡«å……ã€‚
        è°ƒç”¨æ­¤æ–¹æ³•å°†æŠ›å‡º RuntimeErrorã€‚
        
        Parameters
        ----------
        stocks : List[str]
            è‚¡ç¥¨ä»£ç åˆ—è¡¨
        
        Returns
        -------
        List[Dict[str, Any]]
            ä¸ä¼šè¿”å›ï¼Œç›´æ¥æŠ›å‡ºå¼‚å¸¸
        
        Raises
        ------
        RuntimeError
            å§‹ç»ˆæŠ›å‡ºï¼Œç¦æ­¢ä½¿ç”¨å¤‡ç”¨æ•°æ®
        
        Notes
        -----
        å®ç›˜å®‰å…¨ç­–ç•¥ï¼š
        - å¤±è´¥è‚¡ç¥¨åº”ç›´æ¥ä»é€‰è‚¡æ± ä¸­å‰”é™¤ï¼Œè€Œéç”¨è™šå‡æ•°æ®å¡«å……
        - ä½¿ç”¨ä¸­ä½æ•°/é»˜è®¤å€¼å¡«å……å¯èƒ½å¯¼è‡´é€‰è‚¡å¤±çœŸï¼Œé€ æˆå®ç›˜äºæŸ
        - æ­£ç¡®åšæ³•ï¼šåœ¨ calculate_factors æ—¶è¿‡æ»¤æ‰ data_valid=False çš„è‚¡ç¥¨
        """
        error_msg = (
            f"ğŸš¨ å®‰å…¨è­¦å‘Š: ç¦æ­¢ä½¿ç”¨å¤‡ç”¨è´¢åŠ¡æ•°æ®!\n"
            f"   è¯·æ±‚å¡«å…… {len(stocks)} åªè‚¡ç¥¨çš„è™šå‡æ•°æ®ã€‚\n"
            f"   å®ç›˜ç¯å¢ƒä¸‹ï¼Œè¿™å¯èƒ½å¯¼è‡´ä¸¥é‡çš„é€‰è‚¡å¤±çœŸã€‚\n"
            f"   æ­£ç¡®åšæ³•ï¼šå°†è¿™äº›è‚¡ç¥¨ä»é€‰è‚¡æ± ä¸­å‰”é™¤ã€‚\n"
            f"   è‚¡ç¥¨åˆ—è¡¨: {stocks[:5]}..."
        )
        self.logger.critical(error_msg)
        raise RuntimeError(error_msg)
    
    def _clean_financial_data(self) -> None:
        """
        æ¸…æ´—è´¢åŠ¡æ•°æ®
        
        å¤„ç†å¼‚å¸¸å€¼å’Œç¼ºå¤±å€¼ã€‚
        """
        if self.financial_data is None or self.financial_data.empty:
            return
        
        # PE å¼‚å¸¸å€¼å¤„ç†ï¼šè´Ÿå€¼è®¾ä¸º NaNï¼Œè¶…å¤§å€¼æˆªæ–­
        if 'pe_ttm' in self.financial_data.columns:
            self.financial_data.loc[self.financial_data['pe_ttm'] <= 0, 'pe_ttm'] = np.nan
            self.financial_data.loc[self.financial_data['pe_ttm'] > 500, 'pe_ttm'] = 500
        
        # PB å¼‚å¸¸å€¼å¤„ç†
        if 'pb' in self.financial_data.columns:
            self.financial_data.loc[self.financial_data['pb'] <= 0, 'pb'] = np.nan
            self.financial_data.loc[self.financial_data['pb'] > 50, 'pb'] = 50
        
        # ROE å¼‚å¸¸å€¼å¤„ç†
        if 'roe' in self.financial_data.columns:
            self.financial_data.loc[self.financial_data['roe'] < -1, 'roe'] = -1
            self.financial_data.loc[self.financial_data['roe'] > 1, 'roe'] = 1
        
        # è‚¡æ¯ç‡å¼‚å¸¸å€¼å¤„ç†
        if 'dividend_yield' in self.financial_data.columns:
            self.financial_data.loc[self.financial_data['dividend_yield'] < 0, 'dividend_yield'] = 0
            self.financial_data.loc[self.financial_data['dividend_yield'] > 0.20, 'dividend_yield'] = 0.20
        
        self.logger.debug("è´¢åŠ¡æ•°æ®æ¸…æ´—å®Œæˆ")
    
    def _fetch_industry_data(self, stocks: List[str]) -> pd.DataFrame:
        """
        è·å–è¡Œä¸šåˆ†ç±»æ•°æ®
        
        Parameters
        ----------
        stocks : List[str]
            è‚¡ç¥¨ä»£ç åˆ—è¡¨
        
        Returns
        -------
        pd.DataFrame
            è¡Œä¸šåˆ†ç±»æ•°æ®
        """
        self.logger.info("è·å–è¡Œä¸šåˆ†ç±»æ•°æ®...")
        
        try:
            # ä½¿ç”¨ Tushare è·å–è¡Œä¸šåˆ†ç±»
            industry_mapping = self.tushare_loader.fetch_industry_mapping()
            
            if industry_mapping:
                # æ„å»ºè‚¡ç¥¨åˆ°è¡Œä¸šçš„ DataFrame
                stock_industry = {s: industry_mapping.get(s, 'å…¶ä»–') for s in stocks}
                
                result = pd.DataFrame([
                    {'stock_code': k, 'sw_industry_l1': v}
                    for k, v in stock_industry.items()
                ])
                
                self.logger.info(f"è¡Œä¸šåˆ†ç±»æ•°æ®è·å–æˆåŠŸï¼Œå…± {len(result)} æ¡è®°å½•")
                return result
            
        except Exception as e:
            self.logger.warning(f"è·å–çœŸå®è¡Œä¸šæ•°æ®å¤±è´¥: {e}ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
        
        # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨æ¨¡æ‹Ÿè¡Œä¸šæ•°æ®
        industries = ['é“¶è¡Œ', 'éé“¶é‡‘è', 'é£Ÿå“é¥®æ–™', 'åŒ»è¯ç”Ÿç‰©', 'ç”µå­', 
                     'è®¡ç®—æœº', 'å®¶ç”¨ç”µå™¨', 'æ±½è½¦', 'æˆ¿åœ°äº§', 'å»ºç­‘ææ–™']
        
        return pd.DataFrame({
            'stock_code': list(stocks),
            'sw_industry_l1': np.random.choice(industries, len(stocks))
        })
    
    def update_benchmark_data(self) -> bool:
        """
        æ›´æ–°åŸºå‡†æŒ‡æ•°æ•°æ®ï¼ˆç”¨äºå¤§ç›˜é£æ§ï¼‰
        
        è·å–æ²ªæ·±300æŒ‡æ•°æ•°æ®ï¼Œç”¨äºè®¡ç®—MA20é£æ§æŒ‡æ ‡ã€‚
        
        Returns
        -------
        bool
            æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        self.logger.info("å¼€å§‹æ›´æ–°åŸºå‡†æŒ‡æ•°æ•°æ®ï¼ˆæ²ªæ·±300ï¼‰...")
        
        try:
            data_config = self.config.get("data", {})
            start_date = data_config.get("start_date", "2020-01-01")
            end_date = self.today.strftime("%Y-%m-%d")
            
            # ä½¿ç”¨ DataLoader è·å–æ²ªæ·±300æŒ‡æ•°æ•°æ®
            self.benchmark_data = self.financial_loader.fetch_index_price(
                index_code="000300",
                start_date=start_date,
                end_date=end_date
            )
            
            if self.benchmark_data is not None and not self.benchmark_data.empty:
                self.logger.info(
                    f"åŸºå‡†æŒ‡æ•°æ•°æ®æ›´æ–°å®Œæˆï¼Œå…± {len(self.benchmark_data)} æ¡è®°å½•ï¼Œ"
                    f"æ—¥æœŸèŒƒå›´: {self.benchmark_data.index[0].strftime('%Y-%m-%d')} ~ "
                    f"{self.benchmark_data.index[-1].strftime('%Y-%m-%d')}"
                )
                return True
            else:
                self.logger.warning("æœªè·å–åˆ°åŸºå‡†æŒ‡æ•°æ•°æ®ï¼Œå¤§ç›˜é£æ§å°†ä¸ç”Ÿæ•ˆ")
                return False
                
        except Exception as e:
            self.logger.warning(f"æ›´æ–°åŸºå‡†æŒ‡æ•°æ•°æ®å¤±è´¥: {e}ï¼Œå¤§ç›˜é£æ§å°†ä¸ç”Ÿæ•ˆ")
            self.benchmark_data = None
            return False
    
    def is_market_risk_triggered(self) -> bool:
        """
        æ£€æŸ¥å¤§ç›˜é£æ§æ˜¯å¦è§¦å‘
        
        ä»é…ç½®æ–‡ä»¶è¯»å–é£æ§å‚æ•°ï¼š
        - ma_period: å‡çº¿å‘¨æœŸï¼ˆé»˜è®¤60ï¼Œå³MA60ç‰›ç†Šçº¿ï¼‰
        - drop_threshold: è·Œå¹…é˜ˆå€¼ï¼ˆé»˜è®¤0.05ï¼Œå³5%ï¼‰
        - drop_lookback: è·Œå¹…å›æº¯å¤©æ•°ï¼ˆé»˜è®¤20ï¼‰
        
        é£æ§è§¦å‘æ¡ä»¶ï¼ˆæ»¡è¶³ä»»ä¸€å³è§¦å‘ï¼ŒOR é€»è¾‘ï¼‰ï¼š
        1. æ”¶ç›˜ä»· < MA{ma_period}ï¼ˆè·Œç ´å‡çº¿ï¼‰
        2. ï¼ˆå¯é€‰ï¼‰è¿‘{drop_lookback}æ—¥è·Œå¹… > {drop_threshold}
        
        Returns
        -------
        bool
            True è¡¨ç¤ºé£æ§è§¦å‘ï¼ˆåº”ç©ºä»“ï¼‰ï¼ŒFalse è¡¨ç¤ºæ­£å¸¸
        
        Notes
        -----
        é£æ§å‚æ•°ä» config['risk']['market_risk'] ä¸­è¯»å–ï¼Œæ”¯æŒåŠ¨æ€é…ç½®ã€‚
        ä½¿ç”¨ OR é€»è¾‘å¯é¿å…ç¼“æ…¢é˜´è·Œçš„ç†Šå¸‚ä¸­æ— æ³•è§¦å‘é£æ§çš„é—®é¢˜ã€‚
        """
        # è¯»å–é£æ§é…ç½®
        risk_config = self.config.get("risk", {})
        market_risk_config = risk_config.get("market_risk", {})
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨é£æ§
        if not market_risk_config.get("enabled", True):
            self.logger.debug("å¤§ç›˜é£æ§å·²ç¦ç”¨")
            return False
        
        # è¯»å–é£æ§å‚æ•°ï¼ˆä»é…ç½®æ–‡ä»¶ï¼Œæ”¯æŒåŠ¨æ€è°ƒæ•´ï¼‰
        ma_period = market_risk_config.get("ma_period", 60)  # é»˜è®¤ä½¿ç”¨ MA60
        drop_threshold = market_risk_config.get("drop_threshold", 0.05)  # é»˜è®¤ 5%
        drop_lookback = market_risk_config.get("drop_lookback", 20)  # é»˜è®¤ 20 å¤©
        
        if self.benchmark_data is None or self.benchmark_data.empty:
            self.logger.debug("æ— åŸºå‡†æ•°æ®ï¼Œé£æ§æ£€æŸ¥è·³è¿‡")
            return False
        
        try:
            # è·å–è¶³å¤Ÿçš„å†å²æ•°æ®ç”¨äºè®¡ç®—å‡çº¿
            required_days = max(ma_period, drop_lookback) + 1
            latest_data = self.benchmark_data.tail(required_days)
            
            if len(latest_data) < ma_period:
                self.logger.debug(
                    f"åŸºå‡†æ•°æ®ä¸è¶³ {ma_period} å¤©ï¼ˆå½“å‰ {len(latest_data)} å¤©ï¼‰ï¼Œ"
                    f"é£æ§æ£€æŸ¥è·³è¿‡"
                )
                return False
            
            # è®¡ç®—ç§»åŠ¨å¹³å‡çº¿ï¼ˆä½¿ç”¨é…ç½®çš„å‘¨æœŸï¼‰
            ma_value = latest_data['close'].tail(ma_period).mean()
            latest_close = latest_data['close'].iloc[-1]
            
            # æ¡ä»¶1ï¼šè·Œç ´å‡çº¿
            is_below_ma = latest_close < ma_value
            
            # æ¡ä»¶2ï¼šè®¡ç®—è¿‘æœŸè·Œå¹…ï¼ˆå¯é€‰æ¡ä»¶ï¼‰
            is_drop_exceeded = False
            recent_drop = 0.0
            
            if drop_threshold > 0 and len(latest_data) >= drop_lookback:
                lookback_data = latest_data.tail(drop_lookback)
                if len(lookback_data) >= 2:
                    start_price = lookback_data['close'].iloc[0]
                    end_price = lookback_data['close'].iloc[-1]
                    recent_drop = (end_price - start_price) / start_price
                    is_drop_exceeded = recent_drop < -drop_threshold
            
            # ç»¼åˆåˆ¤æ–­ï¼šè·Œç ´å‡çº¿ æˆ– è·Œå¹…è¶…è¿‡é˜ˆå€¼ï¼ˆä»»ä¸€æ»¡è¶³å³è§¦å‘é£æ§ï¼‰
            # åŸé€»è¾‘ä½¿ç”¨ ANDï¼Œä¼šå¯¼è‡´ç¼“æ…¢é˜´è·Œæ—¶æ— æ³•è§¦å‘ï¼Œéå¸¸å±é™©
            # æ–°é€»è¾‘ä½¿ç”¨ ORï¼šåªè¦è·Œç ´å‡çº¿ï¼Œæˆ–è€…å‘ç”Ÿæš´è·Œï¼Œéƒ½è§†ä¸ºé£é™©
            if drop_threshold > 0:
                is_triggered = is_below_ma or is_drop_exceeded
            else:
                is_triggered = is_below_ma
            
            # ä¼˜åŒ–çš„æ—¥å¿—è¾“å‡º
            ma_label = f"MA{ma_period}"
            deviation_pct = (latest_close - ma_value) / ma_value * 100
            
            if is_triggered:
                self.logger.warning(
                    f"ğŸš¨ å¤§ç›˜é£æ§è§¦å‘!\n"
                    f"   å½“å‰ç‚¹ä½: {latest_close:.2f} | {ma_label}: {ma_value:.2f} | "
                    f"åç¦»: {deviation_pct:+.2f}%\n"
                    f"   è¿‘{drop_lookback}æ—¥è·Œå¹…: {recent_drop*100:+.2f}% | "
                    f"é˜ˆå€¼: -{drop_threshold*100:.1f}%"
                )
            else:
                status = "âœ…" if latest_close >= ma_value else "âš ï¸"
                self.logger.info(
                    f"{status} å¤§ç›˜é£æ§æ£€æŸ¥: "
                    f"ç‚¹ä½ {latest_close:.2f} vs {ma_label} {ma_value:.2f} "
                    f"(åç¦» {deviation_pct:+.2f}%) | "
                    f"è¿‘{drop_lookback}æ—¥å˜åŒ–: {recent_drop*100:+.2f}%"
                )
                
                # å¦‚æœæ¥è¿‘è§¦å‘æ¡ä»¶ï¼Œé¢å¤–è­¦å‘Š
                if is_below_ma and not is_drop_exceeded:
                    self.logger.warning(
                        f"   âš ï¸ å·²è·Œç ´ {ma_label}ï¼Œä½†è·Œå¹… ({recent_drop*100:+.2f}%) "
                        f"æœªè¾¾é˜ˆå€¼ (-{drop_threshold*100:.1f}%)ï¼Œç»§ç»­è§‚å¯Ÿ"
                    )
            
            return is_triggered
            
        except Exception as e:
            self.logger.warning(f"é£æ§æ£€æŸ¥å¤±è´¥: {e}")
            import traceback
            self.logger.debug(traceback.format_exc())
            return False
    
    def calculate_factors(self) -> bool:
        """
        è®¡ç®—å› å­æ•°æ®ï¼ˆå®ç›˜å®‰å…¨ç‰ˆï¼‰
        
        åŒ…å«ä»¥ä¸‹å®‰å…¨æœºåˆ¶ï¼š
        - è¿‡æ»¤æ‰è´¢åŠ¡æ•°æ®è·å–å¤±è´¥çš„è‚¡ç¥¨
        - å°†æ— æ•ˆæ•°æ®çš„è‚¡ç¥¨å› å­å¾—åˆ†è®¾ä¸º -infï¼Œç¡®ä¿ä¸ä¼šè¢«é€‰ä¸­
        
        Returns
        -------
        bool
            è®¡ç®—æ˜¯å¦æˆåŠŸ
        """
        self.logger.info("å¼€å§‹è®¡ç®—å› å­ï¼ˆå®ç›˜å®‰å…¨æ¨¡å¼ï¼‰...")
        
        try:
            # å³ä½¿è´¢åŠ¡æ•°æ®æ›´æ–°å¤±è´¥ï¼Œå¦‚æœOHLCVæ•°æ®å­˜åœ¨ï¼Œä»ç»§ç»­æ‰§è¡Œå› å­è®¡ç®—
            if self.ohlcv_data is None:
                self.logger.warning("æ•°æ®ä¸å®Œæ•´ï¼Œæ— æ³•è®¡ç®—å› å­")
                return False
            
            # å¦‚æœè´¢åŠ¡æ•°æ®ä¸ºç©ºï¼Œå°è¯•ä½¿ç”¨ç©ºDataFrameç»§ç»­
            if self.financial_data is None:
                self.logger.warning("è´¢åŠ¡æ•°æ®ä¸ºç©ºï¼Œå°†è·³è¿‡è´¢åŠ¡å› å­è®¡ç®—")
                self.financial_data = pd.DataFrame()

            # å‡†å¤‡æ•°æ®
            ohlcv = self.ohlcv_data.copy()
            
            # ========== åˆ—åæ ‡å‡†åŒ–ï¼ˆå…¼å®¹ Tushare åŸå§‹æ ¼å¼ï¼‰ ==========
            column_mapping = {
                'trade_date': 'date',
                'vol': 'volume',
                'pct_chg': 'pct_change',
            }
            ohlcv.rename(columns=column_mapping, inplace=True)
            
            # ç¡®ä¿æ—¥æœŸåˆ—å­˜åœ¨ï¼ˆå¤„ç† DatetimeIndex å’Œå„ç§åˆ—åæƒ…å†µï¼‰
            if 'date' not in ohlcv.columns:
                if 'trade_date' in ohlcv.columns:
                    ohlcv['date'] = pd.to_datetime(ohlcv['trade_date'])
                elif 'æ—¥æœŸ' in ohlcv.columns:
                    ohlcv['date'] = pd.to_datetime(ohlcv['æ—¥æœŸ'])
                elif isinstance(ohlcv.index, pd.DatetimeIndex):
                    ohlcv = ohlcv.reset_index()
                    # é‡å‘½åç´¢å¼•åˆ—ä¸º 'date'
                    if ohlcv.columns[0] in ['index', 'date', 'æ—¥æœŸ']:
                        ohlcv.rename(columns={ohlcv.columns[0]: 'date'}, inplace=True)
                    else:
                        ohlcv['date'] = ohlcv.index
                else:
                    self.logger.warning("æ— æ³•æ‰¾åˆ°æ—¥æœŸåˆ—ï¼Œå°è¯•ä»æ•°æ®ç»“æ„æ¨æ–­...")
                    # å°è¯•é‡ç½®ç´¢å¼•
                    ohlcv = ohlcv.reset_index()
                    if 'index' in ohlcv.columns:
                        ohlcv.rename(columns={'index': 'date'}, inplace=True)
            
            # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
            required_cols = ['close', 'stock_code']
            missing_cols = [c for c in required_cols if c not in ohlcv.columns]
            if missing_cols:
                self.logger.error(f"OHLCV æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
                self.logger.info(f"å½“å‰åˆ—å: {ohlcv.columns.tolist()}")
                return False
            
            # ç¡®ä¿ date åˆ—æ˜¯ datetime ç±»å‹
            if 'date' in ohlcv.columns:
                ohlcv['date'] = pd.to_datetime(ohlcv['date'])
            
            # ========== å®ç›˜å®‰å…¨ï¼šè¿‡æ»¤æ‰è¢«æ’é™¤çš„è‚¡ç¥¨ ==========
            excluded_stocks = getattr(self, '_excluded_stocks', set())
            if excluded_stocks:
                original_count = len(ohlcv['stock_code'].unique())
                ohlcv = ohlcv[~ohlcv['stock_code'].isin(excluded_stocks)]
                filtered_count = len(ohlcv['stock_code'].unique())
                self.logger.info(
                    f"ğŸ›¡ï¸ å®‰å…¨è¿‡æ»¤: å·²å‰”é™¤ {original_count - filtered_count} åª"
                    f"è´¢åŠ¡æ•°æ®æ— æ•ˆçš„è‚¡ç¥¨ï¼ˆå‰©ä½™ {filtered_count} åªï¼‰"
                )
            
            # åˆå¹¶è´¢åŠ¡æ•°æ® (ä»…åœ¨è´¢åŠ¡æ•°æ®å­˜åœ¨æ—¶åˆå¹¶ï¼Œé¿å…ç¡¬ä¾èµ–)
            if self.financial_data is not None and not self.financial_data.empty:
                # åªåˆå¹¶æœ‰æ•ˆæ•°æ®
                valid_financial = self.financial_data.copy()
                if 'data_valid' in valid_financial.columns:
                    invalid_count = (~valid_financial['data_valid']).sum()
                    if invalid_count > 0:
                        self.logger.warning(
                            f"ğŸ›¡ï¸ è´¢åŠ¡æ•°æ®ä¸­æœ‰ {invalid_count} æ¡æ— æ•ˆè®°å½•ï¼Œå°†è¢«æ ‡è®°"
                        )
                
                # ç§»é™¤è´¢åŠ¡æ•°æ®ä¸­ä¸ OHLCV é‡å¤çš„åˆ—ï¼ˆé¿å…åˆå¹¶å†²çªï¼‰
                ohlcv_cols = set(ohlcv.columns) - {'stock_code'}  # æ’é™¤ stock_codeï¼Œå®ƒéœ€è¦ä¿ç•™ç”¨äºåˆå¹¶
                cols_to_keep = [c for c in valid_financial.columns if c not in ohlcv_cols]
                valid_financial = valid_financial[cols_to_keep]
                
                factor_data = ohlcv.merge(
                    valid_financial,
                    on='stock_code',
                    how='left'
                )
            else:
                factor_data = ohlcv.copy()
            
            # åˆå¹¶è¡Œä¸šæ•°æ®
            if self.industry_data is not None:
                factor_data = factor_data.merge(
                    self.industry_data,
                    on='stock_code',
                    how='left'
                )
            
            # ==================== å› å­è®¡ç®— ====================
            # æ ¹æ®ç­–ç•¥é…ç½®åŠ¨æ€è®¡ç®—æ‰€éœ€å› å­
            
            # 1. åŠ¨é‡å› å­ RSI_20ï¼ˆæ‰€æœ‰ç­–ç•¥é€šç”¨ï¼‰
            factor_data['rsi_20'] = factor_data.groupby('stock_code')['close'].transform(
                lambda x: self._calculate_rsi(x, 20)
            )
            
            # 1.5. åŠ¨é‡å› å­ ROC_20ï¼ˆ20æ—¥å˜åŠ¨ç‡ï¼‰
            factor_data['roc_20'] = factor_data.groupby('stock_code')['close'].transform(
                lambda x: x.pct_change(20) * 100  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
            )
            
            # 2. å°å¸‚å€¼å› å­ small_capï¼ˆæ¿€è¿›å‹ç­–ç•¥ä½¿ç”¨ï¼‰
            # small_cap = -log(æµé€šå¸‚å€¼)ï¼Œå¸‚å€¼è¶Šå°åˆ†æ•°è¶Šé«˜
            if 'circ_mv' in factor_data.columns:
                factor_data['small_cap'] = -np.log(factor_data['circ_mv'].replace(0, np.nan))
                factor_data['small_cap'] = factor_data['small_cap'].replace([np.inf, -np.inf], np.nan)
            elif 'total_mv' in factor_data.columns:
                factor_data['small_cap'] = -np.log(factor_data['total_mv'].replace(0, np.nan))
                factor_data['small_cap'] = factor_data['small_cap'].replace([np.inf, -np.inf], np.nan)
            else:
                factor_data['small_cap'] = np.nan
            
            # 3. æ¢æ‰‹ç‡å› å­ turnover_5dï¼ˆæ¿€è¿›å‹ç­–ç•¥ä½¿ç”¨ï¼‰
            # æ”¯æŒå¤šç§åˆ—åï¼šturn æˆ– turnover
            turn_col = None
            if 'turn' in factor_data.columns:
                turn_col = 'turn'
            elif 'turnover' in factor_data.columns:
                turn_col = 'turnover'
            elif 'turnover_rate' in factor_data.columns:
                turn_col = 'turnover_rate'
            
            if turn_col is not None:
                factor_data['turnover_5d'] = factor_data.groupby('stock_code')[turn_col].transform(
                    lambda x: x.rolling(5, min_periods=1).mean()
                )
                self.logger.debug(f"ä½¿ç”¨ '{turn_col}' åˆ—è®¡ç®—æ¢æ‰‹ç‡å› å­")
            else:
                factor_data['turnover_5d'] = np.nan
                self.logger.warning("æœªæ‰¾åˆ°æ¢æ‰‹ç‡åˆ— (turn/turnover/turnover_rate)ï¼Œæ¢æ‰‹ç‡å› å­å°†ä¸º NaN")
            
            # ========== HS300 æ·±åº¦ä»·å€¼ç­–ç•¥å› å­ ==========
            # ä½¿ç”¨ FactorCalculator çš„æ–¹æ³•è®¡ç®—å¤åˆå› å­
            from src.features import FactorCalculator
            
            # 4.1 å¤åˆä»·å€¼å› å­ï¼ˆEP + BPï¼‰
            try:
                # åˆ›å»ºä¸´æ—¶ FactorCalculator å®ä¾‹
                temp_ohlcv = factor_data[['stock_code', 'close', 'open', 'high', 'low', 'volume']].copy()
                if 'date' in factor_data.columns:
                    temp_ohlcv['date'] = factor_data['date']
                    temp_ohlcv = temp_ohlcv.set_index('date')
                
                temp_fin = factor_data[['stock_code', 'pe_ttm', 'pb', 'roe']].copy() if all(
                    col in factor_data.columns for col in ['pe_ttm', 'pb']
                ) else pd.DataFrame()
                
                if not temp_fin.empty:
                    # æ‰‹åŠ¨è°ƒç”¨ä»·å€¼å› å­è®¡ç®—é€»è¾‘ï¼ˆä¸åˆ›å»ºå®Œæ•´ FactorCalculatorï¼‰
                    # EP Ratio = 1 / PE_TTM
                    pe_ttm = pd.to_numeric(factor_data['pe_ttm'], errors='coerce')
                    pe_ttm = pe_ttm.replace(0, np.nan).where(pe_ttm > 0, np.nan)
                    factor_data['ep_ratio'] = 1.0 / pe_ttm
                    factor_data['ep_ratio'] = factor_data['ep_ratio'].replace([np.inf, -np.inf], np.nan)
                    
                    # BP Ratio = 1 / PB
                    pb = pd.to_numeric(factor_data['pb'], errors='coerce')
                    pb = pb.replace(0, np.nan).where(pb > 0, np.nan)
                    factor_data['bp_ratio'] = 1.0 / pb
                    factor_data['bp_ratio'] = factor_data['bp_ratio'].replace([np.inf, -np.inf], np.nan)
                    
                    self.logger.debug(f"ä»·å€¼å› å­è®¡ç®—å®Œæˆ: EPæœ‰æ•ˆ={factor_data['ep_ratio'].notna().mean():.1%}, BPæœ‰æ•ˆ={factor_data['bp_ratio'].notna().mean():.1%}")
                else:
                    factor_data['ep_ratio'] = np.nan
                    factor_data['bp_ratio'] = np.nan
                    self.logger.warning("è´¢åŠ¡æ•°æ®ç¼ºå°‘ pe_ttm/pb åˆ—ï¼Œä»·å€¼å› å­å°†ä¸º NaN")
            except Exception as e:
                self.logger.warning(f"å¤åˆä»·å€¼å› å­è®¡ç®—å¤±è´¥: {e}")
                factor_data['ep_ratio'] = np.nan
                factor_data['bp_ratio'] = np.nan
            
            # 4.2 ä¼ ç»Ÿ EP_TTM
            if 'pe_ttm' in factor_data.columns:
                factor_data['ep_ttm'] = 1.0 / factor_data['pe_ttm'].replace(0, np.nan)
                factor_data['ep_ttm'] = factor_data['ep_ttm'].replace([np.inf, -np.inf], np.nan)
            else:
                factor_data['ep_ttm'] = np.nan
            
            # æ–°å¢ï¼šROC_20 åŠ¨é‡å› å­è®¡ç®—
            # ä½¿ç”¨ numba åŠ é€Ÿçš„ roc æ–¹æ³•ï¼ˆå¦‚æœ features æ¨¡å—æœ‰æä¾›ï¼Œå¦åˆ™ä½¿ç”¨ pandasï¼‰
            # è¿™é‡Œç®€å•ä½¿ç”¨ pandas å®ç°
            try:
                # å…¼å®¹æ—§é€»è¾‘ï¼šå¦‚æœä¹‹å‰è®¡ç®—è¿‡ï¼Œè¿™é‡Œä¸ä¼šæŠ¥é”™ä½†ä¹Ÿä¸ä¼šè¦†ç›–ï¼ˆé™¤éä½¿ç”¨ assignï¼‰
                # æ³¨æ„ï¼šcalculate_factors ä¸­çš„ factor_data æ˜¯åˆå¹¶äº† financial_data çš„å¤§è¡¨
                # åº”è¯¥æŒ‰ stock_code åˆ†ç»„è®¡ç®—
                factor_data['roc_20'] = factor_data.groupby('stock_code')['close'].transform(
                    lambda x: x.pct_change(20) * 100
                )
                self.logger.debug(f"æ‰‹åŠ¨è®¡ç®— roc_20 å®Œæˆ (calculate_factors)ï¼Œæœ‰æ•ˆç‡: {factor_data['roc_20'].notna().mean():.1%}")
            except Exception as e:
                self.logger.warning(f"æ‰‹åŠ¨è®¡ç®— roc_20 å¤±è´¥ (calculate_factors): {e}")
                factor_data['roc_20'] = np.nan

            # 5. è´¨é‡å› å­ç»„ï¼ˆROE ç›ˆåˆ©èƒ½åŠ›ï¼‰
            # 5.1 ROE å› å­ï¼ˆç›´æ¥ä½¿ç”¨ï¼Œè¶Šé«˜è¶Šå¥½ï¼‰
            if 'roe' in factor_data.columns:
                # ROE å·²ç»å­˜åœ¨ï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®
                factor_data['roe'] = pd.to_numeric(factor_data['roe'], errors='coerce')
                factor_data['roe_stability'] = factor_data['roe']
                self.logger.debug(f"ROE å› å­å°±ç»ªï¼Œæœ‰æ•ˆç‡: {factor_data['roe'].notna().mean():.1%}")
            else:
                factor_data['roe'] = np.nan
                factor_data['roe_stability'] = np.nan
                self.logger.warning("è´¢åŠ¡æ•°æ®ä¸­æœªæ‰¾åˆ° ROE åˆ—ï¼Œè´¨é‡å› å­å°†ä¸º NaN")
            
            # 6. ç‰¹è´¨æ³¢åŠ¨ç‡ IVOLï¼ˆé£é™©å› å­ï¼‰
            factor_data['ivol'] = factor_data.groupby('stock_code')['close'].transform(
                lambda x: x.pct_change().rolling(20).std() * np.sqrt(252)
            )
            # é‡å‘½åä¸ºä¸å›æµ‹ä¸€è‡´çš„åˆ—å
            factor_data['ivol_20'] = factor_data['ivol']
            
            # 7. Sharpe åŠ¨é‡å› å­ï¼ˆæ ¸å¿ƒåŠ¨é‡å› å­ï¼‰
            # sharpe_20 = 20æ—¥æ”¶ç›Š / 20æ—¥æ³¢åŠ¨ç‡
            def _calc_sharpe(close_series: pd.Series, period: int) -> pd.Series:
                """è®¡ç®— Sharpe é£æ ¼åŠ¨é‡å› å­"""
                returns = close_series.pct_change()
                mean_ret = returns.rolling(period, min_periods=max(5, period // 2)).mean()
                std_ret = returns.rolling(period, min_periods=max(5, period // 2)).std()
                # é¿å…é™¤é›¶
                sharpe = mean_ret / (std_ret + 1e-8)
                return sharpe
            
            factor_data['sharpe_20'] = factor_data.groupby('stock_code')['close'].transform(
                lambda x: _calc_sharpe(x, 20)
            )
            factor_data['sharpe_60'] = factor_data.groupby('stock_code')['close'].transform(
                lambda x: _calc_sharpe(x, 60)
            )
            self.logger.debug(f"Sharpe å› å­è®¡ç®—å®Œæˆ: sharpe_20 æœ‰æ•ˆç‡ {factor_data['sharpe_20'].notna().mean():.1%}, sharpe_60 æœ‰æ•ˆç‡ {factor_data['sharpe_60'].notna().mean():.1%}")
            
            # ==================== Z-Score æ ‡å‡†åŒ– ====================
            date_col = 'date' if 'date' in factor_data.columns else 'trade_date'
            
            # å¯¹æ‰€æœ‰è®¡ç®—çš„å› å­è¿›è¡Œ Z-Score æ ‡å‡†åŒ–
            factor_cols_to_normalize = [
                'rsi_20', 'roc_20', 'small_cap', 'turnover_5d', 
                'ep_ttm', 'ep_ratio', 'bp_ratio',          # ä»·å€¼å› å­
                'roe_stability', 'roe',                    # è´¨é‡å› å­
                'ivol_20', 'sharpe_20', 'sharpe_60'        # åŠ¨é‡/é£é™©å› å­
            ]
            # åªæ ‡å‡†åŒ–å­˜åœ¨ä¸”æœ‰æ•ˆçš„å› å­åˆ—
            valid_factor_cols = [
                col for col in factor_cols_to_normalize 
                if col in factor_data.columns and factor_data[col].notna().any()
            ]
            
            self.logger.info(f"å‡†å¤‡æ ‡å‡†åŒ–çš„å› å­åˆ—: {valid_factor_cols}")
            if 'roc_20' not in valid_factor_cols:
                self.logger.warning(f"roc_20 ä¸åœ¨æ ‡å‡†åŒ–åˆ—è¡¨ä¸­! Columns: {factor_data.columns.tolist()}")
                if 'roc_20' in factor_data.columns:
                    self.logger.warning(f"roc_20 æ•°æ®æ¦‚è§ˆ: {factor_data['roc_20'].describe()}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è¡Œä¸šå­—æ®µï¼Œå†³å®šæ˜¯å¦è¿›è¡Œè¡Œä¸šä¸­æ€§åŒ–
            has_industry = 'sw_industry_l1' in factor_data.columns and factor_data['sw_industry_l1'].notna().any()
            
            factor_data = z_score_normalize(
                factor_data,
                factor_cols=valid_factor_cols,
                date_col=date_col,
                industry_col='sw_industry_l1' if has_industry else None,
                industry_neutral=has_industry
            )
            
            if has_industry:
                self.logger.info(f"å·²æ ‡å‡†åŒ–å› å­ï¼ˆè¡Œä¸šä¸­æ€§åŒ–ï¼‰: {valid_factor_cols}")
            else:
                self.logger.info(f"å·²æ ‡å‡†åŒ–å› å­ï¼ˆå¸‚åœºä¸­æ€§åŒ–ï¼‰: {valid_factor_cols}")
            
            # ==================== å› å­åˆ«åæ˜ å°„ ====================
            # å°†æ ‡å‡†åŒ–åçš„å› å­æ˜ å°„åˆ°ç­–ç•¥é…ç½®ä½¿ç”¨çš„åˆ—å
            # æ”¯æŒå¤šç§ç­–ç•¥é…ç½®ï¼šä¸­è¯1000åŠ¨é‡ç­–ç•¥ã€HS300ä»·å€¼ç­–ç•¥ç­‰
            factor_alias_mapping = {
                # åŠ¨é‡å› å­åˆ«å
                'sharpe_20_zscore': 'sharpe_20_zscore',
                'sharpe_60_zscore': 'sharpe_60_zscore',
                'momentum_zscore': 'roc_20_zscore',  # é»˜è®¤åŠ¨é‡å› å­
                # è´¨é‡å› å­åˆ«å
                'ivol_zscore': 'ivol_20_zscore',  # ä½æ³¢åŠ¨è´¨é‡å› å­
                'quality_zscore': 'roe_stability_zscore',  # é»˜è®¤è´¨é‡å› å­
                'roe_zscore': 'roe_zscore',  # ROE è´¨é‡å› å­ï¼ˆHS300ä»·å€¼ç­–ç•¥ï¼‰
                'turnover_5d_zscore': 'turnover_5d_zscore',
                # ä»·å€¼å› å­åˆ«å
                'value_zscore': 'ep_ttm_zscore',  # å•ä¸€ä»·å€¼å› å­
                'ep_zscore': 'ep_ratio_zscore',  # EP ä»·å€¼å› å­
                'bp_zscore': 'bp_ratio_zscore',  # BP ä»·å€¼å› å­
                # å°å¸‚å€¼å› å­åˆ«å
                'size_zscore': 'small_cap_zscore',
            }
            
            # è®¡ç®—å¤åˆä»·å€¼å› å­ï¼ˆEP + BP çš„åŠ æƒå¹³å‡ï¼‰
            ep_col = 'ep_ratio_zscore' if 'ep_ratio_zscore' in factor_data.columns else None
            bp_col = 'bp_ratio_zscore' if 'bp_ratio_zscore' in factor_data.columns else None
            
            if ep_col and bp_col:
                ep_valid = factor_data[ep_col].notna() & (factor_data[ep_col] != 0)
                bp_valid = factor_data[bp_col].notna() & (factor_data[bp_col] != 0)
                
                if ep_valid.any() and bp_valid.any():
                    factor_data['value_composite_zscore'] = (
                        0.5 * factor_data[ep_col].fillna(0) + 
                        0.5 * factor_data[bp_col].fillna(0)
                    )
                    self.logger.debug("å¤åˆä»·å€¼å› å­ value_composite_zscore è®¡ç®—å®Œæˆ")
                elif ep_valid.any():
                    factor_data['value_composite_zscore'] = factor_data[ep_col].fillna(0)
                    self.logger.debug("å¤åˆä»·å€¼å› å­ä½¿ç”¨ EP å•å› å­")
                elif bp_valid.any():
                    factor_data['value_composite_zscore'] = factor_data[bp_col].fillna(0)
                    self.logger.debug("å¤åˆä»·å€¼å› å­ä½¿ç”¨ BP å•å› å­")
                else:
                    factor_data['value_composite_zscore'] = 0.0
                    self.logger.warning("æ— æ³•è®¡ç®—å¤åˆä»·å€¼å› å­ï¼ˆEP/BP æ•°æ®å‡æ— æ•ˆï¼‰")
            else:
                factor_data['value_composite_zscore'] = 0.0
                self.logger.warning("ç¼ºå°‘ ep_ratio_zscore/bp_ratio_zscoreï¼Œå¤åˆä»·å€¼å› å­ä¸º 0")
            
            # ==================== è®¡ç®— Alpha å› å­ï¼ˆé‡ä»·é…åˆ + æŒ¯å¹… + èƒŒç¦» + æ³¢åŠ¨ç‡ + æ•ˆç‡ï¼‰====================
            # å‡çº§ç‰ˆ Alpha å› å­ç»„
            alpha_enabled = False
            date_col = 'date' if 'date' in factor_data.columns else 'trade_date'
            
            try:
                # Alpha_001: (Close - VWAP) / VWAPï¼Œæ­£å€¼è¡¨ç¤ºæ”¶ç›˜ä»·é«˜äºå‡ä»·
                if 'amount' in factor_data.columns and 'volume' in factor_data.columns:
                    vwap = factor_data['amount'] / factor_data['volume'].replace(0, np.nan)
                    factor_data['alpha_001'] = (factor_data['close'] - vwap) / vwap.replace(0, np.nan)
                    factor_data['alpha_001'] = factor_data['alpha_001'].replace([np.inf, -np.inf], np.nan)
                    alpha_enabled = True
                else:
                    factor_data['alpha_001'] = np.nan
                
                # Alpha_002: ä»·æ ¼æŒ¯å¹… = (High - Low) / Close
                if 'high' in factor_data.columns and 'low' in factor_data.columns:
                    factor_data['alpha_002'] = (factor_data['high'] - factor_data['low']) / factor_data['close'].replace(0, np.nan)
                    factor_data['alpha_002'] = factor_data['alpha_002'].replace([np.inf, -np.inf], np.nan)
                else:
                    factor_data['alpha_002'] = np.nan
                
                # Alpha_003: é‡ä»·èƒŒç¦» = ä»·æ ¼å˜åŒ–5æ—¥ - æˆäº¤é‡å˜åŒ–5æ—¥
                if 'close' in factor_data.columns and 'volume' in factor_data.columns:
                    factor_data['price_change_5d'] = factor_data.groupby('stock_code')['close'].pct_change(5)
                    factor_data['volume_change_5d'] = factor_data.groupby('stock_code')['volume'].pct_change(5)
                    factor_data['alpha_003'] = factor_data['price_change_5d'] - factor_data['volume_change_5d']
                    factor_data['alpha_003'] = factor_data['alpha_003'].replace([np.inf, -np.inf], np.nan)
                    factor_data.drop(columns=['price_change_5d', 'volume_change_5d'], inplace=True, errors='ignore')
                else:
                    factor_data['alpha_003'] = np.nan
                
                # Alpha_005: å°¾ç›˜å¼ºåº¦ = (Close - Low) / (High - Low)
                if 'high' in factor_data.columns and 'low' in factor_data.columns:
                    range_hl = factor_data['high'] - factor_data['low']
                    factor_data['alpha_005'] = (factor_data['close'] - factor_data['low']) / range_hl.replace(0, np.nan)
                    factor_data['alpha_005'] = factor_data['alpha_005'].replace([np.inf, -np.inf], np.nan).clip(0, 1)
                else:
                    factor_data['alpha_005'] = np.nan
                
                # IVOL_20: ç‰¹è´¨æ³¢åŠ¨ç‡ = 20æ—¥æ”¶ç›Šç‡æ ‡å‡†å·®ï¼ˆå¹´åŒ–ï¼‰
                if 'close' in factor_data.columns:
                    factor_data['returns'] = factor_data.groupby('stock_code')['close'].pct_change()
                    factor_data['ivol_20'] = factor_data.groupby('stock_code')['returns'].transform(
                        lambda x: x.rolling(20, min_periods=10).std() * np.sqrt(252)
                    )
                    factor_data['ivol_20'] = factor_data['ivol_20'].replace([np.inf, -np.inf], np.nan)
                    factor_data.drop(columns=['returns'], inplace=True, errors='ignore')
                else:
                    factor_data['ivol_20'] = np.nan
                
                # Efficiency_20: è·¯å¾„æ•ˆç‡ = |ç›´çº¿è·ç¦»| / å®é™…è·¯å¾„
                if 'close' in factor_data.columns:
                    factor_data['close_shift_20'] = factor_data.groupby('stock_code')['close'].shift(20)
                    factor_data['direct_distance'] = (factor_data['close'] - factor_data['close_shift_20']).abs()
                    factor_data['price_diff'] = factor_data.groupby('stock_code')['close'].diff().abs()
                    factor_data['actual_path'] = factor_data.groupby('stock_code')['price_diff'].transform(
                        lambda x: x.rolling(20, min_periods=10).sum()
                    )
                    factor_data['efficiency_20'] = factor_data['direct_distance'] / factor_data['actual_path'].replace(0, np.nan)
                    factor_data['efficiency_20'] = factor_data['efficiency_20'].replace([np.inf, -np.inf], np.nan).clip(0, 1)
                    factor_data.drop(columns=['close_shift_20', 'direct_distance', 'price_diff', 'actual_path'], inplace=True, errors='ignore')
                else:
                    factor_data['efficiency_20'] = np.nan
                
                # å¯¹æ‰€æœ‰ Alpha å› å­è¿›è¡Œ Z-Score æ ‡å‡†åŒ–ï¼ˆæ¨ªæˆªé¢ï¼‰
                for col in ['alpha_001', 'alpha_002', 'alpha_003', 'alpha_005', 'ivol_20', 'efficiency_20']:
                    zscore_col = f'{col}_zscore'
                    if col in factor_data.columns and factor_data[col].notna().any():
                        if date_col in factor_data.columns:
                            factor_data[zscore_col] = factor_data.groupby(date_col)[col].transform(
                                lambda x: (x - x.mean()) / (x.std() + 1e-8)
                            ).fillna(0)
                        else:
                            factor_data[zscore_col] = (
                                (factor_data[col] - factor_data[col].mean()) / 
                                (factor_data[col].std() + 1e-8)
                            ).fillna(0)
                    else:
                        factor_data[zscore_col] = 0.0
                
                self.logger.info("Alpha å› å­è®¡ç®—å®Œæˆ: Î±001(VWAP), Î±002(æŒ¯å¹…), Î±003(èƒŒç¦»), Î±005(å°¾ç›˜), IVOL, Efficiency")
                
            except Exception as e:
                for col in ['alpha_001', 'alpha_002', 'alpha_003', 'alpha_005', 'ivol_20', 'efficiency_20']:
                    factor_data[f'{col}_zscore'] = 0.0
                self.logger.warning(f"Alpha å› å­è®¡ç®—å¤±è´¥: {e}")
            
            # ==================== è®¡ç®—å¤åˆåŠ¨é‡å› å­ momentum_composite_zscore ====================
            # å‡çº§ç‰ˆé…æ–¹ v2: 
            # 30% ROC + 20% Sharpe + 15% Î±001 + 10% Î±002 + 10% Î±005 + 10% Efficiency - 5% Î±003(èƒŒç¦»)
            roc_col = 'roc_20_zscore' if 'roc_20_zscore' in factor_data.columns else None
            sharpe_col = 'sharpe_20_zscore' if 'sharpe_20_zscore' in factor_data.columns else None
            
            if roc_col and sharpe_col and alpha_enabled:
                # å‡çº§ç‰ˆå®Œæ•´é…æ–¹ v2
                factor_data['momentum_composite_zscore'] = (
                    0.30 * factor_data[roc_col].fillna(0) +                           # ä»·æ ¼åŠ¨é‡
                    0.20 * factor_data[sharpe_col].fillna(0) +                        # é£é™©è°ƒæ•´åŠ¨é‡
                    0.15 * factor_data['alpha_001_zscore'].fillna(0) +                # VWAP é…åˆ
                    0.10 * factor_data['alpha_002_zscore'].fillna(0) +                # ä»·æ ¼æŒ¯å¹…
                    0.10 * factor_data['alpha_005_zscore'].fillna(0) +                # å°¾ç›˜å¼ºåº¦
                    0.10 * factor_data['efficiency_20_zscore'].fillna(0) +            # è·¯å¾„æ•ˆç‡
                    0.05 * (-factor_data['alpha_003_zscore'].fillna(0))               # é‡ä»·èƒŒç¦»æƒ©ç½šï¼ˆåå‘ï¼‰
                )
                self.logger.info("ğŸš€ å¤åˆåŠ¨é‡å› å­ v2 å®Œæˆ: 30% ROC + 20% Sharpe + 15% Î±001 + 10% Î±002 + 10% Î±005 + 10% Eff - 5% Î±003")
            elif roc_col and sharpe_col:
                # å¤‡é€‰é…æ–¹: 60% ROC + 40% Sharpe
                factor_data['momentum_composite_zscore'] = (
                    0.6 * factor_data[roc_col].fillna(0) +
                    0.4 * factor_data[sharpe_col].fillna(0)
                )
                self.logger.info("å¤åˆåŠ¨é‡å› å­è®¡ç®—å®Œæˆ: 60% ROC + 40% Sharpeï¼ˆæ—  Alphaï¼‰")
            elif roc_col:
                factor_data['momentum_composite_zscore'] = factor_data[roc_col].fillna(0)
                self.logger.warning("å¤åˆåŠ¨é‡å› å­ä½¿ç”¨ ROC å•å› å­")
            else:
                factor_data['momentum_composite_zscore'] = 0.0
                self.logger.warning("æ— æ³•è®¡ç®—å¤åˆåŠ¨é‡å› å­ï¼ˆç¼ºå°‘å¿…è¦å› å­ï¼‰")
            
            # ==================== è®¡ç®—å¤åˆè´¨é‡å› å­ quality_composite_zscore ====================
            # å‡çº§ç‰ˆé…æ–¹: 50% æ¢æ‰‹ç‡ + 30% ä½æ³¢åŠ¨ (IVOLåå‘) + 20% è·¯å¾„æ•ˆç‡
            turnover_col = 'turnover_5d_zscore'
            if turnover_col in factor_data.columns and factor_data[turnover_col].notna().any():
                turnover_component = factor_data[turnover_col].fillna(0)
            else:
                turnover_component = 0.0
            
            # IVOL åå‘ä½¿ç”¨ï¼ˆä½æ³¢åŠ¨æ›´å¥½ï¼‰
            ivol_component = -factor_data['ivol_20_zscore'].fillna(0) if 'ivol_20_zscore' in factor_data.columns else 0.0
            
            # è·¯å¾„æ•ˆç‡ï¼ˆé«˜æ•ˆç‡æ›´å¥½ï¼‰
            efficiency_component = factor_data['efficiency_20_zscore'].fillna(0) if 'efficiency_20_zscore' in factor_data.columns else 0.0
            
            factor_data['quality_composite_zscore'] = (
                0.50 * turnover_component +      # æ¢æ‰‹ç‡/æµåŠ¨æ€§
                0.30 * ivol_component +           # ä½æ³¢åŠ¨å¼‚è±¡ï¼ˆåå‘ï¼‰
                0.20 * efficiency_component       # è·¯å¾„æ•ˆç‡
            )
            self.logger.info("ğŸ“Š å¤åˆè´¨é‡å› å­è®¡ç®—å®Œæˆ: 50% æ¢æ‰‹ç‡ + 30% ä½æ³¢åŠ¨(åå‘) + 20% è·¯å¾„æ•ˆç‡")
            
            for alias, source in factor_alias_mapping.items():
                if source in factor_data.columns and alias not in factor_data.columns:
                    factor_data[alias] = factor_data[source]
                    self.logger.debug(f"åˆ›å»ºå› å­åˆ«å: {alias} <- {source}")
            
            self.logger.info(f"å› å­åˆ«åæ˜ å°„å®Œæˆï¼Œå¯ç”¨å› å­åˆ—: {[c for c in factor_data.columns if c.endswith('_zscore')]}")
            
            self.factor_data = factor_data
            
            # ä¿å­˜å› å­æ•°æ®
            factor_path = DATA_PROCESSED_PATH / f"factors_{self.today.strftime('%Y%m%d')}.parquet"
            self.factor_data.to_parquet(factor_path)
            
            self.logger.info(f"å› å­è®¡ç®—å®Œæˆï¼Œå…± {len(self.factor_data)} æ¡è®°å½•")
            return True
            
        except Exception as e:
            self.logger.error(f"è®¡ç®—å› å­å¤±è´¥: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return False
    
    @staticmethod
    def _calculate_rsi(series: pd.Series, period: int = 20) -> pd.Series:
        """è®¡ç®— RSI æŒ‡æ ‡"""
        delta = series.diff()
        gain = delta.where(delta > 0, 0.0)
        loss = (-delta).where(delta < 0, 0.0)
        
        avg_gain = gain.ewm(alpha=1.0/period, min_periods=period, adjust=False).mean()
        avg_loss = loss.ewm(alpha=1.0/period, min_periods=period, adjust=False).mean()
        
        rs = avg_gain / avg_loss.replace(0, np.nan)
        rsi = 100.0 - (100.0 / (1.0 + rs))
        
        return rsi
    
    def calculate_and_log_factor_ic(self) -> Optional[pd.DataFrame]:
        """
        è®¡ç®—å› å­ IC å¹¶è®°å½•æ—¥å¿—
        
        ä½¿ç”¨å‰ç»æ”¶ç›Šè®¡ç®—å„å› å­çš„ Information Coefficientï¼Œ
        è¯„ä¼°å› å­çš„é¢„æµ‹èƒ½åŠ›ã€‚
        
        Returns
        -------
        Optional[pd.DataFrame]
            å› å­ IC ç»Ÿè®¡ç»“æœï¼Œå¦‚æœæ— æ³•è®¡ç®—åˆ™è¿”å› None
        
        Notes
        -----
        - IC > 0.03 è¢«è§†ä¸ºæœ‰æ•ˆå› å­
        - IC_IR > 0.5 è¡¨ç¤ºå› å­ç¨³å®šæ€§å¥½
        - æ­£ IC æ¯”ä¾‹ > 60% è¡¨ç¤ºæ–¹å‘ç¨³å®š
        """
        if calculate_factor_ic is None:
            self.logger.warning("calculate_factor_ic å‡½æ•°æœªå¯¼å…¥ï¼Œè·³è¿‡ IC ç›‘æ§")
            return None
        
        if self.factor_data is None or self.factor_data.empty:
            self.logger.warning("factor_data ä¸ºç©ºï¼Œæ— æ³•è®¡ç®—å› å­ IC")
            return None
        
        # è·å– IC ç›‘æ§é…ç½®
        ic_config = self.config.get("ic_monitor", {})
        if not ic_config.get("enabled", True):
            self.logger.debug("IC ç›‘æ§æœªå¯ç”¨ï¼Œè·³è¿‡")
            return None
        
        try:
            # è®¡ç®—å‰ç»æ”¶ç›Šï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            lookback_days = ic_config.get("lookback_days", 5)
            return_col = f'forward_return_{lookback_days}d'
            
            # è·å–è¦ç›‘æ§çš„å› å­åˆ—è¡¨
            monitored_factors = ic_config.get("monitored_factors", [
                "momentum_composite_zscore",
                "small_cap_zscore",
                "turnover_5d_zscore",
                "quality_composite_zscore",
                "value_composite_zscore",
                "sharpe_20_zscore",
                "roc_20_zscore"
            ])
            
            # ç¡®å®šæ—¥æœŸåˆ—
            date_col = 'date' if 'date' in self.factor_data.columns else 'trade_date'
            
            # è¿‡æ»¤å‡ºå®é™…å­˜åœ¨çš„å› å­åˆ—
            existing_factors = [f for f in monitored_factors if f in self.factor_data.columns]
            
            if not existing_factors:
                self.logger.warning("æ²¡æœ‰å¯ç›‘æ§çš„å› å­åˆ—")
                return None
            
            # å†…å­˜ä¼˜åŒ–ï¼šåªæå– IC è®¡ç®—æ‰€éœ€çš„åˆ—ï¼Œé¿å…å¤åˆ¶æ•´ä¸ª DataFrame
            required_cols = ['stock_code', date_col, 'close'] + existing_factors
            required_cols = [c for c in required_cols if c in self.factor_data.columns]
            factor_df = self.factor_data[required_cols].copy()
            
            self.logger.debug(f"IC è®¡ç®—æ•°æ®: {len(factor_df)} è¡Œ, {len(required_cols)} åˆ—ï¼ˆå†…å­˜ä¼˜åŒ–ï¼‰")
            
            if return_col not in factor_df.columns:
                # æ‰‹åŠ¨è®¡ç®—å‰ç»æ”¶ç›Šï¼ˆå†…å­˜ä¼˜åŒ–ç‰ˆï¼‰
                if 'stock_code' in factor_df.columns and 'close' in factor_df.columns:
                    factor_df[return_col] = factor_df.groupby('stock_code')['close'].transform(
                        lambda x: x.shift(-lookback_days) / x - 1
                    )
                elif 'close' in factor_df.columns:
                    factor_df[return_col] = factor_df['close'].shift(-lookback_days) / factor_df['close'] - 1
                else:
                    self.logger.warning("ç¼ºå°‘ close åˆ—ï¼Œæ— æ³•è®¡ç®—å‰ç»æ”¶ç›Š")
                    return None
            
            # è¿›ä¸€æ­¥ä¼˜åŒ–ï¼šåªä¿ç•™æœ€è¿‘ N ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®ï¼ˆé»˜è®¤30å¤©ï¼‰
            ic_sample_days = ic_config.get("sample_days", 30)
            if date_col in factor_df.columns:
                unique_dates = factor_df[date_col].dropna().unique()
                if len(unique_dates) > ic_sample_days:
                    recent_dates = sorted(unique_dates)[-ic_sample_days:]
                    factor_df = factor_df[factor_df[date_col].isin(recent_dates)]
                    self.logger.debug(f"IC é‡‡æ ·: æœ€è¿‘ {ic_sample_days} ä¸ªäº¤æ˜“æ—¥, {len(factor_df)} æ¡è®°å½•")
            
            # è®¡ç®— IC
            ic_df = calculate_factor_ic(
                factor_df,
                factor_cols=existing_factors,
                return_col=return_col,
                date_col=date_col,
                log_results=True  # åœ¨å‡½æ•°å†…éƒ¨è¾“å‡ºæ—¥å¿—
            )
            
            # é‡Šæ”¾å†…å­˜
            del factor_df
            
            # ç¼“å­˜ IC ç»“æœç”¨äºæŠ¥å‘Š
            self._factor_ic_results = ic_df
            
            return ic_df
            
        except Exception as e:
            self.logger.warning(f"å› å­ IC è®¡ç®—å¤±è´¥: {e}")
            import traceback
            self.logger.debug(traceback.format_exc())
            return None
    
    def _generate_ic_report_section(self, format: str = "markdown") -> str:
        """
        ç”Ÿæˆå› å­ IC ç›‘æ§æŠ¥å‘Šç‰‡æ®µ
        
        Parameters
        ----------
        format : str
            æŠ¥å‘Šæ ¼å¼ï¼Œ'markdown' æˆ– 'html'
        
        Returns
        -------
        str
            æŠ¥å‘Šç‰‡æ®µ
        """
        if not hasattr(self, '_factor_ic_results') or self._factor_ic_results is None:
            return ""
        
        ic_df = self._factor_ic_results
        if ic_df.empty:
            return ""
        
        ic_threshold = self.config.get("ic_monitor", {}).get("ic_threshold", 0.03)
        
        if format == "markdown":
            lines = [
                "",
                "## å› å­æœ‰æ•ˆæ€§ç›‘æ§",
                "",
                "| å› å­ | ICå‡å€¼ | IC_IR | æ­£ICæ¯”ä¾‹ | çŠ¶æ€ |",
                "|------|--------|-------|---------|------|",
            ]
            
            for _, row in ic_df.iterrows():
                status = "æœ‰æ•ˆ âœ…" if row['ic_mean'] > ic_threshold else (
                    "è¾¹ç¼˜ âš ï¸" if row['ic_mean'] > ic_threshold / 2 else "å¤±æ•ˆ âŒ"
                )
                lines.append(
                    f"| {row['factor']} | {row['ic_mean']:.4f} | "
                    f"{row['ic_ir']:.2f} | {row['ic_positive_ratio']:.1%} | {status} |"
                )
            
            lines.append("")
            return "\n".join(lines)
        
        elif format == "html":
            rows_html = ""
            for _, row in ic_df.iterrows():
                if row['ic_mean'] > ic_threshold:
                    status = '<span style="color: green;">æœ‰æ•ˆ âœ…</span>'
                    row_class = 'ic-valid'
                elif row['ic_mean'] > ic_threshold / 2:
                    status = '<span style="color: orange;">è¾¹ç¼˜ âš ï¸</span>'
                    row_class = 'ic-marginal'
                else:
                    status = '<span style="color: red;">å¤±æ•ˆ âŒ</span>'
                    row_class = 'ic-invalid'
                
                rows_html += f"""
                <tr class="{row_class}">
                    <td>{row['factor']}</td>
                    <td>{row['ic_mean']:.4f}</td>
                    <td>{row['ic_ir']:.2f}</td>
                    <td>{row['ic_positive_ratio']:.1%}</td>
                    <td>{status}</td>
                </tr>
                """
            
            return f"""
            <div class="ic-monitor-section">
                <h2>ğŸ“Š å› å­æœ‰æ•ˆæ€§ç›‘æ§</h2>
                <table class="ic-table">
                    <thead>
                        <tr>
                            <th>å› å­</th>
                            <th>ICå‡å€¼</th>
                            <th>IC_IR</th>
                            <th>æ­£ICæ¯”ä¾‹</th>
                            <th>çŠ¶æ€</th>
                        </tr>
                    </thead>
                    <tbody>
                        {rows_html}
                    </tbody>
                </table>
            </div>
            """
        
        return ""
    
    def is_rebalance_day(self, date: Optional[pd.Timestamp] = None) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦ä¸ºè°ƒä»“æ—¥ï¼ˆæœˆæœ«æœ€åä¸€ä¸ªäº¤æ˜“æ—¥ï¼‰
        
        Parameters
        ----------
        date : Optional[pd.Timestamp]
            æ£€æŸ¥æ—¥æœŸï¼Œé»˜è®¤ä¸ºä»Šæ—¥
        
        Returns
        -------
        bool
            æ˜¯å¦ä¸ºè°ƒä»“æ—¥
        """
        if date is None:
            date = self.today
        
        # è·å–æœ¬æœˆæ‰€æœ‰äº¤æ˜“æ—¥
        if self.ohlcv_data is not None:
            # ä¼˜å…ˆä½¿ç”¨ DatetimeIndexï¼Œå…¶æ¬¡ä½¿ç”¨ date/trade_date åˆ—
            if isinstance(self.ohlcv_data.index, pd.DatetimeIndex):
                trading_dates = self.ohlcv_data.index.unique()
            elif 'date' in self.ohlcv_data.columns:
                trading_dates = pd.to_datetime(self.ohlcv_data['date'].unique())
            elif 'trade_date' in self.ohlcv_data.columns:
                trading_dates = pd.to_datetime(self.ohlcv_data['trade_date'].unique())
            else:
                self.logger.warning("ohlcv_data ä¸­æœªæ‰¾åˆ°æ—¥æœŸåˆ—æˆ– DatetimeIndexï¼Œä½¿ç”¨ç®€åŒ–åˆ¤æ–­")
                trading_dates = None
            
            # ç­›é€‰æœ¬æœˆäº¤æ˜“æ—¥
            if trading_dates is not None:
                month_dates = trading_dates[
                    (trading_dates.year == date.year) & 
                    (trading_dates.month == date.month)
                ]
                
                if len(month_dates) > 0:
                    last_trading_day = month_dates.max()
                    is_last_day = date >= last_trading_day
                    self.logger.info(
                        f"æœ¬æœˆæœ€åäº¤æ˜“æ—¥: {last_trading_day.strftime('%Y-%m-%d')}, "
                        f"ä»Šæ—¥: {date.strftime('%Y-%m-%d')}, æ˜¯å¦è°ƒä»“æ—¥: {is_last_day}"
                    )
                    return is_last_day
        
        # ç®€åŒ–åˆ¤æ–­ï¼šæœˆæœ«æœ€å3å¤©è§†ä¸ºè°ƒä»“æ—¥
        next_month = (date.replace(day=28) + timedelta(days=4)).replace(day=1)
        days_to_month_end = (next_month - date).days
        
        is_month_end = days_to_month_end <= 3
        self.logger.info(f"è·æœˆæœ« {days_to_month_end} å¤©ï¼Œæ˜¯å¦è°ƒä»“æ—¥: {is_month_end}")
        
        return is_month_end
    
    def generate_target_positions(self) -> bool:
        """
        ç”Ÿæˆç›®æ ‡æŒä»“ï¼ˆå®ç›˜å®‰å…¨ç‰ˆï¼‰
        
        åŒ…å«ä»¥ä¸‹å®‰å…¨æœºåˆ¶ï¼š
        1. å¤§ç›˜é£æ§ï¼šå½“å¤§ç›˜è·Œç ´MA{n}ä¸”è·Œå¹…è¶…é˜ˆå€¼æ—¶ï¼Œå¼ºåˆ¶ç©ºä»“
        2. æ•°æ®éªŒè¯ï¼šç¡®ä¿æ‰€é€‰è‚¡ç¥¨éƒ½æœ‰æœ‰æ•ˆçš„è´¢åŠ¡æ•°æ®
        3. ç»“æœæ ¡éªŒï¼šä¿å­˜çš„ JSON æ–‡ä»¶æ˜ç¡®æ ‡è®°é£æ§çŠ¶æ€
        
        Returns
        -------
        bool
            ç”Ÿæˆæ˜¯å¦æˆåŠŸ
        """
        self.logger.info("å¼€å§‹ç”Ÿæˆç›®æ ‡æŒä»“ï¼ˆå®ç›˜å®‰å…¨æ¨¡å¼ï¼‰...")
        
        try:
            # === å¤§ç›˜é£æ§æ£€æŸ¥ ===
            if self.is_market_risk_triggered():
                self.logger.warning("ğŸš¨ å¤§ç›˜é£æ§è§¦å‘ï¼Œç³»ç»Ÿå¼ºåˆ¶ç©ºä»“ï¼")
                self.target_positions = {}
                
                # è¯»å–é£æ§é…ç½®ç”¨äºè®°å½•
                risk_config = self.config.get("risk", {})
                market_risk_config = risk_config.get("market_risk", {})
                ma_period = market_risk_config.get("ma_period", 60)
                drop_threshold = market_risk_config.get("drop_threshold", 0.05)
                
                # ä¿å­˜ç©ºä»“çŠ¶æ€
                portfolio_config = self.config.get("portfolio", {})
                total_capital = portfolio_config.get("total_capital", 1000000)
                
                positions_path = DATA_PROCESSED_PATH / f"target_positions_{self.today.strftime('%Y%m%d')}.json"
                
                # æ„å»ºç©ºä»“ JSONï¼ˆå®ç›˜ä¿æŠ¤ï¼šç¡®ä¿ positions ä¸ºç©ºå­—å…¸ï¼‰
                empty_position_data = {
                    'date': self.today.strftime('%Y-%m-%d'),
                    'positions': {},  # å…³é”®ï¼šç¡®ä¿ä¸ºç©ºå­—å…¸
                    'weights': {},    # å…³é”®ï¼šç¡®ä¿ä¸ºç©ºå­—å…¸
                    'total_capital': total_capital,
                    'market_risk_triggered': True,  # å…³é”®ï¼šæ ‡è®°é£æ§è§¦å‘
                    'reason': f'å¤§ç›˜è·Œç ´MA{ma_period}æˆ–è·Œå¹…è¶…{drop_threshold*100:.0f}%ï¼Œè§¦å‘é£æ§',
                    'risk_params': {
                        'ma_period': ma_period,
                        'drop_threshold': drop_threshold,
                    },
                    'action': 'CLEAR_ALL_POSITIONS',  # æ˜ç¡®æŒ‡ä»¤
                    'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                }
                
                with open(positions_path, 'w', encoding='utf-8') as f:
                    json.dump(empty_position_data, f, ensure_ascii=False, indent=2)
                
                self.logger.info(
                    f"âœ… å·²ä¿å­˜ç©ºä»“ç›®æ ‡æŒä»“ï¼ˆé£æ§è§¦å‘ï¼‰\n"
                    f"   æ–‡ä»¶: {positions_path}\n"
                    f"   positions: {{}}\n"
                    f"   market_risk_triggered: True"
                )
                return True
            # =====================
            
            if self.factor_data is None:
                self.logger.warning("å› å­æ•°æ®ä¸ºç©ºï¼Œæ— æ³•ç”ŸæˆæŒä»“")
                return False
            
            # è·å–æœ€æ–°æ—¥æœŸçš„æ•°æ®
            date_col = 'date' if 'date' in self.factor_data.columns else 'trade_date'
            latest_date = pd.to_datetime(self.factor_data[date_col]).max()
            
            latest_data = self.factor_data[
                pd.to_datetime(self.factor_data[date_col]) == latest_date
            ].copy()
            
            self.logger.info(f"æœ€æ–°æ•°æ®æ—¥æœŸ: {latest_date.strftime('%Y-%m-%d')}, è‚¡ç¥¨æ•°: {len(latest_data)}")
            
            # è¿‡æ»¤è‚¡ç¥¨
            filtered_data = self.strategy.filter_stocks(latest_data, latest_date)
            
            if filtered_data.empty:
                self.logger.warning("è¿‡æ»¤åæ— å¯é€‰è‚¡ç¥¨")
                return False
            
            # é€‰å– Top N è‚¡ç¥¨
            selected_stocks = self.strategy.select_top_stocks(filtered_data)
            
            # ========== å®ç›˜å®‰å…¨ï¼šéªŒè¯æ‰€é€‰è‚¡ç¥¨æ•°æ®æœ‰æ•ˆæ€§ ==========
            excluded_stocks = getattr(self, '_excluded_stocks', set())
            invalid_selected = [s for s in selected_stocks if s in excluded_stocks]
            
            if invalid_selected:
                self.logger.error(
                    f"ğŸš¨ å®‰å…¨è­¦å‘Š: é€‰ä¸­çš„è‚¡ç¥¨ä¸­åŒ…å«æ— æ•ˆæ•°æ®è‚¡ç¥¨: {invalid_selected}\n"
                    f"   è¿™äº›è‚¡ç¥¨å°†è¢«ç§»é™¤ã€‚"
                )
                selected_stocks = [s for s in selected_stocks if s not in excluded_stocks]
            
            if not selected_stocks:
                self.logger.error("è¿‡æ»¤æ— æ•ˆæ•°æ®åæ— å¯é€‰è‚¡ç¥¨ï¼Œå–æ¶ˆæœ¬æ¬¡è°ƒä»“")
                return False
            
            self.logger.info(f"é€‰ä¸­ {len(selected_stocks)} åªè‚¡ç¥¨: {selected_stocks[:5]}...")
            
            # è®¡ç®—ç»¼åˆå¾—åˆ†ç”¨äºå±•ç¤º
            filtered_data['total_score'] = self.strategy.calculate_total_score(filtered_data)
            
            # ä¼˜åŒ–æƒé‡
            portfolio_config = self.config.get("portfolio", {})
            total_capital = portfolio_config.get("total_capital", 1000000)
            max_weight = portfolio_config.get("max_weight", 0.05)
            objective = portfolio_config.get("optimization_objective", "max_sharpe")
            
            # å‡†å¤‡ä»·æ ¼æ•°æ®ç”¨äºä¼˜åŒ–
            if self.ohlcv_data is not None:
                price_pivot = self.ohlcv_data.pivot_table(
                    index='date' if 'date' in self.ohlcv_data.columns else 'trade_date',
                    columns='stock_code',
                    values='close'
                )
                
                # ä¼˜åŒ–æƒé‡
                weights = self.strategy.optimize_weights(
                    price_pivot,
                    selected_stocks,
                    objective=objective,
                    max_weight=max_weight
                )
            else:
                # æ— ä»·æ ¼æ•°æ®æ—¶ä½¿ç”¨ç­‰æƒé‡
                weights = {stock: 1.0 / len(selected_stocks) for stock in selected_stocks}
            
            # è®¡ç®—ç›®æ ‡æŒä»“ï¼ˆé‡‘é¢ï¼‰
            self.target_positions = {
                stock: weight * total_capital
                for stock, weight in weights.items()
                if weight > 0.0001
            }
            
            self.logger.info(f"ç›®æ ‡æŒä»“ç”Ÿæˆå®Œæˆï¼Œå…± {len(self.target_positions)} åªè‚¡ç¥¨")
            
            # ä¿å­˜ç›®æ ‡æŒä»“
            positions_path = DATA_PROCESSED_PATH / f"target_positions_{self.today.strftime('%Y%m%d')}.json"
            with open(positions_path, 'w', encoding='utf-8') as f:
                json.dump({
                    'date': self.today.strftime('%Y-%m-%d'),
                    'positions': self.target_positions,
                    'weights': weights,
                    'total_capital': total_capital,
                    'market_risk_triggered': False,
                }, f, ensure_ascii=False, indent=2)
            
            return True
        
        except LLMCircuitBreakerError as e:
            # ===== LLM ç†”æ–­å™¨è§¦å‘: é£æ§åœæ­¢äº¤æ˜“ =====
            self.logger.critical(
                f"â›” LLM Circuit Breaker Triggered! Risk control failed. "
                f"HALTING ALL TRADING SIGNALS."
            )
            self.logger.critical(f"Error details: {e}")
            
            # ä¿å­˜é£æ§åœæ­¢çŠ¶æ€æ–‡ä»¶
            self.target_positions = {}
            
            portfolio_config = self.config.get("portfolio", {})
            total_capital = portfolio_config.get("total_capital", 1000000)
            
            positions_path = DATA_PROCESSED_PATH / f"target_positions_{self.today.strftime('%Y%m%d')}.json"
            
            # æ„å»ºé£æ§åœæ­¢ JSONï¼ˆæ˜ç¡®æ ‡è®° LLM ç†”æ–­çŠ¶æ€ï¼‰
            halt_position_data = {
                'date': self.today.strftime('%Y-%m-%d'),
                'positions': {},  # å…³é”®ï¼šç¡®ä¿ä¸ºç©ºå­—å…¸ï¼Œä¸äº§ç”Ÿä»»ä½•ä¹°å…¥ä¿¡å·
                'weights': {},    # å…³é”®ï¼šç¡®ä¿ä¸ºç©ºå­—å…¸
                'total_capital': total_capital,
                'market_risk_triggered': False,
                'llm_circuit_breaker_triggered': True,  # å…³é”®ï¼šæ ‡è®° LLM ç†”æ–­è§¦å‘
                'reason': f'LLM Circuit Breaker Triggered: {str(e)[:200]}',
                'action': 'HALT_ALL_TRADING',  # æ˜ç¡®æŒ‡ä»¤ï¼šåœæ­¢æ‰€æœ‰äº¤æ˜“
                'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            }
            
            with open(positions_path, 'w', encoding='utf-8') as f:
                json.dump(halt_position_data, f, ensure_ascii=False, indent=2)
            
            self.logger.critical(
                f"âœ… å·²ä¿å­˜é£æ§åœæ­¢çŠ¶æ€æ–‡ä»¶\n"
                f"   æ–‡ä»¶: {positions_path}\n"
                f"   positions: {{}}\n"
                f"   llm_circuit_breaker_triggered: True\n"
                f"   action: HALT_ALL_TRADING"
            )
            
            # è¿”å› False è¡¨ç¤ºç”Ÿæˆå¤±è´¥ï¼Œè°ƒç”¨æ–¹åº”åœæ­¢åç»­æµç¨‹
            return False
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆç›®æ ‡æŒä»“å¤±è´¥: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return False
    
    def calculate_trade_orders(self) -> Tuple[Dict[str, float], Dict[str, float]]:
        """
        è®¡ç®—äº¤æ˜“è®¢å•
        
        Returns
        -------
        Tuple[Dict[str, float], Dict[str, float]]
            (ä¹°å…¥è®¢å•, å–å‡ºè®¢å•)ï¼Œé”®ä¸ºè‚¡ç¥¨ä»£ç ï¼Œå€¼ä¸ºé‡‘é¢
        """
        buy_orders: Dict[str, float] = {}
        sell_orders: Dict[str, float] = {}
        
        # å½“å‰æŒä»“è‚¡ç¥¨
        current_stocks = set(self.current_positions.keys())
        # ç›®æ ‡æŒä»“è‚¡ç¥¨
        target_stocks = set(self.target_positions.keys())
        
        # éœ€è¦å–å‡ºçš„è‚¡ç¥¨
        stocks_to_sell = current_stocks - target_stocks
        for stock in stocks_to_sell:
            sell_orders[stock] = self.current_positions[stock]
        
        # éœ€è¦ä¹°å…¥çš„è‚¡ç¥¨
        stocks_to_buy = target_stocks - current_stocks
        for stock in stocks_to_buy:
            buy_orders[stock] = self.target_positions[stock]
        
        # éœ€è¦è°ƒæ•´çš„è‚¡ç¥¨
        stocks_to_adjust = current_stocks & target_stocks
        for stock in stocks_to_adjust:
            current = self.current_positions[stock]
            target = self.target_positions[stock]
            diff = target - current
            
            if diff > 100:  # ä¹°å…¥é˜ˆå€¼
                buy_orders[stock] = diff
            elif diff < -100:  # å–å‡ºé˜ˆå€¼
                sell_orders[stock] = -diff
        
        return buy_orders, sell_orders
    
    def generate_report(
        self,
        buy_orders: Dict[str, float],
        sell_orders: Dict[str, float],
        format: str = "markdown"
    ) -> str:
        """
        ç”Ÿæˆäº¤æ˜“æŠ¥å‘Š
        
        Parameters
        ----------
        buy_orders : Dict[str, float]
            ä¹°å…¥è®¢å•
        sell_orders : Dict[str, float]
            å–å‡ºè®¢å•
        format : str
            æŠ¥å‘Šæ ¼å¼ï¼Œ'markdown' æˆ– 'html'
        
        Returns
        -------
        str
            æŠ¥å‘Šå†…å®¹
        """
        report_date = self.today.strftime('%Y-%m-%d')
        
        if format == "markdown":
            return self._generate_markdown_report(buy_orders, sell_orders, report_date)
        elif format == "html":
            return self._generate_html_report(buy_orders, sell_orders, report_date)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æŠ¥å‘Šæ ¼å¼: {format}")
    
    def _get_latest_prices(self) -> Dict[str, float]:
        """è·å–æ‰€æœ‰è‚¡ç¥¨çš„æœ€æ–°æ”¶ç›˜ä»·"""
        if self.ohlcv_data is None or self.ohlcv_data.empty:
            self.logger.warning("ohlcv_data ä¸ºç©ºï¼Œæ— æ³•è·å–æœ€æ–°ä»·æ ¼")
            return {}
            
        try:
            # ç¡®å®šæ—¥æœŸåˆ—
            date_col = next((col for col in ['date', 'trade_date', 'timestamp'] if col in self.ohlcv_data.columns), None)
            
            # ç¡®å®šè‚¡ç¥¨ä»£ç åˆ—
            stock_col = next((col for col in ['stock_code', 'symbol', 'code', 'ts_code'] if col in self.ohlcv_data.columns), None)
            
            # ç¡®å®šæ”¶ç›˜ä»·åˆ—
            price_col = next((col for col in ['close', 'close_price'] if col in self.ohlcv_data.columns), None)
            
            if not date_col or not price_col:
                self.logger.warning(f"ç¼ºå°‘å¿…è¦åˆ—: date_col={date_col}, price_col={price_col}")
                return {}

            df = self.ohlcv_data.copy()
            
            # å¦‚æœæ²¡æœ‰è‚¡ç¥¨ä»£ç åˆ—ï¼Œå°è¯•ä»ç´¢å¼•è·å–
            if not stock_col:
                if isinstance(df.index, pd.MultiIndex):
                    # å‡è®¾ MultiIndex æ˜¯ (date, stock_code) æˆ– (stock_code, date)
                    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œæš‚ä¸æ”¯æŒ MultiIndex è‡ªåŠ¨æ¨æ–­ï¼Œå»ºè®® Reset Index
                    df = df.reset_index()
                    stock_col = next((col for col in ['stock_code', 'symbol', 'code', 'ts_code'] if col in df.columns), None)
            
            if not stock_col:
                self.logger.warning("æ— æ³•æ‰¾åˆ°è‚¡ç¥¨ä»£ç åˆ—")
                return {}
                
            # è·å–æ¯ä¸ªè‚¡ç¥¨çš„æœ€åä¸€æ¡è®°å½•
            # å…ˆæŒ‰æ—¥æœŸæ’åº
            df_sorted = df.sort_values(by=date_col)
            latest_prices = df_sorted.groupby(stock_col)[price_col].last().to_dict()
            
            self.logger.info(f"å·²è·å– {len(latest_prices)} åªè‚¡ç¥¨çš„æœ€æ–°ä»·æ ¼")
            return latest_prices
        except Exception as e:
            self.logger.warning(f"è·å–æœ€æ–°ä»·æ ¼æ˜ å°„å¤±è´¥: {e}")
            return {}

    def _generate_markdown_report(
        self,
        buy_orders: Dict[str, float],
        sell_orders: Dict[str, float],
        report_date: str
    ) -> str:
        """ç”Ÿæˆ Markdown æ ¼å¼æŠ¥å‘Š"""
        latest_prices = self._get_latest_prices()

        lines = [
            f"# æ¯æ—¥è°ƒä»“æŠ¥å‘Š",
            f"",
            f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"",
            f"**æŠ¥å‘Šæ—¥æœŸ**: {report_date}",
            f"",
            f"---",
            f"",
        ]
        
        # ç­–ç•¥ä¿¡æ¯
        lines.extend([
            f"## ç­–ç•¥ä¿¡æ¯",
            f"",
            f"| å‚æ•° | å€¼ |",
            f"|------|-----|",
            f"| ç­–ç•¥åç§° | {self.strategy.name} |",
            f"| ä»·å€¼å› å­æƒé‡ | {self.strategy.value_weight:.0%} |",
            f"| è´¨é‡å› å­æƒé‡ | {self.strategy.quality_weight:.0%} |",
            f"| åŠ¨é‡å› å­æƒé‡ | {self.strategy.momentum_weight:.0%} |",
            f"| é€‰è‚¡æ•°é‡ | {self.strategy.top_n} |",
            f"",
        ])
        
        # æŒä»“æ±‡æ€»
        portfolio_config = self.config.get("portfolio", {})
        total_capital = portfolio_config.get("total_capital", 1000000)
        
        lines.extend([
            f"## æŒä»“æ±‡æ€»",
            f"",
            f"| æŒ‡æ ‡ | æ•°å€¼ |",
            f"|------|------|",
            f"| æ€»èµ„é‡‘ | Â¥{total_capital:,.0f} |",
            f"| ç›®æ ‡æŒä»“æ•° | {len(self.target_positions)} |",
            f"| ä¹°å…¥è‚¡ç¥¨æ•° | {len(buy_orders)} |",
            f"| å–å‡ºè‚¡ç¥¨æ•° | {len(sell_orders)} |",
            f"",
        ])
        
        # ä¹°å…¥æ¸…å•
        lines.extend([
            f"## ğŸ“ˆ æ˜æ—¥éœ€ä¹°å…¥",
            f"",
        ])
        
        if buy_orders:
            lines.extend([
                f"| è‚¡ç¥¨ä»£ç  | ä¹°å…¥é‡‘é¢ |",
                f"|----------|----------|",
            ])
            
            for stock, amount in sorted(buy_orders.items(), key=lambda x: -x[1]):
                lines.append(f"| {stock} | Â¥{amount:,.0f} |")
            
            lines.append(f"")
            lines.append(f"**ä¹°å…¥æ€»é‡‘é¢**: Â¥{sum(buy_orders.values()):,.0f}")
        else:
            lines.append(f"*æ— éœ€ä¹°å…¥*")
        
        lines.append(f"")
        
        # å–å‡ºæ¸…å•
        lines.extend([
            f"## ğŸ“‰ æ˜æ—¥éœ€å–å‡º",
            f"",
        ])
        
        if sell_orders:
            lines.extend([
                f"| è‚¡ç¥¨ä»£ç  | å–å‡ºé‡‘é¢ |",
                f"|----------|----------|",
            ])
            
            for stock, amount in sorted(sell_orders.items(), key=lambda x: -x[1]):
                lines.append(f"| {stock} | Â¥{amount:,.0f} |")
            
            lines.append(f"")
            lines.append(f"**å–å‡ºæ€»é‡‘é¢**: Â¥{sum(sell_orders.values()):,.0f}")
        else:
            lines.append(f"*æ— éœ€å–å‡º*")
        
        lines.append(f"")
        
        # ç›®æ ‡æŒä»“æ˜ç»†
        lines.extend([
            f"## ç›®æ ‡æŒä»“æ˜ç»†",
            f"",
            f"| è‚¡ç¥¨ä»£ç  | ç›®æ ‡é‡‘é¢ | æƒé‡ |",
            f"|----------|----------|------|",
        ])
        
        total_target = sum(self.target_positions.values()) if self.target_positions else 1
        for stock, amount in sorted(self.target_positions.items(), key=lambda x: -x[1]):
            weight = amount / total_target
            lines.append(f"| {stock} | Â¥{amount:,.0f} | {weight:.2%} |")
        
        # æ·»åŠ å› å­ IC ç›‘æ§éƒ¨åˆ†
        ic_section = self._generate_ic_report_section(format="markdown")
        if ic_section:
            lines.append(ic_section)
        
        # æ·»åŠ å†å²ä¸šç»©ç»Ÿè®¡éƒ¨åˆ†
        performance_section = self._generate_performance_report_section(format="markdown")
        if performance_section:
            lines.append(performance_section)
        
        lines.extend([
            f"",
            f"---",
            f"",
            f"*æœ¬æŠ¥å‘Šç”± Aè‚¡é‡åŒ–äº¤æ˜“ç³»ç»Ÿ è‡ªåŠ¨ç”Ÿæˆ*",
        ])
        
        return "\n".join(lines)
    
    def _generate_html_report(
        self,
        buy_orders: Dict[str, float],
        sell_orders: Dict[str, float],
        report_date: str
    ) -> str:
        """ç”Ÿæˆ HTML æ ¼å¼æŠ¥å‘Š"""
        latest_prices = self._get_latest_prices()
        portfolio_config = self.config.get("portfolio", {})
        total_capital = portfolio_config.get("total_capital", 1000000)
        
        # ä¹°å…¥è¡¨æ ¼è¡Œ
        buy_rows = ""
        for stock, amount in sorted(buy_orders.items(), key=lambda x: -x[1]):
            buy_rows += f"""
                <tr>
                    <td>{stock}</td>
                    <td>Â¥{amount:,.0f}</td>
                </tr>
            """
        
        # å–å‡ºè¡¨æ ¼è¡Œ
        sell_rows = ""
        for stock, amount in sorted(sell_orders.items(), key=lambda x: -x[1]):
            sell_rows += f"""
                <tr>
                    <td>{stock}</td>
                    <td>Â¥{amount:,.0f}</td>
                </tr>
            """
        
        # æŒä»“è¡¨æ ¼è¡Œ
        position_rows = ""
        total_target = sum(self.target_positions.values()) if self.target_positions else 1
        for stock, amount in sorted(self.target_positions.items(), key=lambda x: -x[1]):
            weight = amount / total_target
            position_rows += f"""
                <tr>
                    <td>{stock}</td>
                    <td>Â¥{amount:,.0f}</td>
                    <td>{weight:.2%}</td>
                </tr>
            """
        
        html = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>æ¯æ—¥è°ƒä»“æŠ¥å‘Š - {report_date}</title>
    <style>
        * {{
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            color: #eee;
            min-height: 100vh;
            padding: 2rem;
        }}
        .container {{
            max-width: 1000px;
            margin: 0 auto;
        }}
        h1 {{
            font-size: 2.5rem;
            margin-bottom: 0.5rem;
            background: linear-gradient(90deg, #00d9ff, #00ff88);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }}
        .meta {{
            color: #888;
            margin-bottom: 2rem;
        }}
        .card {{
            background: rgba(255, 255, 255, 0.05);
            border-radius: 12px;
            padding: 1.5rem;
            margin-bottom: 1.5rem;
            border: 1px solid rgba(255, 255, 255, 0.1);
        }}
        .card h2 {{
            font-size: 1.3rem;
            margin-bottom: 1rem;
            color: #00d9ff;
        }}
        .card.buy h2 {{
            color: #00ff88;
        }}
        .card.sell h2 {{
            color: #ff6b6b;
        }}
        .stats {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 1rem;
        }}
        .stat {{
            text-align: center;
            padding: 1rem;
            background: rgba(0, 217, 255, 0.1);
            border-radius: 8px;
        }}
        .stat-value {{
            font-size: 1.5rem;
            font-weight: bold;
            color: #00d9ff;
        }}
        .stat-label {{
            font-size: 0.85rem;
            color: #888;
            margin-top: 0.25rem;
        }}
        table {{
            width: 100%;
            border-collapse: collapse;
        }}
        th, td {{
            padding: 0.75rem;
            text-align: left;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }}
        th {{
            color: #888;
            font-weight: 500;
        }}
        tr:hover {{
            background: rgba(255, 255, 255, 0.03);
        }}
        .total {{
            margin-top: 1rem;
            padding-top: 1rem;
            border-top: 2px solid rgba(255, 255, 255, 0.1);
            font-weight: bold;
        }}
        .buy-total {{
            color: #00ff88;
        }}
        .sell-total {{
            color: #ff6b6b;
        }}
        .footer {{
            text-align: center;
            color: #666;
            margin-top: 2rem;
            font-size: 0.85rem;
        }}
        .empty {{
            text-align: center;
            color: #666;
            padding: 2rem;
        }}
        .ic-monitor-section {{
            background: rgba(255, 255, 255, 0.05);
            border-radius: 12px;
            padding: 1.5rem;
            margin-bottom: 1.5rem;
            border: 1px solid rgba(255, 255, 255, 0.1);
        }}
        .ic-monitor-section h2 {{
            font-size: 1.3rem;
            margin-bottom: 1rem;
            color: #00d9ff;
        }}
        .ic-table {{
            width: 100%;
            border-collapse: collapse;
        }}
        .ic-table th, .ic-table td {{
            padding: 0.75rem;
            text-align: left;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }}
        .ic-valid {{
            background: rgba(0, 255, 136, 0.1);
        }}
        .ic-marginal {{
            background: rgba(255, 165, 0, 0.1);
        }}
        .ic-invalid {{
            background: rgba(255, 107, 107, 0.1);
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ“Š æ¯æ—¥è°ƒä»“æŠ¥å‘Š</h1>
        <p class="meta">æŠ¥å‘Šæ—¥æœŸ: {report_date} | ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        
        <div class="card">
            <h2>ç­–ç•¥æ¦‚è§ˆ</h2>
            <div class="stats">
                <div class="stat">
                    <div class="stat-value">Â¥{total_capital:,.0f}</div>
                    <div class="stat-label">æ€»èµ„é‡‘</div>
                </div>
                <div class="stat">
                    <div class="stat-value">{len(self.target_positions)}</div>
                    <div class="stat-label">ç›®æ ‡æŒä»“æ•°</div>
                </div>
                <div class="stat">
                    <div class="stat-value">{len(buy_orders)}</div>
                    <div class="stat-label">ä¹°å…¥è‚¡ç¥¨æ•°</div>
                </div>
                <div class="stat">
                    <div class="stat-value">{len(sell_orders)}</div>
                    <div class="stat-label">å–å‡ºè‚¡ç¥¨æ•°</div>
                </div>
            </div>
        </div>
        
        <div class="card buy">
            <h2>ğŸ“ˆ æ˜æ—¥éœ€ä¹°å…¥</h2>
            {f'''
            <table>
                <thead>
                    <tr>
                        <th>è‚¡ç¥¨ä»£ç </th>
                        <th>ä¹°å…¥é‡‘é¢</th>
                    </tr>
                </thead>
                <tbody>
                    {buy_rows}
                </tbody>
            </table>
            <p class="total buy-total">ä¹°å…¥æ€»é‡‘é¢: Â¥{sum(buy_orders.values()):,.0f}</p>
            ''' if buy_orders else '<p class="empty">æ— éœ€ä¹°å…¥</p>'}
        </div>
        
        <div class="card sell">
            <h2>ğŸ“‰ æ˜æ—¥éœ€å–å‡º</h2>
            {f'''
            <table>
                <thead>
                    <tr>
                        <th>è‚¡ç¥¨ä»£ç </th>
                        <th>å–å‡ºé‡‘é¢</th>
                    </tr>
                </thead>
                <tbody>
                    {sell_rows}
                </tbody>
            </table>
            <p class="total sell-total">å–å‡ºæ€»é‡‘é¢: Â¥{sum(sell_orders.values()):,.0f}</p>
            ''' if sell_orders else '<p class="empty">æ— éœ€å–å‡º</p>'}
        </div>
        
        <div class="card">
            <h2>ğŸ“‹ ç›®æ ‡æŒä»“æ˜ç»†</h2>
            <table>
                <thead>
                    <tr>
                        <th>è‚¡ç¥¨ä»£ç </th>
                        <th>ç›®æ ‡é‡‘é¢</th>
                        <th>æƒé‡</th>
                    </tr>
                </thead>
                <tbody>
                    {position_rows}
                </tbody>
            </table>
        </div>
        
        {self._generate_ic_report_section(format="html")}
        
        {self._generate_performance_report_section(format="html")}
        
        <p class="footer">æœ¬æŠ¥å‘Šç”± Aè‚¡é‡åŒ–äº¤æ˜“ç³»ç»Ÿ è‡ªåŠ¨ç”Ÿæˆ</p>
    </div>
</body>
</html>
        """
        
        return html
    
    def save_report(self, report_content: str, format: str = "markdown") -> Path:
        """
        ä¿å­˜æŠ¥å‘Š
        
        Parameters
        ----------
        report_content : str
            æŠ¥å‘Šå†…å®¹
        format : str
            æŠ¥å‘Šæ ¼å¼
        
        Returns
        -------
        Path
            æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        extension = "md" if format == "markdown" else "html"
        report_path = REPORTS_PATH / f"daily_report_{self.today.strftime('%Y%m%d')}.{extension}"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        self.logger.info(f"æŠ¥å‘Šå·²ä¿å­˜è‡³ {report_path}")
        return report_path
    
    def update_performance_history(self) -> None:
        """
        æ›´æ–°å†å²ä¸šç»©è®°å½•
        
        è®°å½•æ¯æ—¥çš„å‡€å€¼ã€æŒä»“æ•°é‡ã€æ—¥æ”¶ç›Šç­‰ä¿¡æ¯ï¼Œç”¨äºç”Ÿæˆå†å²å¯¹æ¯”æŠ¥å‘Šã€‚
        """
        history_config = self.config.get("performance_history", {})
        if not history_config.get("enabled", True):
            self.logger.debug("å†å²ä¸šç»©è®°å½•æœªå¯ç”¨ï¼Œè·³è¿‡")
            return
        
        history_path = Path(history_config.get(
            "file_path", 
            "data/processed/performance_history.json"
        ))
        
        # åŠ è½½ç°æœ‰å†å²
        history = {}
        if history_path.exists():
            try:
                with open(history_path, 'r', encoding='utf-8') as f:
                    history = json.load(f)
            except Exception as e:
                self.logger.warning(f"åŠ è½½å†å²ä¸šç»©å¤±è´¥: {e}")
        
        # è®¡ç®—ä»Šæ—¥æ•°æ®
        today_str = self.today.strftime('%Y-%m-%d')
        total_value = sum(self.target_positions.values()) if self.target_positions else 0
        
        # è®¡ç®—æ—¥æ”¶ç›Šï¼ˆä¸æ˜¨æ—¥å¯¹æ¯”ï¼‰
        yesterday = (self.today - timedelta(days=1)).strftime('%Y-%m-%d')
        yesterday_value = history.get(yesterday, {}).get('total_value', total_value)
        daily_return = (total_value / yesterday_value - 1) if yesterday_value > 0 else 0
        
        # è®¡ç®—å‡€å€¼ï¼ˆåŸºäºåˆå§‹èµ„é‡‘ï¼‰
        initial_capital = self.config.get("portfolio", {}).get("total_capital", 300000)
        nav = total_value / initial_capital if initial_capital > 0 else 1.0
        
        # è®°å½•ä»Šæ—¥æ•°æ®
        history[today_str] = {
            'nav': nav,
            'total_value': total_value,
            'positions': len(self.target_positions),
            'daily_return': daily_return
        }
        
        # é™åˆ¶å†å²è®°å½•æ•°é‡
        max_days = history_config.get("max_days", 365)
        if len(history) > max_days:
            # æŒ‰æ—¥æœŸæ’åºå¹¶ä¿ç•™æœ€è¿‘çš„è®°å½•
            sorted_dates = sorted(history.keys(), reverse=True)[:max_days]
            history = {k: history[k] for k in sorted_dates}
        
        # ä¿å­˜
        try:
            history_path.parent.mkdir(parents=True, exist_ok=True)
            with open(history_path, 'w', encoding='utf-8') as f:
                json.dump(history, f, ensure_ascii=False, indent=2)
            self.logger.info(f"å†å²ä¸šç»©å·²æ›´æ–°: NAV={nav:.4f}, æ—¥æ”¶ç›Š={daily_return:.2%}")
        except Exception as e:
            self.logger.warning(f"ä¿å­˜å†å²ä¸šç»©å¤±è´¥: {e}")
    
    def get_performance_stats(self, days: int = 30) -> Dict[str, Any]:
        """
        è·å–å†å²ä¸šç»©ç»Ÿè®¡
        
        Parameters
        ----------
        days : int
            ç»Ÿè®¡å¤©æ•°ï¼Œé»˜è®¤ 30 å¤©
        
        Returns
        -------
        Dict[str, Any]
            ä¸šç»©ç»Ÿè®¡ï¼ŒåŒ…å«ï¼š
            - total_return: ç´¯è®¡æ”¶ç›Šç‡
            - max_drawdown: æœ€å¤§å›æ’¤
            - sharpe_ratio: å¤æ™®æ¯”ç‡ï¼ˆå¹´åŒ–ï¼‰
            - win_rate: æ—¥èƒœç‡
            - avg_daily_return: å¹³å‡æ—¥æ”¶ç›Š
            - volatility: æ—¥æ³¢åŠ¨ç‡
            - nav_series: å‡€å€¼åºåˆ—ï¼ˆç”¨äºç»˜å›¾ï¼‰
        """
        history_config = self.config.get("performance_history", {})
        history_path = Path(history_config.get(
            "file_path", 
            "data/processed/performance_history.json"
        ))
        
        if not history_path.exists():
            return {}
        
        try:
            with open(history_path, 'r', encoding='utf-8') as f:
                history = json.load(f)
        except Exception:
            return {}
        
        if len(history) < 2:
            return {}
        
        # æŒ‰æ—¥æœŸæ’åº
        sorted_dates = sorted(history.keys())[-days:]
        
        # æå–æ•°æ®
        navs = [history[d].get('nav', 1.0) for d in sorted_dates]
        returns = [history[d].get('daily_return', 0.0) for d in sorted_dates]
        
        returns_array = np.array(returns)
        navs_array = np.array(navs)
        
        # ç´¯è®¡æ”¶ç›Š
        total_return = navs_array[-1] / navs_array[0] - 1 if navs_array[0] > 0 else 0
        
        # æœ€å¤§å›æ’¤
        peak = np.maximum.accumulate(navs_array)
        drawdown = (navs_array - peak) / peak
        max_drawdown = abs(drawdown.min()) if len(drawdown) > 0 else 0
        
        # å¹³å‡æ—¥æ”¶ç›Šå’Œæ³¢åŠ¨ç‡
        avg_daily_return = returns_array.mean() if len(returns_array) > 0 else 0
        volatility = returns_array.std() if len(returns_array) > 1 else 0
        
        # å¤æ™®æ¯”ç‡ï¼ˆå¹´åŒ–ï¼‰
        risk_free = self.config.get("portfolio", {}).get("risk_free_rate", 0.02)
        daily_rf = risk_free / 252
        if volatility > 0:
            sharpe_ratio = (avg_daily_return - daily_rf) / volatility * np.sqrt(252)
        else:
            sharpe_ratio = 0
        
        # èƒœç‡
        win_rate = (returns_array > 0).mean() if len(returns_array) > 0 else 0
        
        return {
            'total_return': total_return,
            'max_drawdown': max_drawdown,
            'sharpe_ratio': sharpe_ratio,
            'win_rate': win_rate,
            'avg_daily_return': avg_daily_return,
            'volatility': volatility,
            'trading_days': len(sorted_dates),
            'nav_series': {d: history[d].get('nav', 1.0) for d in sorted_dates}
        }
    
    def _generate_performance_report_section(self, format: str = "markdown") -> str:
        """
        ç”Ÿæˆå†å²ä¸šç»©æŠ¥å‘Šç‰‡æ®µ
        
        Parameters
        ----------
        format : str
            æŠ¥å‘Šæ ¼å¼ï¼Œ'markdown' æˆ– 'html'
        
        Returns
        -------
        str
            æŠ¥å‘Šç‰‡æ®µ
        """
        stats = self.get_performance_stats(30)
        if not stats:
            return ""
        
        if format == "markdown":
            lines = [
                "",
                "## å†å²ä¸šç»©ç»Ÿè®¡ (è¿‘30æ—¥)",
                "",
                "| æŒ‡æ ‡ | æ•°å€¼ |",
                "|------|------|",
                f"| ç´¯è®¡æ”¶ç›Š | {stats['total_return']:.2%} |",
                f"| æœ€å¤§å›æ’¤ | {stats['max_drawdown']:.2%} |",
                f"| å¤æ™®æ¯”ç‡ | {stats['sharpe_ratio']:.2f} |",
                f"| æ—¥èƒœç‡ | {stats['win_rate']:.1%} |",
                f"| å¹³å‡æ—¥æ”¶ç›Š | {stats['avg_daily_return']:.3%} |",
                f"| æ—¥æ³¢åŠ¨ç‡ | {stats['volatility']:.3%} |",
                f"| äº¤æ˜“å¤©æ•° | {stats['trading_days']} |",
                "",
            ]
            
            # æ·»åŠ å‡€å€¼èµ°åŠ¿ï¼ˆç®€åŒ–ç‰ˆï¼Œæœ€è¿‘10å¤©ï¼‰
            nav_series = stats.get('nav_series', {})
            if nav_series:
                lines.append("### å‡€å€¼èµ°åŠ¿ (è¿‘10æ—¥)")
                lines.append("")
                lines.append("| æ—¥æœŸ | å‡€å€¼ |")
                lines.append("|------|------|")
                recent_navs = list(nav_series.items())[-10:]
                for date, nav in recent_navs:
                    lines.append(f"| {date} | {nav:.4f} |")
                lines.append("")
            
            return "\n".join(lines)
        
        elif format == "html":
            nav_series = stats.get('nav_series', {})
            nav_rows = ""
            if nav_series:
                recent_navs = list(nav_series.items())[-10:]
                for date, nav in recent_navs:
                    nav_rows += f"<tr><td>{date}</td><td>{nav:.4f}</td></tr>"
            
            return f"""
            <div class="card">
                <h2>ğŸ“ˆ å†å²ä¸šç»©ç»Ÿè®¡ (è¿‘30æ—¥)</h2>
                <div class="stats">
                    <div class="stat">
                        <div class="stat-value">{stats['total_return']:.2%}</div>
                        <div class="stat-label">ç´¯è®¡æ”¶ç›Š</div>
                    </div>
                    <div class="stat">
                        <div class="stat-value">{stats['max_drawdown']:.2%}</div>
                        <div class="stat-label">æœ€å¤§å›æ’¤</div>
                    </div>
                    <div class="stat">
                        <div class="stat-value">{stats['sharpe_ratio']:.2f}</div>
                        <div class="stat-label">å¤æ™®æ¯”ç‡</div>
                    </div>
                    <div class="stat">
                        <div class="stat-value">{stats['win_rate']:.1%}</div>
                        <div class="stat-label">æ—¥èƒœç‡</div>
                    </div>
                </div>
                <h3 style="margin-top: 1rem; color: #888;">å‡€å€¼èµ°åŠ¿ (è¿‘10æ—¥)</h3>
                <table>
                    <thead><tr><th>æ—¥æœŸ</th><th>å‡€å€¼</th></tr></thead>
                    <tbody>{nav_rows}</tbody>
                </table>
            </div>
            """
        
        return ""


def _format_orders_for_push(
    buy_orders: Dict[str, float],
    sell_orders: Dict[str, float],
    target_positions: Dict[str, float],
    report_date: str,
    market_risk_triggered: bool = False,
    stock_prices: Optional[Dict[str, float]] = None
) -> str:
    """
    å°†äº¤æ˜“è®¢å•æ ¼å¼åŒ–ä¸º PushPlus æ¨é€å†…å®¹ï¼ˆHTMLæ ¼å¼ï¼‰
    
    Parameters
    ----------
    buy_orders : Dict[str, float]
        ä¹°å…¥è®¢å• {è‚¡ç¥¨ä»£ç : é‡‘é¢}
    sell_orders : Dict[str, float]
        å–å‡ºè®¢å• {è‚¡ç¥¨ä»£ç : é‡‘é¢}
    target_positions : Dict[str, float]
        ç›®æ ‡æŒä»“ {è‚¡ç¥¨ä»£ç : é‡‘é¢}
    report_date : str
        æŠ¥å‘Šæ—¥æœŸ
    market_risk_triggered : bool
        å¤§ç›˜é£æ§æ˜¯å¦è§¦å‘
    stock_prices : Optional[Dict[str, float]]
        è‚¡ç¥¨ä»·æ ¼ {è‚¡ç¥¨ä»£ç : ä»·æ ¼}ï¼Œç”¨äºè®¡ç®—é¢„ä¼°è‚¡æ•°
    
    Returns
    -------
    str
        HTML æ ¼å¼çš„æ¨é€å†…å®¹
    """
    if stock_prices is None:
        stock_prices = {}
    lines = []
    
    # æ ·å¼
    lines.append("""
    <style>
        body { font-family: -apple-system, sans-serif; padding: 10px; }
        .header { color: #333; border-bottom: 2px solid #667eea; padding-bottom: 10px; }
        .section { margin: 15px 0; }
        .section-title { color: #667eea; font-size: 16px; font-weight: bold; margin-bottom: 8px; }
        .buy { color: #00aa00; }
        .sell { color: #ff4444; }
        .warning { color: #ff8800; background: #fff3cd; padding: 10px; border-radius: 5px; }
        .item { padding: 5px 0; border-bottom: 1px solid #eee; }
        .amount { float: right; font-weight: bold; }
        .summary { background: #f8f9fa; padding: 10px; border-radius: 5px; margin-top: 15px; }
        .no-action { color: #888; text-align: center; padding: 20px; }
    </style>
    """)
    
    # æ ‡é¢˜
    lines.append(f'<div class="header"><h2>ğŸ“Š æ¯æ—¥äº¤æ˜“è®¡åˆ’</h2><p>æ—¥æœŸ: {report_date}</p></div>')
    
    # å¤§ç›˜é£æ§è­¦å‘Š
    if market_risk_triggered:
        lines.append('''
        <div class="warning">
            âš ï¸ <strong>å¤§ç›˜é£æ§è§¦å‘</strong><br>
            æ²ªæ·±300è·Œç ´20æ—¥å‡çº¿ï¼Œç³»ç»Ÿå¼ºåˆ¶ç©ºä»“ï¼
        </div>
        ''')
    
    # åˆ¤æ–­æ˜¯å¦æœ‰æ“ä½œ
    has_orders = bool(buy_orders) or bool(sell_orders)
    
    if not has_orders:
        lines.append('''
        <div class="no-action">
            <p>âœ… ä»Šæ—¥æ— äº¤æ˜“æ“ä½œ</p>
            <p style="font-size: 12px; color: #aaa;">æŒä»“ä¿æŒä¸å˜</p>
        </div>
        ''')
    else:
        # ä¹°å…¥æ¸…å•
        if buy_orders:
            lines.append('<div class="section">')
            lines.append(f'<div class="section-title buy">ğŸ“ˆ æ˜æ—¥éœ€ä¹°å…¥ ({len(buy_orders)}åª)</div>')
            
            for stock, amount in sorted(buy_orders.items(), key=lambda x: -x[1]):
                # ä½¿ç”¨å®é™…ä»·æ ¼è®¡ç®—è‚¡æ•°ï¼Œé»˜è®¤å‡è®¾10å…ƒ
                price = stock_prices.get(stock, 10.0)
                shares = int(amount / price / 100) * 100  # æŒ‰100è‚¡æ•´æ‰‹è®¡ç®—
                lines.append(f'''
                <div class="item">
                    <span>{stock}</span>
                    <span class="amount buy">Â¥{amount:,.0f}</span>
                    <span style="color:#888; font-size:12px;"> (~{shares}è‚¡ @{price:.2f})</span>
                </div>
                ''')
            
            total_buy = sum(buy_orders.values())
            lines.append(f'<div style="text-align:right; margin-top:8px;"><strong>åˆè®¡: Â¥{total_buy:,.0f}</strong></div>')
            lines.append('</div>')
        
        # å–å‡ºæ¸…å•
        if sell_orders:
            lines.append('<div class="section">')
            lines.append(f'<div class="section-title sell">ğŸ“‰ æ˜æ—¥éœ€å–å‡º ({len(sell_orders)}åª)</div>')
            
            for stock, amount in sorted(sell_orders.items(), key=lambda x: -x[1]):
                # ä½¿ç”¨å®é™…ä»·æ ¼è®¡ç®—è‚¡æ•°
                price = stock_prices.get(stock, 10.0)
                shares = int(amount / price / 100) * 100
                lines.append(f'''
                <div class="item">
                    <span>{stock}</span>
                    <span class="amount sell">Â¥{amount:,.0f}</span>
                    <span style="color:#888; font-size:12px;"> (~{shares}è‚¡ @{price:.2f})</span>
                </div>
                ''')
            
            total_sell = sum(sell_orders.values())
            lines.append(f'<div style="text-align:right; margin-top:8px;"><strong>åˆè®¡: Â¥{total_sell:,.0f}</strong></div>')
            lines.append('</div>')
    
    # æŒä»“æ±‡æ€»
    lines.append('<div class="summary">')
    lines.append(f'<strong>ç›®æ ‡æŒä»“: {len(target_positions)} åªè‚¡ç¥¨</strong>')
    if target_positions:
        total_value = sum(target_positions.values())
        lines.append(f'<br>æ€»å¸‚å€¼: Â¥{total_value:,.0f}')
        
        # æ˜¾ç¤ºå‰5åªæŒä»“
        top_5 = sorted(target_positions.items(), key=lambda x: -x[1])[:5]
        lines.append('<br><span style="font-size:12px; color:#666;">Top 5: ')
        lines.append(', '.join([f'{s}({w/total_value:.1%})' for s, w in top_5]))
        lines.append('</span>')
    lines.append('</div>')
    
    # æ—¶é—´æˆ³
    lines.append(f'<p style="text-align:center; color:#aaa; font-size:11px; margin-top:15px;">ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}</p>')
    
    return '\n'.join(lines)


def _send_daily_notification(
    runner: "DailyUpdateRunner",
    buy_orders: Dict[str, float],
    sell_orders: Dict[str, float],
    config: Dict[str, Any]
) -> None:
    """
    å‘é€æ¯æ—¥äº¤æ˜“é€šçŸ¥åˆ°å¾®ä¿¡
    
    Parameters
    ----------
    runner : DailyUpdateRunner
        è¿è¡Œå™¨å®ä¾‹
    buy_orders : Dict[str, float]
        ä¹°å…¥è®¢å•
    sell_orders : Dict[str, float]
        å–å‡ºè®¢å•
    config : Dict[str, Any]
        é…ç½®
    """
    logger = logging.getLogger(__name__)
    
    # è·å– PushPlus Token
    # ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œå…¶æ¬¡ä»é…ç½®æ–‡ä»¶è¯»å–
    token = os.environ.get("PUSHPLUS_TOKEN", "")
    
    if not token:
        token = config.get("notification", {}).get("pushplus_token", "")
    
    if not token:
        logger.debug("æœªé…ç½® PUSHPLUS_TOKENï¼Œè·³è¿‡å¾®ä¿¡æ¨é€")
        return
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºé£æ§è§¦å‘çš„ç©ºä»“
    market_risk_triggered = False
    positions_path = DATA_PROCESSED_PATH / f"target_positions_{runner.today.strftime('%Y%m%d')}.json"
    if positions_path.exists():
        try:
            with open(positions_path, 'r', encoding='utf-8') as f:
                pos_data = json.load(f)
                market_risk_triggered = pos_data.get("market_risk_triggered", False)
        except Exception:
            pass
    
    # è·å–æœ€æ–°ä»·æ ¼ç”¨äºè®¡ç®—è‚¡æ•°
    stock_prices = runner._get_latest_prices() if hasattr(runner, '_get_latest_prices') else {}
    
    # æ ¼å¼åŒ–æ¨é€å†…å®¹
    report_date = runner.today.strftime('%Y-%m-%d')
    content = _format_orders_for_push(
        buy_orders=buy_orders,
        sell_orders=sell_orders,
        target_positions=runner.target_positions,
        report_date=report_date,
        market_risk_triggered=market_risk_triggered,
        stock_prices=stock_prices
    )
    
    # æ„å»ºæ ‡é¢˜
    if market_risk_triggered:
        title = f"âš ï¸ é£æ§è§¦å‘ - {report_date}"
    elif buy_orders or sell_orders:
        title = f"ğŸ“Š äº¤æ˜“è®¡åˆ’ - {report_date}"
    else:
        title = f"âœ… æ— æ“ä½œ - {report_date}"
    
    # å‘é€æ¶ˆæ¯
    success = send_pushplus_msg(
        token=token,
        title=title,
        content=content,
        template="html"
    )
    
    if success:
        logger.info("æ¯æ—¥äº¤æ˜“è®¡åˆ’å·²æ¨é€è‡³å¾®ä¿¡")
    else:
        logger.warning("å¾®ä¿¡æ¨é€å¤±è´¥ï¼Œè¯·æ£€æŸ¥ PUSHPLUS_TOKEN é…ç½®")


def run_daily_update(
    force_rebalance: bool = False,
    config: Optional[Dict[str, Any]] = None,
    no_llm: bool = False
) -> bool:
    """
    è¿è¡Œæ¯æ—¥æ›´æ–°æµç¨‹
    
    æµç¨‹ï¼š
    1. è°ƒç”¨ DataLoader æ›´æ–°è‡³ä»Šæ—¥çš„æœ€æ–°æ•°æ®
    2. è°ƒç”¨ FactorCalculator æ›´æ–°å› å­æ•°æ®
    3. æ›´æ–°åŸºå‡†æŒ‡æ•°æ•°æ®ï¼ˆç”¨äºå¤§ç›˜é£æ§ï¼‰
    4. æ£€æŸ¥ä»Šæ—¥æ˜¯å¦ä¸ºæœˆåº•ï¼ˆè°ƒä»“æ—¥ï¼‰ã€‚å¦‚æœæ˜¯ï¼Œè¿è¡Œ MultiFactorStrategy ç”Ÿæˆæ–°çš„ç›®æ ‡æŒä»“åˆ—è¡¨
    5. è°ƒç”¨ optimize_weights è®¡ç®—æ¯åªæŒä»“è‚¡çš„å…·ä½“è‚¡æ•°
    6. ç”ŸæˆæŠ¥å‘Š
    
    Parameters
    ----------
    force_rebalance : bool
        æ˜¯å¦å¼ºåˆ¶è°ƒä»“ï¼ˆå¿½ç•¥æ—¥æœŸæ£€æŸ¥ï¼‰
    config : Optional[Dict[str, Any]]
        é…ç½®å‚æ•°
    no_llm : bool
        æ˜¯å¦ç¦ç”¨ LLM é£æ§
    
    Returns
    -------
    bool
        è¿è¡Œæ˜¯å¦æˆåŠŸ
    """
    logger = logging.getLogger(__name__)
    
    # Step 0: äº¤æ˜“æ—¥å†æ ¡éªŒ
    # åŠ è½½é…ç½®ä»¥æ£€æŸ¥æ˜¯å¦å¯ç”¨äº¤æ˜“æ—¥å†æ ¡éªŒ
    if config is None:
        try:
            config = load_config(str(CONFIG_PATH))
        except Exception:
            config = {}
    
    calendar_config = config.get("trading_calendar", {})
    if calendar_config.get("check_enabled", True):
        # åˆ›å»ºä¸´æ—¶ Tushare loader ç”¨äºäº¤æ˜“æ—¥å†æŸ¥è¯¢
        try:
            tushare_config = config.get("tushare", {})
            api_token = tushare_config.get("api_token") or os.environ.get("TUSHARE_TOKEN", "")
            if api_token:
                temp_loader = TushareDataLoader(
                    api_token=api_token,
                    cache_dir=tushare_config.get("cache_dir", "data/tushare_cache")
                )
                if not is_trading_day(tushare_loader=temp_loader, config=config):
                    logger.info("=" * 60)
                    logger.info("ä»Šæ—¥éäº¤æ˜“æ—¥ï¼Œè·³è¿‡æ¯æ—¥æ›´æ–°æµç¨‹")
                    logger.info("=" * 60)
                    return True  # éäº¤æ˜“æ—¥è§†ä¸ºæˆåŠŸå®Œæˆ
            else:
                # æ—  token æ—¶ä½¿ç”¨ç®€å•å‘¨æœ«åˆ¤æ–­
                if not is_trading_day(config=config):
                    logger.info("=" * 60)
                    logger.info("ä»Šæ—¥éäº¤æ˜“æ—¥ï¼Œè·³è¿‡æ¯æ—¥æ›´æ–°æµç¨‹")
                    logger.info("=" * 60)
                    return True
        except Exception as e:
            logger.warning(f"äº¤æ˜“æ—¥å†æ ¡éªŒå¤±è´¥: {e}ï¼Œç»§ç»­æ‰§è¡Œæ›´æ–°æµç¨‹")
    
    logger.info("=" * 60)
    logger.info("å¼€å§‹æ¯æ—¥æ›´æ–°æµç¨‹")
    if no_llm:
        logger.info("å‚æ•°è®¾ç½®: ç¦ç”¨ LLM é£æ§")
    logger.info("=" * 60)
    
    try:
        # åˆå§‹åŒ–è¿è¡Œå™¨
        runner = DailyUpdateRunner(config)
        
        # å¤„ç† LLM ç¦ç”¨
        if no_llm:
            if "llm" in runner.config:
                runner.config["llm"] = {}
                # åŒæ—¶ä¹Ÿæ›´æ–° runner å†…éƒ¨å¯èƒ½å·²ç»åˆå§‹åŒ–çš„ç»„ä»¶é…ç½®
                # æ³¨æ„ï¼šDailyUpdateRunner åˆå§‹åŒ–æ—¶å·²ç»ç”¨ config åˆå§‹åŒ–äº†ç»„ä»¶
                # æ‰€ä»¥æœ€å¥½æ˜¯å…ˆä¿®æ”¹ config å†åˆå§‹åŒ– runnerï¼Œæˆ–è€… config ä¼ é€’ None å¹¶åœ¨å†…éƒ¨å¤„ç†
                # ç”±äº runner å·²ç»åˆå§‹åŒ–ï¼Œæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨é€šè¿‡ runner ä¿®æ”¹
                pass
            
            # ç”±äº runner å·²ç»åˆå§‹åŒ–ï¼Œæˆ‘ä»¬éœ€è¦é‡æ–°åˆå§‹åŒ–å—å½±å“çš„ç»„ä»¶
            # æˆ–è€…æ›´å¥½çš„æ–¹å¼æ˜¯åœ¨ DailyUpdateRunner å†…éƒ¨å¤„ç† no_llm
            # è¿™é‡Œä¸ºäº†ç®€å•ï¼Œç›´æ¥ä¿®æ”¹ configï¼Œå¹¶é‡æ–°åˆå§‹åŒ– feature_calculator
            runner.config["llm"] = {}
            runner._init_components()  # é‡æ–°åˆå§‹åŒ–ç»„ä»¶ä»¥åº”ç”¨æ–°é…ç½®

        
        # Step 1: æ›´æ–°å¸‚åœºæ•°æ®
        logger.info("Step 1/8: æ›´æ–°å¸‚åœºæ•°æ®")
        if not runner.update_market_data():
            logger.error("å¸‚åœºæ•°æ®æ›´æ–°å¤±è´¥")
            return False
        
        # Step 2: æ›´æ–°è´¢åŠ¡æ•°æ®
        logger.info("Step 2/8: æ›´æ–°è´¢åŠ¡æ•°æ®")
        if not runner.update_financial_data():
            logger.error("è´¢åŠ¡æ•°æ®æ›´æ–°å¤±è´¥")
            return False
        
        # Step 3: æ›´æ–°åŸºå‡†æŒ‡æ•°æ•°æ®ï¼ˆç”¨äºå¤§ç›˜é£æ§ï¼‰
        logger.info("Step 3/8: æ›´æ–°åŸºå‡†æŒ‡æ•°æ•°æ®ï¼ˆå¤§ç›˜é£æ§ï¼‰")
        runner.update_benchmark_data()  # å³ä½¿å¤±è´¥ä¹Ÿç»§ç»­ï¼Œåªæ˜¯é£æ§ä¸ç”Ÿæ•ˆ
        
        # Step 4: è®¡ç®—å› å­
        logger.info("Step 4/8: è®¡ç®—å› å­æ•°æ®")
        if not runner.calculate_factors():
            logger.error("å› å­è®¡ç®—å¤±è´¥")
            return False
        
        # Step 4.5: è®¡ç®—å› å­ IC ç›‘æ§
        ic_config = runner.config.get("ic_monitor", {})
        if ic_config.get("enabled", True):
            logger.info("Step 4.5/8: è®¡ç®—å› å­ IC ç›‘æ§")
            ic_results = runner.calculate_and_log_factor_ic()
            
            # å› å­å¤±æ•ˆç†”æ–­æ£€æµ‹
            if ic_config.get("circuit_breaker_enabled", False) and ic_results is not None:
                ic_threshold = ic_config.get("circuit_breaker_ic_threshold", 0.01)
                ir_threshold = ic_config.get("circuit_breaker_ir_threshold", 0.3)
                
                breaker_result = runner.strategy.apply_factor_circuit_breaker(
                    ic_results,
                    ic_threshold=ic_threshold,
                    ir_threshold=ir_threshold
                )
                
                if breaker_result:
                    logger.warning(f"å› å­ç†”æ–­å·²è§¦å‘: {list(breaker_result.keys())}")
        
        # Step 5: æ£€æŸ¥æ˜¯å¦è°ƒä»“æ—¥
        is_rebalance = force_rebalance or runner.is_rebalance_day()
        
        # æŒä»“åç§»æ£€æµ‹ï¼ˆéè°ƒä»“æ—¥æ—¶æ£€æŸ¥æ˜¯å¦éœ€è¦å¼ºåˆ¶è°ƒä»“ï¼‰
        drift_config = runner.config.get("position_drift", {})
        if not is_rebalance and drift_config.get("check_enabled", True):
            # åŠ è½½ä¸Šæ¬¡çš„ç›®æ ‡æŒä»“è¿›è¡Œå¯¹æ¯”
            last_target_path = DATA_PROCESSED_PATH / f"target_positions_latest.json"
            last_target_positions = {}
            
            if last_target_path.exists():
                try:
                    with open(last_target_path, 'r', encoding='utf-8') as f:
                        last_data = json.load(f)
                        last_target_positions = last_data.get("positions", {})
                except Exception as e:
                    logger.warning(f"åŠ è½½ä¸Šæ¬¡ç›®æ ‡æŒä»“å¤±è´¥: {e}")
            
            if last_target_positions and runner.current_positions:
                max_drift = drift_config.get("max_drift", 0.15)
                force_by_drift, drift_value, _ = runner.strategy.check_position_drift(
                    runner.current_positions,
                    last_target_positions,
                    max_drift=max_drift
                )
                
                if force_by_drift:
                    logger.warning(
                        f"æŒä»“åç§» {drift_value:.1%} è¶…è¿‡é˜ˆå€¼ {max_drift:.1%}ï¼Œå¼ºåˆ¶è§¦å‘è°ƒä»“"
                    )
                    is_rebalance = True
        
        if is_rebalance:
            logger.info("Step 5/8: ç”Ÿæˆç›®æ ‡æŒä»“ï¼ˆè°ƒä»“æ—¥ï¼‰")
            if not runner.generate_target_positions():
                logger.error("ç›®æ ‡æŒä»“ç”Ÿæˆå¤±è´¥")
                return False
            
            # ä¿å­˜æœ€æ–°ç›®æ ‡æŒä»“ç”¨äºåç§»æ£€æµ‹
            try:
                latest_path = DATA_PROCESSED_PATH / "target_positions_latest.json"
                with open(latest_path, 'w', encoding='utf-8') as f:
                    json.dump({
                        'date': runner.today.strftime('%Y-%m-%d'),
                        'positions': runner.target_positions
                    }, f, ensure_ascii=False, indent=2)
            except Exception as e:
                logger.warning(f"ä¿å­˜æœ€æ–°ç›®æ ‡æŒä»“å¤±è´¥: {e}")
        else:
            logger.info("Step 5/8: éè°ƒä»“æ—¥ï¼Œè·³è¿‡æŒä»“ç”Ÿæˆ")
            runner.target_positions = runner.current_positions.copy()
        
        # Step 6: ç”ŸæˆæŠ¥å‘Š
        logger.info("Step 6/8: ç”Ÿæˆäº¤æ˜“æŠ¥å‘Š")
        buy_orders, sell_orders = runner.calculate_trade_orders()
        
        report_config = runner.config.get("report", {})
        report_format = report_config.get("format", "markdown")
        
        # ç”Ÿæˆä¸¤ç§æ ¼å¼çš„æŠ¥å‘Š
        for fmt in ["markdown", "html"]:
            report_content = runner.generate_report(buy_orders, sell_orders, format=fmt)
            runner.save_report(report_content, format=fmt)
        
        # Step 7: æ›´æ–°å¹¶ä¿å­˜æŒä»“
        logger.info("Step 7/8: æ›´æ–°æŒä»“è®°å½•")
        runner.save_current_holdings(buy_orders, sell_orders)
        
        # Step 7.5: æ›´æ–°å†å²ä¸šç»©è®°å½•
        if runner.config.get("performance_history", {}).get("enabled", True):
            runner.update_performance_history()
        
        # Step 8: å‘é€å¾®ä¿¡æ¨é€é€šçŸ¥
        logger.info("Step 8/8: å‘é€å¾®ä¿¡é€šçŸ¥")
        _send_daily_notification(
            runner=runner,
            buy_orders=buy_orders,
            sell_orders=sell_orders,
            config=runner.config
        )
        
        logger.info("=" * 60)
        logger.info("æ¯æ—¥æ›´æ–°æµç¨‹å®Œæˆ")
        logger.info("=" * 60)
        
        # æ‰“å°æ‘˜è¦
        logger.info(f"ç›®æ ‡æŒä»“: {len(runner.target_positions)} åªè‚¡ç¥¨")
        logger.info(f"éœ€ä¹°å…¥: {len(buy_orders)} åªï¼Œé‡‘é¢ Â¥{sum(buy_orders.values()):,.0f}")
        logger.info(f"éœ€å–å‡º: {len(sell_orders)} åªï¼Œé‡‘é¢ Â¥{sum(sell_orders.values()):,.0f}")
        
        return True
        
    except Exception as e:
        logger.error(f"æ¯æ—¥æ›´æ–°æµç¨‹å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False


def _load_backtest_financial_data(
    stock_list: List[str],
    start_date: str,
    end_date: str,
    data_loader: "DataLoader"
) -> pd.DataFrame:
    """
    åŠ è½½å›æµ‹ç”¨å†å²è´¢åŠ¡æ•°æ®ï¼ˆç‰¹åˆ«æ˜¯æµé€šå¸‚å€¼ circ_mvï¼‰
    
    ä¼˜å…ˆä»æœ¬åœ° parquet æ–‡ä»¶åŠ è½½ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™å°è¯•åœ¨çº¿è·å–ã€‚
    
    Parameters
    ----------
    stock_list : List[str]
        è‚¡ç¥¨ä»£ç åˆ—è¡¨
    start_date : str
        å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
    end_date : str
        ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
    data_loader : DataLoader
        æ•°æ®åŠ è½½å™¨å®ä¾‹
    
    Returns
    -------
    pd.DataFrame
        è´¢åŠ¡æ•°æ®ï¼ŒåŒ…å« date, stock_code, circ_mv, total_mv ç­‰å­—æ®µ
    
    Raises
    ------
    FileNotFoundError
        å½“æœ¬åœ°æ— è´¢åŠ¡æ•°æ®ä¸”æ— æ³•åœ¨çº¿è·å–æ—¶
    """
    logger = logging.getLogger(__name__)
    logger.info(f"åŠ è½½å›æµ‹è´¢åŠ¡æ•°æ®: {len(stock_list)} åªè‚¡ç¥¨, {start_date} ~ {end_date}")
    
    financial_records = []
    failed_stocks = []
    
    # å°è¯•ä»æœ¬åœ°åŠ è½½å·²ä¿å­˜çš„è´¢åŠ¡æ•°æ®
    local_financial_path = DATA_RAW_PATH / "financial_data.parquet"
    if local_financial_path.exists():
        try:
            local_df = pd.read_parquet(local_financial_path)
            logger.info(f"ä»æœ¬åœ°åŠ è½½è´¢åŠ¡æ•°æ®: {len(local_df)} æ¡è®°å½•")
            
            # è¿‡æ»¤æ—¥æœŸèŒƒå›´å’Œè‚¡ç¥¨åˆ—è¡¨
            if 'date' in local_df.columns:
                local_df['date'] = pd.to_datetime(local_df['date'])
                start_dt = pd.to_datetime(start_date)
                end_dt = pd.to_datetime(end_date)
                local_df = local_df[
                    (local_df['date'] >= start_dt) & 
                    (local_df['date'] <= end_dt) &
                    (local_df['stock_code'].isin(stock_list))
                ]
                
                if not local_df.empty and 'circ_mv' in local_df.columns:
                    logger.info(f"æœ¬åœ°è´¢åŠ¡æ•°æ®è¿‡æ»¤å: {len(local_df)} æ¡è®°å½•")
                    return local_df
        except Exception as e:
            logger.warning(f"åŠ è½½æœ¬åœ°è´¢åŠ¡æ•°æ®å¤±è´¥: {e}")
    
    # å°è¯•æŸ¥æ‰¾æŒ‰æ—¥æœŸä¿å­˜çš„è´¢åŠ¡æ•°æ®æ–‡ä»¶
    financial_files = list(DATA_RAW_PATH.glob("financial_*.parquet"))
    if financial_files:
        logger.info(f"æ‰¾åˆ° {len(financial_files)} ä¸ªè´¢åŠ¡æ•°æ®æ–‡ä»¶ï¼Œå°è¯•åŠ è½½...")
        all_financial_data = []
        
        for fpath in financial_files:
            try:
                df = pd.read_parquet(fpath)
                if 'stock_code' in df.columns:
                    # ä»æ–‡ä»¶åæå–æ—¥æœŸ
                    date_str = fpath.stem.replace("financial_", "")
                    if len(date_str) == 8:
                        df['data_date'] = pd.to_datetime(date_str, format='%Y%m%d')
                    all_financial_data.append(df)
            except Exception as e:
                logger.debug(f"åŠ è½½ {fpath} å¤±è´¥: {e}")
        
        if all_financial_data:
            combined_df = pd.concat(all_financial_data, ignore_index=True)
            if 'circ_mv' in combined_df.columns or 'total_mv' in combined_df.columns:
                logger.info(f"åˆå¹¶è´¢åŠ¡æ•°æ®: {len(combined_df)} æ¡è®°å½•")
                return combined_df
    
    # åœ¨çº¿è·å–è´¢åŠ¡æŒ‡æ ‡ï¼ˆä»…è·å–å½“å‰å¿«ç…§ï¼Œç”¨äºè¿‘æœŸå›æµ‹ï¼‰
    logger.warning("æœ¬åœ°æ— å†å²è´¢åŠ¡æ•°æ®ï¼Œå°è¯•åœ¨çº¿è·å–å½“å‰è´¢åŠ¡æŒ‡æ ‡...")
    logger.warning("æ³¨æ„ï¼šåœ¨çº¿è·å–çš„è´¢åŠ¡æ•°æ®ä¸ºå½“å‰å¿«ç…§ï¼Œå¯èƒ½å¯¼è‡´å›æµ‹å­˜åœ¨å‰è§†åå·®")
    
    import time
    for i, stock in enumerate(stock_list):
        try:
            fin_df = data_loader.fetch_financial_indicator(stock)
            
            if fin_df is not None and not fin_df.empty:
                # æå–å¸‚å€¼æ•°æ®
                if isinstance(fin_df, pd.DataFrame) and len(fin_df) > 0:
                    latest = fin_df.iloc[-1] if len(fin_df) > 1 else fin_df.iloc[0]
                    
                    # è·å–æµé€šå¸‚å€¼
                    circ_mv = None
                    total_mv = None
                    
                    for col in ['circ_mv', 'æµé€šå¸‚å€¼']:
                        if col in latest.index:
                            circ_mv = latest[col]
                            break
                    
                    for col in ['total_mv', 'æ€»å¸‚å€¼']:
                        if col in latest.index:
                            total_mv = latest[col]
                            break
                    
                    if circ_mv is not None or total_mv is not None:
                        financial_records.append({
                            'stock_code': stock,
                            'circ_mv': circ_mv if circ_mv is not None else total_mv,
                            'total_mv': total_mv if total_mv is not None else circ_mv,
                            'pe_ttm': latest.get('pe_ttm', np.nan),
                            'pb': latest.get('pb', np.nan),
                        })
                    else:
                        failed_stocks.append(stock)
                else:
                    failed_stocks.append(stock)
            else:
                failed_stocks.append(stock)
                
        except Exception as e:
            logger.debug(f"è·å– {stock} è´¢åŠ¡æ•°æ®å¤±è´¥: {e}")
            failed_stocks.append(stock)
        
        # è¿›åº¦æ—¥å¿—
        if (i + 1) % 20 == 0:
            logger.info(f"è´¢åŠ¡æ•°æ®è·å–è¿›åº¦: {i + 1}/{len(stock_list)}")
        
        # å»¶æ—¶é¿å…è¯·æ±‚è¿‡å¿«
        if (i + 1) % 5 == 0:
            time.sleep(0.5)
    
    if not financial_records:
        error_msg = (
            "æ— æ³•è·å–è´¢åŠ¡æ•°æ®ï¼ˆæµé€šå¸‚å€¼ circ_mvï¼‰ã€‚\n"
            "å°å¸‚å€¼ç­–ç•¥å›æµ‹éœ€è¦å†å²å¸‚å€¼æ•°æ®ã€‚è¯·å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤ä¸‹è½½æ•°æ®ï¼š\n"
            "  python tools/download_financial_data.py --start {start} --end {end}\n"
            "æˆ–åœ¨ data/raw/ ç›®å½•ä¸‹æ”¾ç½®åŒ…å« circ_mv å­—æ®µçš„ financial_data.parquet æ–‡ä»¶ã€‚"
        ).format(start=start_date, end=end_date)
        
        logger.error(error_msg)
        raise FileNotFoundError(error_msg)
    
    financial_df = pd.DataFrame(financial_records)
    
    if failed_stocks:
        logger.warning(
            f"éƒ¨åˆ†è‚¡ç¥¨è´¢åŠ¡æ•°æ®è·å–å¤±è´¥: {len(failed_stocks)}/{len(stock_list)}, "
            f"æˆåŠŸ: {len(financial_records)}"
        )
    
    logger.info(f"è´¢åŠ¡æ•°æ®åŠ è½½å®Œæˆ: {len(financial_df)} åªè‚¡ç¥¨")
    return financial_df


def _generate_backtest_factor_data(
    price_data_dict: Dict[str, pd.DataFrame],
    close_df: pd.DataFrame,
    strategy_config: Dict[str, Any],
    financial_data: Optional[pd.DataFrame] = None
) -> pd.DataFrame:
    """
    ç”Ÿæˆå›æµ‹ç”¨å› å­æ•°æ®ï¼ˆå¢å¼ºç‰ˆï¼‰
    
    è®¡ç®—ä»¥ä¸‹å› å­ï¼š
    - momentum_zscore: åŸºäº RSI_20 çš„åŠ¨é‡å› å­
    - small_cap: å°å¸‚å€¼å› å­ = -log(circ_mv)ï¼Œå¸‚å€¼è¶Šå°åˆ†æ•°è¶Šé«˜
    - small_cap_zscore: å°å¸‚å€¼å› å­çš„ Z-Score æ ‡å‡†åŒ–
    - turnover_5d: 5æ—¥å¹³å‡æ¢æ‰‹ç‡
    - value_zscore, quality_zscore: è´¢åŠ¡å› å­ï¼ˆéœ€è¦è´¢åŠ¡æ•°æ®ï¼‰
    
    Parameters
    ----------
    price_data_dict : Dict[str, pd.DataFrame]
        è‚¡ç¥¨ä»·æ ¼æ•°æ®å­—å…¸ {stock_code: DataFrame}
    close_df : pd.DataFrame
        æ”¶ç›˜ä»·çŸ©é˜µ (Index=æ—¥æœŸ, Columns=è‚¡ç¥¨ä»£ç )
    strategy_config : Dict[str, Any]
        ç­–ç•¥é…ç½®
    financial_data : Optional[pd.DataFrame]
        è´¢åŠ¡æ•°æ®ï¼ŒåŒ…å« stock_code, circ_mv ç­‰å­—æ®µ
    
    Returns
    -------
    pd.DataFrame
        å› å­æ•°æ®ï¼ŒåŒ…å« date, stock_code åŠå„ç±»å› å­åˆ—
    
    Notes
    -----
    å¦‚æœæä¾›äº† financial_data ä¸”åŒ…å« circ_mvï¼Œå°†æ­£ç¡®è®¡ç®— small_cap å› å­ã€‚
    å¦åˆ™ small_cap ç›¸å…³å› å­å°†è¢«è®¾ç½®ä¸º NaNï¼Œå¹¶è®°å½•è­¦å‘Šã€‚
    """
    logger = logging.getLogger(__name__)
    
    has_financial = (
        financial_data is not None and 
        not financial_data.empty and 
        'circ_mv' in financial_data.columns
    )
    
    if has_financial:
        logger.info("ç”Ÿæˆå›æµ‹å› å­æ•°æ®ï¼ˆå«è´¢åŠ¡å› å­ï¼šsmall_cap, valueï¼‰...")
    else:
        logger.info(
            "ç”Ÿæˆå›æµ‹å› å­æ•°æ®ï¼šå°†ä½¿ç”¨ã€Œæ¢æ‰‹ç‡å€’æ¨å¸‚å€¼ã€æ–¹æ³•ä¼°ç®—æµé€šå¸‚å€¼ï¼Œ"
            "å…¬å¼: estimated_circ_mv = amount / (turnover / 100)"
        )
        logger.warning(
            "æ³¨æ„ï¼šä¼°ç®—å¸‚å€¼ä»…ä¾›å›æµ‹å‚è€ƒï¼Œå®é™…å¸‚å€¼ä»¥è´¢åŠ¡æ•°æ®ä¸ºå‡†"
        )
    
    factor_records = []
    
    # æ„å»ºè´¢åŠ¡æ•°æ®æ˜ å°„ {stock_code: {circ_mv, pe_ttm, ...}}
    financial_map: Dict[str, Dict[str, Any]] = {}
    if has_financial:
        for _, row in financial_data.iterrows():
            stock_code = row.get('stock_code', '')
            if stock_code:
                financial_map[stock_code] = {
                    'circ_mv': row.get('circ_mv', np.nan),
                    'total_mv': row.get('total_mv', np.nan),
                    'pe_ttm': row.get('pe_ttm', np.nan),
                    'pb': row.get('pb', np.nan),
                }
    
    # è®¡ç®— RSI_20 for æ¯åªè‚¡ç¥¨
    def calculate_rsi(series: pd.Series, period: int = 20) -> pd.Series:
        """è®¡ç®— RSI æŒ‡æ ‡"""
        delta = series.diff()
        gain = delta.where(delta > 0, 0.0)
        loss = (-delta).where(delta < 0, 0.0)
        
        avg_gain = gain.ewm(alpha=1.0/period, min_periods=period, adjust=False).mean()
        avg_loss = loss.ewm(alpha=1.0/period, min_periods=period, adjust=False).mean()
        
        rs = avg_gain / avg_loss.replace(0, np.nan)
        rsi = 100.0 - (100.0 / (1.0 + rs))
        
        return rsi
    
    for stock_code, df in price_data_dict.items():
        if df is None or df.empty or 'close' not in df.columns:
            continue
        
        # ç¡®ä¿ç´¢å¼•æ˜¯æ—¥æœŸç±»å‹
        df = df.copy()
        if not isinstance(df.index, pd.DatetimeIndex):
            df.index = pd.to_datetime(df.index)
        
        # è®¡ç®— RSI_20
        rsi_20 = calculate_rsi(df['close'], period=20)
        
        # è®¡ç®— Sharpe_20 (æ–°åŠ¨é‡å› å­)
        # æ»šåŠ¨å¹´åŒ–å¤æ™®æ¯”ç‡ = (mean(returns) / std(returns)) * sqrt(252)
        sharpe_20 = pd.Series(np.nan, index=df.index)
        sharpe_60 = pd.Series(np.nan, index=df.index)
        if 'close' in df.columns:
            returns = df['close'].pct_change()
            # min_periods=10: è‡³å°‘éœ€è¦åŠä¸ªçª—å£çš„æ•°æ®
            mean_ret = returns.rolling(20, min_periods=10).mean()
            std_ret = returns.rolling(20, min_periods=10).std()
            sharpe_20 = (mean_ret / std_ret.replace(0, np.nan)) * np.sqrt(252)
            
            # [NEW] Sharpe_60: æ›´å¹³æ»‘çš„é•¿å‘¨æœŸåŠ¨é‡å› å­
            mean_ret_60 = returns.rolling(60, min_periods=30).mean()
            std_ret_60 = returns.rolling(60, min_periods=30).std()
            sharpe_60 = (mean_ret_60 / std_ret_60.replace(0, np.nan)) * np.sqrt(252)

        # è®¡ç®— ROC_20 (åŠ¨é‡å› å­)
        roc_20 = pd.Series(np.nan, index=df.index)
        if 'close' in df.columns:
            # 20æ—¥å˜åŠ¨ç‡ = (Today - 20DaysAgo) / 20DaysAgo * 100
            roc_20 = df['close'].pct_change(20) * 100
        
        # è®¡ç®— 5 æ—¥å¹³å‡æ¢æ‰‹ç‡ï¼ˆæ”¯æŒå¤šç§åˆ—åï¼‰
        turnover_5d = pd.Series(np.nan, index=df.index)
        turnover_col = None
        for col_name in ['turn', 'turnover', 'turnover_rate']:
            if col_name in df.columns:
                turnover_col = col_name
                break
        if turnover_col is not None:
            turnover_5d = df[turnover_col].rolling(5, min_periods=1).mean()
        
        # [Added] é¢„è®¡ç®— IVOL_20 (ç‰¹è´¨æ³¢åŠ¨ç‡)
        ivol_20 = pd.Series(np.nan, index=df.index)
        if 'close' in df.columns:
             # è®¡ç®—æ—¥æ”¶ç›Šç‡
             daily_ret = df['close'].pct_change()
             # æ»šåŠ¨æ ‡å‡†å·® * å¹´åŒ–å› å­
             ivol_20 = daily_ret.rolling(20, min_periods=5).std() * np.sqrt(252)

        # è·å–è´¢åŠ¡æ•°æ®ï¼ˆä½œä¸ºä¼˜å…ˆä½¿ç”¨çš„é™æ€å¸‚å€¼ï¼‰
        fin_data = financial_map.get(stock_code, {})
        static_circ_mv = fin_data.get('circ_mv', np.nan)
        pe_ttm = fin_data.get('pe_ttm', np.nan)
        
        # è®¡ç®—ä¼°ç®—æµé€šå¸‚å€¼åºåˆ—ï¼ˆåŸºäºæ¢æ‰‹ç‡å€’æ¨ï¼‰
        # å…¬å¼: estimated_circ_mv = amount / (turnover / 100)
        # å«ä¹‰: æ¢æ‰‹ç‡ = æˆäº¤é‡ / æµé€šè‚¡æœ¬ï¼Œæˆäº¤é¢ â‰ˆ æˆäº¤é‡ * å½“æ—¥å‡ä»·
        #       æ‰€ä»¥: æµé€šå¸‚å€¼ â‰ˆ æˆäº¤é¢ / æ¢æ‰‹ç‡
        has_turnover = turnover_col is not None
        has_amount = 'amount' in df.columns
        
        estimated_circ_mv_series = pd.Series(np.nan, index=df.index)
        if has_turnover and has_amount:
            # æ¢æ‰‹ç‡è½¬ä¸ºå°æ•° (turnover å•ä½æ˜¯ç™¾åˆ†æ¯”ï¼Œå¦‚ 3.5 è¡¨ç¤º 3.5%)
            turnover_pct = df[turnover_col] / 100.0
            # é¿å…é™¤ä»¥é›¶æˆ–æå°å€¼
            safe_turnover = turnover_pct.replace(0, np.nan)
            safe_turnover = safe_turnover.where(safe_turnover >= 0.0001, np.nan)
            # è®¡ç®—ä¼°ç®—æµé€šå¸‚å€¼ (å•ä½ä¸ amount ä¸€è‡´ï¼Œé€šå¸¸æ˜¯å…ƒ)
            estimated_circ_mv_series = df['amount'] / safe_turnover
        
        # è®¡ç®— EP_TTM (ä»·å€¼å› å­)
        if pd.notna(pe_ttm) and pe_ttm > 0:
            ep_ttm = 1.0 / pe_ttm
        else:
            ep_ttm = np.nan
        
        for date in df.index:
            rsi_val = rsi_20.get(date, np.nan) if date in rsi_20.index else np.nan
            turnover_val = turnover_5d.get(date, np.nan) if date in turnover_5d.index else np.nan
            close_price = df.loc[date, 'close'] if date in df.index else np.nan
            
            # è·å–å½“å¤©çš„ä¼°ç®—å¸‚å€¼
            estimated_circ_mv = estimated_circ_mv_series.get(date, np.nan)
            
            # ä¼˜å…ˆçº§ï¼š1. è´¢åŠ¡æ•°æ®ä¸­çš„ circ_mv  2. æ¢æ‰‹ç‡ä¼°ç®—çš„å¸‚å€¼  3. NaN
            if pd.notna(static_circ_mv) and static_circ_mv > 0:
                circ_mv = static_circ_mv
            elif pd.notna(estimated_circ_mv) and estimated_circ_mv > 0:
                circ_mv = estimated_circ_mv
            else:
                circ_mv = np.nan
            
            # è®¡ç®— small_cap å› å­ï¼š-log(circ_mv)
            # å¸‚å€¼è¶Šå°ï¼Œ-log(å¸‚å€¼) è¶Šå¤§ï¼Œå¾—åˆ†è¶Šé«˜
            if pd.notna(circ_mv) and circ_mv > 0:
                small_cap = -np.log(circ_mv)
            else:
                small_cap = np.nan
            
            # è®¡ç®— ROE ç¨³å®šæ€§ï¼ˆç®€åŒ–ç‰ˆï¼šç”¨ PE çš„å€’æ•°ä½œä¸º ROE ä»£ç†ï¼Œè®¡ç®—å…¶æ³¢åŠ¨ç‡ï¼‰
            # æ³¨æ„ï¼šå‡†ç¡®çš„ roe_stability éœ€è¦å­£åº¦è´¢åŠ¡æ•°æ®ï¼Œè¿™é‡Œä»…ä½œå ä½
            # å®é™…ç”Ÿäº§ä¸­åº”åœ¨ data_loader åŠ è½½å®Œæ•´çš„å­£åº¦ ROE æ•°æ®
            roe_proxy = ep_ttm  # å‡è®¾ EP â‰ˆ ROE (åœ¨ PB=1 æ—¶æˆç«‹)
            roe_stability = roe_proxy if pd.notna(roe_proxy) else 0.0
            
            factor_records.append({
                'date': date,
                'stock_code': stock_code,
                'close': close_price,
                'rsi_20': rsi_val,
                'sharpe_20': sharpe_20.get(date, np.nan) if date in sharpe_20.index else np.nan,
                'sharpe_60': sharpe_60.get(date, np.nan) if date in sharpe_60.index else np.nan,
                'roc_20': roc_20.get(date, np.nan) if date in roc_20.index else np.nan,
                'turnover_5d': turnover_val,
                # å°å¸‚å€¼å› å­ï¼ˆæ ¸å¿ƒï¼‰
                'small_cap': small_cap,
                'circ_mv': circ_mv,
                # ä»·å€¼å› å­
                'ep_ttm': ep_ttm,
                # è´¨é‡å› å­ (æ–°å¢)
                'roe_stability': roe_stability,
                # æ–°å¢å› å­ï¼šç‰¹è´¨æ³¢åŠ¨ç‡ (IVOL)
                'ivol_20': ivol_20.get(date, np.nan) if date in ivol_20.index else np.nan, 
                # ä¼°ç®—ä¸Šå¸‚å¤©æ•°ï¼ˆé»˜è®¤è¶³å¤Ÿé•¿ä»¥é€šè¿‡è¿‡æ»¤ï¼‰
                'listing_days': 1000,
                # æ¶¨è·Œåœæ ‡å¿—ï¼ˆç®€åŒ–ï¼šé»˜è®¤æ— æ¶¨è·Œåœï¼‰
                'is_limit': False,
            })
    
    if not factor_records:
        logger.warning("æ— æ³•ç”Ÿæˆå› å­æ•°æ®")
        return pd.DataFrame()
    
    factor_df = pd.DataFrame(factor_records)
    
    # Z-Score æ ‡å‡†åŒ–ï¼ˆæŒ‰æ—¥æœŸåˆ†ç»„ï¼‰
    def zscore_by_date(group: pd.DataFrame, col: str) -> pd.Series:
        """æŒ‰æ—¥æœŸåˆ†ç»„è®¡ç®— Z-Score"""
        valid_vals = group[col].dropna()
        if len(valid_vals) < 2:
            return pd.Series(np.nan, index=group.index)
        
        mean_val = valid_vals.mean()
        std_val = valid_vals.std()
        if std_val > 0:
            return (group[col] - mean_val) / std_val
        else:
            return pd.Series(0.0, index=group.index)
    
    # è®¡ç®— RSI Z-Scoreï¼ˆåŠ¨é‡å› å­ï¼‰
    factor_df['momentum_zscore'] = factor_df.groupby('date', group_keys=False).apply(
        lambda g: zscore_by_date(g, 'rsi_20'), include_groups=False
    ).reset_index(level=0, drop=True)
    
    # [Added] è®¡ç®— Sharpe_20 Z-Score (æ–°çš„æ ¸å¿ƒåŠ¨é‡å› å­)
    if 'sharpe_20' in factor_df.columns:
        factor_df['sharpe_20_zscore'] = factor_df.groupby('date', group_keys=False).apply(
            lambda g: zscore_by_date(g, 'sharpe_20'), include_groups=False
        ).reset_index(level=0, drop=True)
        logger.info(f"sharpe_20_zscore ç”Ÿæˆå®Œæˆï¼Œæœ‰æ•ˆç‡: {factor_df['sharpe_20_zscore'].notna().mean():.1%}")
    else:
        # å¦‚æœ features.py è¿˜æ²¡è®¡ç®— sharpe_20ï¼Œåˆ™å°è¯•è®¡ç®—å®ƒï¼ˆé’ˆå¯¹å›æµ‹æ¨¡å¼å› å­æœªæ›´æ–°çš„æƒ…å†µï¼‰
        logger.warning("Warning: 'sharpe_20' not found in features, skipping z-score calculation")
        factor_df['sharpe_20_zscore'] = np.nan

    # [NEW] è®¡ç®— Sharpe_60 Z-Score (é•¿å‘¨æœŸåŠ¨é‡å› å­ - æ›´ç¨³å®š)
    if 'sharpe_60' in factor_df.columns:
        factor_df['sharpe_60_zscore'] = factor_df.groupby('date', group_keys=False).apply(
            lambda g: zscore_by_date(g, 'sharpe_60'), include_groups=False
        ).reset_index(level=0, drop=True)
        logger.info(f"sharpe_60_zscore ç”Ÿæˆå®Œæˆï¼Œæœ‰æ•ˆç‡: {factor_df['sharpe_60_zscore'].notna().mean():.1%}")
    else:
        factor_df['sharpe_60_zscore'] = np.nan
        logger.warning("Warning: 'sharpe_60' not found, long-term momentum unavailable")

    # è®¡ç®— ROC_20 Z-Score (å…¼å®¹æ—§ç‰ˆåŠ¨é‡å› å­)
    if 'roc_20' in factor_df.columns:
        factor_df['roc_20_zscore'] = factor_df.groupby('date', group_keys=False).apply(
            lambda g: zscore_by_date(g, 'roc_20'), include_groups=False
        ).reset_index(level=0, drop=True)
        logger.info(f"roc_20_zscore ç”Ÿæˆå®Œæˆï¼Œæœ‰æ•ˆç‡: {factor_df['roc_20_zscore'].notna().mean():.1%}")
    else:
        factor_df['roc_20_zscore'] = np.nan
        logger.warning("æ— æ³•è®¡ç®— roc_20_zscore: roc_20 åˆ—ç¼ºå¤±")

    # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„ small_cap æ•°æ®ï¼ˆæ¥è‡ªè´¢åŠ¡æ•°æ®æˆ–æ¢æ‰‹ç‡ä¼°ç®—ï¼‰
    has_valid_small_cap = factor_df['small_cap'].notna().any()
    
    # è®¡ç®— Small Cap Z-Scoreï¼ˆå°å¸‚å€¼å› å­ï¼‰
    if has_valid_small_cap:
        factor_df['small_cap_zscore'] = factor_df.groupby('date', group_keys=False).apply(
            lambda g: zscore_by_date(g, 'small_cap'), include_groups=False
        ).reset_index(level=0, drop=True)
        
        # è®¡ç®—æ¢æ‰‹ç‡ Z-Score
        factor_df['turnover_5d_zscore'] = factor_df.groupby('date', group_keys=False).apply(
            lambda g: zscore_by_date(g, 'turnover_5d'), include_groups=False
        ).reset_index(level=0, drop=True)
        
        # [Added] è®¡ç®— ROE ç¨³å®šæ€§ Z-Score (æ–°çš„è´¨é‡å› å­)
        # å¦‚æœè´¢åŠ¡æ•°æ®ä¸­åŒ…å« roe_stability (éœ€åœ¨ features.py è®¡ç®—)ï¼Œè¿™é‡Œè¿›è¡Œæ ‡å‡†åŒ–
        if 'roe_stability' in factor_df.columns:
            factor_df['roe_stability_zscore'] = factor_df.groupby('date', group_keys=False).apply(
                lambda g: zscore_by_date(g, 'roe_stability'), include_groups=False
            ).reset_index(level=0, drop=True)
        else:
            # å¦‚æœä¸Šæ¸¸æœªè®¡ç®— roe_stabilityï¼Œæš‚æ—¶ç”¨ roe (ep_ttmçš„å€’æ•°è¿‘ä¼¼) æˆ–è®¾ä¸º 0
            # è¿™é‡Œä¸ºäº†ä¸æŠ¥é”™ï¼Œå…ˆè®¾ä¸º 0ï¼Œåç»­éœ€åœ¨ features.py ç¡®ä¿è®¡ç®—
            factor_df['roe_stability_zscore'] = 0.0
            logger.warning("Warning: 'roe_stability' not found, quality factor set to 0")

        # [Added] è®¡ç®— IVOL Z-Score (ä½æ³¢å› å­)
        # IVOL è¶Šä½è¶Šå¥½ï¼Œå› æ­¤å–è´Ÿå·
        if 'ivol_20' in factor_df.columns:
             # æ³¨æ„ï¼šIVOLå¯èƒ½ä¸º0æˆ–NaNï¼Œéœ€è¦å¤„ç†
            factor_df['ivol_20'] = factor_df['ivol_20'].replace(0, np.nan)
            factor_df['ivol_zscore'] = factor_df.groupby('date', group_keys=False).apply(
                lambda g: zscore_by_date(g, 'ivol_20'), include_groups=False
            ).reset_index(level=0, drop=True)
            # åè½¬å› å­æ–¹å‘ï¼šæ³¢åŠ¨ç‡è¶Šä½åˆ†è¶Šé«˜
            factor_df['ivol_zscore'] = -factor_df['ivol_zscore']
        else:
            factor_df['ivol_zscore'] = 0.0

        # è®¡ç®—ä»·å€¼å› å­ Z-Scoreï¼ˆéœ€è¦è´¢åŠ¡æ•°æ®ï¼‰
        if has_financial:
            factor_df['value_zscore'] = factor_df.groupby('date', group_keys=False).apply(
                lambda g: zscore_by_date(g, 'ep_ttm'), include_groups=False
            ).reset_index(level=0, drop=True)
        else:
            factor_df['value_zscore'] = np.nan
            
        if not has_financial:
            logger.info(
                "å·²é€šè¿‡æ¢æ‰‹ç‡å€’æ¨å¸‚å€¼è®¡ç®— small_cap_zscoreï¼Œ"
                f"æœ‰æ•ˆè®°å½•æ•°: {factor_df['small_cap_zscore'].notna().sum()}"
            )
    else:
        # æ—¢æ— è´¢åŠ¡æ•°æ®ä¹Ÿæ— æ¢æ‰‹ç‡ä¼°ç®—æ—¶è®¾ç½®ä¸º NaN
        factor_df['small_cap_zscore'] = np.nan
        factor_df['turnover_5d_zscore'] = np.nan
        factor_df['value_zscore'] = np.nan
        
        logger.warning(
            "è­¦å‘Šï¼šæ— è´¢åŠ¡æ•°æ®ä¸”æ— æ³•é€šè¿‡æ¢æ‰‹ç‡ä¼°ç®—å¸‚å€¼ï¼Œsmall_cap_zscore è®¾ç½®ä¸º NaNã€‚"
            "å›æµ‹ç»“æœå°†ä»…åŸºäºåŠ¨é‡å› å­ï¼ˆRSIï¼‰ï¼Œæ— æ³•ä½“ç°å°å¸‚å€¼ç­–ç•¥æ•ˆæœã€‚"
        )
    
    # è´¨é‡å› å­ï¼šä½¿ç”¨æ¢æ‰‹ç‡ä½œä¸ºè´¨é‡å› å­ï¼ˆé«˜æ¢æ‰‹ç‡ = é«˜æ´»è·ƒåº¦ = é«˜è´¨é‡ï¼‰
    # å›æµ‹æ¨¡å¼ä¸‹ä¼˜å…ˆä½¿ç”¨ turnover_5d_zscore
    if 'turnover_5d_zscore' in factor_df.columns and factor_df['turnover_5d_zscore'].notna().any():
        factor_df['quality_zscore'] = factor_df['turnover_5d_zscore']
        logger.info(f"quality_zscore ä½¿ç”¨ turnover_5d_zscoreï¼Œæœ‰æ•ˆç‡: {factor_df['quality_zscore'].notna().mean():.1%}")
    else:
        # å›æµ‹æ•°æ®ä¸­æ²¡æœ‰æ¢æ‰‹ç‡ï¼ˆTushare daily æ¥å£ä¸å« turnoverï¼‰
        # è®¾ä¸º 0 è€Œé NaNï¼Œé¿å…è¯„åˆ†å¤±æ•ˆ
        factor_df['quality_zscore'] = 0.0
        logger.warning(
            "å›æµ‹æ¨¡å¼ä¸‹ quality_zscore è®¾ä¸º 0ï¼ˆæ—¥çº¿æ•°æ®ä¸å«æ¢æ‰‹ç‡ï¼‰ã€‚"
            "å»ºè®®ï¼š1) é™ä½ quality_weight æƒé‡ï¼›2) æˆ–ä½¿ç”¨ daily_update æ¨¡å¼è·å–å®Œæ•´æ•°æ®"
        )
    
    # å¡«å……åŠ¨é‡å› å­çš„ NaN
    factor_df['momentum_zscore'] = factor_df['momentum_zscore'].fillna(0.0)
    
    # ==================== è®¡ç®— Alpha å› å­ï¼ˆé‡ä»·é…åˆ + æŒ¯å¹… + èƒŒç¦»ï¼‰====================
    # Alpha_001 = (Close - VWAP) / VWAP (é‡ä»·é…åˆ)
    # Alpha_002 = (High - Low) / Close (ä»·æ ¼æŒ¯å¹…)
    # Alpha_003 = price_change_5d - volume_change_5d (é‡ä»·èƒŒç¦»)
    # IVOL_20 = 20æ—¥æ”¶ç›Šç‡æ ‡å‡†å·®ï¼ˆç‰¹è´¨æ³¢åŠ¨ç‡ï¼‰
    # Efficiency_20 = è·¯å¾„æ•ˆç‡ï¼ˆç›´çº¿è·ç¦»/å®é™…è·¯å¾„ï¼‰
    alpha_enabled = False
    alpha_records = []
    
    try:
        for stock_code, stock_df in price_data_dict.items():
            # Alpha_001: VWAP åŠ¨é‡
            alpha_001 = pd.Series(np.nan, index=stock_df.index)
            if 'amount' in stock_df.columns and 'volume' in stock_df.columns:
                vwap = stock_df['amount'] / stock_df['volume'].replace(0, np.nan)
                alpha_001 = (stock_df['close'] - vwap) / vwap.replace(0, np.nan)
                alpha_001 = alpha_001.replace([np.inf, -np.inf], np.nan)
            
            # Alpha_002: ä»·æ ¼æŒ¯å¹…
            alpha_002 = (stock_df['high'] - stock_df['low']) / stock_df['close'].replace(0, np.nan)
            alpha_002 = alpha_002.replace([np.inf, -np.inf], np.nan)
            
            # Alpha_003: é‡ä»·èƒŒç¦»ï¼ˆä»·æ ¼å˜åŒ– - æˆäº¤é‡å˜åŒ–ï¼‰
            price_change_5d = stock_df['close'].pct_change(5)
            volume_change_5d = stock_df['volume'].pct_change(5)
            alpha_003 = price_change_5d - volume_change_5d
            alpha_003 = alpha_003.replace([np.inf, -np.inf], np.nan)
            
            # IVOL_20: ç‰¹è´¨æ³¢åŠ¨ç‡ï¼ˆ20æ—¥æ”¶ç›Šç‡æ ‡å‡†å·®ï¼Œå¹´åŒ–ï¼‰
            returns = stock_df['close'].pct_change()
            ivol_20 = returns.rolling(20, min_periods=10).std() * np.sqrt(252)
            ivol_20 = ivol_20.replace([np.inf, -np.inf], np.nan)
            
            # Efficiency_20: è·¯å¾„æ•ˆç‡
            # è·¯å¾„æ•ˆç‡ = |ç›´çº¿è·ç¦»| / å®é™…è·¯å¾„è·ç¦»
            close = stock_df['close']
            direct_distance = (close - close.shift(20)).abs()
            actual_path = close.diff().abs().rolling(20, min_periods=10).sum()
            efficiency_20 = direct_distance / actual_path.replace(0, np.nan)
            efficiency_20 = efficiency_20.replace([np.inf, -np.inf], np.nan)
            # é™åˆ¶èŒƒå›´åˆ° [0, 1]
            efficiency_20 = efficiency_20.clip(0, 1)
            
            for date in stock_df.index:
                record = {
                    'date': date,
                    'stock_code': stock_code,
                    'alpha_001': alpha_001.get(date, np.nan),
                    'alpha_002': alpha_002.get(date, np.nan),
                    'alpha_003': alpha_003.get(date, np.nan),
                    'ivol_20': ivol_20.get(date, np.nan),
                    'efficiency_20': efficiency_20.get(date, np.nan),
                }
                alpha_records.append(record)
        
        if alpha_records:
            alpha_df = pd.DataFrame(alpha_records)
            factor_df = factor_df.merge(alpha_df, on=['date', 'stock_code'], how='left')
            
            # Z-Score æ ‡å‡†åŒ–ï¼ˆæŒ‰æ—¥æœŸæ¨ªæˆªé¢ï¼‰
            for col in ['alpha_001', 'alpha_002', 'alpha_003', 'ivol_20', 'efficiency_20']:
                zscore_col = f'{col}_zscore'
                if col in factor_df.columns and factor_df[col].notna().any():
                    factor_df[zscore_col] = factor_df.groupby('date', group_keys=False).apply(
                        lambda g: zscore_by_date(g, col), include_groups=False
                    ).reset_index(level=0, drop=True).fillna(0)
                else:
                    factor_df[zscore_col] = 0.0
            
            alpha_enabled = True
            logger.info("Alpha å› å­è®¡ç®—å®Œæˆ: alpha_001(VWAP), alpha_002(æŒ¯å¹…), alpha_003(èƒŒç¦»), ivol_20(æ³¢åŠ¨ç‡), efficiency_20(è·¯å¾„æ•ˆç‡)")
        else:
            for col in ['alpha_001', 'alpha_002', 'alpha_003', 'ivol_20', 'efficiency_20']:
                factor_df[f'{col}_zscore'] = 0.0
            logger.warning("æ— æ³•è®¡ç®— Alpha å› å­ï¼šç¼ºå°‘ OHLCV æ•°æ®")
    except Exception as e:
        for col in ['alpha_001', 'alpha_002', 'alpha_003', 'ivol_20', 'efficiency_20']:
            factor_df[f'{col}_zscore'] = 0.0
        logger.warning(f"Alpha å› å­è®¡ç®—å¤±è´¥: {e}")
    
    # ==================== è®¡ç®—å¤åˆåŠ¨é‡å› å­ momentum_composite_zscore ====================
    # å‡çº§ç‰ˆé…æ–¹ v2: 
    # 30% ROC (ä»·æ ¼åŠ¨é‡) + 20% Sharpe (é£é™©è°ƒæ•´) + 15% Alpha001 (VWAPé…åˆ)
    # + 10% Alpha002 (æŒ¯å¹…) + 10% Alpha005 (å°¾ç›˜å¼ºåº¦) + 10% Efficiency (è·¯å¾„æ•ˆç‡)
    # + 5% Alpha003 åå‘ (é‡ä»·èƒŒç¦»æƒ©ç½š)
    roc_col = 'roc_20_zscore' if 'roc_20_zscore' in factor_df.columns else None
    sharpe_col = 'sharpe_20_zscore' if 'sharpe_20_zscore' in factor_df.columns else None
    
    if roc_col and sharpe_col and alpha_enabled:
        # è®¡ç®— Alpha_005 (å°¾ç›˜å¼ºåº¦) å¦‚æœå­˜åœ¨
        if 'alpha_005_zscore' not in factor_df.columns:
            # è®¡ç®— alpha_005
            alpha_005_records = []
            for stock_code, stock_df in price_data_dict.items():
                range_hl = stock_df['high'] - stock_df['low']
                alpha_005 = (stock_df['close'] - stock_df['low']) / range_hl.replace(0, np.nan)
                for date in stock_df.index:
                    if pd.notna(alpha_005.get(date)):
                        alpha_005_records.append({'date': date, 'stock_code': stock_code, 'alpha_005': alpha_005[date]})
            if alpha_005_records:
                alpha_005_df = pd.DataFrame(alpha_005_records)
                factor_df = factor_df.merge(alpha_005_df, on=['date', 'stock_code'], how='left')
                factor_df['alpha_005_zscore'] = factor_df.groupby('date', group_keys=False).apply(
                    lambda g: zscore_by_date(g, 'alpha_005'), include_groups=False
                ).reset_index(level=0, drop=True).fillna(0)
            else:
                factor_df['alpha_005_zscore'] = 0.0
        
        # å‡çº§ç‰ˆå¤åˆåŠ¨é‡å› å­
        factor_df['momentum_composite_zscore'] = (
            0.30 * factor_df[roc_col].fillna(0) +                           # ä»·æ ¼åŠ¨é‡
            0.20 * factor_df[sharpe_col].fillna(0) +                        # é£é™©è°ƒæ•´åŠ¨é‡
            0.15 * factor_df['alpha_001_zscore'].fillna(0) +                # VWAP é…åˆ
            0.10 * factor_df['alpha_002_zscore'].fillna(0) +                # ä»·æ ¼æŒ¯å¹…
            0.10 * factor_df.get('alpha_005_zscore', pd.Series(0, index=factor_df.index)).fillna(0) +  # å°¾ç›˜å¼ºåº¦
            0.10 * factor_df['efficiency_20_zscore'].fillna(0) +            # è·¯å¾„æ•ˆç‡
            0.05 * (-factor_df['alpha_003_zscore'].fillna(0))               # é‡ä»·èƒŒç¦»æƒ©ç½šï¼ˆåå‘ï¼‰
        )
        logger.info("ğŸš€ å¤åˆåŠ¨é‡å› å­ v2 è®¡ç®—å®Œæˆ: 30% ROC + 20% Sharpe + 15% Î±001 + 10% Î±002 + 10% Î±005 + 10% Efficiency - 5% Î±003(èƒŒç¦»)")
    elif roc_col and sharpe_col:
        factor_df['momentum_composite_zscore'] = (
            0.6 * factor_df[roc_col].fillna(0) +
            0.4 * factor_df[sharpe_col].fillna(0)
        )
        logger.info("å¤åˆåŠ¨é‡å› å­è®¡ç®—å®Œæˆ: 60% ROC + 40% Sharpeï¼ˆæ—  Alphaï¼‰")
    elif roc_col:
        factor_df['momentum_composite_zscore'] = factor_df[roc_col].fillna(0)
        logger.warning("å¤åˆåŠ¨é‡å› å­ä½¿ç”¨ ROC å•å› å­")
    else:
        factor_df['momentum_composite_zscore'] = factor_df['momentum_zscore'].fillna(0)
        logger.warning("å¤åˆåŠ¨é‡å› å­ä½¿ç”¨ RSI ä½œä¸ºåå¤‡")
    
    # ==================== è®¡ç®—å¤åˆè´¨é‡å› å­ quality_composite_zscore ====================
    # å‡çº§ç‰ˆé…æ–¹: 50% æ¢æ‰‹ç‡ + 30% ä½æ³¢åŠ¨ (IVOLåå‘) + 20% è·¯å¾„æ•ˆç‡
    if 'turnover_5d_zscore' in factor_df.columns and factor_df['turnover_5d_zscore'].notna().any():
        turnover_component = factor_df['turnover_5d_zscore'].fillna(0)
    else:
        turnover_component = pd.Series(0.0, index=factor_df.index)
    
    # IVOL åå‘ä½¿ç”¨ï¼ˆä½æ³¢åŠ¨æ›´å¥½ï¼‰
    ivol_component = -factor_df['ivol_20_zscore'].fillna(0) if 'ivol_20_zscore' in factor_df.columns else pd.Series(0.0, index=factor_df.index)
    
    # è·¯å¾„æ•ˆç‡ï¼ˆé«˜æ•ˆç‡æ›´å¥½ï¼‰
    efficiency_component = factor_df['efficiency_20_zscore'].fillna(0) if 'efficiency_20_zscore' in factor_df.columns else pd.Series(0.0, index=factor_df.index)
    
    factor_df['quality_composite_zscore'] = (
        0.50 * turnover_component +      # æ¢æ‰‹ç‡/æµåŠ¨æ€§
        0.30 * ivol_component +           # ä½æ³¢åŠ¨å¼‚è±¡ï¼ˆåå‘ï¼‰
        0.20 * efficiency_component       # è·¯å¾„æ•ˆç‡
    )
    logger.info("ğŸ“Š å¤åˆè´¨é‡å› å­è®¡ç®—å®Œæˆ: 50% æ¢æ‰‹ç‡ + 30% ä½æ³¢åŠ¨(åå‘) + 20% è·¯å¾„æ•ˆç‡")
    
    # ç»Ÿè®¡æœ‰æ•ˆçš„å°å¸‚å€¼å› å­æ•°é‡
    valid_small_cap = factor_df['small_cap_zscore'].notna().sum()
    total_records = len(factor_df)
    
    logger.info(
        f"å› å­æ•°æ®ç”Ÿæˆå®Œæˆ: {total_records} æ¡è®°å½•, "
        f"{factor_df['stock_code'].nunique()} åªè‚¡ç¥¨, "
        f"{factor_df['date'].nunique()} ä¸ªäº¤æ˜“æ—¥"
    )
    
    if has_financial:
        logger.info(
            f"å°å¸‚å€¼å› å­ (small_cap_zscore) æœ‰æ•ˆç‡: "
            f"{valid_small_cap}/{total_records} ({valid_small_cap/total_records:.1%})"
        )
    
    return factor_df


def run_backtest(
    start_date: str,
    end_date: str,
    config: Optional[Dict[str, Any]] = None,
    strategy_type: str = "multi_factor",
    no_llm: bool = False
) -> bool:
    """
    è¿è¡Œç­–ç•¥å›æµ‹
    
    ä½¿ç”¨ BacktestEngine + MultiFactorStrategy å¯¹æŒ‡å®šæ—¶é—´æ®µçš„å†å²æ•°æ®è¿›è¡Œå›æµ‹ã€‚
    æ”¯æŒå¤§ç›˜é£æ§ï¼ˆé€šè¿‡ benchmark_data ä¼ å…¥åŸºå‡†æŒ‡æ•°æ•°æ®ï¼‰ã€‚
    
    Parameters
    ----------
    start_date : str
        å›æµ‹å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
    end_date : str
        å›æµ‹ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
    config : Optional[Dict[str, Any]]
        å›æµ‹é…ç½®å‚æ•°
    strategy_type : str
        ç­–ç•¥ç±»å‹: 'multi_factor', 'ma_cross'
    no_llm : bool
        æ˜¯å¦ç¦ç”¨ LLM é£æ§
    
    Returns
    -------
    bool
        å›æµ‹æ˜¯å¦æˆåŠŸ
    
    Notes
    -----
    å›æµ‹æµç¨‹ï¼š
    1. åŠ è½½å†å² OHLCV æ•°æ®
    2. å‡†å¤‡ä»·æ ¼çŸ©é˜µ
    3. åŠ è½½å†å²è´¢åŠ¡æ•°æ®ï¼ˆç‰¹åˆ«æ˜¯æµé€šå¸‚å€¼ circ_mvï¼Œç”¨äºå°å¸‚å€¼å› å­ï¼‰
    4. è·å–åŸºå‡†æŒ‡æ•°æ•°æ®ï¼ˆç”¨äºå¤§ç›˜é£æ§ï¼‰
    5. ç”Ÿæˆå› å­æ•°æ®ï¼ˆå« small_cap = -log(circ_mv)ï¼Œmomentum ç­‰ï¼‰
    6. ä½¿ç”¨ BacktestEngine æ‰§è¡Œæƒé‡é©±åŠ¨å›æµ‹
    7. ç”Ÿæˆå›æµ‹æŠ¥å‘Š
    
    å°å¸‚å€¼ç­–ç•¥è¦æ±‚ï¼š
    - éœ€è¦æœ¬åœ°å­˜å‚¨çš„è´¢åŠ¡æ•°æ®æ–‡ä»¶ï¼ˆdata/raw/financial_*.parquetï¼‰
    - è´¢åŠ¡æ•°æ®éœ€åŒ…å« circ_mvï¼ˆæµé€šå¸‚å€¼ï¼‰å­—æ®µ
    - å¦‚æœæ— è´¢åŠ¡æ•°æ®ï¼Œç­–ç•¥ä¼šè‡ªåŠ¨é€€åŒ–ä¸ºçº¯åŠ¨é‡ç­–ç•¥
    """
    logger = logging.getLogger(__name__)
    logger.info("=" * 60)
    logger.info(f"å¼€å§‹å›æµ‹: {start_date} ~ {end_date}")
    logger.info("ä½¿ç”¨å¼•æ“: BacktestEngine (æƒé‡é©±åŠ¨ + å¤§ç›˜é£æ§)")
    if no_llm:
        logger.info("å‚æ•°è®¾ç½®: ç¦ç”¨ LLM é£æ§")
    logger.info("=" * 60)
    
    try:
        # ========================================
        # Step 0: åŠ è½½é…ç½®
        # ========================================
        if config is None:
            try:
                config = load_config(CONFIG_PATH)
            except FileNotFoundError:
                logger.warning(f"é…ç½®æ–‡ä»¶ {CONFIG_PATH} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                config = {}
        
        # å¤„ç† LLM ç¦ç”¨
        if no_llm:
            config["llm"] = {}
        
        # æå–é…ç½®
        backtest_config = config.get("backtest", {})
        portfolio_config = config.get("portfolio", {})
        strategy_config = config.get("strategy", {})
        data_config = config.get("data", {})
        
        initial_capital = portfolio_config.get("total_capital", 300000)
        commission = config.get("trading", {}).get("commission_rate", 0.0003)
        slippage = config.get("trading", {}).get("slippage", 0.001)
        risk_free_rate = portfolio_config.get("risk_free_rate", 0.02)
        optimization_objective = portfolio_config.get("optimization_objective", "equal_weight")
        
        # åŸºå‡†æŒ‡æ•°ä»£ç ï¼ˆé»˜è®¤ä¸­è¯500ï¼‰
        benchmark_code = backtest_config.get("benchmark", "000905")
        
        logger.info(f"å›æµ‹é…ç½®: åˆå§‹èµ„é‡‘=Â¥{initial_capital:,.0f}, åŸºå‡†={benchmark_code}")
        
        # ========================================
        # Step 1: åŠ è½½å†å²æ•°æ®
        # ========================================
        logger.info("Step 1/7: åŠ è½½å†å² OHLCV æ•°æ®")
        
        data_loader = DataLoader(output_dir=str(DATA_RAW_PATH))
        
        # è·å–è‚¡ç¥¨åˆ—è¡¨ï¼ˆæ ¹æ®é…ç½®é€‰æ‹©è‚¡ç¥¨æ± ï¼‰
        stock_pool = data_config.get("stock_pool", "zz500")
        
        # å°è¯•è·å–æŒ‡å®šè‚¡ç¥¨æ± çš„æˆåˆ†è‚¡ï¼ˆä½¿ç”¨ Tushareï¼‰
        stock_list = []
        tushare_loader = create_tushare_loader()
        
        if stock_pool == "zz500":
            # è·å–ä¸­è¯500æˆåˆ†è‚¡
            try:
                stock_list = tushare_loader.fetch_index_constituents(index_code="zz500")
                if stock_list:
                    logger.info(f"è·å–ä¸­è¯500æˆåˆ†è‚¡æˆåŠŸï¼Œå…± {len(stock_list)} åª")
            except Exception as e:
                logger.warning(f"è·å–ä¸­è¯500æˆåˆ†è‚¡å¤±è´¥: {e}")
            
            if not stock_list:
                logger.warning("æ— æ³•è·å–ä¸­è¯500æˆåˆ†è‚¡ï¼Œå°è¯•è·å–æ²ªæ·±300")
                stock_list = data_loader.get_hs300_constituents()
        elif stock_pool == "hs300":
            stock_list = data_loader.get_hs300_constituents()
        elif stock_pool == "zz1000":
            # è·å–ä¸­è¯1000æˆåˆ†è‚¡
            try:
                stock_list = tushare_loader.fetch_index_constituents(index_code="zz1000")
                if stock_list:
                    logger.info(f"è·å–ä¸­è¯1000æˆåˆ†è‚¡æˆåŠŸï¼Œå…± {len(stock_list)} åª")
            except Exception as e:
                logger.warning(f"è·å–ä¸­è¯1000æˆåˆ†è‚¡å¤±è´¥: {e}")
                
            if not stock_list:
                logger.warning("æ— æ³•è·å–ä¸­è¯1000æˆåˆ†è‚¡ï¼Œå°è¯•ä»æœ¬åœ°ç¼“å­˜åŠ è½½æˆ–ä½¿ç”¨ç¤ºä¾‹è‚¡ç¥¨")
        else:
            stock_list = data_loader.get_hs300_constituents()
        
        if not stock_list:
            logger.warning("æ— æ³•è·å–æˆåˆ†è‚¡åˆ—è¡¨ï¼Œä½¿ç”¨ç¤ºä¾‹è‚¡ç¥¨")
            stock_list = ["000001", "000002", "600519", "601318", "000858",
                         "000063", "000651", "000725", "002415", "600036"]
        
        # é™åˆ¶å›æµ‹è‚¡ç¥¨æ•°é‡ï¼ˆé¿å…è¿‡é•¿æ—¶é—´ï¼‰
        max_stocks = backtest_config.get("max_stocks", 100)
        stock_list = stock_list[:max_stocks]
        logger.info(f"è‚¡ç¥¨æ± : {stock_pool}, å›æµ‹è‚¡ç¥¨æ•°é‡: {len(stock_list)}")
        
        # ä¸‹è½½å†å²æ•°æ®
        price_data_dict: Dict[str, pd.DataFrame] = {}
        start_fmt = start_date.replace("-", "")
        end_fmt = end_date.replace("-", "")
        
        # [OPTIMIZED] ä¼˜å…ˆä»æœ¬åœ°ç¼“å­˜åŠ è½½æ•°æ®
        # è·¯å¾„: data/lake/daily/{stock}.parquet
        local_cache_dir = Path("data/lake/daily")
        loaded_from_cache = 0
        
        for i, stock in enumerate(stock_list):
            df = None
            try:
                # 1. å°è¯•è¯»å–æœ¬åœ°ç¼“å­˜
                cache_file = local_cache_dir / f"{stock}.parquet"
                if cache_file.exists():
                    try:
                        cached_df = pd.read_parquet(cache_file)
                        
                        # å¤„ç†æ—¥æœŸï¼šå¯èƒ½åœ¨ 'date' åˆ—æˆ–ä½œä¸º index
                        if 'date' not in cached_df.columns:
                            # æ—¥æœŸå¯èƒ½æ˜¯ indexï¼Œå°è¯• reset_index
                            if isinstance(cached_df.index, pd.DatetimeIndex):
                                cached_df = cached_df.reset_index()
                                cached_df.columns = ['date'] + list(cached_df.columns[1:])
                            elif cached_df.index.name == 'date' or cached_df.index.name == 'trade_date':
                                cached_df = cached_df.reset_index()
                        
                        # ç¡®ä¿ date åˆ—å­˜åœ¨
                        if not cached_df.empty and 'date' in cached_df.columns:
                            cached_df['date'] = pd.to_datetime(cached_df['date'])
                            cache_start = cached_df['date'].min()
                            cache_end = cached_df['date'].max()
                            req_start = pd.to_datetime(start_date)
                            req_end = pd.to_datetime(end_date)
                            
                            # [FIX] æ”¾å®½æ—¥æœŸæ£€æŸ¥ï¼šå…è®¸ 7 å¤©çš„è¯¯å·®ï¼ˆå¤„ç†èŠ‚å‡æ—¥å’Œæ•°æ®å»¶è¿Ÿï¼‰
                            # å› ä¸ºå®é™…äº¤æ˜“æ—¥å¯èƒ½æ¯”æ—¥å†æ—¥å°‘
                            tolerance = pd.Timedelta(days=7)
                            if cache_start <= req_start and cache_end >= (req_end - tolerance):
                                # ç­›é€‰æ—¶é—´æ®µ
                                df = cached_df[(cached_df['date'] >= req_start) & (cached_df['date'] <= cache_end)].copy()
                                if not df.empty:
                                    df = df.set_index('date').sort_index()
                                    loaded_from_cache += 1
                    except Exception as e:
                        logger.debug(f"è¯»å–æœ¬åœ°ç¼“å­˜ {stock} å¤±è´¥: {e}")

                # 2. å¦‚æœæœ¬åœ°æ²¡æœ‰æˆ–ä¸æ»¡è¶³ï¼Œåˆ™ä¸‹è½½
                if df is None or df.empty:
                    df = data_loader.fetch_daily_price(stock, start_fmt, end_fmt)
                    
                    # [NEW] ä¸‹è½½æˆåŠŸåä¿å­˜åˆ°æœ¬åœ°ç¼“å­˜
                    if df is not None and not df.empty:
                        try:
                            local_cache_dir.mkdir(parents=True, exist_ok=True)
                            # ä¿å­˜æ—¶å°† index è½¬ä¸º date åˆ—
                            save_df = df.reset_index()
                            save_df.columns = ['date'] + list(save_df.columns[1:])
                            save_df.to_parquet(cache_file, index=False)
                        except Exception as e:
                            logger.debug(f"ä¿å­˜ç¼“å­˜ {stock} å¤±è´¥: {e}")
                
                if df is not None and not df.empty:
                    price_data_dict[stock] = df
            except Exception as e:
                logger.debug(f"è·å– {stock} æ•°æ®å¤±è´¥: {e}")
            
            if (i + 1) % 100 == 0:
                logger.info(f"æ•°æ®åŠ è½½è¿›åº¦: {i + 1}/{len(stock_list)} (ç¼“å­˜å‘½ä¸­: {loaded_from_cache})")
        
        if not price_data_dict:
            logger.error("æœªè·å–åˆ°ä»»ä½•å†å²æ•°æ®")
            return False
        
        logger.info(f"æˆåŠŸåŠ è½½ {len(price_data_dict)} åªè‚¡ç¥¨çš„å†å²æ•°æ®")
        
        # ========================================
        # Step 2: å‡†å¤‡ä»·æ ¼çŸ©é˜µ
        # ========================================
        logger.info("Step 2/7: å‡†å¤‡ä»·æ ¼çŸ©é˜µ")
        
        # æ„å»ºæ”¶ç›˜ä»· DataFrame (è¡Œ=æ—¥æœŸ, åˆ—=è‚¡ç¥¨)
        close_prices = {}
        for stock, df in price_data_dict.items():
            if 'close' in df.columns:
                close_prices[stock] = df['close']
        
        close_df = pd.DataFrame(close_prices)
        close_df.index = pd.to_datetime(close_df.index)
        close_df = close_df.sort_index()
        
        # å¡«å……ç¼ºå¤±å€¼
        close_df = close_df.ffill().bfill()
        
        logger.info(f"ä»·æ ¼çŸ©é˜µ: {close_df.shape[0]} å¤© x {close_df.shape[1]} åªè‚¡ç¥¨")
        
        # ========================================
        # Step 2.5: è·å–æ¢æ‰‹ç‡æ•°æ®ï¼ˆquality å› å­éœ€è¦ï¼‰
        # ========================================
        logger.info("Step 2.5/7: è·å–æ¢æ‰‹ç‡æ•°æ®ï¼ˆdaily_basic æ¥å£ï¼‰")
        
        try:
            # è·å–å›æµ‹æœŸé—´å†…çš„æ‰€æœ‰äº¤æ˜“æ—¥
            trading_dates = close_df.index.strftime('%Y%m%d').tolist()
            
            # ä» daily_basic æ¥å£æ‰¹é‡è·å–æ¢æ‰‹ç‡
            turnover_data = {}
            from src.tushare_loader import TushareDataLoader
            ts_loader = TushareDataLoader()
            
            # æŒ‰æ—¥æœŸæ‰¹é‡è·å–ï¼ˆé¿å…é¢‘ç¹ API è°ƒç”¨ï¼‰
            sample_dates = trading_dates[::5]  # æ¯5å¤©é‡‡æ ·ä¸€æ¬¡ï¼Œå‡å°‘APIè°ƒç”¨
            logger.info(f"é‡‡æ ·è·å– {len(sample_dates)} ä¸ªäº¤æ˜“æ—¥çš„æ¢æ‰‹ç‡æ•°æ®...")
            
            for trade_date in sample_dates:
                try:
                    basic_df = ts_loader.fetch_daily_basic(trade_date=trade_date)
                    if basic_df is not None and not basic_df.empty:
                        # æå–æ¢æ‰‹ç‡ (turn åˆ—)
                        if 'turn' in basic_df.columns and 'ts_code' in basic_df.columns:
                            for _, row in basic_df.iterrows():
                                ts_code = row['ts_code']
                                stock_code = ts_code.split('.')[0] if '.' in ts_code else ts_code
                                if stock_code in price_data_dict:
                                    if stock_code not in turnover_data:
                                        turnover_data[stock_code] = {}
                                    date_key = pd.to_datetime(trade_date)
                                    turnover_data[stock_code][date_key] = row.get('turn', np.nan)
                except Exception as e:
                    logger.debug(f"è·å– {trade_date} æ¢æ‰‹ç‡å¤±è´¥: {e}")
                    continue
            
            # å°†æ¢æ‰‹ç‡åˆå¹¶åˆ° price_data_dict
            turnover_merged_count = 0
            for stock_code, df in price_data_dict.items():
                if stock_code in turnover_data:
                    turn_series = pd.Series(turnover_data[stock_code])
                    # å°†æ¢æ‰‹ç‡æ·»åŠ ä¸ºæ–°åˆ—ï¼Œå¹¶ç”¨å‰å‘å¡«å……è¡¥å…¨
                    df['turn'] = turn_series.reindex(df.index).ffill().bfill()
                    if df['turn'].notna().any():
                        turnover_merged_count += 1
            
            logger.info(f"æ¢æ‰‹ç‡æ•°æ®åˆå¹¶å®Œæˆ: {turnover_merged_count}/{len(price_data_dict)} åªè‚¡ç¥¨æœ‰æ¢æ‰‹ç‡")
            
        except Exception as e:
            logger.warning(f"è·å–æ¢æ‰‹ç‡æ•°æ®å¤±è´¥ï¼Œquality å› å­å°†ä¸å¯ç”¨: {e}")
        
        # ========================================
        # Step 3: åŠ è½½å†å²è´¢åŠ¡æ•°æ®ï¼ˆå…³é”®ï¼šå°å¸‚å€¼å› å­éœ€è¦ circ_mvï¼‰
        # ========================================
        logger.info("Step 3/7: åŠ è½½å†å²è´¢åŠ¡æ•°æ®ï¼ˆæµé€šå¸‚å€¼ circ_mvï¼‰")
        
        financial_data: Optional[pd.DataFrame] = None
        has_financial_data = False
        
        try:
            financial_data = _load_backtest_financial_data(
                stock_list=list(price_data_dict.keys()),
                start_date=start_date,
                end_date=end_date,
                data_loader=data_loader
            )
            
            if financial_data is not None and not financial_data.empty:
                has_financial_data = 'circ_mv' in financial_data.columns
                logger.info(
                    f"è´¢åŠ¡æ•°æ®åŠ è½½æˆåŠŸ: {len(financial_data)} æ¡è®°å½•, "
                    f"circ_mv å¯ç”¨: {has_financial_data}"
                )
            else:
                logger.warning("è´¢åŠ¡æ•°æ®ä¸ºç©º")
                
        except FileNotFoundError as e:
            logger.error(f"è´¢åŠ¡æ•°æ®åŠ è½½å¤±è´¥: {e}")
            logger.error("å°å¸‚å€¼ç­–ç•¥å›æµ‹éœ€è¦è´¢åŠ¡æ•°æ®ã€‚å¦‚æœæ‚¨åªæƒ³è¿è¡ŒåŠ¨é‡ç­–ç•¥ï¼Œè¯·ç»§ç»­ï¼›å¦åˆ™è¯·å…ˆå‡†å¤‡è´¢åŠ¡æ•°æ®ã€‚")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œå…è®¸ç»§ç»­ï¼ˆé€€åŒ–ä¸ºçº¯åŠ¨é‡ç­–ç•¥ï¼‰
            financial_data = None
        except Exception as e:
            logger.warning(f"åŠ è½½è´¢åŠ¡æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}ï¼Œå°†ä½¿ç”¨çº¯åŠ¨é‡ç­–ç•¥")
            financial_data = None
        
        # ========================================
        # Step 4: è·å–åŸºå‡†æŒ‡æ•°æ•°æ®ï¼ˆç”¨äºå¤§ç›˜é£æ§ï¼‰
        # ========================================
        logger.info(f"Step 4/7: è·å–åŸºå‡†æŒ‡æ•°æ•°æ® ({benchmark_code})")
        
        benchmark_data: Optional[pd.DataFrame] = None
        
        try:
            benchmark_data = data_loader.fetch_index_price(
                index_code=benchmark_code,
                start_date=start_date,
                end_date=end_date
            )
            
            if benchmark_data is not None and not benchmark_data.empty:
                logger.info(
                    f"åŸºå‡†æŒ‡æ•°æ•°æ®è·å–æˆåŠŸ: {len(benchmark_data)} æ¡è®°å½•, "
                    f"æ—¥æœŸèŒƒå›´: {benchmark_data.index[0].strftime('%Y-%m-%d')} ~ "
                    f"{benchmark_data.index[-1].strftime('%Y-%m-%d')}"
                )
            else:
                logger.warning("åŸºå‡†æŒ‡æ•°æ•°æ®ä¸ºç©ºï¼Œå¤§ç›˜é£æ§å°†ä¸ç”Ÿæ•ˆ")
                benchmark_data = None
                
        except Exception as e:
            logger.warning(f"è·å–åŸºå‡†æŒ‡æ•°æ•°æ®å¤±è´¥: {e}ï¼Œå¤§ç›˜é£æ§å°†ä¸ç”Ÿæ•ˆ")
            benchmark_data = None
        
        # ========================================
        # Step 5: ç”Ÿæˆå› å­æ•°æ®ï¼ˆå«å°å¸‚å€¼å› å­ï¼‰
        # ========================================
        if has_financial_data:
            logger.info("Step 5/7: ç”Ÿæˆå› å­æ•°æ®ï¼ˆå«å°å¸‚å€¼å› å­ small_capï¼‰")
        else:
            logger.warning("Step 5/7: ç”Ÿæˆå› å­æ•°æ®ï¼ˆæ— è´¢åŠ¡æ•°æ®ï¼Œä»…åŠ¨é‡å› å­ï¼‰")
        
        factor_data = _generate_backtest_factor_data(
            price_data_dict=price_data_dict,
            close_df=close_df,
            strategy_config=strategy_config,
            financial_data=financial_data
        )
        
        if factor_data.empty:
            logger.error("å› å­æ•°æ®ç”Ÿæˆå¤±è´¥")
            return False
        
        # ========================================
        # Step 6: åˆå§‹åŒ–ç­–ç•¥å’Œå¼•æ“ï¼Œæ‰§è¡Œå›æµ‹
        # ========================================
        logger.info("Step 6/7: åˆå§‹åŒ–ç­–ç•¥å’Œå¼•æ“ï¼Œæ‰§è¡Œå›æµ‹")
        
        if strategy_type == "multi_factor":
            # å¤šå› å­ç­–ç•¥
            # ä»é…ç½®è¯»å–å› å­æƒé‡
            value_weight = strategy_config.get("value_weight", 0.0)
            quality_weight = strategy_config.get("quality_weight", 0.0)
            momentum_weight = strategy_config.get("momentum_weight", 1.0)
            size_weight = strategy_config.get("size_weight", 0.0)
            
            # [NEW] æ£€æµ‹ quality_zscore æ•°æ®å¯ç”¨æ€§ï¼ˆå›æµ‹æ¨¡å¼ä¸‹å¯èƒ½å…¨ä¸º 0ï¼‰
            if 'quality_zscore' in factor_data.columns:
                quality_valid_rate = (factor_data['quality_zscore'] != 0).mean()
                if quality_valid_rate < 0.01 and quality_weight > 0:
                    logger.warning(
                        f"âš ï¸ å›æµ‹æ•°æ®ç¼ºå°‘æ¢æ‰‹ç‡ï¼Œquality_zscore å…¨ä¸º 0ã€‚"
                        f"è‡ªåŠ¨è°ƒæ•´: quality_weight {quality_weight:.0%} -> 0%ï¼Œ"
                        f"momentum_weight {momentum_weight:.0%} -> {momentum_weight + quality_weight:.0%}"
                    )
                    momentum_weight += quality_weight  # å°† quality æƒé‡è½¬ç§»åˆ° momentum
                    quality_weight = 0.0
            
            # æ ¹æ®è´¢åŠ¡æ•°æ®å¯ç”¨æ€§è°ƒæ•´ç­–ç•¥é…ç½®
            if has_financial_data:
                # è´¢åŠ¡æ•°æ®å¯ç”¨ï¼Œå¯ä»¥ä½¿ç”¨å°å¸‚å€¼ç­–ç•¥
                logger.info("è´¢åŠ¡æ•°æ®å¯ç”¨ï¼Œå¯ç”¨å°å¸‚å€¼å› å­ (small_cap)")
                
                # å¦‚æœé…ç½®äº† size_weight æˆ–ç­–ç•¥éœ€è¦å°å¸‚å€¼å› å­
                if size_weight > 0 or strategy_config.get("use_small_cap", True):
                    # ä½¿ç”¨å°å¸‚å€¼å› å­
                    value_col = strategy_config.get("value_col", "small_cap_zscore")
                    size_col = strategy_config.get("size_col", "small_cap_zscore")
                else:
                    value_col = strategy_config.get("value_col", "value_zscore")
                    size_col = strategy_config.get("size_col", "small_cap_zscore")
            else:
                # æ— è´¢åŠ¡æ•°æ®ï¼Œé€€åŒ–ä¸ºçº¯åŠ¨é‡ç­–ç•¥
                logger.warning(
                    f"æ— è´¢åŠ¡æ•°æ®ï¼Œå°å¸‚å€¼å› å­ä¸å¯ç”¨ã€‚"
                    f"è‡ªåŠ¨è°ƒæ•´ä¸ºçº¯åŠ¨é‡ç­–ç•¥ (momentum=1.0)"
                )
                # å¼ºåˆ¶è°ƒæ•´æƒé‡
                if value_weight > 0 or size_weight > 0:
                    logger.warning(
                        f"åŸé…ç½®æƒé‡ (value={value_weight}, size={size_weight}) "
                        f"å› ç¼ºå°‘è´¢åŠ¡æ•°æ®è¢«ç½®ä¸º 0"
                    )
                value_weight = 0.0
                size_weight = 0.0
                quality_weight = 0.0
                momentum_weight = 1.0
                value_col = "value_zscore"
                size_col = "small_cap_zscore"
            
            strategy = MultiFactorStrategy(
                name="Multi-Factor Backtest" + (" (å°å¸‚å€¼å¢å¼º)" if has_financial_data else " (çº¯åŠ¨é‡)"),
                config={
                    "value_weight": value_weight,
                    "quality_weight": quality_weight,
                    "momentum_weight": momentum_weight,
                    "size_weight": size_weight,
                    "top_n": strategy_config.get("top_n", 5),
                    "min_listing_days": strategy_config.get("min_listing_days", 126),
                    "rebalance_frequency": strategy_config.get("rebalance_frequency", "monthly"),
                    "rebalance_buffer": strategy_config.get("rebalance_buffer", 0.05),
                    # [NEW] æŒè‚¡æƒ¯æ€§åŠ åˆ†
                    "holding_bonus": strategy_config.get("holding_bonus", 0.0),
                    # [NEW] å¤§ç›˜é£æ§é…ç½®ï¼ˆä» risk éƒ¨åˆ†è¯»å–ï¼‰
                    "market_risk": config.get("risk", {}).get("market_risk", {}),
                    # å› å­åˆ—åé…ç½®
                    "value_col": value_col,
                    "quality_col": strategy_config.get("quality_col", "quality_zscore"),
                    "momentum_col": strategy_config.get("momentum_col", "momentum_zscore"),
                    "size_col": size_col,
                    "date_col": "date",
                    "stock_col": "stock_code",
                }
            )
            logger.info(
                f"ä½¿ç”¨å¤šå› å­ç­–ç•¥: value={value_weight}, quality={quality_weight}, "
                f"momentum={momentum_weight}, size={size_weight}, top_n={strategy.top_n}"
            )
            if has_financial_data:
                logger.info(f"å› å­åˆ—: value_col={value_col}, size_col={size_col}")
        else:
            # å‡çº¿äº¤å‰ç­–ç•¥ï¼ˆä¸æ”¯æŒæƒé‡é©±åŠ¨å›æµ‹ï¼Œä½¿ç”¨ç®€åŒ–é€»è¾‘ï¼‰
            strategy = MACrossStrategy(
                name="MA Cross Backtest",
                config={
                    "short_window": 5,
                    "long_window": 20,
                }
            )
            logger.info("ä½¿ç”¨å‡çº¿äº¤å‰ç­–ç•¥")
            logger.warning("å‡çº¿ç­–ç•¥æš‚ä¸æ”¯æŒæƒé‡é©±åŠ¨å›æµ‹ï¼Œä½¿ç”¨ç®€åŒ–é€»è¾‘")
        
        # åˆå§‹åŒ– BacktestEngine
        backtest_engine = BacktestEngine(config={
            "initial_capital": initial_capital,
            "commission": commission,
            "slippage": slippage,
            "risk_free_rate": risk_free_rate,
        })
        
        logger.info(
            f"BacktestEngine åˆå§‹åŒ–: åˆå§‹èµ„é‡‘=Â¥{initial_capital:,.0f}, "
            f"ä½£é‡‘={commission*10000:.1f}â€±, æ»‘ç‚¹={slippage*100:.2f}%"
        )
        
        # æ‰§è¡Œå›æµ‹ï¼ˆæƒé‡é©±åŠ¨æ¨¡å¼ï¼‰
        if strategy_type == "multi_factor":
            logger.info("æ‰§è¡Œæƒé‡é©±åŠ¨å›æµ‹...")
            
            result = backtest_engine.run(
                strategy=strategy,
                price_data=close_df,
                factor_data=factor_data,
                objective=optimization_objective,
                benchmark_data=benchmark_data  # ä¼ å…¥åŸºå‡†æ•°æ®ç”¨äºå¤§ç›˜é£æ§
            )
            
            total_return = result.total_return
            annual_return = result.annual_return
            sharpe_ratio = result.sharpe_ratio
            max_drawdown = result.max_drawdown
            total_trades = result.total_trades
            win_rate = result.win_rate
            
        else:
            # MA Cross ç­–ç•¥ä½¿ç”¨ç®€åŒ–å›æµ‹
            logger.warning("MA Cross ç­–ç•¥ä½¿ç”¨ç®€åŒ–å›æµ‹é€»è¾‘")
            
            # ä½¿ç”¨ç¬¬ä¸€åªè‚¡ç¥¨è¿›è¡Œå•è‚¡ç¥¨å›æµ‹æ¼”ç¤º
            stock_code = list(price_data_dict.keys())[0]
            single_price_df = price_data_dict[stock_code]
            
            # ç”Ÿæˆä¿¡å·
            signals = strategy.generate_signals(single_price_df)
            
            # ç®€åŒ–è®¡ç®—æ”¶ç›Š
            returns = single_price_df['close'].pct_change()
            strategy_returns = returns * signals.shift(1)
            
            total_return = (1 + strategy_returns).prod() - 1
            annual_return = (1 + total_return) ** (252 / len(strategy_returns)) - 1
            sharpe_ratio = strategy_returns.mean() / strategy_returns.std() * np.sqrt(252) if strategy_returns.std() > 0 else 0
            
            cum_returns = (1 + strategy_returns).cumprod()
            peak = cum_returns.expanding().max()
            drawdown = (cum_returns - peak) / peak
            max_drawdown = abs(drawdown.min())
            
            total_trades = (signals.diff().abs() > 0).sum()
            win_rate = (strategy_returns > 0).sum() / len(strategy_returns) if len(strategy_returns) > 0 else 0
        
        # ========================================
        # Step 7: ç”Ÿæˆå›æµ‹æŠ¥å‘Š
        # ========================================
        logger.info("Step 7/7: ç”Ÿæˆå›æµ‹æŠ¥å‘Š")
        
        report_content = _generate_backtest_report(
            start_date=start_date,
            end_date=end_date,
            strategy_name=strategy.name,
            total_return=total_return,
            annual_return=annual_return,
            sharpe_ratio=sharpe_ratio,
            max_drawdown=max_drawdown,
            initial_capital=initial_capital,
            num_stocks=len(close_df.columns),
        )
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = REPORTS_PATH / f"backtest_{start_date}_{end_date}.html"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logger.info(f"å›æµ‹æŠ¥å‘Šå·²ä¿å­˜è‡³ {report_path}")
        
        # ========================================
        # æ‰“å°å›æµ‹ç»“æœæ‘˜è¦
        # ========================================
        logger.info("=" * 60)
        logger.info("å›æµ‹ç»“æœæ‘˜è¦")
        logger.info("=" * 60)
        logger.info(f"å›æµ‹å¼•æ“:    BacktestEngine (æƒé‡é©±åŠ¨ + å¤§ç›˜é£æ§)")
        logger.info(f"ç­–ç•¥åç§°:    {strategy.name}")
        logger.info(f"å›æµ‹åŒºé—´:    {start_date} ~ {end_date}")
        logger.info(f"è‚¡ç¥¨æ± :      {stock_pool} ({len(close_df.columns)} åªè‚¡ç¥¨)")
        logger.info(f"è´¢åŠ¡æ•°æ®:    {'âœ“ å·²åŠ è½½ (small_cap å› å­å¯ç”¨)' if has_financial_data else 'âœ— æœªåŠ è½½ (çº¯åŠ¨é‡ç­–ç•¥)'}")
        logger.info(f"åŸºå‡†æŒ‡æ•°:    {benchmark_code} {'âœ“ å·²å¯ç”¨é£æ§' if benchmark_data is not None else 'âœ— é£æ§æœªå¯ç”¨'}")
        logger.info("-" * 60)
        logger.info(f"åˆå§‹èµ„é‡‘:    Â¥{initial_capital:,.0f}")
        logger.info(f"æ€»æ”¶ç›Šç‡:    {total_return:.2%}")
        logger.info(f"å¹´åŒ–æ”¶ç›Š:    {annual_return:.2%}")
        logger.info(f"å¤æ™®æ¯”ç‡:    {sharpe_ratio:.2f}")
        logger.info(f"æœ€å¤§å›æ’¤:    {max_drawdown:.2%}")
        if strategy_type == "multi_factor":
            logger.info(f"æ€»äº¤æ˜“æ¬¡æ•°:  {total_trades}")
            logger.info(f"èƒœç‡:        {win_rate:.2%}")
        logger.info("=" * 60)
        
        return True
        
    except Exception as e:
        logger.error(f"å›æµ‹å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False


def _generate_backtest_report(
    start_date: str,
    end_date: str,
    strategy_name: str,
    total_return: float,
    annual_return: float,
    sharpe_ratio: float,
    max_drawdown: float,
    initial_capital: float,
    num_stocks: int,
) -> str:
    """
    ç”Ÿæˆå›æµ‹æŠ¥å‘Š HTML
    
    Parameters
    ----------
    start_date : str
        å¼€å§‹æ—¥æœŸ
    end_date : str
        ç»“æŸæ—¥æœŸ
    strategy_name : str
        ç­–ç•¥åç§°
    total_return : float
        æ€»æ”¶ç›Šç‡
    annual_return : float
        å¹´åŒ–æ”¶ç›Šç‡
    sharpe_ratio : float
        å¤æ™®æ¯”ç‡
    max_drawdown : float
        æœ€å¤§å›æ’¤
    initial_capital : float
        åˆå§‹èµ„é‡‘
    num_stocks : int
        è‚¡ç¥¨æ•°é‡
    
    Returns
    -------
    str
        HTML æŠ¥å‘Šå†…å®¹
    """
    final_capital = initial_capital * (1 + total_return)
    profit = final_capital - initial_capital
    
    # è¯„çº§
    if sharpe_ratio >= 2.0:
        rating = "â­â­â­â­â­ ä¼˜ç§€"
        rating_color = "#00ff88"
    elif sharpe_ratio >= 1.5:
        rating = "â­â­â­â­ è‰¯å¥½"
        rating_color = "#88ff00"
    elif sharpe_ratio >= 1.0:
        rating = "â­â­â­ ä¸€èˆ¬"
        rating_color = "#ffff00"
    elif sharpe_ratio >= 0.5:
        rating = "â­â­ è¾ƒå·®"
        rating_color = "#ff8800"
    else:
        rating = "â­ å·®"
        rating_color = "#ff4444"
    
    html = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>å›æµ‹æŠ¥å‘Š - {strategy_name}</title>
    <style>
        * {{
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            background: linear-gradient(135deg, #0f0f23 0%, #1a1a3e 50%, #0f0f23 100%);
            color: #eee;
            min-height: 100vh;
            padding: 2rem;
        }}
        .container {{
            max-width: 1100px;
            margin: 0 auto;
        }}
        h1 {{
            font-size: 2.5rem;
            margin-bottom: 0.5rem;
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }}
        .meta {{
            color: #888;
            margin-bottom: 2rem;
            font-size: 1.1rem;
        }}
        .rating {{
            display: inline-block;
            padding: 0.5rem 1rem;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 20px;
            color: {rating_color};
            font-weight: bold;
            margin-left: 1rem;
        }}
        .card {{
            background: rgba(255, 255, 255, 0.05);
            border-radius: 16px;
            padding: 2rem;
            margin-bottom: 1.5rem;
            border: 1px solid rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
        }}
        .card h2 {{
            font-size: 1.4rem;
            margin-bottom: 1.5rem;
            color: #667eea;
        }}
        .stats-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 1.5rem;
        }}
        .stat {{
            text-align: center;
            padding: 1.5rem;
            background: linear-gradient(135deg, rgba(102, 126, 234, 0.2), rgba(118, 75, 162, 0.2));
            border-radius: 12px;
            border: 1px solid rgba(102, 126, 234, 0.3);
        }}
        .stat-value {{
            font-size: 2rem;
            font-weight: bold;
            margin-bottom: 0.5rem;
        }}
        .stat-value.positive {{
            color: #00ff88;
        }}
        .stat-value.negative {{
            color: #ff6b6b;
        }}
        .stat-value.neutral {{
            color: #667eea;
        }}
        .stat-label {{
            font-size: 0.9rem;
            color: #888;
        }}
        .info-table {{
            width: 100%;
            border-collapse: collapse;
        }}
        .info-table tr {{
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }}
        .info-table td {{
            padding: 1rem;
        }}
        .info-table td:first-child {{
            color: #888;
            width: 40%;
        }}
        .info-table td:last-child {{
            font-weight: 500;
        }}
        .footer {{
            text-align: center;
            color: #666;
            margin-top: 3rem;
            font-size: 0.9rem;
        }}
        .highlight {{
            background: linear-gradient(90deg, #667eea, #764ba2);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            font-weight: bold;
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ“ˆ ç­–ç•¥å›æµ‹æŠ¥å‘Š</h1>
        <p class="meta">
            {strategy_name}
            <span class="rating">{rating}</span>
        </p>
        
        <div class="card">
            <h2>æ ¸å¿ƒæŒ‡æ ‡</h2>
            <div class="stats-grid">
                <div class="stat">
                    <div class="stat-value {'positive' if total_return >= 0 else 'negative'}">{total_return:+.2%}</div>
                    <div class="stat-label">æ€»æ”¶ç›Šç‡</div>
                </div>
                <div class="stat">
                    <div class="stat-value {'positive' if annual_return >= 0 else 'negative'}">{annual_return:+.2%}</div>
                    <div class="stat-label">å¹´åŒ–æ”¶ç›Š</div>
                </div>
                <div class="stat">
                    <div class="stat-value neutral">{sharpe_ratio:.2f}</div>
                    <div class="stat-label">å¤æ™®æ¯”ç‡</div>
                </div>
                <div class="stat">
                    <div class="stat-value negative">{max_drawdown:.2%}</div>
                    <div class="stat-label">æœ€å¤§å›æ’¤</div>
                </div>
            </div>
        </div>
        
        <div class="card">
            <h2>èµ„é‡‘å˜åŒ–</h2>
            <div class="stats-grid">
                <div class="stat">
                    <div class="stat-value neutral">Â¥{initial_capital:,.0f}</div>
                    <div class="stat-label">åˆå§‹èµ„é‡‘</div>
                </div>
                <div class="stat">
                    <div class="stat-value {'positive' if profit >= 0 else 'negative'}">Â¥{final_capital:,.0f}</div>
                    <div class="stat-label">æœ€ç»ˆèµ„é‡‘</div>
                </div>
                <div class="stat">
                    <div class="stat-value {'positive' if profit >= 0 else 'negative'}">{'+'if profit >= 0 else ''}Â¥{profit:,.0f}</div>
                    <div class="stat-label">ç›ˆäºé‡‘é¢</div>
                </div>
            </div>
        </div>
        
        <div class="card">
            <h2>å›æµ‹ä¿¡æ¯</h2>
            <table class="info-table">
                <tr>
                    <td>ç­–ç•¥åç§°</td>
                    <td>{strategy_name}</td>
                </tr>
                <tr>
                    <td>å›æµ‹åŒºé—´</td>
                    <td>{start_date} ~ {end_date}</td>
                </tr>
                <tr>
                    <td>è‚¡ç¥¨æ•°é‡</td>
                    <td>{num_stocks} åª</td>
                </tr>
                <tr>
                    <td>æŠ¥å‘Šç”Ÿæˆæ—¶é—´</td>
                    <td>{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</td>
                </tr>
            </table>
        </div>
        
        <p class="footer">
            æœ¬æŠ¥å‘Šç”± <span class="highlight">Aè‚¡é‡åŒ–äº¤æ˜“ç³»ç»Ÿ</span> è‡ªåŠ¨ç”Ÿæˆ<br>
            ä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®
        </p>
    </div>
</body>
</html>
    """
    
    return html


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="Aè‚¡é‡åŒ–äº¤æ˜“ç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
    python main.py --daily-update              # è¿è¡Œæ¯æ—¥æ›´æ–°
    python main.py --daily-update --force      # å¼ºåˆ¶è°ƒä»“
    python main.py --backtest                  # è¿è¡Œå›æµ‹ï¼ˆé»˜è®¤å¤šå› å­ç­–ç•¥ï¼‰
    python main.py --backtest --strategy ma    # è¿è¡Œå›æµ‹ï¼ˆå‡çº¿ç­–ç•¥ï¼‰
    python main.py --backtest --start 2022-01-01 --end 2023-12-31
        """
    )
    
    parser.add_argument(
        "--daily-update", "-d",
        action="store_true",
        help="è¿è¡Œæ¯æ—¥æ›´æ–°æµç¨‹"
    )
    
    parser.add_argument(
        "--force-rebalance", "-f",
        action="store_true",
        help="å¼ºåˆ¶è°ƒä»“ï¼ˆå¿½ç•¥æ—¥æœŸæ£€æŸ¥ï¼‰"
    )
    
    parser.add_argument(
        "--backtest", "-b",
        action="store_true",
        help="è¿è¡Œå›æµ‹"
    )
    
    parser.add_argument(
        "--strategy", "-s",
        type=str,
        default="multi_factor",
        choices=["multi_factor", "ma_cross"],
        help="å›æµ‹ç­–ç•¥ç±»å‹: multi_factor(å¤šå› å­), ma_cross(å‡çº¿äº¤å‰)"
    )
    
    parser.add_argument(
        "--start",
        type=str,
        default="2023-01-01",
        help="å›æµ‹å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)"
    )
    
    parser.add_argument(
        "--end",
        type=str,
        default="2024-01-01",
        help="å›æµ‹ç»“æŸæ—¥æœŸ (YYYY-MM-DD)"
    )
    
    parser.add_argument(
        "--log-level",
        type=str,
        default="INFO",
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        help="æ—¥å¿—çº§åˆ«"
    )
    
    parser.add_argument(
        "--no-llm",
        action="store_true",
        help="ç¦ç”¨ LLM é£æ§åŠŸèƒ½ï¼ˆå¼ºåˆ¶è¦†ç›–é…ç½®ï¼‰"
    )
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    log_level = getattr(logging, args.log_level)
    log_file = LOGS_PATH / f"quant_{datetime.now().strftime('%Y%m%d')}.log"
    setup_logging(level=log_level, log_file=str(log_file))
    
    logger = logging.getLogger(__name__)
    logger.info("Aè‚¡é‡åŒ–äº¤æ˜“ç³»ç»Ÿå¯åŠ¨")
    
    if args.daily_update:
        success = run_daily_update(
            force_rebalance=args.force_rebalance,
            no_llm=args.no_llm
        )
        exit(0 if success else 1)
    
    elif args.backtest:
        logger.info(f"å›æµ‹æ¨¡å¼: {args.start} ~ {args.end}, ç­–ç•¥: {args.strategy}")
        success = run_backtest(
            start_date=args.start,
            end_date=args.end,
            strategy_type=args.strategy,
            no_llm=args.no_llm
        )
        exit(0 if success else 1)
    
    else:
        parser.print_help()
        exit(0)


if __name__ == "__main__":
    main()

